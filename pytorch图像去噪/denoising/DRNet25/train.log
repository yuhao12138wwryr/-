25-05-12 08:25:39.740 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/100_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 15
      sigma_test: 15
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 15
      sigma_test: 15
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 10000
    checkpoint_save: 10000
    checkpoint_print: 10000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-12 08:25:39.740 : Random seed: 1738
25-05-12 08:25:39.883 : Number of train images: 31,005, iters: 31,005
25-05-12 08:25:42.003 : 
Networks name: DRNet
Params number: 99683721
Net structure:
DRNet(
  (prelu): PReLU(num_parameters=1)
  (conv_first): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (proj): Conv2d(96, 96, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(64, 64), depth=8
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(64, 64), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(32, 32), depth=8
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(32, 32), dim=192
        (reduction): Linear(in_features=768, out_features=384, bias=False)
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=384, input_resolution=(16, 16), depth=8
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(16, 16), dim=384
        (reduction): Linear(in_features=1536, out_features=768, bias=False)
        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=768, input_resolution=(8, 8), depth=8
      (blocks): ModuleList(
        (0-7): 8 x SwinTransformerBlock(
          dim=768, input_resolution=(8, 8), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=768, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (layers_up): ModuleList(
    (0): UpSample(
      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (up_p): Sequential(
        (0): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): PReLU(num_parameters=1)
        (2): PixelShuffle(upscale_factor=2)
        (3): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (up_b): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Upsample(scale_factor=2.0, mode='bilinear')
        (3): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
    )
    (1): BasicLayer_up(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=384, input_resolution=(16, 16), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (upsample): UpSample(
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (up_p): Sequential(
          (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): PReLU(num_parameters=1)
          (2): PixelShuffle(upscale_factor=2)
          (3): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (up_b): Sequential(
          (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
          (1): PReLU(num_parameters=1)
          (2): Upsample(scale_factor=2.0, mode='bilinear')
          (3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (2): BasicLayer_up(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (upsample): UpSample(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (up_p): Sequential(
          (0): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): PReLU(num_parameters=1)
          (2): PixelShuffle(upscale_factor=2)
          (3): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (up_b): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): PReLU(num_parameters=1)
          (2): Upsample(scale_factor=2.0, mode='bilinear')
          (3): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (3): BasicLayer_up(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=96, input_resolution=(64, 64), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(8, 8), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (concat_back_dim): ModuleList(
    (0): Identity()
    (1): Linear(in_features=768, out_features=384, bias=True)
    (2): Linear(in_features=384, out_features=192, bias=True)
    (3): Linear(in_features=192, out_features=96, bias=True)
  )
  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (norm_up): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  (up): UpSample(
    (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (up_p): Sequential(
      (0): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): PReLU(num_parameters=1)
      (2): PixelShuffle(upscale_factor=4)
      (3): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (up_b): Sequential(
      (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Upsample(scale_factor=4.0, mode='bilinear')
      (3): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (output): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
)

25-05-12 08:25:44.254 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || prelu.weight
 |  0.000 | -0.271 |  0.306 |  0.118 | torch.Size([96, 3, 3, 3]) || conv_first.weight
 | -0.004 | -0.254 |  0.242 |  0.136 | torch.Size([96]) || conv_first.bias
 |  0.000 | -0.458 |  0.415 |  0.053 | torch.Size([96, 96, 4, 4]) || patch_embed.proj.weight
 | -0.002 | -0.129 |  0.135 |  0.062 | torch.Size([96]) || patch_embed.proj.bias
 |  1.090 |  0.965 |  1.279 |  0.077 | torch.Size([96]) || patch_embed.norm.weight
 | -0.000 | -0.051 |  0.071 |  0.028 | torch.Size([96]) || patch_embed.norm.bias
 |  0.927 |  0.766 |  1.134 |  0.091 | torch.Size([96]) || layers.0.blocks.0.norm1.weight
 | -0.002 | -0.253 |  0.182 |  0.096 | torch.Size([96]) || layers.0.blocks.0.norm1.bias
 | -0.009 | -0.258 |  0.610 |  0.069 | torch.Size([225, 8]) || layers.0.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.blocks.0.attn.relative_position_index
 |  0.000 | -0.293 |  0.258 |  0.042 | torch.Size([288, 96]) || layers.0.blocks.0.attn.qkv.weight
 | -0.000 | -0.066 |  0.054 |  0.017 | torch.Size([288]) || layers.0.blocks.0.attn.qkv.bias
 |  0.000 | -0.148 |  0.150 |  0.034 | torch.Size([96, 96]) || layers.0.blocks.0.attn.proj.weight
 | -0.002 | -0.177 |  0.146 |  0.066 | torch.Size([96]) || layers.0.blocks.0.attn.proj.bias
 |  1.036 |  0.861 |  1.273 |  0.117 | torch.Size([96]) || layers.0.blocks.0.norm2.weight
 | -0.004 | -0.150 |  0.140 |  0.077 | torch.Size([96]) || layers.0.blocks.0.norm2.bias
 | -0.001 | -0.441 |  0.399 |  0.057 | torch.Size([384, 96]) || layers.0.blocks.0.mlp.fc1.weight
 |  0.001 | -0.052 |  0.052 |  0.025 | torch.Size([384]) || layers.0.blocks.0.mlp.fc1.bias
 | -0.000 | -0.346 |  0.326 |  0.054 | torch.Size([96, 384]) || layers.0.blocks.0.mlp.fc2.weight
 | -0.001 | -0.069 |  0.057 |  0.027 | torch.Size([96]) || layers.0.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.blocks.1.attn_mask
 |  0.919 |  0.748 |  1.114 |  0.059 | torch.Size([96]) || layers.0.blocks.1.norm1.weight
 | -0.005 | -0.169 |  0.175 |  0.069 | torch.Size([96]) || layers.0.blocks.1.norm1.bias
 | -0.007 | -0.232 |  0.342 |  0.074 | torch.Size([225, 8]) || layers.0.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.blocks.1.attn.relative_position_index
 |  0.000 | -0.181 |  0.201 |  0.032 | torch.Size([288, 96]) || layers.0.blocks.1.attn.qkv.weight
 |  0.001 | -0.073 |  0.071 |  0.021 | torch.Size([288]) || layers.0.blocks.1.attn.qkv.bias
 | -0.000 | -0.165 |  0.146 |  0.034 | torch.Size([96, 96]) || layers.0.blocks.1.attn.proj.weight
 | -0.002 | -0.059 |  0.055 |  0.026 | torch.Size([96]) || layers.0.blocks.1.attn.proj.bias
 |  1.037 |  0.878 |  1.230 |  0.074 | torch.Size([96]) || layers.0.blocks.1.norm2.weight
 | -0.002 | -0.093 |  0.082 |  0.032 | torch.Size([96]) || layers.0.blocks.1.norm2.bias
 | -0.001 | -0.308 |  0.443 |  0.047 | torch.Size([384, 96]) || layers.0.blocks.1.mlp.fc1.weight
 | -0.017 | -0.096 |  0.036 |  0.025 | torch.Size([384]) || layers.0.blocks.1.mlp.fc1.bias
 | -0.001 | -0.297 |  0.262 |  0.036 | torch.Size([96, 384]) || layers.0.blocks.1.mlp.fc2.weight
 |  0.001 | -0.075 |  0.071 |  0.032 | torch.Size([96]) || layers.0.blocks.1.mlp.fc2.bias
 |  0.951 |  0.829 |  1.065 |  0.053 | torch.Size([96]) || layers.0.blocks.2.norm1.weight
 | -0.004 | -0.201 |  0.220 |  0.070 | torch.Size([96]) || layers.0.blocks.2.norm1.bias
 | -0.012 | -0.236 |  0.765 |  0.109 | torch.Size([225, 8]) || layers.0.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.blocks.2.attn.relative_position_index
 | -0.000 | -0.170 |  0.165 |  0.037 | torch.Size([288, 96]) || layers.0.blocks.2.attn.qkv.weight
 | -0.000 | -0.054 |  0.050 |  0.015 | torch.Size([288]) || layers.0.blocks.2.attn.qkv.bias
 | -0.000 | -0.156 |  0.180 |  0.038 | torch.Size([96, 96]) || layers.0.blocks.2.attn.proj.weight
 |  0.000 | -0.061 |  0.065 |  0.026 | torch.Size([96]) || layers.0.blocks.2.attn.proj.bias
 |  1.047 |  0.929 |  1.192 |  0.055 | torch.Size([96]) || layers.0.blocks.2.norm2.weight
 | -0.000 | -0.068 |  0.052 |  0.026 | torch.Size([96]) || layers.0.blocks.2.norm2.bias
 | -0.001 | -0.276 |  0.214 |  0.045 | torch.Size([384, 96]) || layers.0.blocks.2.mlp.fc1.weight
 | -0.017 | -0.095 |  0.042 |  0.025 | torch.Size([384]) || layers.0.blocks.2.mlp.fc1.bias
 | -0.000 | -0.180 |  0.163 |  0.034 | torch.Size([96, 384]) || layers.0.blocks.2.mlp.fc2.weight
 |  0.001 | -0.065 |  0.076 |  0.027 | torch.Size([96]) || layers.0.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.blocks.3.attn_mask
 |  0.992 |  0.873 |  1.119 |  0.042 | torch.Size([96]) || layers.0.blocks.3.norm1.weight
 | -0.006 | -0.147 |  0.145 |  0.053 | torch.Size([96]) || layers.0.blocks.3.norm1.bias
 | -0.024 | -0.611 |  0.758 |  0.122 | torch.Size([225, 8]) || layers.0.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.blocks.3.attn.relative_position_index
 | -0.000 | -0.187 |  0.157 |  0.040 | torch.Size([288, 96]) || layers.0.blocks.3.attn.qkv.weight
 | -0.001 | -0.077 |  0.060 |  0.019 | torch.Size([288]) || layers.0.blocks.3.attn.qkv.bias
 |  0.000 | -0.164 |  0.156 |  0.042 | torch.Size([96, 96]) || layers.0.blocks.3.attn.proj.weight
 |  0.001 | -0.079 |  0.070 |  0.030 | torch.Size([96]) || layers.0.blocks.3.attn.proj.bias
 |  1.043 |  0.841 |  1.181 |  0.054 | torch.Size([96]) || layers.0.blocks.3.norm2.weight
 | -0.002 | -0.060 |  0.073 |  0.026 | torch.Size([96]) || layers.0.blocks.3.norm2.bias
 | -0.001 | -0.352 |  0.238 |  0.042 | torch.Size([384, 96]) || layers.0.blocks.3.mlp.fc1.weight
 | -0.018 | -0.085 |  0.038 |  0.022 | torch.Size([384]) || layers.0.blocks.3.mlp.fc1.bias
 | -0.000 | -0.159 |  0.165 |  0.031 | torch.Size([96, 384]) || layers.0.blocks.3.mlp.fc2.weight
 |  0.000 | -0.056 |  0.079 |  0.026 | torch.Size([96]) || layers.0.blocks.3.mlp.fc2.bias
 |  0.976 |  0.852 |  1.086 |  0.045 | torch.Size([96]) || layers.0.blocks.4.norm1.weight
 | -0.005 | -0.098 |  0.173 |  0.038 | torch.Size([96]) || layers.0.blocks.4.norm1.bias
 | -0.008 | -0.376 |  0.435 |  0.093 | torch.Size([225, 8]) || layers.0.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.blocks.4.attn.relative_position_index
 |  0.000 | -0.201 |  0.171 |  0.038 | torch.Size([288, 96]) || layers.0.blocks.4.attn.qkv.weight
 | -0.000 | -0.059 |  0.064 |  0.018 | torch.Size([288]) || layers.0.blocks.4.attn.qkv.bias
 |  0.000 | -0.180 |  0.167 |  0.037 | torch.Size([96, 96]) || layers.0.blocks.4.attn.proj.weight
 |  0.000 | -0.046 |  0.042 |  0.019 | torch.Size([96]) || layers.0.blocks.4.attn.proj.bias
 |  1.023 |  0.878 |  1.146 |  0.051 | torch.Size([96]) || layers.0.blocks.4.norm2.weight
 | -0.002 | -0.042 |  0.059 |  0.021 | torch.Size([96]) || layers.0.blocks.4.norm2.bias
 | -0.001 | -0.214 |  0.196 |  0.037 | torch.Size([384, 96]) || layers.0.blocks.4.mlp.fc1.weight
 | -0.011 | -0.094 |  0.042 |  0.019 | torch.Size([384]) || layers.0.blocks.4.mlp.fc1.bias
 | -0.000 | -0.140 |  0.132 |  0.029 | torch.Size([96, 384]) || layers.0.blocks.4.mlp.fc2.weight
 |  0.000 | -0.045 |  0.061 |  0.022 | torch.Size([96]) || layers.0.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.blocks.5.attn_mask
 |  0.985 |  0.801 |  1.084 |  0.051 | torch.Size([96]) || layers.0.blocks.5.norm1.weight
 | -0.004 | -0.166 |  0.161 |  0.041 | torch.Size([96]) || layers.0.blocks.5.norm1.bias
 | -0.009 | -0.383 |  0.635 |  0.084 | torch.Size([225, 8]) || layers.0.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.blocks.5.attn.relative_position_index
 |  0.000 | -0.199 |  0.156 |  0.039 | torch.Size([288, 96]) || layers.0.blocks.5.attn.qkv.weight
 | -0.002 | -0.056 |  0.065 |  0.016 | torch.Size([288]) || layers.0.blocks.5.attn.qkv.bias
 | -0.000 | -0.143 |  0.149 |  0.038 | torch.Size([96, 96]) || layers.0.blocks.5.attn.proj.weight
 |  0.001 | -0.055 |  0.041 |  0.020 | torch.Size([96]) || layers.0.blocks.5.attn.proj.bias
 |  0.997 |  0.827 |  1.102 |  0.048 | torch.Size([96]) || layers.0.blocks.5.norm2.weight
 | -0.004 | -0.069 |  0.083 |  0.022 | torch.Size([96]) || layers.0.blocks.5.norm2.bias
 | -0.001 | -0.217 |  0.176 |  0.034 | torch.Size([384, 96]) || layers.0.blocks.5.mlp.fc1.weight
 | -0.008 | -0.066 |  0.037 |  0.017 | torch.Size([384]) || layers.0.blocks.5.mlp.fc1.bias
 | -0.000 | -0.154 |  0.122 |  0.027 | torch.Size([96, 384]) || layers.0.blocks.5.mlp.fc2.weight
 |  0.000 | -0.048 |  0.050 |  0.021 | torch.Size([96]) || layers.0.blocks.5.mlp.fc2.bias
 |  0.977 |  0.759 |  1.063 |  0.051 | torch.Size([96]) || layers.0.blocks.6.norm1.weight
 | -0.006 | -0.126 |  0.209 |  0.041 | torch.Size([96]) || layers.0.blocks.6.norm1.bias
 | -0.006 | -0.499 |  0.534 |  0.107 | torch.Size([225, 8]) || layers.0.blocks.6.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.blocks.6.attn.relative_position_index
 |  0.000 | -0.177 |  0.166 |  0.040 | torch.Size([288, 96]) || layers.0.blocks.6.attn.qkv.weight
 | -0.000 | -0.061 |  0.072 |  0.018 | torch.Size([288]) || layers.0.blocks.6.attn.qkv.bias
 | -0.000 | -0.152 |  0.173 |  0.037 | torch.Size([96, 96]) || layers.0.blocks.6.attn.proj.weight
 |  0.000 | -0.041 |  0.048 |  0.015 | torch.Size([96]) || layers.0.blocks.6.attn.proj.bias
 |  0.975 |  0.860 |  1.100 |  0.045 | torch.Size([96]) || layers.0.blocks.6.norm2.weight
 | -0.005 | -0.086 |  0.099 |  0.027 | torch.Size([96]) || layers.0.blocks.6.norm2.bias
 | -0.001 | -0.185 |  0.199 |  0.030 | torch.Size([384, 96]) || layers.0.blocks.6.mlp.fc1.weight
 | -0.004 | -0.051 |  0.044 |  0.016 | torch.Size([384]) || layers.0.blocks.6.mlp.fc1.bias
 |  0.000 | -0.136 |  0.116 |  0.025 | torch.Size([96, 384]) || layers.0.blocks.6.mlp.fc2.weight
 | -0.000 | -0.041 |  0.052 |  0.018 | torch.Size([96]) || layers.0.blocks.6.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.blocks.7.attn_mask
 |  0.971 |  0.786 |  1.058 |  0.047 | torch.Size([96]) || layers.0.blocks.7.norm1.weight
 | -0.008 | -0.130 |  0.198 |  0.038 | torch.Size([96]) || layers.0.blocks.7.norm1.bias
 | -0.005 | -0.378 |  0.341 |  0.060 | torch.Size([225, 8]) || layers.0.blocks.7.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.blocks.7.attn.relative_position_index
 |  0.000 | -0.135 |  0.178 |  0.037 | torch.Size([288, 96]) || layers.0.blocks.7.attn.qkv.weight
 | -0.000 | -0.060 |  0.063 |  0.017 | torch.Size([288]) || layers.0.blocks.7.attn.qkv.bias
 |  0.000 | -0.156 |  0.124 |  0.033 | torch.Size([96, 96]) || layers.0.blocks.7.attn.proj.weight
 | -0.000 | -0.035 |  0.043 |  0.015 | torch.Size([96]) || layers.0.blocks.7.attn.proj.bias
 |  0.989 |  0.870 |  1.098 |  0.045 | torch.Size([96]) || layers.0.blocks.7.norm2.weight
 | -0.002 | -0.095 |  0.117 |  0.037 | torch.Size([96]) || layers.0.blocks.7.norm2.bias
 | -0.001 | -0.251 |  0.168 |  0.031 | torch.Size([384, 96]) || layers.0.blocks.7.mlp.fc1.weight
 | -0.010 | -0.064 |  0.036 |  0.020 | torch.Size([384]) || layers.0.blocks.7.mlp.fc1.bias
 |  0.000 | -0.134 |  0.149 |  0.026 | torch.Size([96, 384]) || layers.0.blocks.7.mlp.fc2.weight
 | -0.001 | -0.047 |  0.049 |  0.016 | torch.Size([96]) || layers.0.blocks.7.mlp.fc2.bias
 |  0.000 | -0.215 |  0.212 |  0.043 | torch.Size([192, 384]) || layers.0.downsample.reduction.weight
 |  0.984 |  0.813 |  1.104 |  0.035 | torch.Size([384]) || layers.0.downsample.norm.weight
 | -0.010 | -0.178 |  0.146 |  0.037 | torch.Size([384]) || layers.0.downsample.norm.bias
 |  0.970 |  0.914 |  1.017 |  0.017 | torch.Size([192]) || layers.1.blocks.0.norm1.weight
 | -0.001 | -0.044 |  0.040 |  0.016 | torch.Size([192]) || layers.1.blocks.0.norm1.bias
 | -0.000 | -0.111 |  0.106 |  0.020 | torch.Size([225, 8]) || layers.1.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.blocks.0.attn.relative_position_index
 |  0.000 | -0.114 |  0.097 |  0.023 | torch.Size([576, 192]) || layers.1.blocks.0.attn.qkv.weight
 |  0.000 | -0.030 |  0.038 |  0.009 | torch.Size([576]) || layers.1.blocks.0.attn.qkv.bias
 | -0.000 | -0.100 |  0.097 |  0.023 | torch.Size([192, 192]) || layers.1.blocks.0.attn.proj.weight
 |  0.000 | -0.037 |  0.036 |  0.013 | torch.Size([192]) || layers.1.blocks.0.attn.proj.bias
 |  1.014 |  0.981 |  1.061 |  0.013 | torch.Size([192]) || layers.1.blocks.0.norm2.weight
 |  0.001 | -0.025 |  0.037 |  0.013 | torch.Size([192]) || layers.1.blocks.0.norm2.bias
 |  0.000 | -0.117 |  0.114 |  0.024 | torch.Size([768, 192]) || layers.1.blocks.0.mlp.fc1.weight
 | -0.007 | -0.029 |  0.012 |  0.007 | torch.Size([768]) || layers.1.blocks.0.mlp.fc1.bias
 | -0.000 | -0.107 |  0.106 |  0.022 | torch.Size([192, 768]) || layers.1.blocks.0.mlp.fc2.weight
 | -0.000 | -0.042 |  0.038 |  0.015 | torch.Size([192]) || layers.1.blocks.0.mlp.fc2.bias
 | -23.438 | -100.000 |  0.000 | 42.361 | torch.Size([16, 64, 64]) || layers.1.blocks.1.attn_mask
 |  0.988 |  0.946 |  1.018 |  0.013 | torch.Size([192]) || layers.1.blocks.1.norm1.weight
 |  0.001 | -0.022 |  0.037 |  0.010 | torch.Size([192]) || layers.1.blocks.1.norm1.bias
 |  0.000 | -0.068 |  0.070 |  0.020 | torch.Size([225, 8]) || layers.1.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.blocks.1.attn.relative_position_index
 | -0.000 | -0.096 |  0.097 |  0.022 | torch.Size([576, 192]) || layers.1.blocks.1.attn.qkv.weight
 |  0.000 | -0.032 |  0.029 |  0.008 | torch.Size([576]) || layers.1.blocks.1.attn.qkv.bias
 | -0.000 | -0.101 |  0.090 |  0.023 | torch.Size([192, 192]) || layers.1.blocks.1.attn.proj.weight
 | -0.000 | -0.037 |  0.046 |  0.014 | torch.Size([192]) || layers.1.blocks.1.attn.proj.bias
 |  1.006 |  0.982 |  1.040 |  0.011 | torch.Size([192]) || layers.1.blocks.1.norm2.weight
 |  0.001 | -0.023 |  0.024 |  0.008 | torch.Size([192]) || layers.1.blocks.1.norm2.bias
 | -0.000 | -0.111 |  0.108 |  0.022 | torch.Size([768, 192]) || layers.1.blocks.1.mlp.fc1.weight
 | -0.004 | -0.027 |  0.017 |  0.007 | torch.Size([768]) || layers.1.blocks.1.mlp.fc1.bias
 | -0.000 | -0.100 |  0.099 |  0.022 | torch.Size([192, 768]) || layers.1.blocks.1.mlp.fc2.weight
 | -0.000 | -0.048 |  0.044 |  0.017 | torch.Size([192]) || layers.1.blocks.1.mlp.fc2.bias
 |  0.992 |  0.953 |  1.024 |  0.011 | torch.Size([192]) || layers.1.blocks.2.norm1.weight
 |  0.000 | -0.037 |  0.039 |  0.012 | torch.Size([192]) || layers.1.blocks.2.norm1.bias
 |  0.000 | -0.069 |  0.073 |  0.021 | torch.Size([225, 8]) || layers.1.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.blocks.2.attn.relative_position_index
 |  0.000 | -0.103 |  0.104 |  0.022 | torch.Size([576, 192]) || layers.1.blocks.2.attn.qkv.weight
 | -0.000 | -0.024 |  0.030 |  0.008 | torch.Size([576]) || layers.1.blocks.2.attn.qkv.bias
 |  0.000 | -0.103 |  0.099 |  0.023 | torch.Size([192, 192]) || layers.1.blocks.2.attn.proj.weight
 | -0.000 | -0.039 |  0.036 |  0.014 | torch.Size([192]) || layers.1.blocks.2.attn.proj.bias
 |  0.997 |  0.973 |  1.021 |  0.008 | torch.Size([192]) || layers.1.blocks.2.norm2.weight
 |  0.000 | -0.017 |  0.019 |  0.007 | torch.Size([192]) || layers.1.blocks.2.norm2.bias
 |  0.000 | -0.098 |  0.097 |  0.022 | torch.Size([768, 192]) || layers.1.blocks.2.mlp.fc1.weight
 | -0.006 | -0.029 |  0.016 |  0.007 | torch.Size([768]) || layers.1.blocks.2.mlp.fc1.bias
 |  0.000 | -0.089 |  0.087 |  0.021 | torch.Size([192, 768]) || layers.1.blocks.2.mlp.fc2.weight
 | -0.000 | -0.046 |  0.041 |  0.017 | torch.Size([192]) || layers.1.blocks.2.mlp.fc2.bias
 | -23.438 | -100.000 |  0.000 | 42.361 | torch.Size([16, 64, 64]) || layers.1.blocks.3.attn_mask
 |  0.985 |  0.942 |  1.012 |  0.012 | torch.Size([192]) || layers.1.blocks.3.norm1.weight
 |  0.000 | -0.040 |  0.028 |  0.011 | torch.Size([192]) || layers.1.blocks.3.norm1.bias
 | -0.000 | -0.061 |  0.064 |  0.020 | torch.Size([225, 8]) || layers.1.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.blocks.3.attn.relative_position_index
 | -0.000 | -0.102 |  0.099 |  0.022 | torch.Size([576, 192]) || layers.1.blocks.3.attn.qkv.weight
 | -0.000 | -0.022 |  0.027 |  0.007 | torch.Size([576]) || layers.1.blocks.3.attn.qkv.bias
 | -0.000 | -0.094 |  0.119 |  0.024 | torch.Size([192, 192]) || layers.1.blocks.3.attn.proj.weight
 | -0.000 | -0.040 |  0.040 |  0.013 | torch.Size([192]) || layers.1.blocks.3.attn.proj.bias
 |  0.994 |  0.970 |  1.011 |  0.008 | torch.Size([192]) || layers.1.blocks.3.norm2.weight
 |  0.000 | -0.018 |  0.020 |  0.007 | torch.Size([192]) || layers.1.blocks.3.norm2.bias
 |  0.000 | -0.094 |  0.092 |  0.021 | torch.Size([768, 192]) || layers.1.blocks.3.mlp.fc1.weight
 | -0.006 | -0.025 |  0.018 |  0.007 | torch.Size([768]) || layers.1.blocks.3.mlp.fc1.bias
 | -0.000 | -0.091 |  0.096 |  0.021 | torch.Size([192, 768]) || layers.1.blocks.3.mlp.fc2.weight
 | -0.000 | -0.043 |  0.041 |  0.015 | torch.Size([192]) || layers.1.blocks.3.mlp.fc2.bias
 |  0.992 |  0.962 |  1.043 |  0.012 | torch.Size([192]) || layers.1.blocks.4.norm1.weight
 |  0.000 | -0.028 |  0.026 |  0.011 | torch.Size([192]) || layers.1.blocks.4.norm1.bias
 | -0.000 | -0.081 |  0.073 |  0.021 | torch.Size([225, 8]) || layers.1.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.blocks.4.attn.relative_position_index
 |  0.000 | -0.115 |  0.102 |  0.023 | torch.Size([576, 192]) || layers.1.blocks.4.attn.qkv.weight
 | -0.000 | -0.028 |  0.026 |  0.007 | torch.Size([576]) || layers.1.blocks.4.attn.qkv.bias
 |  0.000 | -0.097 |  0.104 |  0.024 | torch.Size([192, 192]) || layers.1.blocks.4.attn.proj.weight
 | -0.000 | -0.030 |  0.031 |  0.012 | torch.Size([192]) || layers.1.blocks.4.attn.proj.bias
 |  0.991 |  0.964 |  1.015 |  0.008 | torch.Size([192]) || layers.1.blocks.4.norm2.weight
 |  0.001 | -0.021 |  0.032 |  0.008 | torch.Size([192]) || layers.1.blocks.4.norm2.bias
 |  0.000 | -0.101 |  0.092 |  0.021 | torch.Size([768, 192]) || layers.1.blocks.4.mlp.fc1.weight
 | -0.007 | -0.031 |  0.014 |  0.007 | torch.Size([768]) || layers.1.blocks.4.mlp.fc1.bias
 | -0.000 | -0.092 |  0.096 |  0.021 | torch.Size([192, 768]) || layers.1.blocks.4.mlp.fc2.weight
 | -0.000 | -0.037 |  0.040 |  0.014 | torch.Size([192]) || layers.1.blocks.4.mlp.fc2.bias
 | -23.438 | -100.000 |  0.000 | 42.361 | torch.Size([16, 64, 64]) || layers.1.blocks.5.attn_mask
 |  0.988 |  0.953 |  1.021 |  0.013 | torch.Size([192]) || layers.1.blocks.5.norm1.weight
 | -0.000 | -0.029 |  0.036 |  0.011 | torch.Size([192]) || layers.1.blocks.5.norm1.bias
 |  0.000 | -0.056 |  0.098 |  0.020 | torch.Size([225, 8]) || layers.1.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.blocks.5.attn.relative_position_index
 | -0.000 | -0.108 |  0.098 |  0.023 | torch.Size([576, 192]) || layers.1.blocks.5.attn.qkv.weight
 |  0.000 | -0.032 |  0.030 |  0.008 | torch.Size([576]) || layers.1.blocks.5.attn.qkv.bias
 | -0.000 | -0.092 |  0.103 |  0.024 | torch.Size([192, 192]) || layers.1.blocks.5.attn.proj.weight
 | -0.001 | -0.032 |  0.032 |  0.012 | torch.Size([192]) || layers.1.blocks.5.attn.proj.bias
 |  0.990 |  0.966 |  1.009 |  0.008 | torch.Size([192]) || layers.1.blocks.5.norm2.weight
 |  0.001 | -0.015 |  0.016 |  0.006 | torch.Size([192]) || layers.1.blocks.5.norm2.bias
 | -0.000 | -0.094 |  0.090 |  0.021 | torch.Size([768, 192]) || layers.1.blocks.5.mlp.fc1.weight
 | -0.007 | -0.028 |  0.014 |  0.007 | torch.Size([768]) || layers.1.blocks.5.mlp.fc1.bias
 | -0.000 | -0.092 |  0.093 |  0.021 | torch.Size([192, 768]) || layers.1.blocks.5.mlp.fc2.weight
 | -0.000 | -0.032 |  0.042 |  0.013 | torch.Size([192]) || layers.1.blocks.5.mlp.fc2.bias
 |  0.989 |  0.959 |  1.018 |  0.012 | torch.Size([192]) || layers.1.blocks.6.norm1.weight
 | -0.000 | -0.026 |  0.023 |  0.009 | torch.Size([192]) || layers.1.blocks.6.norm1.bias
 | -0.000 | -0.148 |  0.098 |  0.021 | torch.Size([225, 8]) || layers.1.blocks.6.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.blocks.6.attn.relative_position_index
 | -0.000 | -0.104 |  0.098 |  0.023 | torch.Size([576, 192]) || layers.1.blocks.6.attn.qkv.weight
 |  0.000 | -0.031 |  0.025 |  0.007 | torch.Size([576]) || layers.1.blocks.6.attn.qkv.bias
 |  0.000 | -0.095 |  0.109 |  0.024 | torch.Size([192, 192]) || layers.1.blocks.6.attn.proj.weight
 | -0.000 | -0.026 |  0.027 |  0.012 | torch.Size([192]) || layers.1.blocks.6.attn.proj.bias
 |  0.991 |  0.972 |  1.007 |  0.007 | torch.Size([192]) || layers.1.blocks.6.norm2.weight
 | -0.001 | -0.018 |  0.018 |  0.007 | torch.Size([192]) || layers.1.blocks.6.norm2.bias
 |  0.000 | -0.090 |  0.106 |  0.021 | torch.Size([768, 192]) || layers.1.blocks.6.mlp.fc1.weight
 | -0.006 | -0.029 |  0.015 |  0.007 | torch.Size([768]) || layers.1.blocks.6.mlp.fc1.bias
 | -0.000 | -0.095 |  0.095 |  0.021 | torch.Size([192, 768]) || layers.1.blocks.6.mlp.fc2.weight
 | -0.000 | -0.032 |  0.043 |  0.013 | torch.Size([192]) || layers.1.blocks.6.mlp.fc2.bias
 | -23.438 | -100.000 |  0.000 | 42.361 | torch.Size([16, 64, 64]) || layers.1.blocks.7.attn_mask
 |  0.988 |  0.955 |  1.028 |  0.012 | torch.Size([192]) || layers.1.blocks.7.norm1.weight
 |  0.000 | -0.023 |  0.024 |  0.009 | torch.Size([192]) || layers.1.blocks.7.norm1.bias
 |  0.000 | -0.107 |  0.120 |  0.022 | torch.Size([225, 8]) || layers.1.blocks.7.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.blocks.7.attn.relative_position_index
 |  0.000 | -0.102 |  0.100 |  0.023 | torch.Size([576, 192]) || layers.1.blocks.7.attn.qkv.weight
 |  0.000 | -0.033 |  0.022 |  0.007 | torch.Size([576]) || layers.1.blocks.7.attn.qkv.bias
 |  0.000 | -0.113 |  0.100 |  0.024 | torch.Size([192, 192]) || layers.1.blocks.7.attn.proj.weight
 | -0.000 | -0.024 |  0.036 |  0.011 | torch.Size([192]) || layers.1.blocks.7.attn.proj.bias
 |  0.990 |  0.967 |  1.013 |  0.008 | torch.Size([192]) || layers.1.blocks.7.norm2.weight
 | -0.000 | -0.021 |  0.021 |  0.007 | torch.Size([192]) || layers.1.blocks.7.norm2.bias
 |  0.000 | -0.087 |  0.089 |  0.021 | torch.Size([768, 192]) || layers.1.blocks.7.mlp.fc1.weight
 | -0.007 | -0.023 |  0.012 |  0.006 | torch.Size([768]) || layers.1.blocks.7.mlp.fc1.bias
 | -0.000 | -0.086 |  0.093 |  0.021 | torch.Size([192, 768]) || layers.1.blocks.7.mlp.fc2.weight
 | -0.000 | -0.025 |  0.040 |  0.011 | torch.Size([192]) || layers.1.blocks.7.mlp.fc2.bias
 |  0.000 | -0.118 |  0.120 |  0.027 | torch.Size([384, 768]) || layers.1.downsample.reduction.weight
 |  0.994 |  0.944 |  1.045 |  0.016 | torch.Size([768]) || layers.1.downsample.norm.weight
 |  0.000 | -0.036 |  0.038 |  0.012 | torch.Size([768]) || layers.1.downsample.norm.bias
 |  1.000 |  0.991 |  1.013 |  0.004 | torch.Size([384]) || layers.2.blocks.0.norm1.weight
 |  0.000 | -0.007 |  0.008 |  0.003 | torch.Size([384]) || layers.2.blocks.0.norm1.bias
 |  0.000 | -0.070 |  0.061 |  0.019 | torch.Size([225, 8]) || layers.2.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.blocks.0.attn.relative_position_index
 | -0.000 | -0.091 |  0.091 |  0.020 | torch.Size([1152, 384]) || layers.2.blocks.0.attn.qkv.weight
 |  0.000 | -0.010 |  0.010 |  0.003 | torch.Size([1152]) || layers.2.blocks.0.attn.qkv.bias
 |  0.000 | -0.087 |  0.091 |  0.020 | torch.Size([384, 384]) || layers.2.blocks.0.attn.proj.weight
 |  0.000 | -0.010 |  0.009 |  0.004 | torch.Size([384]) || layers.2.blocks.0.attn.proj.bias
 |  1.001 |  0.994 |  1.011 |  0.003 | torch.Size([384]) || layers.2.blocks.0.norm2.weight
 |  0.000 | -0.009 |  0.008 |  0.004 | torch.Size([384]) || layers.2.blocks.0.norm2.bias
 |  0.000 | -0.099 |  0.093 |  0.020 | torch.Size([1536, 384]) || layers.2.blocks.0.mlp.fc1.weight
 |  0.001 | -0.008 |  0.009 |  0.004 | torch.Size([1536]) || layers.2.blocks.0.mlp.fc1.bias
 | -0.000 | -0.097 |  0.093 |  0.020 | torch.Size([384, 1536]) || layers.2.blocks.0.mlp.fc2.weight
 |  0.000 | -0.010 |  0.010 |  0.005 | torch.Size([384]) || layers.2.blocks.0.mlp.fc2.bias
 | -43.750 | -100.000 |  0.000 | 49.609 | torch.Size([4, 64, 64]) || layers.2.blocks.1.attn_mask
 |  1.000 |  0.993 |  1.008 |  0.003 | torch.Size([384]) || layers.2.blocks.1.norm1.weight
 |  0.000 | -0.008 |  0.009 |  0.004 | torch.Size([384]) || layers.2.blocks.1.norm1.bias
 |  0.000 | -0.082 |  0.069 |  0.020 | torch.Size([225, 8]) || layers.2.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.blocks.1.attn.relative_position_index
 |  0.000 | -0.102 |  0.093 |  0.020 | torch.Size([1152, 384]) || layers.2.blocks.1.attn.qkv.weight
 |  0.000 | -0.010 |  0.009 |  0.003 | torch.Size([1152]) || layers.2.blocks.1.attn.qkv.bias
 | -0.000 | -0.091 |  0.089 |  0.020 | torch.Size([384, 384]) || layers.2.blocks.1.attn.proj.weight
 |  0.000 | -0.011 |  0.011 |  0.006 | torch.Size([384]) || layers.2.blocks.1.attn.proj.bias
 |  1.001 |  0.994 |  1.009 |  0.003 | torch.Size([384]) || layers.2.blocks.1.norm2.weight
 |  0.000 | -0.007 |  0.007 |  0.004 | torch.Size([384]) || layers.2.blocks.1.norm2.bias
 |  0.000 | -0.096 |  0.088 |  0.020 | torch.Size([1536, 384]) || layers.2.blocks.1.mlp.fc1.weight
 |  0.001 | -0.007 |  0.008 |  0.004 | torch.Size([1536]) || layers.2.blocks.1.mlp.fc1.bias
 | -0.000 | -1.998 |  0.099 |  0.020 | torch.Size([384, 1536]) || layers.2.blocks.1.mlp.fc2.weight
 | -0.000 | -0.010 |  0.009 |  0.005 | torch.Size([384]) || layers.2.blocks.1.mlp.fc2.bias
 |  1.000 |  0.994 |  1.006 |  0.003 | torch.Size([384]) || layers.2.blocks.2.norm1.weight
 | -0.000 | -0.007 |  0.007 |  0.003 | torch.Size([384]) || layers.2.blocks.2.norm1.bias
 | -0.000 | -0.072 |  0.070 |  0.020 | torch.Size([225, 8]) || layers.2.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.blocks.2.attn.relative_position_index
 | -0.000 | -0.100 |  0.098 |  0.020 | torch.Size([1152, 384]) || layers.2.blocks.2.attn.qkv.weight
 | -0.000 | -0.008 |  0.008 |  0.003 | torch.Size([1152]) || layers.2.blocks.2.attn.qkv.bias
 | -0.000 | -0.094 |  0.089 |  0.020 | torch.Size([384, 384]) || layers.2.blocks.2.attn.proj.weight
 | -0.000 | -0.010 |  0.009 |  0.005 | torch.Size([384]) || layers.2.blocks.2.attn.proj.bias
 |  1.001 |  0.994 |  1.008 |  0.003 | torch.Size([384]) || layers.2.blocks.2.norm2.weight
 |  0.000 | -0.009 |  0.009 |  0.004 | torch.Size([384]) || layers.2.blocks.2.norm2.bias
 |  0.000 | -0.097 |  0.098 |  0.020 | torch.Size([1536, 384]) || layers.2.blocks.2.mlp.fc1.weight
 |  0.001 | -0.009 |  0.009 |  0.004 | torch.Size([1536]) || layers.2.blocks.2.mlp.fc1.bias
 |  0.000 | -0.103 |  0.096 |  0.020 | torch.Size([384, 1536]) || layers.2.blocks.2.mlp.fc2.weight
 | -0.000 | -0.012 |  0.011 |  0.006 | torch.Size([384]) || layers.2.blocks.2.mlp.fc2.bias
 | -43.750 | -100.000 |  0.000 | 49.609 | torch.Size([4, 64, 64]) || layers.2.blocks.3.attn_mask
 |  1.000 |  0.993 |  1.006 |  0.003 | torch.Size([384]) || layers.2.blocks.3.norm1.weight
 |  0.000 | -0.009 |  0.009 |  0.004 | torch.Size([384]) || layers.2.blocks.3.norm1.bias
 | -0.001 | -0.066 |  0.068 |  0.020 | torch.Size([225, 8]) || layers.2.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.blocks.3.attn.relative_position_index
 |  0.000 | -0.093 |  0.094 |  0.020 | torch.Size([1152, 384]) || layers.2.blocks.3.attn.qkv.weight
 |  0.000 | -0.010 |  0.010 |  0.003 | torch.Size([1152]) || layers.2.blocks.3.attn.qkv.bias
 |  0.000 | -0.084 |  0.089 |  0.020 | torch.Size([384, 384]) || layers.2.blocks.3.attn.proj.weight
 | -0.000 | -0.011 |  0.011 |  0.006 | torch.Size([384]) || layers.2.blocks.3.attn.proj.bias
 |  1.001 |  0.994 |  1.008 |  0.002 | torch.Size([384]) || layers.2.blocks.3.norm2.weight
 | -0.000 | -0.009 |  0.009 |  0.004 | torch.Size([384]) || layers.2.blocks.3.norm2.bias
 |  0.000 | -0.098 |  0.095 |  0.020 | torch.Size([1536, 384]) || layers.2.blocks.3.mlp.fc1.weight
 |  0.001 | -0.009 |  0.009 |  0.004 | torch.Size([1536]) || layers.2.blocks.3.mlp.fc1.bias
 |  0.000 | -0.098 |  0.096 |  0.020 | torch.Size([384, 1536]) || layers.2.blocks.3.mlp.fc2.weight
 | -0.000 | -0.012 |  0.011 |  0.006 | torch.Size([384]) || layers.2.blocks.3.mlp.fc2.bias
 |  1.000 |  0.993 |  1.007 |  0.003 | torch.Size([384]) || layers.2.blocks.4.norm1.weight
 |  0.000 | -0.010 |  0.009 |  0.004 | torch.Size([384]) || layers.2.blocks.4.norm1.bias
 | -0.000 | -0.073 |  0.073 |  0.020 | torch.Size([225, 8]) || layers.2.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.blocks.4.attn.relative_position_index
 | -0.000 | -0.098 |  0.095 |  0.020 | torch.Size([1152, 384]) || layers.2.blocks.4.attn.qkv.weight
 |  0.000 | -0.010 |  0.011 |  0.004 | torch.Size([1152]) || layers.2.blocks.4.attn.qkv.bias
 |  0.000 | -0.099 |  0.094 |  0.020 | torch.Size([384, 384]) || layers.2.blocks.4.attn.proj.weight
 |  0.000 | -0.012 |  0.011 |  0.006 | torch.Size([384]) || layers.2.blocks.4.attn.proj.bias
 |  1.001 |  0.996 |  1.007 |  0.002 | torch.Size([384]) || layers.2.blocks.4.norm2.weight
 |  0.000 | -0.008 |  0.009 |  0.004 | torch.Size([384]) || layers.2.blocks.4.norm2.bias
 |  0.000 | -0.098 |  0.099 |  0.020 | torch.Size([1536, 384]) || layers.2.blocks.4.mlp.fc1.weight
 |  0.001 | -0.008 |  0.008 |  0.004 | torch.Size([1536]) || layers.2.blocks.4.mlp.fc1.bias
 |  0.000 | -0.095 |  0.093 |  0.020 | torch.Size([384, 1536]) || layers.2.blocks.4.mlp.fc2.weight
 |  0.000 | -0.012 |  0.011 |  0.006 | torch.Size([384]) || layers.2.blocks.4.mlp.fc2.bias
 | -43.750 | -100.000 |  0.000 | 49.609 | torch.Size([4, 64, 64]) || layers.2.blocks.5.attn_mask
 |  1.000 |  0.994 |  1.006 |  0.003 | torch.Size([384]) || layers.2.blocks.5.norm1.weight
 | -0.000 | -0.009 |  0.009 |  0.004 | torch.Size([384]) || layers.2.blocks.5.norm1.bias
 | -0.001 | -0.064 |  0.071 |  0.020 | torch.Size([225, 8]) || layers.2.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.blocks.5.attn.relative_position_index
 | -0.000 | -0.101 |  0.108 |  0.020 | torch.Size([1152, 384]) || layers.2.blocks.5.attn.qkv.weight
 |  0.000 | -0.009 |  0.010 |  0.003 | torch.Size([1152]) || layers.2.blocks.5.attn.qkv.bias
 |  0.000 | -0.086 |  0.092 |  0.020 | torch.Size([384, 384]) || layers.2.blocks.5.attn.proj.weight
 | -0.000 | -0.012 |  0.011 |  0.006 | torch.Size([384]) || layers.2.blocks.5.attn.proj.bias
 |  1.001 |  0.996 |  1.006 |  0.002 | torch.Size([384]) || layers.2.blocks.5.norm2.weight
 |  0.000 | -0.008 |  0.008 |  0.004 | torch.Size([384]) || layers.2.blocks.5.norm2.bias
 | -0.000 | -0.097 |  0.104 |  0.020 | torch.Size([1536, 384]) || layers.2.blocks.5.mlp.fc1.weight
 |  0.001 | -0.008 |  0.008 |  0.003 | torch.Size([1536]) || layers.2.blocks.5.mlp.fc1.bias
 |  0.000 | -0.093 |  0.100 |  0.020 | torch.Size([384, 1536]) || layers.2.blocks.5.mlp.fc2.weight
 | -0.000 | -0.011 |  0.011 |  0.006 | torch.Size([384]) || layers.2.blocks.5.mlp.fc2.bias
 |  1.000 |  0.994 |  1.006 |  0.003 | torch.Size([384]) || layers.2.blocks.6.norm1.weight
 |  0.000 | -0.008 |  0.008 |  0.004 | torch.Size([384]) || layers.2.blocks.6.norm1.bias
 | -0.000 | -0.055 |  0.065 |  0.019 | torch.Size([225, 8]) || layers.2.blocks.6.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.blocks.6.attn.relative_position_index
 | -0.000 | -0.089 |  0.093 |  0.020 | torch.Size([1152, 384]) || layers.2.blocks.6.attn.qkv.weight
 |  0.000 | -0.009 |  0.010 |  0.003 | torch.Size([1152]) || layers.2.blocks.6.attn.qkv.bias
 |  0.000 | -0.091 |  0.103 |  0.020 | torch.Size([384, 384]) || layers.2.blocks.6.attn.proj.weight
 | -0.000 | -0.011 |  0.011 |  0.006 | torch.Size([384]) || layers.2.blocks.6.attn.proj.bias
 |  1.001 |  0.996 |  1.007 |  0.002 | torch.Size([384]) || layers.2.blocks.6.norm2.weight
 |  0.000 | -0.007 |  0.007 |  0.003 | torch.Size([384]) || layers.2.blocks.6.norm2.bias
 |  0.000 | -0.094 |  0.089 |  0.020 | torch.Size([1536, 384]) || layers.2.blocks.6.mlp.fc1.weight
 |  0.001 | -0.007 |  0.007 |  0.003 | torch.Size([1536]) || layers.2.blocks.6.mlp.fc1.bias
 |  0.000 | -0.095 |  0.092 |  0.020 | torch.Size([384, 1536]) || layers.2.blocks.6.mlp.fc2.weight
 | -0.000 | -0.010 |  0.010 |  0.006 | torch.Size([384]) || layers.2.blocks.6.mlp.fc2.bias
 | -43.750 | -100.000 |  0.000 | 49.609 | torch.Size([4, 64, 64]) || layers.2.blocks.7.attn_mask
 |  1.000 |  0.997 |  1.003 |  0.001 | torch.Size([384]) || layers.2.blocks.7.norm1.weight
 |  0.000 | -0.005 |  0.005 |  0.002 | torch.Size([384]) || layers.2.blocks.7.norm1.bias
 | -0.000 | -0.066 |  0.070 |  0.020 | torch.Size([225, 8]) || layers.2.blocks.7.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.blocks.7.attn.relative_position_index
 |  0.000 | -0.098 |  0.095 |  0.020 | torch.Size([1152, 384]) || layers.2.blocks.7.attn.qkv.weight
 |  0.000 | -0.006 |  0.007 |  0.002 | torch.Size([1152]) || layers.2.blocks.7.attn.qkv.bias
 | -0.000 | -0.086 |  0.095 |  0.020 | torch.Size([384, 384]) || layers.2.blocks.7.attn.proj.weight
 | -0.000 | -0.008 |  0.008 |  0.004 | torch.Size([384]) || layers.2.blocks.7.attn.proj.bias
 |  1.001 |  0.996 |  1.005 |  0.002 | torch.Size([384]) || layers.2.blocks.7.norm2.weight
 | -0.000 | -0.007 |  0.007 |  0.003 | torch.Size([384]) || layers.2.blocks.7.norm2.bias
 |  0.000 | -0.095 |  0.098 |  0.020 | torch.Size([1536, 384]) || layers.2.blocks.7.mlp.fc1.weight
 |  0.000 | -0.007 |  0.007 |  0.003 | torch.Size([1536]) || layers.2.blocks.7.mlp.fc1.bias
 | -0.000 | -0.096 |  0.088 |  0.020 | torch.Size([384, 1536]) || layers.2.blocks.7.mlp.fc2.weight
 | -0.000 | -0.010 |  0.010 |  0.005 | torch.Size([384]) || layers.2.blocks.7.mlp.fc2.bias
 |  0.000 | -0.104 |  0.096 |  0.020 | torch.Size([768, 1536]) || layers.2.downsample.reduction.weight
 |  1.000 |  0.992 |  1.012 |  0.003 | torch.Size([1536]) || layers.2.downsample.norm.weight
 | -0.000 | -0.012 |  0.011 |  0.005 | torch.Size([1536]) || layers.2.downsample.norm.bias
 |  1.000 |  0.994 |  1.008 |  0.003 | torch.Size([768]) || layers.3.blocks.0.norm1.weight
 |  0.000 | -0.009 |  0.009 |  0.004 | torch.Size([768]) || layers.3.blocks.0.norm1.bias
 |  0.001 | -0.062 |  0.065 |  0.020 | torch.Size([225, 8]) || layers.3.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.blocks.0.attn.relative_position_index
 | -0.000 | -0.094 |  0.097 |  0.020 | torch.Size([2304, 768]) || layers.3.blocks.0.attn.qkv.weight
 |  0.000 | -0.009 |  0.009 |  0.003 | torch.Size([2304]) || layers.3.blocks.0.attn.qkv.bias
 | -0.000 | -0.090 |  0.093 |  0.020 | torch.Size([768, 768]) || layers.3.blocks.0.attn.proj.weight
 |  0.000 | -0.014 |  0.011 |  0.004 | torch.Size([768]) || layers.3.blocks.0.attn.proj.bias
 |  1.001 |  0.995 |  1.008 |  0.002 | torch.Size([768]) || layers.3.blocks.0.norm2.weight
 | -0.000 | -0.008 |  0.007 |  0.003 | torch.Size([768]) || layers.3.blocks.0.norm2.bias
 | -0.000 | -0.099 |  0.105 |  0.020 | torch.Size([3072, 768]) || layers.3.blocks.0.mlp.fc1.weight
 |  0.000 | -0.005 |  0.008 |  0.002 | torch.Size([3072]) || layers.3.blocks.0.mlp.fc1.bias
 |  0.000 | -0.099 |  0.095 |  0.020 | torch.Size([768, 3072]) || layers.3.blocks.0.mlp.fc2.weight
 |  0.000 | -0.013 |  0.010 |  0.004 | torch.Size([768]) || layers.3.blocks.0.mlp.fc2.bias
 |  1.000 |  0.994 |  1.008 |  0.002 | torch.Size([768]) || layers.3.blocks.1.norm1.weight
 |  0.000 | -0.009 |  0.009 |  0.003 | torch.Size([768]) || layers.3.blocks.1.norm1.bias
 | -0.000 | -0.069 |  0.079 |  0.020 | torch.Size([225, 8]) || layers.3.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.blocks.1.attn.relative_position_index
 | -0.000 | -1.998 |  0.093 |  0.020 | torch.Size([2304, 768]) || layers.3.blocks.1.attn.qkv.weight
 |  0.000 | -0.010 |  0.008 |  0.003 | torch.Size([2304]) || layers.3.blocks.1.attn.qkv.bias
 |  0.000 | -0.092 |  0.098 |  0.020 | torch.Size([768, 768]) || layers.3.blocks.1.attn.proj.weight
 | -0.000 | -0.010 |  0.011 |  0.004 | torch.Size([768]) || layers.3.blocks.1.attn.proj.bias
 |  1.000 |  0.996 |  1.005 |  0.002 | torch.Size([768]) || layers.3.blocks.1.norm2.weight
 |  0.000 | -0.006 |  0.007 |  0.003 | torch.Size([768]) || layers.3.blocks.1.norm2.bias
 |  0.000 | -0.096 |  0.097 |  0.020 | torch.Size([3072, 768]) || layers.3.blocks.1.mlp.fc1.weight
 |  0.000 | -0.005 |  0.007 |  0.002 | torch.Size([3072]) || layers.3.blocks.1.mlp.fc1.bias
 |  0.000 | -2.000 |  0.097 |  0.020 | torch.Size([768, 3072]) || layers.3.blocks.1.mlp.fc2.weight
 |  0.000 | -0.012 |  0.010 |  0.004 | torch.Size([768]) || layers.3.blocks.1.mlp.fc2.bias
 |  1.000 |  0.994 |  1.006 |  0.002 | torch.Size([768]) || layers.3.blocks.2.norm1.weight
 |  0.000 | -0.008 |  0.007 |  0.003 | torch.Size([768]) || layers.3.blocks.2.norm1.bias
 |  0.000 | -0.058 |  0.064 |  0.020 | torch.Size([225, 8]) || layers.3.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.blocks.2.attn.relative_position_index
 | -0.000 | -0.100 |  0.098 |  0.020 | torch.Size([2304, 768]) || layers.3.blocks.2.attn.qkv.weight
 |  0.000 | -0.007 |  0.008 |  0.002 | torch.Size([2304]) || layers.3.blocks.2.attn.qkv.bias
 |  0.000 | -0.092 |  0.096 |  0.020 | torch.Size([768, 768]) || layers.3.blocks.2.attn.proj.weight
 |  0.000 | -0.011 |  0.010 |  0.003 | torch.Size([768]) || layers.3.blocks.2.attn.proj.bias
 |  1.000 |  0.996 |  1.007 |  0.002 | torch.Size([768]) || layers.3.blocks.2.norm2.weight
 |  0.000 | -0.006 |  0.006 |  0.002 | torch.Size([768]) || layers.3.blocks.2.norm2.bias
 |  0.000 | -0.100 |  0.107 |  0.020 | torch.Size([3072, 768]) || layers.3.blocks.2.mlp.fc1.weight
 |  0.000 | -0.005 |  0.007 |  0.002 | torch.Size([3072]) || layers.3.blocks.2.mlp.fc1.bias
 |  0.000 | -0.099 |  0.103 |  0.020 | torch.Size([768, 3072]) || layers.3.blocks.2.mlp.fc2.weight
 | -0.000 | -0.010 |  0.011 |  0.004 | torch.Size([768]) || layers.3.blocks.2.mlp.fc2.bias
 |  1.000 |  0.994 |  1.005 |  0.002 | torch.Size([768]) || layers.3.blocks.3.norm1.weight
 | -0.000 | -0.006 |  0.007 |  0.002 | torch.Size([768]) || layers.3.blocks.3.norm1.bias
 |  0.001 | -0.069 |  0.071 |  0.020 | torch.Size([225, 8]) || layers.3.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.blocks.3.attn.relative_position_index
 | -0.000 | -0.105 |  0.099 |  0.020 | torch.Size([2304, 768]) || layers.3.blocks.3.attn.qkv.weight
 | -0.000 | -0.008 |  0.008 |  0.002 | torch.Size([2304]) || layers.3.blocks.3.attn.qkv.bias
 |  0.000 | -0.098 |  0.093 |  0.020 | torch.Size([768, 768]) || layers.3.blocks.3.attn.proj.weight
 |  0.000 | -0.010 |  0.011 |  0.003 | torch.Size([768]) || layers.3.blocks.3.attn.proj.bias
 |  1.000 |  0.996 |  1.005 |  0.001 | torch.Size([768]) || layers.3.blocks.3.norm2.weight
 | -0.000 | -0.005 |  0.005 |  0.002 | torch.Size([768]) || layers.3.blocks.3.norm2.bias
 |  0.000 | -0.095 |  0.098 |  0.020 | torch.Size([3072, 768]) || layers.3.blocks.3.mlp.fc1.weight
 |  0.000 | -0.005 |  0.005 |  0.001 | torch.Size([3072]) || layers.3.blocks.3.mlp.fc1.bias
 | -0.000 | -0.096 |  0.100 |  0.020 | torch.Size([768, 3072]) || layers.3.blocks.3.mlp.fc2.weight
 |  0.000 | -0.009 |  0.009 |  0.003 | torch.Size([768]) || layers.3.blocks.3.mlp.fc2.bias
 |  1.000 |  0.995 |  1.006 |  0.002 | torch.Size([768]) || layers.3.blocks.4.norm1.weight
 |  0.000 | -0.007 |  0.006 |  0.002 | torch.Size([768]) || layers.3.blocks.4.norm1.bias
 |  0.001 | -0.057 |  0.061 |  0.019 | torch.Size([225, 8]) || layers.3.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.blocks.4.attn.relative_position_index
 |  0.000 | -0.098 |  0.097 |  0.020 | torch.Size([2304, 768]) || layers.3.blocks.4.attn.qkv.weight
 | -0.000 | -0.007 |  0.006 |  0.002 | torch.Size([2304]) || layers.3.blocks.4.attn.qkv.bias
 | -0.000 | -0.091 |  0.093 |  0.020 | torch.Size([768, 768]) || layers.3.blocks.4.attn.proj.weight
 |  0.000 | -0.007 |  0.008 |  0.003 | torch.Size([768]) || layers.3.blocks.4.attn.proj.bias
 |  1.000 |  0.996 |  1.004 |  0.001 | torch.Size([768]) || layers.3.blocks.4.norm2.weight
 |  0.000 | -0.004 |  0.005 |  0.001 | torch.Size([768]) || layers.3.blocks.4.norm2.bias
 | -0.000 | -0.096 |  0.101 |  0.020 | torch.Size([3072, 768]) || layers.3.blocks.4.mlp.fc1.weight
 |  0.000 | -0.004 |  0.005 |  0.001 | torch.Size([3072]) || layers.3.blocks.4.mlp.fc1.bias
 | -0.000 | -2.000 |  0.107 |  0.020 | torch.Size([768, 3072]) || layers.3.blocks.4.mlp.fc2.weight
 |  0.000 | -0.008 |  0.011 |  0.003 | torch.Size([768]) || layers.3.blocks.4.mlp.fc2.bias
 |  1.000 |  0.995 |  1.005 |  0.001 | torch.Size([768]) || layers.3.blocks.5.norm1.weight
 |  0.000 | -0.005 |  0.006 |  0.002 | torch.Size([768]) || layers.3.blocks.5.norm1.bias
 |  0.001 | -0.064 |  0.066 |  0.020 | torch.Size([225, 8]) || layers.3.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.blocks.5.attn.relative_position_index
 |  0.000 | -0.100 |  0.101 |  0.020 | torch.Size([2304, 768]) || layers.3.blocks.5.attn.qkv.weight
 | -0.000 | -0.007 |  0.006 |  0.001 | torch.Size([2304]) || layers.3.blocks.5.attn.qkv.bias
 |  0.000 | -0.095 |  0.091 |  0.020 | torch.Size([768, 768]) || layers.3.blocks.5.attn.proj.weight
 |  0.000 | -0.008 |  0.011 |  0.003 | torch.Size([768]) || layers.3.blocks.5.attn.proj.bias
 |  1.000 |  0.997 |  1.006 |  0.001 | torch.Size([768]) || layers.3.blocks.5.norm2.weight
 |  0.000 | -0.004 |  0.004 |  0.001 | torch.Size([768]) || layers.3.blocks.5.norm2.bias
 | -0.000 | -1.999 |  0.104 |  0.020 | torch.Size([3072, 768]) || layers.3.blocks.5.mlp.fc1.weight
 |  0.000 | -0.004 |  0.005 |  0.001 | torch.Size([3072]) || layers.3.blocks.5.mlp.fc1.bias
 |  0.000 | -0.101 |  0.106 |  0.020 | torch.Size([768, 3072]) || layers.3.blocks.5.mlp.fc2.weight
 |  0.000 | -0.008 |  0.010 |  0.003 | torch.Size([768]) || layers.3.blocks.5.mlp.fc2.bias
 |  1.000 |  0.996 |  1.006 |  0.002 | torch.Size([768]) || layers.3.blocks.6.norm1.weight
 | -0.000 | -0.005 |  0.005 |  0.002 | torch.Size([768]) || layers.3.blocks.6.norm1.bias
 | -0.000 | -0.071 |  0.061 |  0.020 | torch.Size([225, 8]) || layers.3.blocks.6.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.blocks.6.attn.relative_position_index
 |  0.000 | -0.100 |  0.100 |  0.020 | torch.Size([2304, 768]) || layers.3.blocks.6.attn.qkv.weight
 |  0.000 | -0.006 |  0.006 |  0.001 | torch.Size([2304]) || layers.3.blocks.6.attn.qkv.bias
 | -0.000 | -0.097 |  0.094 |  0.020 | torch.Size([768, 768]) || layers.3.blocks.6.attn.proj.weight
 |  0.000 | -0.009 |  0.011 |  0.003 | torch.Size([768]) || layers.3.blocks.6.attn.proj.bias
 |  1.000 |  0.997 |  1.004 |  0.001 | torch.Size([768]) || layers.3.blocks.6.norm2.weight
 |  0.000 | -0.005 |  0.005 |  0.001 | torch.Size([768]) || layers.3.blocks.6.norm2.bias
 | -0.000 | -0.106 |  0.096 |  0.020 | torch.Size([3072, 768]) || layers.3.blocks.6.mlp.fc1.weight
 | -0.000 | -0.003 |  0.005 |  0.001 | torch.Size([3072]) || layers.3.blocks.6.mlp.fc1.bias
 |  0.000 | -0.098 |  0.101 |  0.020 | torch.Size([768, 3072]) || layers.3.blocks.6.mlp.fc2.weight
 | -0.000 | -0.009 |  0.010 |  0.003 | torch.Size([768]) || layers.3.blocks.6.mlp.fc2.bias
 |  1.000 |  0.996 |  1.004 |  0.001 | torch.Size([768]) || layers.3.blocks.7.norm1.weight
 |  0.000 | -0.005 |  0.005 |  0.002 | torch.Size([768]) || layers.3.blocks.7.norm1.bias
 | -0.000 | -0.072 |  0.070 |  0.020 | torch.Size([225, 8]) || layers.3.blocks.7.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.blocks.7.attn.relative_position_index
 | -0.000 | -0.095 |  0.101 |  0.020 | torch.Size([2304, 768]) || layers.3.blocks.7.attn.qkv.weight
 |  0.000 | -0.006 |  0.006 |  0.001 | torch.Size([2304]) || layers.3.blocks.7.attn.qkv.bias
 |  0.000 | -0.092 |  0.090 |  0.020 | torch.Size([768, 768]) || layers.3.blocks.7.attn.proj.weight
 | -0.000 | -0.009 |  0.010 |  0.003 | torch.Size([768]) || layers.3.blocks.7.attn.proj.bias
 |  1.000 |  0.997 |  1.003 |  0.001 | torch.Size([768]) || layers.3.blocks.7.norm2.weight
 |  0.000 | -0.004 |  0.004 |  0.001 | torch.Size([768]) || layers.3.blocks.7.norm2.bias
 | -0.000 | -0.097 |  0.101 |  0.020 | torch.Size([3072, 768]) || layers.3.blocks.7.mlp.fc1.weight
 | -0.000 | -0.003 |  0.004 |  0.001 | torch.Size([3072]) || layers.3.blocks.7.mlp.fc1.bias
 |  0.000 | -0.104 |  0.096 |  0.020 | torch.Size([768, 3072]) || layers.3.blocks.7.mlp.fc2.weight
 |  0.000 | -0.009 |  0.009 |  0.002 | torch.Size([768]) || layers.3.blocks.7.mlp.fc2.bias
 | -0.000 | -0.069 |  0.070 |  0.021 | torch.Size([384, 768, 1, 1]) || layers_up.0.conv.weight
 | -0.000 | -0.068 |  0.074 |  0.021 | torch.Size([1536, 768, 1, 1]) || layers_up.0.up_p.0.weight
 |  0.204 |  0.204 |  0.204 |    nan | torch.Size([1]) || layers_up.0.up_p.1.weight
 |  0.000 | -0.088 |  0.083 |  0.029 | torch.Size([384, 384, 1, 1]) || layers_up.0.up_p.3.weight
 | -0.000 | -0.049 |  0.050 |  0.021 | torch.Size([768, 768, 1, 1]) || layers_up.0.up_b.0.weight
 | -0.002 | -0.040 |  0.038 |  0.021 | torch.Size([768]) || layers_up.0.up_b.0.bias
 |  0.098 |  0.098 |  0.098 |    nan | torch.Size([1]) || layers_up.0.up_b.1.weight
 |  0.000 | -0.049 |  0.051 |  0.021 | torch.Size([384, 768, 1, 1]) || layers_up.0.up_b.3.weight
 |  0.961 |  0.869 |  1.002 |  0.017 | torch.Size([384]) || layers_up.1.blocks.0.norm1.weight
 |  0.000 | -0.028 |  0.030 |  0.010 | torch.Size([384]) || layers_up.1.blocks.0.norm1.bias
 | -0.000 | -0.075 |  0.062 |  0.020 | torch.Size([225, 8]) || layers_up.1.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.1.blocks.0.attn.relative_position_index
 |  0.000 | -0.104 |  0.101 |  0.021 | torch.Size([1152, 384]) || layers_up.1.blocks.0.attn.qkv.weight
 |  0.000 | -0.037 |  0.037 |  0.010 | torch.Size([1152]) || layers_up.1.blocks.0.attn.qkv.bias
 | -0.000 | -0.089 |  0.095 |  0.021 | torch.Size([384, 384]) || layers_up.1.blocks.0.attn.proj.weight
 |  0.000 | -0.064 |  0.084 |  0.023 | torch.Size([384]) || layers_up.1.blocks.0.attn.proj.bias
 |  0.963 |  0.878 |  1.001 |  0.016 | torch.Size([384]) || layers_up.1.blocks.0.norm2.weight
 |  0.000 | -0.057 |  0.044 |  0.020 | torch.Size([384]) || layers_up.1.blocks.0.norm2.bias
 |  0.000 | -0.101 |  0.096 |  0.021 | torch.Size([1536, 384]) || layers_up.1.blocks.0.mlp.fc1.weight
 | -0.013 | -0.038 |  0.009 |  0.008 | torch.Size([1536]) || layers_up.1.blocks.0.mlp.fc1.bias
 |  0.000 | -0.122 |  0.101 |  0.021 | torch.Size([384, 1536]) || layers_up.1.blocks.0.mlp.fc2.weight
 |  0.001 | -0.058 |  0.068 |  0.019 | torch.Size([384]) || layers_up.1.blocks.0.mlp.fc2.bias
 | -43.750 | -100.000 |  0.000 | 49.609 | torch.Size([4, 64, 64]) || layers_up.1.blocks.1.attn_mask
 |  0.964 |  0.811 |  0.997 |  0.019 | torch.Size([384]) || layers_up.1.blocks.1.norm1.weight
 | -0.000 | -0.042 |  0.039 |  0.015 | torch.Size([384]) || layers_up.1.blocks.1.norm1.bias
 | -0.001 | -0.063 |  0.145 |  0.021 | torch.Size([225, 8]) || layers_up.1.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.1.blocks.1.attn.relative_position_index
 |  0.000 | -0.112 |  0.113 |  0.022 | torch.Size([1152, 384]) || layers_up.1.blocks.1.attn.qkv.weight
 | -0.000 | -0.023 |  0.032 |  0.007 | torch.Size([1152]) || layers_up.1.blocks.1.attn.qkv.bias
 |  0.000 | -0.092 |  0.092 |  0.021 | torch.Size([384, 384]) || layers_up.1.blocks.1.attn.proj.weight
 |  0.000 | -0.058 |  0.072 |  0.019 | torch.Size([384]) || layers_up.1.blocks.1.attn.proj.bias
 |  0.977 |  0.866 |  1.015 |  0.015 | torch.Size([384]) || layers_up.1.blocks.1.norm2.weight
 | -0.000 | -0.048 |  0.036 |  0.013 | torch.Size([384]) || layers_up.1.blocks.1.norm2.bias
 |  0.000 | -0.098 |  0.108 |  0.021 | torch.Size([1536, 384]) || layers_up.1.blocks.1.mlp.fc1.weight
 | -0.009 | -0.031 |  0.013 |  0.008 | torch.Size([1536]) || layers_up.1.blocks.1.mlp.fc1.bias
 |  0.000 | -0.107 |  0.096 |  0.021 | torch.Size([384, 1536]) || layers_up.1.blocks.1.mlp.fc2.weight
 |  0.000 | -0.050 |  0.070 |  0.018 | torch.Size([384]) || layers_up.1.blocks.1.mlp.fc2.bias
 |  0.967 |  0.791 |  1.002 |  0.021 | torch.Size([384]) || layers_up.1.blocks.2.norm1.weight
 |  0.001 | -0.046 |  0.041 |  0.015 | torch.Size([384]) || layers_up.1.blocks.2.norm1.bias
 |  0.000 | -0.066 |  0.092 |  0.020 | torch.Size([225, 8]) || layers_up.1.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.1.blocks.2.attn.relative_position_index
 | -0.000 | -0.102 |  0.093 |  0.021 | torch.Size([1152, 384]) || layers_up.1.blocks.2.attn.qkv.weight
 |  0.000 | -0.025 |  0.037 |  0.007 | torch.Size([1152]) || layers_up.1.blocks.2.attn.qkv.bias
 | -0.000 | -0.092 |  0.102 |  0.021 | torch.Size([384, 384]) || layers_up.1.blocks.2.attn.proj.weight
 |  0.000 | -0.049 |  0.078 |  0.018 | torch.Size([384]) || layers_up.1.blocks.2.attn.proj.bias
 |  0.978 |  0.847 |  1.008 |  0.016 | torch.Size([384]) || layers_up.1.blocks.2.norm2.weight
 | -0.001 | -0.046 |  0.037 |  0.014 | torch.Size([384]) || layers_up.1.blocks.2.norm2.bias
 |  0.000 | -0.098 |  0.112 |  0.021 | torch.Size([1536, 384]) || layers_up.1.blocks.2.mlp.fc1.weight
 | -0.008 | -0.037 |  0.022 |  0.009 | torch.Size([1536]) || layers_up.1.blocks.2.mlp.fc1.bias
 | -0.000 | -0.104 |  0.100 |  0.021 | torch.Size([384, 1536]) || layers_up.1.blocks.2.mlp.fc2.weight
 |  0.000 | -0.061 |  0.072 |  0.019 | torch.Size([384]) || layers_up.1.blocks.2.mlp.fc2.bias
 | -43.750 | -100.000 |  0.000 | 49.609 | torch.Size([4, 64, 64]) || layers_up.1.blocks.3.attn_mask
 |  0.969 |  0.831 |  1.001 |  0.020 | torch.Size([384]) || layers_up.1.blocks.3.norm1.weight
 |  0.000 | -0.039 |  0.053 |  0.015 | torch.Size([384]) || layers_up.1.blocks.3.norm1.bias
 | -0.000 | -0.102 |  0.344 |  0.027 | torch.Size([225, 8]) || layers_up.1.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.1.blocks.3.attn.relative_position_index
 |  0.000 | -0.111 |  0.103 |  0.022 | torch.Size([1152, 384]) || layers_up.1.blocks.3.attn.qkv.weight
 | -0.000 | -0.025 |  0.028 |  0.007 | torch.Size([1152]) || layers_up.1.blocks.3.attn.qkv.bias
 |  0.000 | -0.091 |  0.091 |  0.022 | torch.Size([384, 384]) || layers_up.1.blocks.3.attn.proj.weight
 |  0.000 | -0.049 |  0.067 |  0.018 | torch.Size([384]) || layers_up.1.blocks.3.attn.proj.bias
 |  0.981 |  0.841 |  1.018 |  0.018 | torch.Size([384]) || layers_up.1.blocks.3.norm2.weight
 | -0.001 | -0.043 |  0.048 |  0.016 | torch.Size([384]) || layers_up.1.blocks.3.norm2.bias
 |  0.000 | -0.094 |  0.111 |  0.021 | torch.Size([1536, 384]) || layers_up.1.blocks.3.mlp.fc1.weight
 | -0.008 | -0.030 |  0.016 |  0.008 | torch.Size([1536]) || layers_up.1.blocks.3.mlp.fc1.bias
 |  0.000 | -0.094 |  0.097 |  0.021 | torch.Size([384, 1536]) || layers_up.1.blocks.3.mlp.fc2.weight
 |  0.000 | -0.044 |  0.062 |  0.017 | torch.Size([384]) || layers_up.1.blocks.3.mlp.fc2.bias
 |  0.971 |  0.767 |  1.004 |  0.023 | torch.Size([384]) || layers_up.1.blocks.4.norm1.weight
 | -0.000 | -0.039 |  0.041 |  0.014 | torch.Size([384]) || layers_up.1.blocks.4.norm1.bias
 |  0.001 | -0.080 |  0.517 |  0.025 | torch.Size([225, 8]) || layers_up.1.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.1.blocks.4.attn.relative_position_index
 | -0.000 | -0.106 |  0.099 |  0.022 | torch.Size([1152, 384]) || layers_up.1.blocks.4.attn.qkv.weight
 |  0.000 | -0.025 |  0.025 |  0.007 | torch.Size([1152]) || layers_up.1.blocks.4.attn.qkv.bias
 | -0.000 | -0.092 |  0.085 |  0.021 | torch.Size([384, 384]) || layers_up.1.blocks.4.attn.proj.weight
 | -0.000 | -0.055 |  0.062 |  0.017 | torch.Size([384]) || layers_up.1.blocks.4.attn.proj.bias
 |  0.983 |  0.849 |  1.015 |  0.017 | torch.Size([384]) || layers_up.1.blocks.4.norm2.weight
 | -0.000 | -0.043 |  0.038 |  0.016 | torch.Size([384]) || layers_up.1.blocks.4.norm2.bias
 |  0.000 | -0.110 |  0.096 |  0.021 | torch.Size([1536, 384]) || layers_up.1.blocks.4.mlp.fc1.weight
 | -0.009 | -0.030 |  0.015 |  0.008 | torch.Size([1536]) || layers_up.1.blocks.4.mlp.fc1.bias
 |  0.000 | -0.098 |  0.090 |  0.021 | torch.Size([384, 1536]) || layers_up.1.blocks.4.mlp.fc2.weight
 |  0.000 | -0.047 |  0.061 |  0.016 | torch.Size([384]) || layers_up.1.blocks.4.mlp.fc2.bias
 | -43.750 | -100.000 |  0.000 | 49.609 | torch.Size([4, 64, 64]) || layers_up.1.blocks.5.attn_mask
 |  0.959 |  0.760 |  1.014 |  0.024 | torch.Size([384]) || layers_up.1.blocks.5.norm1.weight
 | -0.000 | -0.081 |  0.045 |  0.016 | torch.Size([384]) || layers_up.1.blocks.5.norm1.bias
 | -0.002 | -0.418 |  2.418 |  0.066 | torch.Size([225, 8]) || layers_up.1.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.1.blocks.5.attn.relative_position_index
 |  0.000 | -0.130 |  0.113 |  0.022 | torch.Size([1152, 384]) || layers_up.1.blocks.5.attn.qkv.weight
 |  0.000 | -0.024 |  0.024 |  0.006 | torch.Size([1152]) || layers_up.1.blocks.5.attn.qkv.bias
 | -0.000 | -0.127 |  0.119 |  0.023 | torch.Size([384, 384]) || layers_up.1.blocks.5.attn.proj.weight
 |  0.000 | -0.040 |  0.043 |  0.015 | torch.Size([384]) || layers_up.1.blocks.5.attn.proj.bias
 |  0.987 |  0.841 |  1.020 |  0.018 | torch.Size([384]) || layers_up.1.blocks.5.norm2.weight
 |  0.001 | -0.036 |  0.033 |  0.012 | torch.Size([384]) || layers_up.1.blocks.5.norm2.bias
 | -0.000 | -0.102 |  0.104 |  0.022 | torch.Size([1536, 384]) || layers_up.1.blocks.5.mlp.fc1.weight
 | -0.004 | -0.028 |  0.020 |  0.009 | torch.Size([1536]) || layers_up.1.blocks.5.mlp.fc1.bias
 | -0.000 | -0.095 |  0.100 |  0.021 | torch.Size([384, 1536]) || layers_up.1.blocks.5.mlp.fc2.weight
 |  0.000 | -0.043 |  0.061 |  0.017 | torch.Size([384]) || layers_up.1.blocks.5.mlp.fc2.bias
 |  0.972 |  0.772 |  1.004 |  0.022 | torch.Size([384]) || layers_up.1.blocks.6.norm1.weight
 | -0.000 | -0.057 |  0.050 |  0.016 | torch.Size([384]) || layers_up.1.blocks.6.norm1.bias
 | -0.000 | -0.078 |  0.093 |  0.020 | torch.Size([225, 8]) || layers_up.1.blocks.6.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.1.blocks.6.attn.relative_position_index
 | -0.000 | -0.094 |  0.102 |  0.021 | torch.Size([1152, 384]) || layers_up.1.blocks.6.attn.qkv.weight
 |  0.000 | -0.027 |  0.029 |  0.006 | torch.Size([1152]) || layers_up.1.blocks.6.attn.qkv.bias
 | -0.000 | -0.103 |  0.089 |  0.021 | torch.Size([384, 384]) || layers_up.1.blocks.6.attn.proj.weight
 | -0.000 | -0.040 |  0.043 |  0.015 | torch.Size([384]) || layers_up.1.blocks.6.attn.proj.bias
 |  0.984 |  0.863 |  1.017 |  0.018 | torch.Size([384]) || layers_up.1.blocks.6.norm2.weight
 | -0.000 | -0.036 |  0.031 |  0.012 | torch.Size([384]) || layers_up.1.blocks.6.norm2.bias
 |  0.000 | -0.096 |  0.106 |  0.022 | torch.Size([1536, 384]) || layers_up.1.blocks.6.mlp.fc1.weight
 | -0.007 | -0.053 |  0.022 |  0.009 | torch.Size([1536]) || layers_up.1.blocks.6.mlp.fc1.bias
 |  0.000 | -1.962 |  0.093 |  0.021 | torch.Size([384, 1536]) || layers_up.1.blocks.6.mlp.fc2.weight
 | -0.000 | -0.048 |  0.047 |  0.017 | torch.Size([384]) || layers_up.1.blocks.6.mlp.fc2.bias
 | -43.750 | -100.000 |  0.000 | 49.609 | torch.Size([4, 64, 64]) || layers_up.1.blocks.7.attn_mask
 |  0.961 |  0.778 |  1.006 |  0.024 | torch.Size([384]) || layers_up.1.blocks.7.norm1.weight
 |  0.000 | -0.071 |  0.061 |  0.019 | torch.Size([384]) || layers_up.1.blocks.7.norm1.bias
 | -0.001 | -0.286 |  1.754 |  0.068 | torch.Size([225, 8]) || layers_up.1.blocks.7.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.1.blocks.7.attn.relative_position_index
 | -0.000 | -0.128 |  0.123 |  0.022 | torch.Size([1152, 384]) || layers_up.1.blocks.7.attn.qkv.weight
 | -0.000 | -0.025 |  0.028 |  0.006 | torch.Size([1152]) || layers_up.1.blocks.7.attn.qkv.bias
 | -0.000 | -0.121 |  0.143 |  0.024 | torch.Size([384, 384]) || layers_up.1.blocks.7.attn.proj.weight
 | -0.000 | -0.047 |  0.041 |  0.016 | torch.Size([384]) || layers_up.1.blocks.7.attn.proj.bias
 |  0.985 |  0.904 |  1.018 |  0.016 | torch.Size([384]) || layers_up.1.blocks.7.norm2.weight
 |  0.000 | -0.037 |  0.039 |  0.012 | torch.Size([384]) || layers_up.1.blocks.7.norm2.bias
 |  0.000 | -0.104 |  0.098 |  0.022 | torch.Size([1536, 384]) || layers_up.1.blocks.7.mlp.fc1.weight
 | -0.007 | -0.035 |  0.022 |  0.009 | torch.Size([1536]) || layers_up.1.blocks.7.mlp.fc1.bias
 |  0.000 | -0.106 |  0.097 |  0.021 | torch.Size([384, 1536]) || layers_up.1.blocks.7.mlp.fc2.weight
 | -0.000 | -0.060 |  0.054 |  0.019 | torch.Size([384]) || layers_up.1.blocks.7.mlp.fc2.bias
 | -0.000 | -0.105 |  0.116 |  0.031 | torch.Size([192, 384, 1, 1]) || layers_up.1.upsample.conv.weight
 | -0.000 | -0.136 |  0.129 |  0.034 | torch.Size([768, 384, 1, 1]) || layers_up.1.upsample.up_p.0.weight
 |  0.380 |  0.380 |  0.380 |    nan | torch.Size([1]) || layers_up.1.upsample.up_p.1.weight
 |  0.000 | -0.133 |  0.134 |  0.041 | torch.Size([192, 192, 1, 1]) || layers_up.1.upsample.up_p.3.weight
 | -0.000 | -0.113 |  0.126 |  0.032 | torch.Size([384, 384, 1, 1]) || layers_up.1.upsample.up_b.0.weight
 | -0.008 | -0.075 |  0.129 |  0.034 | torch.Size([384]) || layers_up.1.upsample.up_b.0.bias
 |  0.155 |  0.155 |  0.155 |    nan | torch.Size([1]) || layers_up.1.upsample.up_b.1.weight
 |  0.000 | -0.105 |  0.113 |  0.032 | torch.Size([192, 384, 1, 1]) || layers_up.1.upsample.up_b.3.weight
 |  0.810 |  0.620 |  0.919 |  0.045 | torch.Size([192]) || layers_up.2.blocks.0.norm1.weight
 | -0.003 | -0.189 |  0.235 |  0.063 | torch.Size([192]) || layers_up.2.blocks.0.norm1.bias
 | -0.000 | -0.233 |  0.398 |  0.029 | torch.Size([225, 8]) || layers_up.2.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.2.blocks.0.attn.relative_position_index
 | -0.000 | -0.125 |  0.154 |  0.027 | torch.Size([576, 192]) || layers_up.2.blocks.0.attn.qkv.weight
 |  0.000 | -0.072 |  0.068 |  0.018 | torch.Size([576]) || layers_up.2.blocks.0.attn.qkv.bias
 |  0.000 | -0.117 |  0.111 |  0.028 | torch.Size([192, 192]) || layers_up.2.blocks.0.attn.proj.weight
 | -0.002 | -0.097 |  0.059 |  0.026 | torch.Size([192]) || layers_up.2.blocks.0.attn.proj.bias
 |  1.067 |  0.937 |  1.168 |  0.045 | torch.Size([192]) || layers_up.2.blocks.0.norm2.weight
 | -0.003 | -0.129 |  0.109 |  0.058 | torch.Size([192]) || layers_up.2.blocks.0.norm2.bias
 |  0.000 | -0.199 |  0.194 |  0.039 | torch.Size([768, 192]) || layers_up.2.blocks.0.mlp.fc1.weight
 | -0.031 | -0.118 |  0.035 |  0.023 | torch.Size([768]) || layers_up.2.blocks.0.mlp.fc1.bias
 |  0.000 | -0.220 |  0.186 |  0.032 | torch.Size([192, 768]) || layers_up.2.blocks.0.mlp.fc2.weight
 | -0.003 | -0.105 |  0.064 |  0.028 | torch.Size([192]) || layers_up.2.blocks.0.mlp.fc2.bias
 | -23.438 | -100.000 |  0.000 | 42.361 | torch.Size([16, 64, 64]) || layers_up.2.blocks.1.attn_mask
 |  0.826 |  0.632 |  0.928 |  0.048 | torch.Size([192]) || layers_up.2.blocks.1.norm1.weight
 | -0.003 | -0.266 |  0.250 |  0.078 | torch.Size([192]) || layers_up.2.blocks.1.norm1.bias
 |  0.000 | -0.285 |  0.225 |  0.026 | torch.Size([225, 8]) || layers_up.2.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.2.blocks.1.attn.relative_position_index
 | -0.000 | -0.128 |  0.139 |  0.028 | torch.Size([576, 192]) || layers_up.2.blocks.1.attn.qkv.weight
 |  0.000 | -0.056 |  0.051 |  0.015 | torch.Size([576]) || layers_up.2.blocks.1.attn.qkv.bias
 | -0.000 | -0.134 |  0.130 |  0.031 | torch.Size([192, 192]) || layers_up.2.blocks.1.attn.proj.weight
 | -0.003 | -0.092 |  0.050 |  0.022 | torch.Size([192]) || layers_up.2.blocks.1.attn.proj.bias
 |  1.049 |  0.922 |  1.146 |  0.042 | torch.Size([192]) || layers_up.2.blocks.1.norm2.weight
 | -0.001 | -0.059 |  0.061 |  0.023 | torch.Size([192]) || layers_up.2.blocks.1.norm2.bias
 | -0.000 | -0.230 |  0.269 |  0.037 | torch.Size([768, 192]) || layers_up.2.blocks.1.mlp.fc1.weight
 | -0.019 | -0.085 |  0.047 |  0.020 | torch.Size([768]) || layers_up.2.blocks.1.mlp.fc1.bias
 |  0.000 | -0.174 |  0.186 |  0.031 | torch.Size([192, 768]) || layers_up.2.blocks.1.mlp.fc2.weight
 | -0.004 | -0.101 |  0.064 |  0.029 | torch.Size([192]) || layers_up.2.blocks.1.mlp.fc2.bias
 |  0.834 |  0.634 |  0.941 |  0.052 | torch.Size([192]) || layers_up.2.blocks.2.norm1.weight
 | -0.003 | -0.287 |  0.335 |  0.084 | torch.Size([192]) || layers_up.2.blocks.2.norm1.bias
 | -0.000 | -0.937 |  0.637 |  0.053 | torch.Size([225, 8]) || layers_up.2.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.2.blocks.2.attn.relative_position_index
 |  0.000 | -0.145 |  0.158 |  0.031 | torch.Size([576, 192]) || layers_up.2.blocks.2.attn.qkv.weight
 | -0.000 | -0.056 |  0.071 |  0.015 | torch.Size([576]) || layers_up.2.blocks.2.attn.qkv.bias
 |  0.000 | -0.152 |  0.157 |  0.036 | torch.Size([192, 192]) || layers_up.2.blocks.2.attn.proj.weight
 | -0.001 | -0.089 |  0.044 |  0.021 | torch.Size([192]) || layers_up.2.blocks.2.attn.proj.bias
 |  1.075 |  0.960 |  1.170 |  0.044 | torch.Size([192]) || layers_up.2.blocks.2.norm2.weight
 | -0.002 | -0.064 |  0.057 |  0.026 | torch.Size([192]) || layers_up.2.blocks.2.norm2.bias
 | -0.000 | -0.196 |  0.187 |  0.041 | torch.Size([768, 192]) || layers_up.2.blocks.2.mlp.fc1.weight
 | -0.018 | -0.080 |  0.040 |  0.019 | torch.Size([768]) || layers_up.2.blocks.2.mlp.fc1.bias
 |  0.000 | -0.225 |  0.172 |  0.033 | torch.Size([192, 768]) || layers_up.2.blocks.2.mlp.fc2.weight
 | -0.004 | -0.103 |  0.060 |  0.032 | torch.Size([192]) || layers_up.2.blocks.2.mlp.fc2.bias
 | -23.438 | -100.000 |  0.000 | 42.361 | torch.Size([16, 64, 64]) || layers_up.2.blocks.3.attn_mask
 |  0.872 |  0.550 |  0.991 |  0.055 | torch.Size([192]) || layers_up.2.blocks.3.norm1.weight
 | -0.004 | -0.338 |  0.323 |  0.075 | torch.Size([192]) || layers_up.2.blocks.3.norm1.bias
 | -0.019 | -1.566 |  3.494 |  0.155 | torch.Size([225, 8]) || layers_up.2.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.2.blocks.3.attn.relative_position_index
 | -0.000 | -0.192 |  0.195 |  0.034 | torch.Size([576, 192]) || layers_up.2.blocks.3.attn.qkv.weight
 |  0.001 | -0.055 |  0.058 |  0.015 | torch.Size([576]) || layers_up.2.blocks.3.attn.qkv.bias
 | -0.000 | -0.198 |  0.195 |  0.041 | torch.Size([192, 192]) || layers_up.2.blocks.3.attn.proj.weight
 |  0.000 | -0.105 |  0.068 |  0.026 | torch.Size([192]) || layers_up.2.blocks.3.attn.proj.bias
 |  1.074 |  0.910 |  1.187 |  0.050 | torch.Size([192]) || layers_up.2.blocks.3.norm2.weight
 | -0.003 | -0.081 |  0.104 |  0.029 | torch.Size([192]) || layers_up.2.blocks.3.norm2.bias
 | -0.000 | -0.213 |  0.190 |  0.039 | torch.Size([768, 192]) || layers_up.2.blocks.3.mlp.fc1.weight
 | -0.016 | -0.082 |  0.052 |  0.021 | torch.Size([768]) || layers_up.2.blocks.3.mlp.fc1.bias
 |  0.001 | -0.168 |  0.149 |  0.032 | torch.Size([192, 768]) || layers_up.2.blocks.3.mlp.fc2.weight
 | -0.002 | -0.103 |  0.063 |  0.032 | torch.Size([192]) || layers_up.2.blocks.3.mlp.fc2.bias
 |  0.858 |  0.562 |  0.966 |  0.050 | torch.Size([192]) || layers_up.2.blocks.4.norm1.weight
 | -0.004 | -0.270 |  0.359 |  0.070 | torch.Size([192]) || layers_up.2.blocks.4.norm1.bias
 | -0.001 | -1.865 |  2.298 |  0.116 | torch.Size([225, 8]) || layers_up.2.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.2.blocks.4.attn.relative_position_index
 | -0.000 | -0.191 |  0.198 |  0.034 | torch.Size([576, 192]) || layers_up.2.blocks.4.attn.qkv.weight
 |  0.000 | -0.051 |  0.054 |  0.017 | torch.Size([576]) || layers_up.2.blocks.4.attn.qkv.bias
 | -0.000 | -0.194 |  0.191 |  0.041 | torch.Size([192, 192]) || layers_up.2.blocks.4.attn.proj.weight
 | -0.001 | -0.090 |  0.052 |  0.025 | torch.Size([192]) || layers_up.2.blocks.4.attn.proj.bias
 |  1.092 |  0.943 |  1.204 |  0.047 | torch.Size([192]) || layers_up.2.blocks.4.norm2.weight
 | -0.002 | -0.084 |  0.085 |  0.038 | torch.Size([192]) || layers_up.2.blocks.4.norm2.bias
 | -0.000 | -0.201 |  0.190 |  0.041 | torch.Size([768, 192]) || layers_up.2.blocks.4.mlp.fc1.weight
 | -0.017 | -0.091 |  0.049 |  0.023 | torch.Size([768]) || layers_up.2.blocks.4.mlp.fc1.bias
 |  0.000 | -0.166 |  0.164 |  0.033 | torch.Size([192, 768]) || layers_up.2.blocks.4.mlp.fc2.weight
 | -0.001 | -0.096 |  0.070 |  0.035 | torch.Size([192]) || layers_up.2.blocks.4.mlp.fc2.bias
 | -23.438 | -100.000 |  0.000 | 42.361 | torch.Size([16, 64, 64]) || layers_up.2.blocks.5.attn_mask
 |  0.860 |  0.543 |  0.953 |  0.049 | torch.Size([192]) || layers_up.2.blocks.5.norm1.weight
 | -0.008 | -0.292 |  0.369 |  0.073 | torch.Size([192]) || layers_up.2.blocks.5.norm1.bias
 | -0.007 | -1.396 |  1.729 |  0.111 | torch.Size([225, 8]) || layers_up.2.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.2.blocks.5.attn.relative_position_index
 | -0.000 | -0.176 |  0.196 |  0.034 | torch.Size([576, 192]) || layers_up.2.blocks.5.attn.qkv.weight
 | -0.000 | -0.067 |  0.066 |  0.018 | torch.Size([576]) || layers_up.2.blocks.5.attn.qkv.bias
 | -0.000 | -0.160 |  0.192 |  0.040 | torch.Size([192, 192]) || layers_up.2.blocks.5.attn.proj.weight
 | -0.002 | -0.094 |  0.059 |  0.028 | torch.Size([192]) || layers_up.2.blocks.5.attn.proj.bias
 |  1.105 |  0.888 |  1.235 |  0.051 | torch.Size([192]) || layers_up.2.blocks.5.norm2.weight
 | -0.002 | -0.149 |  0.126 |  0.050 | torch.Size([192]) || layers_up.2.blocks.5.norm2.bias
 | -0.001 | -0.192 |  0.220 |  0.042 | torch.Size([768, 192]) || layers_up.2.blocks.5.mlp.fc1.weight
 | -0.015 | -0.092 |  0.054 |  0.025 | torch.Size([768]) || layers_up.2.blocks.5.mlp.fc1.bias
 |  0.000 | -0.165 |  0.171 |  0.034 | torch.Size([192, 768]) || layers_up.2.blocks.5.mlp.fc2.weight
 | -0.002 | -0.096 |  0.094 |  0.035 | torch.Size([192]) || layers_up.2.blocks.5.mlp.fc2.bias
 |  0.853 |  0.480 |  0.971 |  0.056 | torch.Size([192]) || layers_up.2.blocks.6.norm1.weight
 | -0.006 | -0.276 |  0.446 |  0.078 | torch.Size([192]) || layers_up.2.blocks.6.norm1.bias
 | -0.003 | -1.918 |  0.946 |  0.117 | torch.Size([225, 8]) || layers_up.2.blocks.6.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.2.blocks.6.attn.relative_position_index
 |  0.000 | -0.192 |  0.191 |  0.035 | torch.Size([576, 192]) || layers_up.2.blocks.6.attn.qkv.weight
 |  0.000 | -0.094 |  0.067 |  0.018 | torch.Size([576]) || layers_up.2.blocks.6.attn.qkv.bias
 |  0.000 | -0.198 |  0.220 |  0.043 | torch.Size([192, 192]) || layers_up.2.blocks.6.attn.proj.weight
 | -0.002 | -0.123 |  0.114 |  0.042 | torch.Size([192]) || layers_up.2.blocks.6.attn.proj.bias
 |  1.122 |  0.901 |  1.278 |  0.059 | torch.Size([192]) || layers_up.2.blocks.6.norm2.weight
 | -0.001 | -0.141 |  0.115 |  0.044 | torch.Size([192]) || layers_up.2.blocks.6.norm2.bias
 | -0.001 | -0.214 |  0.211 |  0.043 | torch.Size([768, 192]) || layers_up.2.blocks.6.mlp.fc1.weight
 | -0.016 | -0.098 |  0.058 |  0.024 | torch.Size([768]) || layers_up.2.blocks.6.mlp.fc1.bias
 | -0.000 | -0.172 |  0.180 |  0.036 | torch.Size([192, 768]) || layers_up.2.blocks.6.mlp.fc2.weight
 |  0.000 | -0.091 |  0.100 |  0.038 | torch.Size([192]) || layers_up.2.blocks.6.mlp.fc2.bias
 | -23.438 | -100.000 |  0.000 | 42.361 | torch.Size([16, 64, 64]) || layers_up.2.blocks.7.attn_mask
 |  0.862 |  0.506 |  0.957 |  0.054 | torch.Size([192]) || layers_up.2.blocks.7.norm1.weight
 | -0.005 | -0.292 |  0.390 |  0.083 | torch.Size([192]) || layers_up.2.blocks.7.norm1.bias
 | -0.009 | -1.512 |  2.186 |  0.120 | torch.Size([225, 8]) || layers_up.2.blocks.7.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.2.blocks.7.attn.relative_position_index
 |  0.000 | -0.210 |  0.190 |  0.035 | torch.Size([576, 192]) || layers_up.2.blocks.7.attn.qkv.weight
 | -0.001 | -0.066 |  0.060 |  0.019 | torch.Size([576]) || layers_up.2.blocks.7.attn.qkv.bias
 |  0.000 | -0.193 |  0.152 |  0.040 | torch.Size([192, 192]) || layers_up.2.blocks.7.attn.proj.weight
 |  0.000 | -0.111 |  0.119 |  0.050 | torch.Size([192]) || layers_up.2.blocks.7.attn.proj.bias
 |  1.114 |  0.857 |  1.284 |  0.063 | torch.Size([192]) || layers_up.2.blocks.7.norm2.weight
 | -0.003 | -0.086 |  0.114 |  0.033 | torch.Size([192]) || layers_up.2.blocks.7.norm2.bias
 | -0.000 | -0.192 |  0.211 |  0.044 | torch.Size([768, 192]) || layers_up.2.blocks.7.mlp.fc1.weight
 | -0.012 | -0.081 |  0.061 |  0.023 | torch.Size([768]) || layers_up.2.blocks.7.mlp.fc1.bias
 | -0.000 | -0.180 |  0.184 |  0.036 | torch.Size([192, 768]) || layers_up.2.blocks.7.mlp.fc2.weight
 |  0.000 | -0.104 |  0.099 |  0.042 | torch.Size([192]) || layers_up.2.blocks.7.mlp.fc2.bias
 |  0.000 | -0.158 |  0.189 |  0.045 | torch.Size([96, 192, 1, 1]) || layers_up.2.upsample.conv.weight
 | -0.000 | -0.218 |  0.214 |  0.054 | torch.Size([384, 192, 1, 1]) || layers_up.2.upsample.up_p.0.weight
 |  0.246 |  0.246 |  0.246 |    nan | torch.Size([1]) || layers_up.2.upsample.up_p.1.weight
 |  0.000 | -0.215 |  0.235 |  0.059 | torch.Size([96, 96, 1, 1]) || layers_up.2.upsample.up_p.3.weight
 |  0.000 | -0.203 |  0.198 |  0.048 | torch.Size([192, 192, 1, 1]) || layers_up.2.upsample.up_b.0.weight
 | -0.031 | -0.162 |  0.075 |  0.049 | torch.Size([192]) || layers_up.2.upsample.up_b.0.bias
 |  0.045 |  0.045 |  0.045 |    nan | torch.Size([1]) || layers_up.2.upsample.up_b.1.weight
 |  0.000 | -0.192 |  0.182 |  0.046 | torch.Size([96, 192, 1, 1]) || layers_up.2.upsample.up_b.3.weight
 |  1.004 |  0.813 |  1.187 |  0.082 | torch.Size([96]) || layers_up.3.blocks.0.norm1.weight
 | -0.000 | -0.274 |  0.231 |  0.080 | torch.Size([96]) || layers_up.3.blocks.0.norm1.bias
 | -0.144 | -0.839 |  1.800 |  0.324 | torch.Size([225, 8]) || layers_up.3.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.3.blocks.0.attn.relative_position_index
 |  0.000 | -0.507 |  0.576 |  0.071 | torch.Size([288, 96]) || layers_up.3.blocks.0.attn.qkv.weight
 |  0.000 | -0.068 |  0.070 |  0.016 | torch.Size([288]) || layers_up.3.blocks.0.attn.qkv.bias
 | -0.000 | -0.229 |  0.236 |  0.046 | torch.Size([96, 96]) || layers_up.3.blocks.0.attn.proj.weight
 |  0.002 | -0.053 |  0.045 |  0.019 | torch.Size([96]) || layers_up.3.blocks.0.attn.proj.bias
 |  0.979 |  0.840 |  1.204 |  0.063 | torch.Size([96]) || layers_up.3.blocks.0.norm2.weight
 |  0.003 | -0.101 |  0.115 |  0.044 | torch.Size([96]) || layers_up.3.blocks.0.norm2.bias
 | -0.000 | -0.265 |  0.339 |  0.048 | torch.Size([384, 96]) || layers_up.3.blocks.0.mlp.fc1.weight
 | -0.000 | -0.052 |  0.041 |  0.018 | torch.Size([384]) || layers_up.3.blocks.0.mlp.fc1.bias
 | -0.000 | -0.247 |  0.217 |  0.037 | torch.Size([96, 384]) || layers_up.3.blocks.0.mlp.fc2.weight
 |  0.001 | -0.065 |  0.043 |  0.018 | torch.Size([96]) || layers_up.3.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers_up.3.blocks.1.attn_mask
 |  1.076 |  0.827 |  1.224 |  0.099 | torch.Size([96]) || layers_up.3.blocks.1.norm1.weight
 | -0.000 | -0.301 |  0.240 |  0.073 | torch.Size([96]) || layers_up.3.blocks.1.norm1.bias
 | -0.136 | -0.828 |  1.740 |  0.313 | torch.Size([225, 8]) || layers_up.3.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.3.blocks.1.attn.relative_position_index
 |  0.000 | -0.495 |  0.554 |  0.087 | torch.Size([288, 96]) || layers_up.3.blocks.1.attn.qkv.weight
 |  0.000 | -0.125 |  0.140 |  0.026 | torch.Size([288]) || layers_up.3.blocks.1.attn.qkv.bias
 | -0.001 | -0.283 |  0.281 |  0.050 | torch.Size([96, 96]) || layers_up.3.blocks.1.attn.proj.weight
 |  0.001 | -0.073 |  0.065 |  0.019 | torch.Size([96]) || layers_up.3.blocks.1.attn.proj.bias
 |  0.974 |  0.730 |  1.136 |  0.082 | torch.Size([96]) || layers_up.3.blocks.1.norm2.weight
 |  0.002 | -0.235 |  0.202 |  0.066 | torch.Size([96]) || layers_up.3.blocks.1.norm2.bias
 |  0.000 | -0.415 |  0.341 |  0.048 | torch.Size([384, 96]) || layers_up.3.blocks.1.mlp.fc1.weight
 | -0.005 | -0.069 |  0.032 |  0.015 | torch.Size([384]) || layers_up.3.blocks.1.mlp.fc1.bias
 | -0.000 | -0.233 |  0.235 |  0.032 | torch.Size([96, 384]) || layers_up.3.blocks.1.mlp.fc2.weight
 |  0.002 | -0.049 |  0.036 |  0.017 | torch.Size([96]) || layers_up.3.blocks.1.mlp.fc2.bias
 |  1.080 |  0.751 |  1.383 |  0.140 | torch.Size([96]) || layers_up.3.blocks.2.norm1.weight
 | -0.000 | -0.327 |  0.322 |  0.100 | torch.Size([96]) || layers_up.3.blocks.2.norm1.bias
 | -0.066 | -0.623 |  1.900 |  0.231 | torch.Size([225, 8]) || layers_up.3.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.3.blocks.2.attn.relative_position_index
 | -0.000 | -0.470 |  0.513 |  0.083 | torch.Size([288, 96]) || layers_up.3.blocks.2.attn.qkv.weight
 |  0.000 | -0.107 |  0.107 |  0.022 | torch.Size([288]) || layers_up.3.blocks.2.attn.qkv.bias
 | -0.000 | -0.252 |  0.272 |  0.051 | torch.Size([96, 96]) || layers_up.3.blocks.2.attn.proj.weight
 | -0.000 | -0.070 |  0.072 |  0.021 | torch.Size([96]) || layers_up.3.blocks.2.attn.proj.bias
 |  0.959 |  0.689 |  1.116 |  0.110 | torch.Size([96]) || layers_up.3.blocks.2.norm2.weight
 | -0.000 | -0.278 |  0.301 |  0.084 | torch.Size([96]) || layers_up.3.blocks.2.norm2.bias
 | -0.000 | -0.439 |  0.428 |  0.044 | torch.Size([384, 96]) || layers_up.3.blocks.2.mlp.fc1.weight
 | -0.005 | -0.085 |  0.026 |  0.014 | torch.Size([384]) || layers_up.3.blocks.2.mlp.fc1.bias
 | -0.000 | -0.295 |  0.402 |  0.031 | torch.Size([96, 384]) || layers_up.3.blocks.2.mlp.fc2.weight
 |  0.002 | -0.048 |  0.045 |  0.017 | torch.Size([96]) || layers_up.3.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers_up.3.blocks.3.attn_mask
 |  1.097 |  0.785 |  1.329 |  0.151 | torch.Size([96]) || layers_up.3.blocks.3.norm1.weight
 | -0.003 | -0.349 |  0.295 |  0.098 | torch.Size([96]) || layers_up.3.blocks.3.norm1.bias
 | -0.094 | -0.722 |  1.524 |  0.233 | torch.Size([225, 8]) || layers_up.3.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.3.blocks.3.attn.relative_position_index
 | -0.000 | -0.461 |  0.515 |  0.088 | torch.Size([288, 96]) || layers_up.3.blocks.3.attn.qkv.weight
 |  0.000 | -0.097 |  0.091 |  0.017 | torch.Size([288]) || layers_up.3.blocks.3.attn.qkv.bias
 |  0.000 | -0.286 |  0.257 |  0.055 | torch.Size([96, 96]) || layers_up.3.blocks.3.attn.proj.weight
 | -0.001 | -0.065 |  0.069 |  0.023 | torch.Size([96]) || layers_up.3.blocks.3.attn.proj.bias
 |  0.920 |  0.587 |  1.140 |  0.131 | torch.Size([96]) || layers_up.3.blocks.3.norm2.weight
 | -0.000 | -0.350 |  0.342 |  0.099 | torch.Size([96]) || layers_up.3.blocks.3.norm2.bias
 | -0.000 | -0.336 |  0.385 |  0.040 | torch.Size([384, 96]) || layers_up.3.blocks.3.mlp.fc1.weight
 | -0.006 | -0.091 |  0.039 |  0.014 | torch.Size([384]) || layers_up.3.blocks.3.mlp.fc1.bias
 |  0.000 | -0.215 |  0.205 |  0.031 | torch.Size([96, 384]) || layers_up.3.blocks.3.mlp.fc2.weight
 |  0.001 | -0.047 |  0.038 |  0.015 | torch.Size([96]) || layers_up.3.blocks.3.mlp.fc2.bias
 |  1.091 |  0.683 |  1.345 |  0.168 | torch.Size([96]) || layers_up.3.blocks.4.norm1.weight
 | -0.005 | -0.338 |  0.354 |  0.103 | torch.Size([96]) || layers_up.3.blocks.4.norm1.bias
 | -0.089 | -0.475 |  1.359 |  0.195 | torch.Size([225, 8]) || layers_up.3.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.3.blocks.4.attn.relative_position_index
 | -0.000 | -0.482 |  0.490 |  0.082 | torch.Size([288, 96]) || layers_up.3.blocks.4.attn.qkv.weight
 |  0.002 | -0.091 |  0.111 |  0.022 | torch.Size([288]) || layers_up.3.blocks.4.attn.qkv.bias
 |  0.000 | -0.285 |  0.245 |  0.055 | torch.Size([96, 96]) || layers_up.3.blocks.4.attn.proj.weight
 | -0.000 | -0.062 |  0.065 |  0.020 | torch.Size([96]) || layers_up.3.blocks.4.attn.proj.bias
 |  0.859 |  0.521 |  1.055 |  0.148 | torch.Size([96]) || layers_up.3.blocks.4.norm2.weight
 | -0.002 | -0.366 |  0.462 |  0.128 | torch.Size([96]) || layers_up.3.blocks.4.norm2.bias
 |  0.000 | -0.338 |  0.408 |  0.035 | torch.Size([384, 96]) || layers_up.3.blocks.4.mlp.fc1.weight
 | -0.004 | -0.102 |  0.034 |  0.012 | torch.Size([384]) || layers_up.3.blocks.4.mlp.fc1.bias
 |  0.000 | -0.260 |  0.186 |  0.028 | torch.Size([96, 384]) || layers_up.3.blocks.4.mlp.fc2.weight
 |  0.001 | -0.042 |  0.039 |  0.015 | torch.Size([96]) || layers_up.3.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers_up.3.blocks.5.attn_mask
 |  1.082 |  0.560 |  1.378 |  0.214 | torch.Size([96]) || layers_up.3.blocks.5.norm1.weight
 | -0.000 | -0.418 |  0.476 |  0.128 | torch.Size([96]) || layers_up.3.blocks.5.norm1.bias
 | -0.086 | -0.371 |  2.049 |  0.224 | torch.Size([225, 8]) || layers_up.3.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.3.blocks.5.attn.relative_position_index
 |  0.000 | -0.429 |  0.489 |  0.082 | torch.Size([288, 96]) || layers_up.3.blocks.5.attn.qkv.weight
 | -0.001 | -0.103 |  0.083 |  0.018 | torch.Size([288]) || layers_up.3.blocks.5.attn.qkv.bias
 |  0.001 | -0.248 |  0.269 |  0.055 | torch.Size([96, 96]) || layers_up.3.blocks.5.attn.proj.weight
 | -0.000 | -0.047 |  0.055 |  0.015 | torch.Size([96]) || layers_up.3.blocks.5.attn.proj.bias
 |  0.884 |  0.507 |  1.119 |  0.153 | torch.Size([96]) || layers_up.3.blocks.5.norm2.weight
 | -0.008 | -0.465 |  0.395 |  0.126 | torch.Size([96]) || layers_up.3.blocks.5.norm2.bias
 |  0.000 | -0.393 |  0.418 |  0.036 | torch.Size([384, 96]) || layers_up.3.blocks.5.mlp.fc1.weight
 | -0.001 | -0.048 |  0.030 |  0.010 | torch.Size([384]) || layers_up.3.blocks.5.mlp.fc1.bias
 |  0.000 | -0.313 |  0.180 |  0.026 | torch.Size([96, 384]) || layers_up.3.blocks.5.mlp.fc2.weight
 |  0.000 | -0.045 |  0.038 |  0.015 | torch.Size([96]) || layers_up.3.blocks.5.mlp.fc2.bias
 |  1.140 |  0.715 |  1.412 |  0.191 | torch.Size([96]) || layers_up.3.blocks.6.norm1.weight
 | -0.002 | -0.297 |  0.304 |  0.094 | torch.Size([96]) || layers_up.3.blocks.6.norm1.bias
 | -0.139 | -0.474 |  1.431 |  0.255 | torch.Size([225, 8]) || layers_up.3.blocks.6.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.3.blocks.6.attn.relative_position_index
 | -0.000 | -0.445 |  0.472 |  0.092 | torch.Size([288, 96]) || layers_up.3.blocks.6.attn.qkv.weight
 | -0.000 | -0.110 |  0.110 |  0.018 | torch.Size([288]) || layers_up.3.blocks.6.attn.qkv.bias
 | -0.000 | -0.258 |  0.305 |  0.053 | torch.Size([96, 96]) || layers_up.3.blocks.6.attn.proj.weight
 | -0.001 | -0.073 |  0.077 |  0.031 | torch.Size([96]) || layers_up.3.blocks.6.attn.proj.bias
 |  0.910 |  0.462 |  1.110 |  0.170 | torch.Size([96]) || layers_up.3.blocks.6.norm2.weight
 | -0.004 | -0.460 |  0.465 |  0.136 | torch.Size([96]) || layers_up.3.blocks.6.norm2.bias
 | -0.000 | -0.442 |  0.399 |  0.040 | torch.Size([384, 96]) || layers_up.3.blocks.6.mlp.fc1.weight
 |  0.000 | -0.056 |  0.033 |  0.010 | torch.Size([384]) || layers_up.3.blocks.6.mlp.fc1.bias
 |  0.000 | -0.172 |  0.163 |  0.032 | torch.Size([96, 384]) || layers_up.3.blocks.6.mlp.fc2.weight
 |  0.001 | -0.041 |  0.051 |  0.016 | torch.Size([96]) || layers_up.3.blocks.6.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers_up.3.blocks.7.attn_mask
 |  1.121 |  0.653 |  1.431 |  0.202 | torch.Size([96]) || layers_up.3.blocks.7.norm1.weight
 | -0.004 | -0.387 |  0.340 |  0.100 | torch.Size([96]) || layers_up.3.blocks.7.norm1.bias
 | -0.170 | -0.564 |  1.840 |  0.266 | torch.Size([225, 8]) || layers_up.3.blocks.7.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers_up.3.blocks.7.attn.relative_position_index
 |  0.000 | -0.510 |  0.543 |  0.089 | torch.Size([288, 96]) || layers_up.3.blocks.7.attn.qkv.weight
 |  0.001 | -0.103 |  0.067 |  0.015 | torch.Size([288]) || layers_up.3.blocks.7.attn.qkv.bias
 | -0.000 | -0.305 |  0.232 |  0.051 | torch.Size([96, 96]) || layers_up.3.blocks.7.attn.proj.weight
 | -0.001 | -0.058 |  0.063 |  0.024 | torch.Size([96]) || layers_up.3.blocks.7.attn.proj.bias
 |  0.936 |  0.416 |  1.206 |  0.216 | torch.Size([96]) || layers_up.3.blocks.7.norm2.weight
 | -0.005 | -0.456 |  0.478 |  0.155 | torch.Size([96]) || layers_up.3.blocks.7.norm2.bias
 | -0.000 | -0.436 |  0.344 |  0.050 | torch.Size([384, 96]) || layers_up.3.blocks.7.mlp.fc1.weight
 | -0.000 | -0.094 |  0.032 |  0.010 | torch.Size([384]) || layers_up.3.blocks.7.mlp.fc1.bias
 | -0.000 | -0.184 |  0.217 |  0.039 | torch.Size([96, 384]) || layers_up.3.blocks.7.mlp.fc2.weight
 |  0.001 | -0.034 |  0.052 |  0.019 | torch.Size([96]) || layers_up.3.blocks.7.mlp.fc2.bias
 | -0.000 | -0.168 |  0.171 |  0.026 | torch.Size([384, 768]) || concat_back_dim.1.weight
 | -0.000 | -0.062 |  0.105 |  0.024 | torch.Size([384]) || concat_back_dim.1.bias
 |  0.000 | -0.168 |  0.221 |  0.036 | torch.Size([192, 384]) || concat_back_dim.2.weight
 | -0.005 | -0.119 |  0.073 |  0.031 | torch.Size([192]) || concat_back_dim.2.bias
 |  0.000 | -0.442 |  0.350 |  0.059 | torch.Size([96, 192]) || concat_back_dim.3.weight
 |  0.002 | -0.052 |  0.050 |  0.021 | torch.Size([96]) || concat_back_dim.3.bias
 |  0.976 |  0.934 |  0.998 |  0.014 | torch.Size([768]) || norm.weight
 | -0.001 | -0.039 |  0.039 |  0.020 | torch.Size([768]) || norm.bias
 |  0.988 |  0.857 |  1.077 |  0.044 | torch.Size([96]) || norm_up.weight
 |  0.003 | -0.102 |  0.117 |  0.027 | torch.Size([96]) || norm_up.bias
 |  0.000 | -0.167 |  0.170 |  0.040 | torch.Size([96, 192, 1, 1]) || up.conv.weight
 |  0.000 | -0.547 |  0.507 |  0.086 | torch.Size([1536, 96, 1, 1]) || up.up_p.0.weight
 |  0.126 |  0.126 |  0.126 |    nan | torch.Size([1]) || up.up_p.1.weight
 | -0.001 | -0.183 |  0.177 |  0.056 | torch.Size([96, 96, 1, 1]) || up.up_p.3.weight
 |  0.000 | -0.274 |  0.227 |  0.060 | torch.Size([96, 96, 1, 1]) || up.up_b.0.weight
 | -0.004 | -0.121 |  0.133 |  0.062 | torch.Size([96]) || up.up_b.0.bias
 |  0.169 |  0.169 |  0.169 |    nan | torch.Size([1]) || up.up_b.1.weight
 |  0.000 | -0.191 |  0.230 |  0.059 | torch.Size([96, 96, 1, 1]) || up.up_b.3.weight
 |  0.001 | -0.096 |  0.068 |  0.022 | torch.Size([3, 96, 3, 3]) || output.weight

25-05-12 08:49:49.917 : <epoch:  0, iter:  10,000, lr:1.000e-04> G_loss: 1.249e-03 
25-05-12 08:49:49.918 : Saving the model.
25-05-12 08:49:52.316 : ---1--> airplane_111.jpg | 34.70dB
25-05-12 08:49:52.431 : ---2--> airport_111.jpg | 35.01dB
25-05-12 08:49:52.520 : ---3--> baseball_diamond_111.jpg | 35.42dB
25-05-12 08:49:52.563 : ---4--> basketball_court_111.jpg | 33.89dB
25-05-12 08:49:52.604 : ---5--> beach_111.jpg | 33.14dB
25-05-12 08:49:52.658 : ---6--> bridge_111.jpg | 37.53dB
25-05-12 08:49:52.713 : ---7--> chaparral_111.jpg | 32.43dB
25-05-12 08:49:52.754 : ---8--> church_111.jpg | 33.44dB
25-05-12 08:49:52.797 : ---9--> circular_farmland_111.jpg | 35.94dB
25-05-12 08:49:52.840 : --10--> cloud_111.jpg | 38.84dB
25-05-12 08:49:52.888 : --11--> commercial_area_111.jpg | 35.32dB
25-05-12 08:49:52.934 : --12--> dense_residential_111.jpg | 32.13dB
25-05-12 08:49:52.985 : --13--> desert_111.jpg | 33.28dB
25-05-12 08:49:53.029 : --14--> forest_111.jpg | 34.24dB
25-05-12 08:49:53.070 : --15--> freeway_111.jpg | 35.64dB
25-05-12 08:49:53.115 : --16--> golf_course_111.jpg | 35.07dB
25-05-12 08:49:53.154 : --17--> ground_track_field_111.jpg | 33.09dB
25-05-12 08:49:53.197 : --18--> harbor_111.jpg | 33.96dB
25-05-12 08:49:53.242 : --19--> industrial_area_111.jpg | 33.91dB
25-05-12 08:49:53.285 : --20--> intersection_111.jpg | 32.99dB
25-05-12 08:49:53.331 : --21--> island_111.jpg | 34.64dB
25-05-12 08:49:53.374 : --22--> lake_111.jpg | 34.16dB
25-05-12 08:49:53.419 : --23--> meadow_111.jpg | 32.84dB
25-05-12 08:49:53.461 : --24--> medium_residential_111.jpg | 31.22dB
25-05-12 08:49:53.503 : --25--> mobile_home_park_111.jpg | 33.79dB
25-05-12 08:49:53.565 : --26--> mountain_111.jpg | 32.07dB
25-05-12 08:49:53.606 : --27--> overpass_111.jpg | 32.55dB
25-05-12 08:49:53.647 : --28--> palace_111.jpg | 32.58dB
25-05-12 08:49:53.690 : --29--> parking_lot_111.jpg | 32.47dB
25-05-12 08:49:53.731 : --30--> railway_111.jpg | 32.62dB
25-05-12 08:49:53.775 : --31--> railway_station_111.jpg | 33.56dB
25-05-12 08:49:53.817 : --32--> rectangular_farmland_111.jpg | 35.53dB
25-05-12 08:49:53.891 : --33--> river_111.jpg | 32.84dB
25-05-12 08:49:53.939 : --34--> roundabout_111.jpg | 33.14dB
25-05-12 08:49:53.980 : --35--> runway_111.jpg | 37.74dB
25-05-12 08:49:54.022 : --36--> sea_ice_111.jpg | 34.92dB
25-05-12 08:49:54.074 : --37--> ship_111.jpg | 39.50dB
25-05-12 08:49:54.122 : --38--> snowberg_111.jpg | 34.24dB
25-05-12 08:49:54.161 : --39--> sparse_residential_111.jpg | 32.83dB
25-05-12 08:49:54.203 : --40--> stadium_111.jpg | 32.78dB
25-05-12 08:49:54.248 : --41--> storage_tank_111.jpg | 33.89dB
25-05-12 08:49:54.292 : --42--> tennis_court_111.jpg | 33.35dB
25-05-12 08:49:54.340 : --43--> terrace_111.jpg | 34.86dB
25-05-12 08:49:54.381 : --44--> thermal_power_station_111.jpg | 33.21dB
25-05-12 08:49:54.423 : --45--> wetland_111.jpg | 33.57dB
25-05-12 08:49:54.430 : <epoch:  0, iter:  10,000, Average PSNR : 34.11dB

25-05-12 09:14:23.425 : <epoch:  0, iter:  20,000, lr:1.000e-04> G_loss: 1.883e-03 
25-05-12 09:14:23.426 : Saving the model.
25-05-12 09:14:25.960 : ---1--> airplane_111.jpg | 34.85dB
25-05-12 09:14:26.063 : ---2--> airport_111.jpg | 35.23dB
25-05-12 09:14:26.167 : ---3--> baseball_diamond_111.jpg | 35.98dB
25-05-12 09:14:26.212 : ---4--> basketball_court_111.jpg | 34.14dB
25-05-12 09:14:26.256 : ---5--> beach_111.jpg | 33.28dB
25-05-12 09:14:26.302 : ---6--> bridge_111.jpg | 37.75dB
25-05-12 09:14:26.346 : ---7--> chaparral_111.jpg | 32.77dB
25-05-12 09:14:26.399 : ---8--> church_111.jpg | 34.06dB
25-05-12 09:14:26.447 : ---9--> circular_farmland_111.jpg | 36.19dB
25-05-12 09:14:26.488 : --10--> cloud_111.jpg | 38.20dB
25-05-12 09:14:26.534 : --11--> commercial_area_111.jpg | 35.63dB
25-05-12 09:14:26.578 : --12--> dense_residential_111.jpg | 32.29dB
25-05-12 09:14:26.620 : --13--> desert_111.jpg | 37.93dB
25-05-12 09:14:26.662 : --14--> forest_111.jpg | 34.80dB
25-05-12 09:14:26.708 : --15--> freeway_111.jpg | 36.59dB
25-05-12 09:14:26.757 : --16--> golf_course_111.jpg | 35.53dB
25-05-12 09:14:26.835 : --17--> ground_track_field_111.jpg | 33.38dB
25-05-12 09:14:26.879 : --18--> harbor_111.jpg | 34.22dB
25-05-12 09:14:26.924 : --19--> industrial_area_111.jpg | 34.01dB
25-05-12 09:14:26.967 : --20--> intersection_111.jpg | 33.25dB
25-05-12 09:14:27.009 : --21--> island_111.jpg | 34.98dB
25-05-12 09:14:27.069 : --22--> lake_111.jpg | 34.49dB
25-05-12 09:14:27.117 : --23--> meadow_111.jpg | 33.02dB
25-05-12 09:14:27.159 : --24--> medium_residential_111.jpg | 31.42dB
25-05-12 09:14:27.200 : --25--> mobile_home_park_111.jpg | 34.04dB
25-05-12 09:14:27.248 : --26--> mountain_111.jpg | 32.23dB
25-05-12 09:14:27.286 : --27--> overpass_111.jpg | 33.00dB
25-05-12 09:14:27.324 : --28--> palace_111.jpg | 32.74dB
25-05-12 09:14:27.370 : --29--> parking_lot_111.jpg | 32.70dB
25-05-12 09:14:27.419 : --30--> railway_111.jpg | 32.78dB
25-05-12 09:14:27.465 : --31--> railway_station_111.jpg | 33.71dB
25-05-12 09:14:27.511 : --32--> rectangular_farmland_111.jpg | 35.62dB
25-05-12 09:14:27.553 : --33--> river_111.jpg | 32.97dB
25-05-12 09:14:27.596 : --34--> roundabout_111.jpg | 33.40dB
25-05-12 09:14:27.640 : --35--> runway_111.jpg | 38.43dB
25-05-12 09:14:27.682 : --36--> sea_ice_111.jpg | 36.27dB
25-05-12 09:14:27.732 : --37--> ship_111.jpg | 40.14dB
25-05-12 09:14:27.775 : --38--> snowberg_111.jpg | 34.91dB
25-05-12 09:14:27.820 : --39--> sparse_residential_111.jpg | 33.07dB
25-05-12 09:14:27.863 : --40--> stadium_111.jpg | 33.11dB
25-05-12 09:14:27.915 : --41--> storage_tank_111.jpg | 34.07dB
25-05-12 09:14:27.958 : --42--> tennis_court_111.jpg | 33.58dB
25-05-12 09:14:28.005 : --43--> terrace_111.jpg | 35.00dB
25-05-12 09:14:28.045 : --44--> thermal_power_station_111.jpg | 33.35dB
25-05-12 09:14:28.089 : --45--> wetland_111.jpg | 33.93dB
25-05-12 09:14:28.100 : <epoch:  0, iter:  20,000, Average PSNR : 34.51dB

25-05-12 09:39:18.502 : <epoch:  0, iter:  30,000, lr:1.000e-04> G_loss: 2.034e-03 
25-05-12 09:39:18.503 : Saving the model.
25-05-12 09:39:21.015 : ---1--> airplane_111.jpg | 32.31dB
25-05-12 09:39:21.124 : ---2--> airport_111.jpg | 34.29dB
25-05-12 09:39:21.198 : ---3--> baseball_diamond_111.jpg | 35.60dB
25-05-12 09:39:21.244 : ---4--> basketball_court_111.jpg | 33.97dB
25-05-12 09:39:21.299 : ---5--> beach_111.jpg | 32.27dB
25-05-12 09:39:21.344 : ---6--> bridge_111.jpg | 37.06dB
25-05-12 09:39:21.387 : ---7--> chaparral_111.jpg | 32.23dB
25-05-12 09:39:21.445 : ---8--> church_111.jpg | 33.43dB
25-05-12 09:39:21.493 : ---9--> circular_farmland_111.jpg | 35.28dB
25-05-12 09:39:21.538 : --10--> cloud_111.jpg | 31.30dB
25-05-12 09:39:21.585 : --11--> commercial_area_111.jpg | 34.51dB
25-05-12 09:39:21.634 : --12--> dense_residential_111.jpg | 31.97dB
25-05-12 09:39:21.679 : --13--> desert_111.jpg | 38.48dB
25-05-12 09:39:21.724 : --14--> forest_111.jpg | 34.48dB
25-05-12 09:39:21.768 : --15--> freeway_111.jpg | 36.24dB
25-05-12 09:39:21.833 : --16--> golf_course_111.jpg | 35.10dB
25-05-12 09:39:21.877 : --17--> ground_track_field_111.jpg | 33.20dB
25-05-12 09:39:21.923 : --18--> harbor_111.jpg | 33.78dB
25-05-12 09:39:21.969 : --19--> industrial_area_111.jpg | 32.94dB
25-05-12 09:39:22.011 : --20--> intersection_111.jpg | 33.02dB
25-05-12 09:39:22.056 : --21--> island_111.jpg | 31.61dB
25-05-12 09:39:22.096 : --22--> lake_111.jpg | 34.47dB
25-05-12 09:39:22.142 : --23--> meadow_111.jpg | 33.08dB
25-05-12 09:39:22.188 : --24--> medium_residential_111.jpg | 30.88dB
25-05-12 09:39:22.238 : --25--> mobile_home_park_111.jpg | 31.69dB
25-05-12 09:39:22.290 : --26--> mountain_111.jpg | 32.04dB
25-05-12 09:39:22.348 : --27--> overpass_111.jpg | 32.73dB
25-05-12 09:39:22.409 : --28--> palace_111.jpg | 32.39dB
25-05-12 09:39:22.451 : --29--> parking_lot_111.jpg | 32.34dB
25-05-12 09:39:22.502 : --30--> railway_111.jpg | 32.69dB
25-05-12 09:39:22.551 : --31--> railway_station_111.jpg | 33.41dB
25-05-12 09:39:22.597 : --32--> rectangular_farmland_111.jpg | 35.13dB
25-05-12 09:39:22.646 : --33--> river_111.jpg | 32.70dB
25-05-12 09:39:22.696 : --34--> roundabout_111.jpg | 32.99dB
25-05-12 09:39:22.746 : --35--> runway_111.jpg | 38.25dB
25-05-12 09:39:22.791 : --36--> sea_ice_111.jpg | 33.97dB
25-05-12 09:39:22.844 : --37--> ship_111.jpg | 39.36dB
25-05-12 09:39:22.898 : --38--> snowberg_111.jpg | 29.94dB
25-05-12 09:39:22.949 : --39--> sparse_residential_111.jpg | 32.82dB
25-05-12 09:39:22.994 : --40--> stadium_111.jpg | 31.58dB
25-05-12 09:39:23.040 : --41--> storage_tank_111.jpg | 32.92dB
25-05-12 09:39:23.087 : --42--> tennis_court_111.jpg | 32.97dB
25-05-12 09:39:23.133 : --43--> terrace_111.jpg | 31.46dB
25-05-12 09:39:23.178 : --44--> thermal_power_station_111.jpg | 31.07dB
25-05-12 09:39:23.220 : --45--> wetland_111.jpg | 33.87dB
25-05-12 09:39:23.230 : <epoch:  0, iter:  30,000, Average PSNR : 33.51dB

25-05-12 10:04:14.067 : <epoch:  1, iter:  40,000, lr:1.000e-04> G_loss: 1.579e-03 
25-05-12 10:04:14.068 : Saving the model.
25-05-12 10:04:16.673 : ---1--> airplane_111.jpg | 34.93dB
25-05-12 10:04:16.792 : ---2--> airport_111.jpg | 35.38dB
25-05-12 10:04:16.872 : ---3--> baseball_diamond_111.jpg | 36.03dB
25-05-12 10:04:16.914 : ---4--> basketball_court_111.jpg | 34.29dB
25-05-12 10:04:16.959 : ---5--> beach_111.jpg | 33.28dB
25-05-12 10:04:17.007 : ---6--> bridge_111.jpg | 37.73dB
25-05-12 10:04:17.049 : ---7--> chaparral_111.jpg | 32.93dB
25-05-12 10:04:17.092 : ---8--> church_111.jpg | 34.17dB
25-05-12 10:04:17.132 : ---9--> circular_farmland_111.jpg | 36.25dB
25-05-12 10:04:17.175 : --10--> cloud_111.jpg | 36.76dB
25-05-12 10:04:17.221 : --11--> commercial_area_111.jpg | 35.65dB
25-05-12 10:04:17.272 : --12--> dense_residential_111.jpg | 32.44dB
25-05-12 10:04:17.330 : --13--> desert_111.jpg | 36.88dB
25-05-12 10:04:17.375 : --14--> forest_111.jpg | 34.92dB
25-05-12 10:04:17.421 : --15--> freeway_111.jpg | 36.67dB
25-05-12 10:04:17.468 : --16--> golf_course_111.jpg | 35.64dB
25-05-12 10:04:17.507 : --17--> ground_track_field_111.jpg | 33.50dB
25-05-12 10:04:17.551 : --18--> harbor_111.jpg | 34.30dB
25-05-12 10:04:17.629 : --19--> industrial_area_111.jpg | 34.21dB
25-05-12 10:04:17.674 : --20--> intersection_111.jpg | 33.41dB
25-05-12 10:04:17.719 : --21--> island_111.jpg | 34.46dB
25-05-12 10:04:17.763 : --22--> lake_111.jpg | 34.56dB
25-05-12 10:04:17.806 : --23--> meadow_111.jpg | 33.22dB
25-05-12 10:04:17.851 : --24--> medium_residential_111.jpg | 31.57dB
25-05-12 10:04:17.893 : --25--> mobile_home_park_111.jpg | 34.08dB
25-05-12 10:04:17.935 : --26--> mountain_111.jpg | 32.40dB
25-05-12 10:04:17.985 : --27--> overpass_111.jpg | 33.15dB
25-05-12 10:04:18.057 : --28--> palace_111.jpg | 32.87dB
25-05-12 10:04:18.099 : --29--> parking_lot_111.jpg | 32.82dB
25-05-12 10:04:18.138 : --30--> railway_111.jpg | 32.92dB
25-05-12 10:04:18.181 : --31--> railway_station_111.jpg | 33.89dB
25-05-12 10:04:18.220 : --32--> rectangular_farmland_111.jpg | 35.76dB
25-05-12 10:04:18.265 : --33--> river_111.jpg | 33.11dB
25-05-12 10:04:18.307 : --34--> roundabout_111.jpg | 33.56dB
25-05-12 10:04:18.349 : --35--> runway_111.jpg | 38.44dB
25-05-12 10:04:18.391 : --36--> sea_ice_111.jpg | 36.29dB
25-05-12 10:04:18.431 : --37--> ship_111.jpg | 39.90dB
25-05-12 10:04:18.478 : --38--> snowberg_111.jpg | 34.63dB
25-05-12 10:04:18.521 : --39--> sparse_residential_111.jpg | 33.23dB
25-05-12 10:04:18.566 : --40--> stadium_111.jpg | 33.08dB
25-05-12 10:04:18.610 : --41--> storage_tank_111.jpg | 34.19dB
25-05-12 10:04:18.655 : --42--> tennis_court_111.jpg | 33.71dB
25-05-12 10:04:18.700 : --43--> terrace_111.jpg | 35.06dB
25-05-12 10:04:18.746 : --44--> thermal_power_station_111.jpg | 33.45dB
25-05-12 10:04:18.796 : --45--> wetland_111.jpg | 34.06dB
25-05-12 10:04:18.808 : <epoch:  1, iter:  40,000, Average PSNR : 34.53dB

25-05-12 10:29:11.138 : <epoch:  1, iter:  50,000, lr:1.000e-04> G_loss: 1.275e-03 
25-05-12 10:29:11.139 : Saving the model.
25-05-12 10:29:13.558 : ---1--> airplane_111.jpg | 35.17dB
25-05-12 10:29:13.647 : ---2--> airport_111.jpg | 35.52dB
25-05-12 10:29:13.727 : ---3--> baseball_diamond_111.jpg | 36.18dB
25-05-12 10:29:13.811 : ---4--> basketball_court_111.jpg | 34.48dB
25-05-12 10:29:13.890 : ---5--> beach_111.jpg | 33.65dB
25-05-12 10:29:13.958 : ---6--> bridge_111.jpg | 37.98dB
25-05-12 10:29:14.001 : ---7--> chaparral_111.jpg | 33.26dB
25-05-12 10:29:14.042 : ---8--> church_111.jpg | 34.35dB
25-05-12 10:29:14.103 : ---9--> circular_farmland_111.jpg | 36.43dB
25-05-12 10:29:14.149 : --10--> cloud_111.jpg | 39.44dB
25-05-12 10:29:14.202 : --11--> commercial_area_111.jpg | 35.77dB
25-05-12 10:29:14.246 : --12--> dense_residential_111.jpg | 32.64dB
25-05-12 10:29:14.287 : --13--> desert_111.jpg | 38.69dB
25-05-12 10:29:14.331 : --14--> forest_111.jpg | 34.99dB
25-05-12 10:29:14.372 : --15--> freeway_111.jpg | 36.79dB
25-05-12 10:29:14.414 : --16--> golf_course_111.jpg | 35.75dB
25-05-12 10:29:14.475 : --17--> ground_track_field_111.jpg | 33.69dB
25-05-12 10:29:14.523 : --18--> harbor_111.jpg | 34.50dB
25-05-12 10:29:14.572 : --19--> industrial_area_111.jpg | 34.36dB
25-05-12 10:29:14.651 : --20--> intersection_111.jpg | 33.57dB
25-05-12 10:29:14.697 : --21--> island_111.jpg | 35.35dB
25-05-12 10:29:14.753 : --22--> lake_111.jpg | 34.74dB
25-05-12 10:29:14.800 : --23--> meadow_111.jpg | 33.39dB
25-05-12 10:29:14.850 : --24--> medium_residential_111.jpg | 31.76dB
25-05-12 10:29:14.896 : --25--> mobile_home_park_111.jpg | 34.33dB
25-05-12 10:29:14.939 : --26--> mountain_111.jpg | 32.67dB
25-05-12 10:29:14.980 : --27--> overpass_111.jpg | 33.31dB
25-05-12 10:29:15.025 : --28--> palace_111.jpg | 33.06dB
25-05-12 10:29:15.069 : --29--> parking_lot_111.jpg | 32.93dB
25-05-12 10:29:15.113 : --30--> railway_111.jpg | 33.08dB
25-05-12 10:29:15.154 : --31--> railway_station_111.jpg | 34.07dB
25-05-12 10:29:15.196 : --32--> rectangular_farmland_111.jpg | 35.92dB
25-05-12 10:29:15.237 : --33--> river_111.jpg | 33.30dB
25-05-12 10:29:15.278 : --34--> roundabout_111.jpg | 33.71dB
25-05-12 10:29:15.321 : --35--> runway_111.jpg | 38.57dB
25-05-12 10:29:15.377 : --36--> sea_ice_111.jpg | 36.61dB
25-05-12 10:29:15.430 : --37--> ship_111.jpg | 40.18dB
25-05-12 10:29:15.473 : --38--> snowberg_111.jpg | 35.49dB
25-05-12 10:29:15.514 : --39--> sparse_residential_111.jpg | 33.39dB
25-05-12 10:29:15.575 : --40--> stadium_111.jpg | 33.42dB
25-05-12 10:29:15.620 : --41--> storage_tank_111.jpg | 34.35dB
25-05-12 10:29:15.662 : --42--> tennis_court_111.jpg | 33.92dB
25-05-12 10:29:15.707 : --43--> terrace_111.jpg | 35.26dB
25-05-12 10:29:15.785 : --44--> thermal_power_station_111.jpg | 33.73dB
25-05-12 10:29:15.825 : --45--> wetland_111.jpg | 34.21dB
25-05-12 10:29:15.836 : <epoch:  1, iter:  50,000, Average PSNR : 34.84dB

25-05-12 10:54:04.067 : <epoch:  1, iter:  60,000, lr:2.500e-05> G_loss: 1.369e-03 
25-05-12 10:54:04.068 : Saving the model.
25-05-12 10:54:06.442 : ---1--> airplane_111.jpg | 35.12dB
25-05-12 10:54:06.543 : ---2--> airport_111.jpg | 35.33dB
25-05-12 10:54:06.612 : ---3--> baseball_diamond_111.jpg | 35.96dB
25-05-12 10:54:06.683 : ---4--> basketball_court_111.jpg | 34.34dB
25-05-12 10:54:06.737 : ---5--> beach_111.jpg | 33.59dB
25-05-12 10:54:06.786 : ---6--> bridge_111.jpg | 37.71dB
25-05-12 10:54:06.828 : ---7--> chaparral_111.jpg | 33.15dB
25-05-12 10:54:06.879 : ---8--> church_111.jpg | 34.35dB
25-05-12 10:54:06.922 : ---9--> circular_farmland_111.jpg | 36.32dB
25-05-12 10:54:06.967 : --10--> cloud_111.jpg | 39.12dB
25-05-12 10:54:07.016 : --11--> commercial_area_111.jpg | 35.65dB
25-05-12 10:54:07.059 : --12--> dense_residential_111.jpg | 32.69dB
25-05-12 10:54:07.101 : --13--> desert_111.jpg | 37.26dB
25-05-12 10:54:07.146 : --14--> forest_111.jpg | 34.89dB
25-05-12 10:54:07.194 : --15--> freeway_111.jpg | 36.59dB
25-05-12 10:54:07.239 : --16--> golf_course_111.jpg | 35.64dB
25-05-12 10:54:07.286 : --17--> ground_track_field_111.jpg | 33.64dB
25-05-12 10:54:07.342 : --18--> harbor_111.jpg | 34.45dB
25-05-12 10:54:07.387 : --19--> industrial_area_111.jpg | 34.32dB
25-05-12 10:54:07.433 : --20--> intersection_111.jpg | 33.58dB
25-05-12 10:54:07.479 : --21--> island_111.jpg | 35.22dB
25-05-12 10:54:07.524 : --22--> lake_111.jpg | 34.70dB
25-05-12 10:54:07.573 : --23--> meadow_111.jpg | 33.32dB
25-05-12 10:54:07.616 : --24--> medium_residential_111.jpg | 31.83dB
25-05-12 10:54:07.661 : --25--> mobile_home_park_111.jpg | 34.26dB
25-05-12 10:54:07.703 : --26--> mountain_111.jpg | 32.62dB
25-05-12 10:54:07.747 : --27--> overpass_111.jpg | 33.35dB
25-05-12 10:54:07.789 : --28--> palace_111.jpg | 33.08dB
25-05-12 10:54:07.830 : --29--> parking_lot_111.jpg | 32.96dB
25-05-12 10:54:07.877 : --30--> railway_111.jpg | 33.09dB
25-05-12 10:54:07.919 : --31--> railway_station_111.jpg | 34.04dB
25-05-12 10:54:07.963 : --32--> rectangular_farmland_111.jpg | 35.66dB
25-05-12 10:54:08.001 : --33--> river_111.jpg | 33.30dB
25-05-12 10:54:08.043 : --34--> roundabout_111.jpg | 33.73dB
25-05-12 10:54:08.084 : --35--> runway_111.jpg | 38.12dB
25-05-12 10:54:08.132 : --36--> sea_ice_111.jpg | 36.53dB
25-05-12 10:54:08.176 : --37--> ship_111.jpg | 39.78dB
25-05-12 10:54:08.222 : --38--> snowberg_111.jpg | 35.06dB
25-05-12 10:54:08.264 : --39--> sparse_residential_111.jpg | 33.34dB
25-05-12 10:54:08.309 : --40--> stadium_111.jpg | 33.32dB
25-05-12 10:54:08.355 : --41--> storage_tank_111.jpg | 34.27dB
25-05-12 10:54:08.399 : --42--> tennis_court_111.jpg | 33.91dB
25-05-12 10:54:08.442 : --43--> terrace_111.jpg | 35.16dB
25-05-12 10:54:08.486 : --44--> thermal_power_station_111.jpg | 33.71dB
25-05-12 10:54:08.534 : --45--> wetland_111.jpg | 34.14dB
25-05-12 10:54:08.545 : <epoch:  1, iter:  60,000, Average PSNR : 34.72dB

25-05-12 11:18:55.897 : <epoch:  2, iter:  70,000, lr:5.000e-05> G_loss: 1.351e-03 
25-05-12 11:18:55.898 : Saving the model.
25-05-12 11:18:58.610 : ---1--> airplane_111.jpg | 35.38dB
25-05-12 11:18:58.713 : ---2--> airport_111.jpg | 35.62dB
25-05-12 11:18:58.798 : ---3--> baseball_diamond_111.jpg | 36.29dB
25-05-12 11:18:58.874 : ---4--> basketball_court_111.jpg | 34.63dB
25-05-12 11:18:58.919 : ---5--> beach_111.jpg | 33.80dB
25-05-12 11:18:58.962 : ---6--> bridge_111.jpg | 38.09dB
25-05-12 11:18:59.010 : ---7--> chaparral_111.jpg | 33.42dB
25-05-12 11:18:59.058 : ---8--> church_111.jpg | 34.55dB
25-05-12 11:18:59.109 : ---9--> circular_farmland_111.jpg | 36.59dB
25-05-12 11:18:59.150 : --10--> cloud_111.jpg | 39.59dB
25-05-12 11:18:59.196 : --11--> commercial_area_111.jpg | 35.87dB
25-05-12 11:18:59.242 : --12--> dense_residential_111.jpg | 32.86dB
25-05-12 11:18:59.288 : --13--> desert_111.jpg | 38.71dB
25-05-12 11:18:59.345 : --14--> forest_111.jpg | 35.08dB
25-05-12 11:18:59.392 : --15--> freeway_111.jpg | 36.90dB
25-05-12 11:18:59.437 : --16--> golf_course_111.jpg | 35.89dB
25-05-12 11:18:59.481 : --17--> ground_track_field_111.jpg | 33.84dB
25-05-12 11:18:59.526 : --18--> harbor_111.jpg | 34.66dB
25-05-12 11:18:59.569 : --19--> industrial_area_111.jpg | 34.57dB
25-05-12 11:18:59.612 : --20--> intersection_111.jpg | 33.74dB
25-05-12 11:18:59.659 : --21--> island_111.jpg | 35.52dB
25-05-12 11:18:59.708 : --22--> lake_111.jpg | 34.86dB
25-05-12 11:18:59.753 : --23--> meadow_111.jpg | 33.53dB
25-05-12 11:18:59.794 : --24--> medium_residential_111.jpg | 31.98dB
25-05-12 11:18:59.835 : --25--> mobile_home_park_111.jpg | 34.49dB
25-05-12 11:18:59.894 : --26--> mountain_111.jpg | 32.84dB
25-05-12 11:18:59.939 : --27--> overpass_111.jpg | 33.50dB
25-05-12 11:18:59.986 : --28--> palace_111.jpg | 33.24dB
25-05-12 11:19:00.034 : --29--> parking_lot_111.jpg | 33.14dB
25-05-12 11:19:00.077 : --30--> railway_111.jpg | 33.24dB
25-05-12 11:19:00.126 : --31--> railway_station_111.jpg | 34.23dB
25-05-12 11:19:00.189 : --32--> rectangular_farmland_111.jpg | 36.04dB
25-05-12 11:19:00.273 : --33--> river_111.jpg | 33.47dB
25-05-12 11:19:00.314 : --34--> roundabout_111.jpg | 33.90dB
25-05-12 11:19:00.356 : --35--> runway_111.jpg | 38.67dB
25-05-12 11:19:00.395 : --36--> sea_ice_111.jpg | 36.87dB
25-05-12 11:19:00.439 : --37--> ship_111.jpg | 40.28dB
25-05-12 11:19:00.500 : --38--> snowberg_111.jpg | 35.70dB
25-05-12 11:19:00.544 : --39--> sparse_residential_111.jpg | 33.53dB
25-05-12 11:19:00.589 : --40--> stadium_111.jpg | 33.61dB
25-05-12 11:19:00.632 : --41--> storage_tank_111.jpg | 34.51dB
25-05-12 11:19:00.682 : --42--> tennis_court_111.jpg | 34.11dB
25-05-12 11:19:00.726 : --43--> terrace_111.jpg | 35.37dB
25-05-12 11:19:00.765 : --44--> thermal_power_station_111.jpg | 33.93dB
25-05-12 11:19:00.806 : --45--> wetland_111.jpg | 34.32dB
25-05-12 11:19:00.820 : <epoch:  2, iter:  70,000, Average PSNR : 35.00dB

25-05-12 11:43:42.525 : <epoch:  2, iter:  80,000, lr:5.000e-05> G_loss: 1.329e-03 
25-05-12 11:43:42.526 : Saving the model.
25-05-12 11:43:44.955 : ---1--> airplane_111.jpg | 35.42dB
25-05-12 11:43:45.073 : ---2--> airport_111.jpg | 35.63dB
25-05-12 11:43:45.119 : ---3--> baseball_diamond_111.jpg | 36.31dB
25-05-12 11:43:45.166 : ---4--> basketball_court_111.jpg | 34.63dB
25-05-12 11:43:45.215 : ---5--> beach_111.jpg | 33.85dB
25-05-12 11:43:45.260 : ---6--> bridge_111.jpg | 38.10dB
25-05-12 11:43:45.304 : ---7--> chaparral_111.jpg | 33.46dB
25-05-12 11:43:45.348 : ---8--> church_111.jpg | 34.57dB
25-05-12 11:43:45.408 : ---9--> circular_farmland_111.jpg | 36.60dB
25-05-12 11:43:45.452 : --10--> cloud_111.jpg | 39.71dB
25-05-12 11:43:45.503 : --11--> commercial_area_111.jpg | 35.87dB
25-05-12 11:43:45.547 : --12--> dense_residential_111.jpg | 32.89dB
25-05-12 11:43:45.588 : --13--> desert_111.jpg | 38.75dB
25-05-12 11:43:45.633 : --14--> forest_111.jpg | 35.09dB
25-05-12 11:43:45.677 : --15--> freeway_111.jpg | 36.90dB
25-05-12 11:43:45.722 : --16--> golf_course_111.jpg | 35.89dB
25-05-12 11:43:45.768 : --17--> ground_track_field_111.jpg | 33.87dB
25-05-12 11:43:45.812 : --18--> harbor_111.jpg | 34.68dB
25-05-12 11:43:45.857 : --19--> industrial_area_111.jpg | 34.60dB
25-05-12 11:43:45.901 : --20--> intersection_111.jpg | 33.78dB
25-05-12 11:43:45.954 : --21--> island_111.jpg | 35.51dB
25-05-12 11:43:45.998 : --22--> lake_111.jpg | 34.89dB
25-05-12 11:43:46.045 : --23--> meadow_111.jpg | 33.54dB
25-05-12 11:43:46.090 : --24--> medium_residential_111.jpg | 32.03dB
25-05-12 11:43:46.132 : --25--> mobile_home_park_111.jpg | 34.51dB
25-05-12 11:43:46.168 : --26--> mountain_111.jpg | 32.85dB
25-05-12 11:43:46.208 : --27--> overpass_111.jpg | 33.53dB
25-05-12 11:43:46.262 : --28--> palace_111.jpg | 33.26dB
25-05-12 11:43:46.305 : --29--> parking_lot_111.jpg | 33.19dB
25-05-12 11:43:46.355 : --30--> railway_111.jpg | 33.27dB
25-05-12 11:43:46.428 : --31--> railway_station_111.jpg | 34.26dB
25-05-12 11:43:46.469 : --32--> rectangular_farmland_111.jpg | 36.06dB
25-05-12 11:43:46.512 : --33--> river_111.jpg | 33.49dB
25-05-12 11:43:46.558 : --34--> roundabout_111.jpg | 33.93dB
25-05-12 11:43:46.601 : --35--> runway_111.jpg | 38.67dB
25-05-12 11:43:46.650 : --36--> sea_ice_111.jpg | 36.88dB
25-05-12 11:43:46.694 : --37--> ship_111.jpg | 40.28dB
25-05-12 11:43:46.737 : --38--> snowberg_111.jpg | 35.79dB
25-05-12 11:43:46.777 : --39--> sparse_residential_111.jpg | 33.54dB
25-05-12 11:43:46.822 : --40--> stadium_111.jpg | 33.65dB
25-05-12 11:43:46.866 : --41--> storage_tank_111.jpg | 34.54dB
25-05-12 11:43:46.934 : --42--> tennis_court_111.jpg | 34.14dB
25-05-12 11:43:46.980 : --43--> terrace_111.jpg | 35.41dB
25-05-12 11:43:47.017 : --44--> thermal_power_station_111.jpg | 33.97dB
25-05-12 11:43:47.068 : --45--> wetland_111.jpg | 34.31dB
25-05-12 11:43:47.081 : <epoch:  2, iter:  80,000, Average PSNR : 35.02dB

25-05-12 12:08:29.114 : <epoch:  2, iter:  90,000, lr:1.250e-05> G_loss: 1.849e-03 
25-05-12 12:08:29.115 : Saving the model.
25-05-12 12:08:30.262 : ---1--> airplane_111.jpg | 35.39dB
25-05-12 12:08:30.352 : ---2--> airport_111.jpg | 35.63dB
25-05-12 12:08:30.442 : ---3--> baseball_diamond_111.jpg | 36.32dB
25-05-12 12:08:30.516 : ---4--> basketball_court_111.jpg | 34.63dB
25-05-12 12:08:30.562 : ---5--> beach_111.jpg | 33.86dB
25-05-12 12:08:30.603 : ---6--> bridge_111.jpg | 38.07dB
25-05-12 12:08:30.656 : ---7--> chaparral_111.jpg | 33.45dB
25-05-12 12:08:30.698 : ---8--> church_111.jpg | 34.61dB
25-05-12 12:08:30.749 : ---9--> circular_farmland_111.jpg | 36.59dB
25-05-12 12:08:30.792 : --10--> cloud_111.jpg | 39.34dB
25-05-12 12:08:30.837 : --11--> commercial_area_111.jpg | 35.85dB
25-05-12 12:08:30.881 : --12--> dense_residential_111.jpg | 32.91dB
25-05-12 12:08:30.929 : --13--> desert_111.jpg | 38.45dB
25-05-12 12:08:30.983 : --14--> forest_111.jpg | 35.10dB
25-05-12 12:08:31.027 : --15--> freeway_111.jpg | 36.89dB
25-05-12 12:08:31.072 : --16--> golf_course_111.jpg | 35.89dB
25-05-12 12:08:31.117 : --17--> ground_track_field_111.jpg | 33.89dB
25-05-12 12:08:31.164 : --18--> harbor_111.jpg | 34.68dB
25-05-12 12:08:31.204 : --19--> industrial_area_111.jpg | 34.59dB
25-05-12 12:08:31.250 : --20--> intersection_111.jpg | 33.78dB
25-05-12 12:08:31.295 : --21--> island_111.jpg | 35.52dB
25-05-12 12:08:31.344 : --22--> lake_111.jpg | 34.89dB
25-05-12 12:08:31.386 : --23--> meadow_111.jpg | 33.56dB
25-05-12 12:08:31.431 : --24--> medium_residential_111.jpg | 32.04dB
25-05-12 12:08:31.474 : --25--> mobile_home_park_111.jpg | 34.49dB
25-05-12 12:08:31.544 : --26--> mountain_111.jpg | 32.86dB
25-05-12 12:08:31.588 : --27--> overpass_111.jpg | 33.54dB
25-05-12 12:08:31.631 : --28--> palace_111.jpg | 33.29dB
25-05-12 12:08:31.674 : --29--> parking_lot_111.jpg | 33.20dB
25-05-12 12:08:31.716 : --30--> railway_111.jpg | 33.29dB
25-05-12 12:08:31.766 : --31--> railway_station_111.jpg | 34.25dB
25-05-12 12:08:31.812 : --32--> rectangular_farmland_111.jpg | 36.07dB
25-05-12 12:08:31.859 : --33--> river_111.jpg | 33.50dB
25-05-12 12:08:31.910 : --34--> roundabout_111.jpg | 33.95dB
25-05-12 12:08:31.954 : --35--> runway_111.jpg | 38.63dB
25-05-12 12:08:31.997 : --36--> sea_ice_111.jpg | 36.85dB
25-05-12 12:08:32.043 : --37--> ship_111.jpg | 40.23dB
25-05-12 12:08:32.089 : --38--> snowberg_111.jpg | 35.52dB
25-05-12 12:08:32.136 : --39--> sparse_residential_111.jpg | 33.56dB
25-05-12 12:08:32.181 : --40--> stadium_111.jpg | 33.65dB
25-05-12 12:08:32.225 : --41--> storage_tank_111.jpg | 34.50dB
25-05-12 12:08:32.272 : --42--> tennis_court_111.jpg | 34.13dB
25-05-12 12:08:32.313 : --43--> terrace_111.jpg | 35.31dB
25-05-12 12:08:32.352 : --44--> thermal_power_station_111.jpg | 33.92dB
25-05-12 12:08:32.395 : --45--> wetland_111.jpg | 34.34dB
25-05-12 12:08:32.410 : <epoch:  2, iter:  90,000, Average PSNR : 35.00dB

25-05-12 12:33:24.468 : <epoch:  3, iter: 100,000, lr:2.500e-05> G_loss: 1.295e-03 
25-05-12 12:33:24.469 : Saving the model.
25-05-12 12:33:27.559 : ---1--> airplane_111.jpg | 35.49dB
25-05-12 12:33:27.700 : ---2--> airport_111.jpg | 35.69dB
25-05-12 12:33:27.749 : ---3--> baseball_diamond_111.jpg | 36.35dB
25-05-12 12:33:27.829 : ---4--> basketball_court_111.jpg | 34.67dB
25-05-12 12:33:27.889 : ---5--> beach_111.jpg | 33.90dB
25-05-12 12:33:27.940 : ---6--> bridge_111.jpg | 38.13dB
25-05-12 12:33:27.988 : ---7--> chaparral_111.jpg | 33.53dB
25-05-12 12:33:28.032 : ---8--> church_111.jpg | 34.66dB
25-05-12 12:33:28.072 : ---9--> circular_farmland_111.jpg | 36.65dB
25-05-12 12:33:28.119 : --10--> cloud_111.jpg | 39.68dB
25-05-12 12:33:28.163 : --11--> commercial_area_111.jpg | 35.90dB
25-05-12 12:33:28.205 : --12--> dense_residential_111.jpg | 32.96dB
25-05-12 12:33:28.248 : --13--> desert_111.jpg | 38.83dB
25-05-12 12:33:28.288 : --14--> forest_111.jpg | 35.12dB
25-05-12 12:33:28.328 : --15--> freeway_111.jpg | 36.93dB
25-05-12 12:33:28.375 : --16--> golf_course_111.jpg | 35.93dB
25-05-12 12:33:28.420 : --17--> ground_track_field_111.jpg | 33.93dB
25-05-12 12:33:28.467 : --18--> harbor_111.jpg | 34.72dB
25-05-12 12:33:28.508 : --19--> industrial_area_111.jpg | 34.67dB
25-05-12 12:33:28.551 : --20--> intersection_111.jpg | 33.83dB
25-05-12 12:33:28.597 : --21--> island_111.jpg | 35.59dB
25-05-12 12:33:28.641 : --22--> lake_111.jpg | 34.91dB
25-05-12 12:33:28.683 : --23--> meadow_111.jpg | 33.57dB
25-05-12 12:33:28.727 : --24--> medium_residential_111.jpg | 32.10dB
25-05-12 12:33:28.775 : --25--> mobile_home_park_111.jpg | 34.56dB
25-05-12 12:33:28.822 : --26--> mountain_111.jpg | 32.92dB
25-05-12 12:33:28.867 : --27--> overpass_111.jpg | 33.59dB
25-05-12 12:33:28.908 : --28--> palace_111.jpg | 33.33dB
25-05-12 12:33:28.956 : --29--> parking_lot_111.jpg | 33.26dB
25-05-12 12:33:28.998 : --30--> railway_111.jpg | 33.34dB
25-05-12 12:33:29.044 : --31--> railway_station_111.jpg | 34.30dB
25-05-12 12:33:29.086 : --32--> rectangular_farmland_111.jpg | 36.13dB
25-05-12 12:33:29.129 : --33--> river_111.jpg | 33.53dB
25-05-12 12:33:29.182 : --34--> roundabout_111.jpg | 33.99dB
25-05-12 12:33:29.247 : --35--> runway_111.jpg | 38.70dB
25-05-12 12:33:29.295 : --36--> sea_ice_111.jpg | 36.92dB
25-05-12 12:33:29.336 : --37--> ship_111.jpg | 40.29dB
25-05-12 12:33:29.392 : --38--> snowberg_111.jpg | 35.85dB
25-05-12 12:33:29.436 : --39--> sparse_residential_111.jpg | 33.58dB
25-05-12 12:33:29.483 : --40--> stadium_111.jpg | 33.72dB
25-05-12 12:33:29.530 : --41--> storage_tank_111.jpg | 34.58dB
25-05-12 12:33:29.577 : --42--> tennis_court_111.jpg | 34.20dB
25-05-12 12:33:29.627 : --43--> terrace_111.jpg | 35.42dB
25-05-12 12:33:29.673 : --44--> thermal_power_station_111.jpg | 34.01dB
25-05-12 12:33:29.719 : --45--> wetland_111.jpg | 34.36dB
25-05-12 12:33:29.735 : <epoch:  3, iter: 100,000, Average PSNR : 35.07dB

25-05-12 12:58:03.568 : <epoch:  3, iter: 110,000, lr:2.500e-05> G_loss: 1.426e-03 
25-05-12 12:58:03.569 : Saving the model.
25-05-12 12:58:06.046 : ---1--> airplane_111.jpg | 35.49dB
25-05-12 12:58:06.172 : ---2--> airport_111.jpg | 35.69dB
25-05-12 12:58:06.251 : ---3--> baseball_diamond_111.jpg | 36.37dB
25-05-12 12:58:06.296 : ---4--> basketball_court_111.jpg | 34.68dB
25-05-12 12:58:06.347 : ---5--> beach_111.jpg | 33.91dB
25-05-12 12:58:06.393 : ---6--> bridge_111.jpg | 38.13dB
25-05-12 12:58:06.459 : ---7--> chaparral_111.jpg | 33.54dB
25-05-12 12:58:06.503 : ---8--> church_111.jpg | 34.68dB
25-05-12 12:58:06.548 : ---9--> circular_farmland_111.jpg | 36.67dB
25-05-12 12:58:06.592 : --10--> cloud_111.jpg | 39.66dB
25-05-12 12:58:06.634 : --11--> commercial_area_111.jpg | 35.90dB
25-05-12 12:58:06.684 : --12--> dense_residential_111.jpg | 32.98dB
25-05-12 12:58:06.736 : --13--> desert_111.jpg | 38.89dB
25-05-12 12:58:06.787 : --14--> forest_111.jpg | 35.13dB
25-05-12 12:58:06.833 : --15--> freeway_111.jpg | 36.94dB
25-05-12 12:58:06.882 : --16--> golf_course_111.jpg | 35.93dB
25-05-12 12:58:06.927 : --17--> ground_track_field_111.jpg | 33.93dB
25-05-12 12:58:06.974 : --18--> harbor_111.jpg | 34.73dB
25-05-12 12:58:07.026 : --19--> industrial_area_111.jpg | 34.69dB
25-05-12 12:58:07.067 : --20--> intersection_111.jpg | 33.84dB
25-05-12 12:58:07.120 : --21--> island_111.jpg | 35.61dB
25-05-12 12:58:07.161 : --22--> lake_111.jpg | 34.92dB
25-05-12 12:58:07.203 : --23--> meadow_111.jpg | 33.60dB
25-05-12 12:58:07.252 : --24--> medium_residential_111.jpg | 32.12dB
25-05-12 12:58:07.295 : --25--> mobile_home_park_111.jpg | 34.57dB
25-05-12 12:58:07.370 : --26--> mountain_111.jpg | 32.92dB
25-05-12 12:58:07.419 : --27--> overpass_111.jpg | 33.60dB
25-05-12 12:58:07.462 : --28--> palace_111.jpg | 33.35dB
25-05-12 12:58:07.518 : --29--> parking_lot_111.jpg | 33.28dB
25-05-12 12:58:07.587 : --30--> railway_111.jpg | 33.35dB
25-05-12 12:58:07.664 : --31--> railway_station_111.jpg | 34.32dB
25-05-12 12:58:07.706 : --32--> rectangular_farmland_111.jpg | 36.12dB
25-05-12 12:58:07.752 : --33--> river_111.jpg | 33.54dB
25-05-12 12:58:07.794 : --34--> roundabout_111.jpg | 34.00dB
25-05-12 12:58:07.835 : --35--> runway_111.jpg | 38.71dB
25-05-12 12:58:07.885 : --36--> sea_ice_111.jpg | 36.98dB
25-05-12 12:58:07.927 : --37--> ship_111.jpg | 40.31dB
25-05-12 12:58:07.990 : --38--> snowberg_111.jpg | 35.85dB
25-05-12 12:58:08.057 : --39--> sparse_residential_111.jpg | 33.60dB
25-05-12 12:58:08.103 : --40--> stadium_111.jpg | 33.74dB
25-05-12 12:58:08.154 : --41--> storage_tank_111.jpg | 34.58dB
25-05-12 12:58:08.203 : --42--> tennis_court_111.jpg | 34.21dB
25-05-12 12:58:08.251 : --43--> terrace_111.jpg | 35.44dB
25-05-12 12:58:08.296 : --44--> thermal_power_station_111.jpg | 34.03dB
25-05-12 12:58:08.337 : --45--> wetland_111.jpg | 34.36dB
25-05-12 12:58:08.347 : <epoch:  3, iter: 110,000, Average PSNR : 35.09dB

25-05-12 13:22:36.266 : <epoch:  3, iter: 120,000, lr:6.250e-06> G_loss: 1.814e-03 
25-05-12 13:22:36.267 : Saving the model.
25-05-12 13:22:38.694 : ---1--> airplane_111.jpg | 35.51dB
25-05-12 13:22:38.815 : ---2--> airport_111.jpg | 35.70dB
25-05-12 13:22:38.895 : ---3--> baseball_diamond_111.jpg | 36.38dB
25-05-12 13:22:38.946 : ---4--> basketball_court_111.jpg | 34.69dB
25-05-12 13:22:38.991 : ---5--> beach_111.jpg | 33.93dB
25-05-12 13:22:39.036 : ---6--> bridge_111.jpg | 38.16dB
25-05-12 13:22:39.078 : ---7--> chaparral_111.jpg | 33.55dB
25-05-12 13:22:39.120 : ---8--> church_111.jpg | 34.70dB
25-05-12 13:22:39.165 : ---9--> circular_farmland_111.jpg | 36.69dB
25-05-12 13:22:39.208 : --10--> cloud_111.jpg | 39.74dB
25-05-12 13:22:39.254 : --11--> commercial_area_111.jpg | 35.92dB
25-05-12 13:22:39.298 : --12--> dense_residential_111.jpg | 32.99dB
25-05-12 13:22:39.345 : --13--> desert_111.jpg | 38.93dB
25-05-12 13:22:39.389 : --14--> forest_111.jpg | 35.14dB
25-05-12 13:22:39.435 : --15--> freeway_111.jpg | 36.97dB
25-05-12 13:22:39.484 : --16--> golf_course_111.jpg | 35.95dB
25-05-12 13:22:39.527 : --17--> ground_track_field_111.jpg | 33.96dB
25-05-12 13:22:39.571 : --18--> harbor_111.jpg | 34.75dB
25-05-12 13:22:39.614 : --19--> industrial_area_111.jpg | 34.70dB
25-05-12 13:22:39.654 : --20--> intersection_111.jpg | 33.86dB
25-05-12 13:22:39.697 : --21--> island_111.jpg | 35.63dB
25-05-12 13:22:39.746 : --22--> lake_111.jpg | 34.92dB
25-05-12 13:22:39.789 : --23--> meadow_111.jpg | 33.61dB
25-05-12 13:22:39.833 : --24--> medium_residential_111.jpg | 32.14dB
25-05-12 13:22:39.882 : --25--> mobile_home_park_111.jpg | 34.58dB
25-05-12 13:22:39.927 : --26--> mountain_111.jpg | 32.93dB
25-05-12 13:22:39.974 : --27--> overpass_111.jpg | 33.63dB
25-05-12 13:22:40.015 : --28--> palace_111.jpg | 33.35dB
25-05-12 13:22:40.062 : --29--> parking_lot_111.jpg | 33.30dB
25-05-12 13:22:40.105 : --30--> railway_111.jpg | 33.36dB
25-05-12 13:22:40.149 : --31--> railway_station_111.jpg | 34.33dB
25-05-12 13:22:40.192 : --32--> rectangular_farmland_111.jpg | 36.14dB
25-05-12 13:22:40.232 : --33--> river_111.jpg | 33.55dB
25-05-12 13:22:40.280 : --34--> roundabout_111.jpg | 34.02dB
25-05-12 13:22:40.323 : --35--> runway_111.jpg | 38.73dB
25-05-12 13:22:40.366 : --36--> sea_ice_111.jpg | 36.98dB
25-05-12 13:22:40.410 : --37--> ship_111.jpg | 40.34dB
25-05-12 13:22:40.456 : --38--> snowberg_111.jpg | 35.88dB
25-05-12 13:22:40.503 : --39--> sparse_residential_111.jpg | 33.62dB
25-05-12 13:22:40.548 : --40--> stadium_111.jpg | 33.75dB
25-05-12 13:22:40.599 : --41--> storage_tank_111.jpg | 34.60dB
25-05-12 13:22:40.646 : --42--> tennis_court_111.jpg | 34.23dB
25-05-12 13:22:40.689 : --43--> terrace_111.jpg | 35.45dB
25-05-12 13:22:40.730 : --44--> thermal_power_station_111.jpg | 34.02dB
25-05-12 13:22:40.773 : --45--> wetland_111.jpg | 34.37dB
25-05-12 13:22:40.784 : <epoch:  3, iter: 120,000, Average PSNR : 35.10dB

25-05-12 13:47:15.956 : <epoch:  4, iter: 130,000, lr:1.250e-05> G_loss: 1.851e-03 
25-05-12 13:47:15.957 : Saving the model.
25-05-12 13:47:18.683 : ---1--> airplane_111.jpg | 35.53dB
25-05-12 13:47:18.787 : ---2--> airport_111.jpg | 35.70dB
25-05-12 13:47:18.865 : ---3--> baseball_diamond_111.jpg | 36.39dB
25-05-12 13:47:18.941 : ---4--> basketball_court_111.jpg | 34.69dB
25-05-12 13:47:18.991 : ---5--> beach_111.jpg | 33.94dB
25-05-12 13:47:19.046 : ---6--> bridge_111.jpg | 38.16dB
25-05-12 13:47:19.098 : ---7--> chaparral_111.jpg | 33.57dB
25-05-12 13:47:19.144 : ---8--> church_111.jpg | 34.72dB
25-05-12 13:47:19.188 : ---9--> circular_farmland_111.jpg | 36.70dB
25-05-12 13:47:19.247 : --10--> cloud_111.jpg | 39.76dB
25-05-12 13:47:19.292 : --11--> commercial_area_111.jpg | 35.91dB
25-05-12 13:47:19.333 : --12--> dense_residential_111.jpg | 33.02dB
25-05-12 13:47:19.376 : --13--> desert_111.jpg | 38.93dB
25-05-12 13:47:19.422 : --14--> forest_111.jpg | 35.14dB
25-05-12 13:47:19.464 : --15--> freeway_111.jpg | 36.97dB
25-05-12 13:47:19.506 : --16--> golf_course_111.jpg | 35.95dB
25-05-12 13:47:19.548 : --17--> ground_track_field_111.jpg | 33.96dB
25-05-12 13:47:19.616 : --18--> harbor_111.jpg | 34.77dB
25-05-12 13:47:19.658 : --19--> industrial_area_111.jpg | 34.71dB
25-05-12 13:47:19.705 : --20--> intersection_111.jpg | 33.87dB
25-05-12 13:47:19.748 : --21--> island_111.jpg | 35.65dB
25-05-12 13:47:19.793 : --22--> lake_111.jpg | 34.93dB
25-05-12 13:47:19.839 : --23--> meadow_111.jpg | 33.60dB
25-05-12 13:47:19.880 : --24--> medium_residential_111.jpg | 32.16dB
25-05-12 13:47:19.924 : --25--> mobile_home_park_111.jpg | 34.59dB
25-05-12 13:47:19.970 : --26--> mountain_111.jpg | 32.94dB
25-05-12 13:47:20.010 : --27--> overpass_111.jpg | 33.63dB
25-05-12 13:47:20.056 : --28--> palace_111.jpg | 33.38dB
25-05-12 13:47:20.105 : --29--> parking_lot_111.jpg | 33.32dB
25-05-12 13:47:20.147 : --30--> railway_111.jpg | 33.39dB
25-05-12 13:47:20.193 : --31--> railway_station_111.jpg | 34.34dB
25-05-12 13:47:20.263 : --32--> rectangular_farmland_111.jpg | 36.14dB
25-05-12 13:47:20.304 : --33--> river_111.jpg | 33.56dB
25-05-12 13:47:20.350 : --34--> roundabout_111.jpg | 34.03dB
25-05-12 13:47:20.396 : --35--> runway_111.jpg | 38.73dB
25-05-12 13:47:20.441 : --36--> sea_ice_111.jpg | 36.97dB
25-05-12 13:47:20.490 : --37--> ship_111.jpg | 40.35dB
25-05-12 13:47:20.535 : --38--> snowberg_111.jpg | 35.90dB
25-05-12 13:47:20.581 : --39--> sparse_residential_111.jpg | 33.62dB
25-05-12 13:47:20.624 : --40--> stadium_111.jpg | 33.77dB
25-05-12 13:47:20.671 : --41--> storage_tank_111.jpg | 34.60dB
25-05-12 13:47:20.710 : --42--> tennis_court_111.jpg | 34.23dB
25-05-12 13:47:20.754 : --43--> terrace_111.jpg | 35.43dB
25-05-12 13:47:20.792 : --44--> thermal_power_station_111.jpg | 34.04dB
25-05-12 13:47:20.833 : --45--> wetland_111.jpg | 34.38dB
25-05-12 13:47:20.846 : <epoch:  4, iter: 130,000, Average PSNR : 35.11dB

25-05-12 14:11:58.650 : <epoch:  4, iter: 140,000, lr:1.250e-05> G_loss: 1.528e-03 
25-05-12 14:11:58.651 : Saving the model.
25-05-12 14:12:01.174 : ---1--> airplane_111.jpg | 35.54dB
25-05-12 14:12:01.283 : ---2--> airport_111.jpg | 35.72dB
25-05-12 14:12:01.375 : ---3--> baseball_diamond_111.jpg | 36.38dB
25-05-12 14:12:01.435 : ---4--> basketball_court_111.jpg | 34.69dB
25-05-12 14:12:01.478 : ---5--> beach_111.jpg | 33.96dB
25-05-12 14:12:01.526 : ---6--> bridge_111.jpg | 38.17dB
25-05-12 14:12:01.570 : ---7--> chaparral_111.jpg | 33.58dB
25-05-12 14:12:01.613 : ---8--> church_111.jpg | 34.72dB
25-05-12 14:12:01.657 : ---9--> circular_farmland_111.jpg | 36.72dB
25-05-12 14:12:01.701 : --10--> cloud_111.jpg | 39.79dB
25-05-12 14:12:01.745 : --11--> commercial_area_111.jpg | 35.92dB
25-05-12 14:12:01.788 : --12--> dense_residential_111.jpg | 33.02dB
25-05-12 14:12:01.832 : --13--> desert_111.jpg | 38.98dB
25-05-12 14:12:01.876 : --14--> forest_111.jpg | 35.14dB
25-05-12 14:12:01.924 : --15--> freeway_111.jpg | 36.97dB
25-05-12 14:12:01.968 : --16--> golf_course_111.jpg | 35.96dB
25-05-12 14:12:02.010 : --17--> ground_track_field_111.jpg | 33.97dB
25-05-12 14:12:02.058 : --18--> harbor_111.jpg | 34.77dB
25-05-12 14:12:02.099 : --19--> industrial_area_111.jpg | 34.73dB
25-05-12 14:12:02.146 : --20--> intersection_111.jpg | 33.88dB
25-05-12 14:12:02.212 : --21--> island_111.jpg | 35.66dB
25-05-12 14:12:02.255 : --22--> lake_111.jpg | 34.94dB
25-05-12 14:12:02.300 : --23--> meadow_111.jpg | 33.61dB
25-05-12 14:12:02.345 : --24--> medium_residential_111.jpg | 32.17dB
25-05-12 14:12:02.390 : --25--> mobile_home_park_111.jpg | 34.61dB
25-05-12 14:12:02.442 : --26--> mountain_111.jpg | 32.95dB
25-05-12 14:12:02.484 : --27--> overpass_111.jpg | 33.64dB
25-05-12 14:12:02.525 : --28--> palace_111.jpg | 33.38dB
25-05-12 14:12:02.569 : --29--> parking_lot_111.jpg | 33.33dB
25-05-12 14:12:02.614 : --30--> railway_111.jpg | 33.39dB
25-05-12 14:12:02.657 : --31--> railway_station_111.jpg | 34.35dB
25-05-12 14:12:02.702 : --32--> rectangular_farmland_111.jpg | 36.15dB
25-05-12 14:12:02.747 : --33--> river_111.jpg | 33.57dB
25-05-12 14:12:02.791 : --34--> roundabout_111.jpg | 34.04dB
25-05-12 14:12:02.835 : --35--> runway_111.jpg | 38.73dB
25-05-12 14:12:02.884 : --36--> sea_ice_111.jpg | 36.99dB
25-05-12 14:12:02.928 : --37--> ship_111.jpg | 40.34dB
25-05-12 14:12:02.978 : --38--> snowberg_111.jpg | 35.94dB
25-05-12 14:12:03.022 : --39--> sparse_residential_111.jpg | 33.63dB
25-05-12 14:12:03.070 : --40--> stadium_111.jpg | 33.78dB
25-05-12 14:12:03.115 : --41--> storage_tank_111.jpg | 34.61dB
25-05-12 14:12:03.158 : --42--> tennis_court_111.jpg | 34.25dB
25-05-12 14:12:03.200 : --43--> terrace_111.jpg | 35.44dB
25-05-12 14:12:03.242 : --44--> thermal_power_station_111.jpg | 34.05dB
25-05-12 14:12:03.281 : --45--> wetland_111.jpg | 34.37dB
25-05-12 14:12:03.294 : <epoch:  4, iter: 140,000, Average PSNR : 35.12dB

25-05-12 14:36:44.137 : <epoch:  4, iter: 150,000, lr:1.250e-05> G_loss: 5.734e-04 
25-05-12 14:36:44.138 : Saving the model.
25-05-12 14:36:46.510 : ---1--> airplane_111.jpg | 35.54dB
25-05-12 14:36:46.611 : ---2--> airport_111.jpg | 35.71dB
25-05-12 14:36:46.699 : ---3--> baseball_diamond_111.jpg | 36.39dB
25-05-12 14:36:46.771 : ---4--> basketball_court_111.jpg | 34.70dB
25-05-12 14:36:46.813 : ---5--> beach_111.jpg | 33.96dB
25-05-12 14:36:46.856 : ---6--> bridge_111.jpg | 38.17dB
25-05-12 14:36:46.905 : ---7--> chaparral_111.jpg | 33.58dB
25-05-12 14:36:46.948 : ---8--> church_111.jpg | 34.73dB
25-05-12 14:36:46.991 : ---9--> circular_farmland_111.jpg | 36.72dB
25-05-12 14:36:47.032 : --10--> cloud_111.jpg | 39.72dB
25-05-12 14:36:47.079 : --11--> commercial_area_111.jpg | 35.92dB
25-05-12 14:36:47.125 : --12--> dense_residential_111.jpg | 33.03dB
25-05-12 14:36:47.168 : --13--> desert_111.jpg | 38.89dB
25-05-12 14:36:47.214 : --14--> forest_111.jpg | 35.15dB
25-05-12 14:36:47.262 : --15--> freeway_111.jpg | 36.98dB
25-05-12 14:36:47.307 : --16--> golf_course_111.jpg | 35.96dB
25-05-12 14:36:47.363 : --17--> ground_track_field_111.jpg | 33.98dB
25-05-12 14:36:47.408 : --18--> harbor_111.jpg | 34.78dB
25-05-12 14:36:47.453 : --19--> industrial_area_111.jpg | 34.73dB
25-05-12 14:36:47.499 : --20--> intersection_111.jpg | 33.89dB
25-05-12 14:36:47.541 : --21--> island_111.jpg | 35.67dB
25-05-12 14:36:47.588 : --22--> lake_111.jpg | 34.93dB
25-05-12 14:36:47.634 : --23--> meadow_111.jpg | 33.61dB
25-05-12 14:36:47.678 : --24--> medium_residential_111.jpg | 32.17dB
25-05-12 14:36:47.723 : --25--> mobile_home_park_111.jpg | 34.61dB
25-05-12 14:36:47.766 : --26--> mountain_111.jpg | 32.95dB
25-05-12 14:36:47.811 : --27--> overpass_111.jpg | 33.65dB
25-05-12 14:36:47.851 : --28--> palace_111.jpg | 33.40dB
25-05-12 14:36:47.905 : --29--> parking_lot_111.jpg | 33.34dB
25-05-12 14:36:47.948 : --30--> railway_111.jpg | 33.40dB
25-05-12 14:36:47.995 : --31--> railway_station_111.jpg | 34.35dB
25-05-12 14:36:48.071 : --32--> rectangular_farmland_111.jpg | 36.15dB
25-05-12 14:36:48.114 : --33--> river_111.jpg | 33.57dB
25-05-12 14:36:48.154 : --34--> roundabout_111.jpg | 34.05dB
25-05-12 14:36:48.198 : --35--> runway_111.jpg | 38.73dB
25-05-12 14:36:48.246 : --36--> sea_ice_111.jpg | 37.00dB
25-05-12 14:36:48.291 : --37--> ship_111.jpg | 40.35dB
25-05-12 14:36:48.336 : --38--> snowberg_111.jpg | 35.92dB
25-05-12 14:36:48.379 : --39--> sparse_residential_111.jpg | 33.63dB
25-05-12 14:36:48.423 : --40--> stadium_111.jpg | 33.79dB
25-05-12 14:36:48.465 : --41--> storage_tank_111.jpg | 34.62dB
25-05-12 14:36:48.509 : --42--> tennis_court_111.jpg | 34.26dB
25-05-12 14:36:48.553 : --43--> terrace_111.jpg | 35.44dB
25-05-12 14:36:48.594 : --44--> thermal_power_station_111.jpg | 34.06dB
25-05-12 14:36:48.666 : --45--> wetland_111.jpg | 34.38dB
25-05-12 14:36:48.677 : <epoch:  4, iter: 150,000, Average PSNR : 35.12dB

25-05-12 15:02:05.793 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/100_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 15
      sigma_test: 15
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 15
      sigma_test: 15
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 10000
    checkpoint_save: 10000
    checkpoint_print: 10000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-12 15:02:05.794 : Random seed: 7926
25-05-12 15:02:05.930 : Number of train images: 31,005, iters: 31,005
25-05-12 15:02:06.995 : 
Networks name: DRNet
Params number: 35274045
Net structure:
DRNet(
  (endconv): outconv(
    (conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
  )
  (FE1): FE(
    (fe): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
    (1): PReLU(num_parameters=1)
  )
  (Deep_FE1): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (FCN_SFT1): FCN_SFT(
    (fcn1): FCN(
      (fcn): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
      )
    )
    (fcn2): FCN(
      (fcn): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
      )
    )
    (sft1): SFTLayer(
      (SFT_scale_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (Sigmoid): Sigmoid()
    )
    (sft2): SFTLayer(
      (SFT_scale_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (Sigmoid): Sigmoid()
    )
    (con): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (JTF1): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF11): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
  (Deep_FE2): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (JTF2): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF21): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (conv_noise2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  (Deep_FE3): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (JTF3): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF31): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (conv_noise3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  (conv_noise4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
  (JTF4): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF41): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (up1): up(
    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
  )
  (JTF5): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF51): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (up2): up(
    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
  )
  (JTF6): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF61): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
)

25-05-12 15:02:06.502 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.001 | -0.061 |  0.096 |  0.031 | torch.Size([3, 64, 1, 1]) || endconv.conv.weight
 | -0.002 | -0.003 | -0.001 |  0.001 | torch.Size([3]) || endconv.conv.bias
 |  0.000 | -0.219 |  0.152 |  0.040 | torch.Size([64, 3, 3, 3]) || FE1.fe.0.weight
 |  0.062 | -0.043 |  0.101 |  0.021 | torch.Size([64]) || FE1.fe.0.bias
 |  0.227 |  0.227 |  0.227 |    nan | torch.Size([1]) || FE1.fe.1.weight
 |  0.002 | -0.151 |  0.214 |  0.025 | torch.Size([64, 64, 3, 3]) || FE1.fe.2.weight
 |  0.022 |  0.002 |  0.067 |  0.011 | torch.Size([64]) || FE1.fe.2.bias
 |  0.509 |  0.509 |  0.509 |    nan | torch.Size([1]) || FE1.fe.3.weight
 |  0.003 | -0.132 |  0.219 |  0.022 | torch.Size([64, 64, 3, 3]) || FE1.fe.4.weight
 |  0.014 | -0.001 |  0.041 |  0.006 | torch.Size([64]) || FE1.fe.4.bias
 |  0.377 |  0.377 |  0.377 |    nan | torch.Size([1]) || FE1.fe.5.weight
 | -0.001 | -0.090 |  0.064 |  0.025 | torch.Size([64, 3, 1, 1]) || conv1.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv1.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || conv1.1.weight
 | -0.001 | -0.226 |  0.278 |  0.032 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.0.weight
 |  0.021 | -0.050 |  0.085 |  0.032 | torch.Size([64]) || Deep_FE1.fe.0.bias
 |  0.142 |  0.142 |  0.142 |    nan | torch.Size([1]) || Deep_FE1.fe.1.weight
 | -0.000 | -0.231 |  0.368 |  0.037 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.2.weight
 |  0.014 | -0.050 |  0.078 |  0.029 | torch.Size([64]) || Deep_FE1.fe.2.bias
 |  0.087 |  0.087 |  0.087 |    nan | torch.Size([1]) || Deep_FE1.fe.3.weight
 | -0.001 | -0.237 |  0.253 |  0.036 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.4.weight
 |  0.011 | -0.037 |  0.049 |  0.027 | torch.Size([64]) || Deep_FE1.fe.4.bias
 |  0.049 |  0.049 |  0.049 |    nan | torch.Size([1]) || Deep_FE1.fe.5.weight
 | -0.001 | -0.332 |  0.247 |  0.037 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.6.weight
 |  0.009 | -0.037 |  0.039 |  0.017 | torch.Size([64]) || Deep_FE1.fe.6.bias
 |  0.003 |  0.003 |  0.003 |    nan | torch.Size([1]) || Deep_FE1.fe.7.weight
 | -0.006 | -0.238 |  0.261 |  0.047 | torch.Size([64, 64, 1, 1]) || Deep_FE1.fe.8.weight
 | -0.010 | -0.025 |  0.011 |  0.006 | torch.Size([64]) || Deep_FE1.fe.8.bias
 | -0.000 | -0.033 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.1.weight
 | -0.000 | -0.036 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.3.weight
 | -0.000 | -0.032 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.4.weight
 | -0.000 | -0.001 |  0.002 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.5.weight
 |  0.000 | -0.036 |  0.044 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.1.weight
 | -0.000 | -0.035 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.3.weight
 |  0.000 | -0.039 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.4.weight
 |  0.000 | -0.001 |  0.002 |  0.001 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.5.weight
 |  0.000 | -0.082 |  0.092 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_scale_conv0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_scale_conv0.bias
 |  0.000 | -0.085 |  0.090 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_scale_conv1.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_scale_conv1.bias
 | -0.000 | -0.089 |  0.087 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_shift_conv0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_shift_conv0.bias
 |  0.000 | -0.091 |  0.082 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_shift_conv1.weight
 | -0.000 | -0.002 |  0.001 |  0.001 | torch.Size([64]) || FCN_SFT1.sft1.SFT_shift_conv1.bias
 | -0.000 | -0.081 |  0.081 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_scale_conv0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_scale_conv0.bias
 |  0.000 | -0.083 |  0.096 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_scale_conv1.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_scale_conv1.bias
 | -0.000 | -0.090 |  0.086 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_shift_conv0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_shift_conv0.bias
 | -0.000 | -0.087 |  0.079 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_shift_conv1.weight
 | -0.000 | -0.001 |  0.001 |  0.001 | torch.Size([64]) || FCN_SFT1.sft2.SFT_shift_conv1.bias
 | -0.000 | -0.066 |  0.062 |  0.018 | torch.Size([64, 128, 1, 1]) || FCN_SFT1.con.weight
 |  0.001 | -0.008 |  0.007 |  0.004 | torch.Size([64]) || FCN_SFT1.con.bias
 |  0.000 | -0.045 |  0.051 |  0.010 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.0.weight
 | -0.001 | -0.012 |  0.010 |  0.005 | torch.Size([64]) || JTF1.target_kg.conv_first.0.bias
 |  0.271 |  0.271 |  0.271 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.1.weight
 |  0.000 | -0.042 |  0.044 |  0.010 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.2.weight
 |  0.001 | -0.005 |  0.013 |  0.003 | torch.Size([64]) || JTF1.target_kg.conv_first.2.bias
 |  0.271 |  0.271 |  0.271 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.3.weight
 |  0.001 | -0.036 |  0.039 |  0.009 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.4.weight
 |  0.004 | -0.030 |  0.038 |  0.018 | torch.Size([64]) || JTF1.target_kg.conv_first.4.bias
 |  0.271 |  0.271 |  0.271 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.5.weight
 |  0.001 | -0.041 |  0.054 |  0.012 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.6.weight
 |  0.005 | -0.051 |  0.068 |  0.045 | torch.Size([64]) || JTF1.target_kg.conv_first.6.bias
 |  0.271 |  0.271 |  0.271 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.7.weight
 | -0.000 | -0.110 |  0.092 |  0.021 | torch.Size([144, 64, 1, 1]) || JTF1.target_kg.conv_first.8.weight
 |  0.004 | -0.096 |  0.138 |  0.031 | torch.Size([144]) || JTF1.target_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.041 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.0.weight
 | -0.001 | -0.004 |  0.006 |  0.002 | torch.Size([64]) || JTF1.guidance_kg.conv_first.0.bias
 |  0.279 |  0.279 |  0.279 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.1.weight
 | -0.000 | -0.034 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.2.weight
 | -0.000 | -0.001 |  0.001 |  0.000 | torch.Size([64]) || JTF1.guidance_kg.conv_first.2.bias
 |  0.279 |  0.279 |  0.279 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.3.weight
 | -0.000 | -0.033 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.4.weight
 |  0.004 | -0.031 |  0.038 |  0.020 | torch.Size([64]) || JTF1.guidance_kg.conv_first.4.bias
 |  0.279 |  0.279 |  0.279 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.5.weight
 |  0.001 | -0.042 |  0.053 |  0.012 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.6.weight
 |  0.007 | -0.051 |  0.071 |  0.049 | torch.Size([64]) || JTF1.guidance_kg.conv_first.6.bias
 |  0.279 |  0.279 |  0.279 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.7.weight
 | -0.000 | -0.091 |  0.102 |  0.022 | torch.Size([144, 64, 1, 1]) || JTF1.guidance_kg.conv_first.8.weight
 | -0.001 | -0.092 |  0.139 |  0.032 | torch.Size([144]) || JTF1.guidance_kg.conv_first.8.bias
 | -0.001 | -0.165 |  0.093 |  0.016 | torch.Size([64, 64, 3, 3]) || JTF1.jbf_conv.0.weight
 | -0.024 | -0.080 |  0.004 |  0.023 | torch.Size([64]) || JTF1.jbf_conv.0.bias
 |  0.098 |  0.098 |  0.098 |    nan | torch.Size([1]) || JTF1.jbf_conv.1.weight
 |  0.012 | -0.108 |  0.102 |  0.016 | torch.Size([64, 64, 3, 3]) || JTF1.jbf_conv.2.weight
 | -0.021 | -0.039 |  0.010 |  0.010 | torch.Size([64]) || JTF1.jbf_conv.2.bias
 |  0.000 | -0.069 |  0.056 |  0.013 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.0.weight
 | -0.004 | -0.014 |  0.009 |  0.004 | torch.Size([64]) || JTF11.target_kg.conv_first.0.bias
 |  0.254 |  0.254 |  0.254 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.1.weight
 |  0.003 | -0.053 |  0.073 |  0.013 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.2.weight
 | -0.001 | -0.015 |  0.021 |  0.006 | torch.Size([64]) || JTF11.target_kg.conv_first.2.bias
 |  0.254 |  0.254 |  0.254 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.3.weight
 |  0.002 | -0.043 |  0.062 |  0.013 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.4.weight
 |  0.002 | -0.042 |  0.053 |  0.033 | torch.Size([64]) || JTF11.target_kg.conv_first.4.bias
 |  0.254 |  0.254 |  0.254 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.5.weight
 | -0.002 | -0.057 |  0.073 |  0.016 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.6.weight
 | -0.024 | -0.070 |  0.087 |  0.052 | torch.Size([64]) || JTF11.target_kg.conv_first.6.bias
 |  0.254 |  0.254 |  0.254 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.7.weight
 | -0.001 | -0.101 |  0.098 |  0.024 | torch.Size([144, 64, 1, 1]) || JTF11.target_kg.conv_first.8.weight
 |  0.004 | -0.083 |  0.135 |  0.037 | torch.Size([144]) || JTF11.target_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.0.weight
 |  0.000 | -0.003 |  0.003 |  0.002 | torch.Size([64]) || JTF11.guidance_kg.conv_first.0.bias
 |  0.302 |  0.302 |  0.302 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.1.weight
 |  0.000 | -0.037 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.2.weight
 | -0.002 | -0.016 |  0.001 |  0.004 | torch.Size([64]) || JTF11.guidance_kg.conv_first.2.bias
 |  0.302 |  0.302 |  0.302 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.3.weight
 | -0.000 | -0.042 |  0.037 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.4.weight
 | -0.005 | -0.045 |  0.055 |  0.031 | torch.Size([64]) || JTF11.guidance_kg.conv_first.4.bias
 |  0.302 |  0.302 |  0.302 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.5.weight
 | -0.001 | -0.060 |  0.074 |  0.015 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.6.weight
 | -0.004 | -0.070 |  0.091 |  0.066 | torch.Size([64]) || JTF11.guidance_kg.conv_first.6.bias
 |  0.302 |  0.302 |  0.302 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.7.weight
 | -0.000 | -0.093 |  0.092 |  0.025 | torch.Size([144, 64, 1, 1]) || JTF11.guidance_kg.conv_first.8.weight
 |  0.000 | -0.130 |  0.099 |  0.037 | torch.Size([144]) || JTF11.guidance_kg.conv_first.8.bias
 |  0.001 | -0.123 |  0.119 |  0.018 | torch.Size([64, 64, 3, 3]) || JTF11.jbf_conv.0.weight
 | -0.021 | -0.078 |  0.011 |  0.023 | torch.Size([64]) || JTF11.jbf_conv.0.bias
 |  0.102 |  0.102 |  0.102 |    nan | torch.Size([1]) || JTF11.jbf_conv.1.weight
 |  0.010 | -0.132 |  0.142 |  0.017 | torch.Size([64, 64, 3, 3]) || JTF11.jbf_conv.2.weight
 | -0.021 | -0.039 |  0.011 |  0.010 | torch.Size([64]) || JTF11.jbf_conv.2.bias
 |  0.000 | -0.199 |  0.165 |  0.036 | torch.Size([128, 64, 1, 1]) || conv2.weight
 |  0.001 | -0.017 |  0.025 |  0.006 | torch.Size([128]) || conv2.bias
 | -0.000 | -0.275 |  0.330 |  0.036 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.0.weight
 | -0.007 | -0.063 |  0.036 |  0.019 | torch.Size([128]) || Deep_FE2.fe.0.bias
 |  0.132 |  0.132 |  0.132 |    nan | torch.Size([1]) || Deep_FE2.fe.1.weight
 | -0.001 | -0.323 |  0.259 |  0.034 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.2.weight
 | -0.005 | -0.072 |  0.046 |  0.023 | torch.Size([128]) || Deep_FE2.fe.2.bias
 |  0.087 |  0.087 |  0.087 |    nan | torch.Size([1]) || Deep_FE2.fe.3.weight
 | -0.002 | -0.280 |  0.335 |  0.035 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.4.weight
 | -0.003 | -0.068 |  0.048 |  0.022 | torch.Size([128]) || Deep_FE2.fe.4.bias
 |  0.093 |  0.093 |  0.093 |    nan | torch.Size([1]) || Deep_FE2.fe.5.weight
 | -0.002 | -0.260 |  0.318 |  0.031 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.6.weight
 |  0.010 | -0.032 |  0.033 |  0.012 | torch.Size([128]) || Deep_FE2.fe.6.bias
 |  0.169 |  0.169 |  0.169 |    nan | torch.Size([1]) || Deep_FE2.fe.7.weight
 | -0.000 | -0.181 |  0.181 |  0.037 | torch.Size([128, 128, 1, 1]) || Deep_FE2.fe.8.weight
 | -0.000 | -0.009 |  0.009 |  0.003 | torch.Size([128]) || Deep_FE2.fe.8.bias
 |  0.000 | -0.028 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.1.weight
 |  0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.3.weight
 | -0.000 | -0.027 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.5.weight
 |  0.000 | -0.032 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.7.weight
 |  0.000 | -0.064 |  0.066 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF2.target_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF2.target_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.1.weight
 | -0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.3.weight
 | -0.000 | -0.027 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.5.weight
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.7.weight
 | -0.000 | -0.058 |  0.066 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF2.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF2.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.jbf_conv.0.weight
 | -0.002 | -0.007 | -0.000 |  0.001 | torch.Size([128]) || JTF2.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF2.jbf_conv.1.weight
 | -0.000 | -0.030 |  0.032 |  0.007 | torch.Size([128, 128, 3, 3]) || JTF2.jbf_conv.2.weight
 | -0.000 | -0.010 |  0.007 |  0.003 | torch.Size([128]) || JTF2.jbf_conv.2.bias
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.1.weight
 | -0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.3.weight
 | -0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.5.weight
 |  0.000 | -0.031 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.7.weight
 | -0.000 | -0.067 |  0.063 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF21.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF21.target_kg.conv_first.8.bias
 | -0.000 | -0.024 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.1.weight
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.3.weight
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.5.weight
 | -0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.7.weight
 |  0.000 | -0.067 |  0.060 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF21.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF21.guidance_kg.conv_first.8.bias
 | -0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.jbf_conv.0.weight
 | -0.002 | -0.006 | -0.000 |  0.002 | torch.Size([128]) || JTF21.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF21.jbf_conv.1.weight
 | -0.000 | -0.035 |  0.031 |  0.007 | torch.Size([128, 128, 3, 3]) || JTF21.jbf_conv.2.weight
 | -0.000 | -0.010 |  0.007 |  0.003 | torch.Size([128]) || JTF21.jbf_conv.2.bias
 | -0.000 | -0.186 |  0.212 |  0.042 | torch.Size([256, 128, 1, 1]) || conv3.weight
 |  0.001 | -0.013 |  0.020 |  0.006 | torch.Size([256]) || conv3.bias
 | -0.000 | -0.070 |  0.068 |  0.018 | torch.Size([64, 128, 1, 1]) || conv_noise2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv_noise2.bias
 | -0.000 | -0.198 |  0.194 |  0.028 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.0.weight
 | -0.016 | -0.072 |  0.025 |  0.014 | torch.Size([256]) || Deep_FE3.fe.0.bias
 |  0.116 |  0.116 |  0.116 |    nan | torch.Size([1]) || Deep_FE3.fe.1.weight
 | -0.003 | -0.249 |  0.183 |  0.029 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.2.weight
 | -0.010 | -0.123 |  0.041 |  0.024 | torch.Size([256]) || Deep_FE3.fe.2.bias
 |  0.055 |  0.055 |  0.055 |    nan | torch.Size([1]) || Deep_FE3.fe.3.weight
 | -0.003 | -0.308 |  0.155 |  0.029 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.4.weight
 | -0.008 | -0.138 |  0.035 |  0.023 | torch.Size([256]) || Deep_FE3.fe.4.bias
 |  0.054 |  0.054 |  0.054 |    nan | torch.Size([1]) || Deep_FE3.fe.5.weight
 | -0.003 | -0.244 |  0.172 |  0.027 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.6.weight
 |  0.007 | -0.047 |  0.030 |  0.012 | torch.Size([256]) || Deep_FE3.fe.6.bias
 |  0.102 |  0.102 |  0.102 |    nan | torch.Size([1]) || Deep_FE3.fe.7.weight
 | -0.000 | -0.111 |  0.114 |  0.024 | torch.Size([256, 256, 1, 1]) || Deep_FE3.fe.8.weight
 | -0.000 | -0.006 |  0.006 |  0.002 | torch.Size([256]) || Deep_FE3.fe.8.bias
 |  0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.1.weight
 |  0.000 | -0.018 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.3.weight
 |  0.000 | -0.021 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.5.weight
 | -0.000 | -0.021 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.7.weight
 | -0.000 | -0.053 |  0.050 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF3.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF3.target_kg.conv_first.8.bias
 | -0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.1.weight
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.5.weight
 | -0.000 | -0.022 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.7.weight
 |  0.000 | -0.051 |  0.052 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF3.guidance_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF3.guidance_kg.conv_first.8.bias
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.jbf_conv.0.weight
 | -0.002 | -0.012 | -0.000 |  0.002 | torch.Size([256]) || JTF3.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF3.jbf_conv.1.weight
 | -0.000 | -0.029 |  0.027 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF3.jbf_conv.2.weight
 | -0.000 | -0.009 |  0.009 |  0.003 | torch.Size([256]) || JTF3.jbf_conv.2.bias
 | -0.000 | -0.022 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.1.weight
 | -0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.5.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.7.weight
 | -0.000 | -0.053 |  0.054 |  0.012 | torch.Size([144, 256, 1, 1]) || JTF31.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF31.target_kg.conv_first.8.bias
 |  0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.1.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.3.weight
 | -0.000 | -0.019 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.5.weight
 |  0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.7.weight
 |  0.000 | -0.048 |  0.054 |  0.012 | torch.Size([144, 256, 1, 1]) || JTF31.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF31.guidance_kg.conv_first.8.bias
 | -0.000 | -0.020 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.jbf_conv.0.weight
 | -0.002 | -0.010 | -0.000 |  0.002 | torch.Size([256]) || JTF31.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF31.jbf_conv.1.weight
 | -0.000 | -0.034 |  0.035 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF31.jbf_conv.2.weight
 | -0.000 | -0.009 |  0.009 |  0.003 | torch.Size([256]) || JTF31.jbf_conv.2.bias
 | -0.000 | -0.052 |  0.047 |  0.013 | torch.Size([64, 256, 1, 1]) || conv_noise3.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv_noise3.bias
 |  0.000 | -0.047 |  0.046 |  0.013 | torch.Size([256, 64, 1, 1]) || conv_noise4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || conv_noise4.bias
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.1.weight
 |  0.000 | -0.021 |  0.025 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.3.weight
 |  0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.5.weight
 | -0.000 | -0.021 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.7.weight
 |  0.000 | -0.051 |  0.053 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF4.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF4.target_kg.conv_first.8.bias
 |  0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.1.weight
 | -0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.3.weight
 | -0.000 | -0.021 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.5.weight
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.7.weight
 | -0.000 | -0.056 |  0.050 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF4.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF4.guidance_kg.conv_first.8.bias
 | -0.000 | -0.021 |  0.022 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.jbf_conv.0.weight
 | -0.004 | -0.015 | -0.000 |  0.003 | torch.Size([256]) || JTF4.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF4.jbf_conv.1.weight
 |  0.000 | -0.031 |  0.029 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF4.jbf_conv.2.weight
 | -0.000 | -0.015 |  0.010 |  0.003 | torch.Size([256]) || JTF4.jbf_conv.2.bias
 |  0.000 | -0.018 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.1.weight
 | -0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.3.weight
 |  0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.5.weight
 | -0.000 | -0.019 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.7.weight
 | -0.000 | -0.048 |  0.048 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF41.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF41.target_kg.conv_first.8.bias
 | -0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.1.weight
 |  0.000 | -0.019 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.5.weight
 |  0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.7.weight
 |  0.000 | -0.050 |  0.051 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF41.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF41.guidance_kg.conv_first.8.bias
 | -0.000 | -0.021 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.jbf_conv.0.weight
 | -0.004 | -0.012 | -0.000 |  0.003 | torch.Size([256]) || JTF41.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF41.jbf_conv.1.weight
 |  0.000 | -0.035 |  0.032 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF41.jbf_conv.2.weight
 | -0.000 | -0.015 |  0.010 |  0.003 | torch.Size([256]) || JTF41.jbf_conv.2.bias
 | -0.000 | -0.125 |  0.109 |  0.022 | torch.Size([256, 128, 2, 2]) || up1.up.weight
 | -0.000 | -0.023 |  0.029 |  0.011 | torch.Size([128]) || up1.up.bias
 | -0.000 | -0.025 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.1.weight
 |  0.000 | -0.024 |  0.029 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.3.weight
 |  0.000 | -0.025 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.5.weight
 | -0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.7.weight
 | -0.000 | -0.072 |  0.067 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF5.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF5.target_kg.conv_first.8.bias
 | -0.000 | -0.025 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.1.weight
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.3.weight
 | -0.000 | -0.028 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.5.weight
 |  0.000 | -0.027 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.7.weight
 |  0.000 | -0.063 |  0.061 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF5.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF5.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.jbf_conv.0.weight
 | -0.004 | -0.011 | -0.000 |  0.002 | torch.Size([128]) || JTF5.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF5.jbf_conv.1.weight
 | -0.000 | -0.029 |  0.029 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.jbf_conv.2.weight
 |  0.000 | -0.018 |  0.013 |  0.006 | torch.Size([128]) || JTF5.jbf_conv.2.bias
 | -0.000 | -0.025 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.1.weight
 |  0.000 | -0.024 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.3.weight
 | -0.000 | -0.028 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.5.weight
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.7.weight
 |  0.000 | -0.067 |  0.083 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF51.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF51.target_kg.conv_first.8.bias
 | -0.000 | -0.027 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.1.weight
 |  0.000 | -0.029 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.3.weight
 | -0.000 | -0.025 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.5.weight
 |  0.000 | -0.025 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.7.weight
 | -0.000 | -0.072 |  0.069 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF51.guidance_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF51.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.jbf_conv.0.weight
 | -0.004 | -0.009 | -0.000 |  0.002 | torch.Size([128]) || JTF51.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF51.jbf_conv.1.weight
 | -0.000 | -0.028 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.jbf_conv.2.weight
 |  0.000 | -0.018 |  0.013 |  0.006 | torch.Size([128]) || JTF51.jbf_conv.2.bias
 | -0.000 | -0.157 |  0.204 |  0.028 | torch.Size([128, 64, 2, 2]) || up2.up.weight
 | -0.006 | -0.025 |  0.008 |  0.006 | torch.Size([64]) || up2.up.bias
 | -0.000 | -0.034 |  0.032 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.1.weight
 |  0.000 | -0.033 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.3.weight
 | -0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.5.weight
 |  0.000 | -0.039 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.7.weight
 |  0.000 | -0.061 |  0.061 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF6.target_kg.conv_first.8.weight
 |  0.000 | -0.001 |  0.002 |  0.000 | torch.Size([144]) || JTF6.target_kg.conv_first.8.bias
 |  0.000 | -0.034 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.1.weight
 |  0.000 | -0.036 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.3.weight
 | -0.000 | -0.037 |  0.038 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.5.weight
 |  0.000 | -0.035 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.7.weight
 | -0.000 | -0.058 |  0.061 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF6.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.002 |  0.000 | torch.Size([144]) || JTF6.guidance_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.jbf_conv.0.weight
 | -0.002 | -0.009 | -0.000 |  0.002 | torch.Size([64]) || JTF6.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF6.jbf_conv.1.weight
 |  0.000 | -0.033 |  0.035 |  0.009 | torch.Size([64, 64, 3, 3]) || JTF6.jbf_conv.2.weight
 | -0.001 | -0.007 |  0.010 |  0.003 | torch.Size([64]) || JTF6.jbf_conv.2.bias
 |  0.000 | -0.033 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.1.weight
 | -0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.3.weight
 | -0.000 | -0.035 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.5.weight
 | -0.000 | -0.036 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.001 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.7.weight
 |  0.000 | -0.065 |  0.074 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF61.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.015 |  0.001 | torch.Size([144]) || JTF61.target_kg.conv_first.8.bias
 | -0.000 | -0.033 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.1.weight
 |  0.000 | -0.036 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.3.weight
 | -0.000 | -0.033 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.5.weight
 |  0.000 | -0.034 |  0.037 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.001 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.7.weight
 |  0.000 | -0.059 |  0.060 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF61.guidance_kg.conv_first.8.weight
 |  0.000 | -0.001 |  0.015 |  0.001 | torch.Size([144]) || JTF61.guidance_kg.conv_first.8.bias
 | -0.000 | -0.032 |  0.032 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.jbf_conv.0.weight
 | -0.003 | -0.009 | -0.000 |  0.002 | torch.Size([64]) || JTF61.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF61.jbf_conv.1.weight
 |  0.000 | -0.037 |  0.039 |  0.009 | torch.Size([64, 64, 3, 3]) || JTF61.jbf_conv.2.weight
 | -0.001 | -0.007 |  0.010 |  0.003 | torch.Size([64]) || JTF61.jbf_conv.2.bias

25-05-12 16:07:14.557 : <epoch:  0, iter:  10,000, lr:1.000e-04> G_loss: 4.159e-05 
25-05-12 16:07:14.558 : Saving the model.
25-05-12 16:07:15.803 : ---1--> airplane_111.jpg | 34.86dB
25-05-12 16:07:15.929 : ---2--> airport_111.jpg | 35.14dB
25-05-12 16:07:16.055 : ---3--> baseball_diamond_111.jpg | 35.82dB
25-05-12 16:07:16.179 : ---4--> basketball_court_111.jpg | 33.92dB
25-05-12 16:07:16.304 : ---5--> beach_111.jpg | 33.20dB
25-05-12 16:07:16.429 : ---6--> bridge_111.jpg | 37.55dB
25-05-12 16:07:16.554 : ---7--> chaparral_111.jpg | 32.64dB
25-05-12 16:07:16.680 : ---8--> church_111.jpg | 33.93dB
25-05-12 16:07:16.806 : ---9--> circular_farmland_111.jpg | 36.04dB
25-05-12 16:07:16.933 : --10--> cloud_111.jpg | 39.49dB
25-05-12 16:07:17.060 : --11--> commercial_area_111.jpg | 35.46dB
25-05-12 16:07:17.186 : --12--> dense_residential_111.jpg | 32.12dB
25-05-12 16:07:17.311 : --13--> desert_111.jpg | 38.73dB
25-05-12 16:07:17.437 : --14--> forest_111.jpg | 34.62dB
25-05-12 16:07:17.562 : --15--> freeway_111.jpg | 36.29dB
25-05-12 16:07:17.688 : --16--> golf_course_111.jpg | 35.37dB
25-05-12 16:07:17.815 : --17--> ground_track_field_111.jpg | 33.13dB
25-05-12 16:07:17.941 : --18--> harbor_111.jpg | 34.08dB
25-05-12 16:07:18.067 : --19--> industrial_area_111.jpg | 33.83dB
25-05-12 16:07:18.194 : --20--> intersection_111.jpg | 33.01dB
25-05-12 16:07:18.321 : --21--> island_111.jpg | 34.87dB
25-05-12 16:07:18.447 : --22--> lake_111.jpg | 34.21dB
25-05-12 16:07:18.571 : --23--> meadow_111.jpg | 32.75dB
25-05-12 16:07:18.696 : --24--> medium_residential_111.jpg | 31.39dB
25-05-12 16:07:18.823 : --25--> mobile_home_park_111.jpg | 33.98dB
25-05-12 16:07:18.949 : --26--> mountain_111.jpg | 32.02dB
25-05-12 16:07:19.076 : --27--> overpass_111.jpg | 32.81dB
25-05-12 16:07:19.201 : --28--> palace_111.jpg | 32.56dB
25-05-12 16:07:19.326 : --29--> parking_lot_111.jpg | 32.62dB
25-05-12 16:07:19.452 : --30--> railway_111.jpg | 32.63dB
25-05-12 16:07:19.578 : --31--> railway_station_111.jpg | 33.52dB
25-05-12 16:07:19.704 : --32--> rectangular_farmland_111.jpg | 35.55dB
25-05-12 16:07:19.830 : --33--> river_111.jpg | 32.76dB
25-05-12 16:07:19.956 : --34--> roundabout_111.jpg | 33.26dB
25-05-12 16:07:20.084 : --35--> runway_111.jpg | 38.31dB
25-05-12 16:07:20.208 : --36--> sea_ice_111.jpg | 36.11dB
25-05-12 16:07:20.332 : --37--> ship_111.jpg | 39.97dB
25-05-12 16:07:20.455 : --38--> snowberg_111.jpg | 35.15dB
25-05-12 16:07:20.578 : --39--> sparse_residential_111.jpg | 32.85dB
25-05-12 16:07:20.702 : --40--> stadium_111.jpg | 33.02dB
25-05-12 16:07:20.825 : --41--> storage_tank_111.jpg | 33.99dB
25-05-12 16:07:20.949 : --42--> tennis_court_111.jpg | 33.35dB
25-05-12 16:07:21.072 : --43--> terrace_111.jpg | 34.85dB
25-05-12 16:07:21.196 : --44--> thermal_power_station_111.jpg | 33.22dB
25-05-12 16:07:21.319 : --45--> wetland_111.jpg | 33.66dB
25-05-12 16:07:21.327 : <epoch:  0, iter:  10,000, Average PSNR : 34.41dB

25-05-12 17:13:12.555 : <epoch:  0, iter:  20,000, lr:1.000e-04> G_loss: 5.033e-05 
25-05-12 17:13:12.557 : Saving the model.
25-05-12 17:13:13.924 : ---1--> airplane_111.jpg | 34.94dB
25-05-12 17:13:14.048 : ---2--> airport_111.jpg | 35.19dB
25-05-12 17:13:14.173 : ---3--> baseball_diamond_111.jpg | 35.87dB
25-05-12 17:13:14.297 : ---4--> basketball_court_111.jpg | 33.99dB
25-05-12 17:13:14.422 : ---5--> beach_111.jpg | 33.28dB
25-05-12 17:13:14.549 : ---6--> bridge_111.jpg | 37.63dB
25-05-12 17:13:14.674 : ---7--> chaparral_111.jpg | 32.76dB
25-05-12 17:13:14.800 : ---8--> church_111.jpg | 34.01dB
25-05-12 17:13:14.926 : ---9--> circular_farmland_111.jpg | 36.11dB
25-05-12 17:13:15.050 : --10--> cloud_111.jpg | 39.49dB
25-05-12 17:13:15.175 : --11--> commercial_area_111.jpg | 35.48dB
25-05-12 17:13:15.300 : --12--> dense_residential_111.jpg | 32.21dB
25-05-12 17:13:15.426 : --13--> desert_111.jpg | 38.78dB
25-05-12 17:13:15.551 : --14--> forest_111.jpg | 34.65dB
25-05-12 17:13:15.681 : --15--> freeway_111.jpg | 36.37dB
25-05-12 17:13:15.807 : --16--> golf_course_111.jpg | 35.44dB
25-05-12 17:13:15.933 : --17--> ground_track_field_111.jpg | 33.24dB
25-05-12 17:13:16.058 : --18--> harbor_111.jpg | 34.16dB
25-05-12 17:13:16.189 : --19--> industrial_area_111.jpg | 33.93dB
25-05-12 17:13:16.316 : --20--> intersection_111.jpg | 33.12dB
25-05-12 17:13:16.443 : --21--> island_111.jpg | 34.95dB
25-05-12 17:13:16.571 : --22--> lake_111.jpg | 34.31dB
25-05-12 17:13:16.696 : --23--> meadow_111.jpg | 32.85dB
25-05-12 17:13:16.824 : --24--> medium_residential_111.jpg | 31.47dB
25-05-12 17:13:16.951 : --25--> mobile_home_park_111.jpg | 34.04dB
25-05-12 17:13:17.077 : --26--> mountain_111.jpg | 32.16dB
25-05-12 17:13:17.203 : --27--> overpass_111.jpg | 32.93dB
25-05-12 17:13:17.330 : --28--> palace_111.jpg | 32.63dB
25-05-12 17:13:17.461 : --29--> parking_lot_111.jpg | 32.69dB
25-05-12 17:13:17.587 : --30--> railway_111.jpg | 32.74dB
25-05-12 17:13:17.721 : --31--> railway_station_111.jpg | 33.65dB
25-05-12 17:13:17.848 : --32--> rectangular_farmland_111.jpg | 35.60dB
25-05-12 17:13:17.975 : --33--> river_111.jpg | 32.87dB
25-05-12 17:13:18.102 : --34--> roundabout_111.jpg | 33.35dB
25-05-12 17:13:18.231 : --35--> runway_111.jpg | 38.36dB
25-05-12 17:13:18.358 : --36--> sea_ice_111.jpg | 36.24dB
25-05-12 17:13:18.484 : --37--> ship_111.jpg | 40.02dB
25-05-12 17:13:18.612 : --38--> snowberg_111.jpg | 35.26dB
25-05-12 17:13:18.739 : --39--> sparse_residential_111.jpg | 32.94dB
25-05-12 17:13:18.866 : --40--> stadium_111.jpg | 33.09dB
25-05-12 17:13:18.993 : --41--> storage_tank_111.jpg | 34.05dB
25-05-12 17:13:19.121 : --42--> tennis_court_111.jpg | 33.46dB
25-05-12 17:13:19.248 : --43--> terrace_111.jpg | 34.94dB
25-05-12 17:13:19.375 : --44--> thermal_power_station_111.jpg | 33.31dB
25-05-12 17:13:19.502 : --45--> wetland_111.jpg | 33.76dB
25-05-12 17:13:19.514 : <epoch:  0, iter:  20,000, Average PSNR : 34.50dB

25-05-12 18:19:11.401 : <epoch:  0, iter:  30,000, lr:1.000e-04> G_loss: 4.288e-05 
25-05-12 18:19:11.402 : Saving the model.
25-05-12 18:19:12.487 : ---1--> airplane_111.jpg | 35.03dB
25-05-12 18:19:12.611 : ---2--> airport_111.jpg | 35.27dB
25-05-12 18:19:12.735 : ---3--> baseball_diamond_111.jpg | 35.94dB
25-05-12 18:19:12.858 : ---4--> basketball_court_111.jpg | 34.11dB
25-05-12 18:19:12.982 : ---5--> beach_111.jpg | 33.38dB
25-05-12 18:19:13.105 : ---6--> bridge_111.jpg | 37.72dB
25-05-12 18:19:11.946 : ---7--> chaparral_111.jpg | 32.89dB
25-05-12 18:19:12.069 : ---8--> church_111.jpg | 34.14dB
25-05-12 18:19:12.193 : ---9--> circular_farmland_111.jpg | 36.21dB
25-05-12 18:19:12.318 : --10--> cloud_111.jpg | 39.56dB
25-05-12 18:19:12.441 : --11--> commercial_area_111.jpg | 35.58dB
25-05-12 18:19:12.568 : --12--> dense_residential_111.jpg | 32.35dB
25-05-12 18:19:12.690 : --13--> desert_111.jpg | 38.81dB
25-05-12 18:19:12.813 : --14--> forest_111.jpg | 34.73dB
25-05-12 18:19:12.936 : --15--> freeway_111.jpg | 36.50dB
25-05-12 18:19:13.060 : --16--> golf_course_111.jpg | 35.53dB
25-05-12 18:19:13.184 : --17--> ground_track_field_111.jpg | 33.36dB
25-05-12 18:19:13.308 : --18--> harbor_111.jpg | 34.25dB
25-05-12 18:19:13.433 : --19--> industrial_area_111.jpg | 34.04dB
25-05-12 18:19:13.559 : --20--> intersection_111.jpg | 33.24dB
25-05-12 18:19:13.685 : --21--> island_111.jpg | 35.06dB
25-05-12 18:19:13.811 : --22--> lake_111.jpg | 34.38dB
25-05-12 18:19:13.936 : --23--> meadow_111.jpg | 32.95dB
25-05-12 18:19:14.063 : --24--> medium_residential_111.jpg | 31.57dB
25-05-12 18:19:14.188 : --25--> mobile_home_park_111.jpg | 34.15dB
25-05-12 18:19:14.314 : --26--> mountain_111.jpg | 32.26dB
25-05-12 18:19:14.440 : --27--> overpass_111.jpg | 33.03dB
25-05-12 18:19:14.566 : --28--> palace_111.jpg | 32.76dB
25-05-12 18:19:14.691 : --29--> parking_lot_111.jpg | 32.84dB
25-05-12 18:19:14.817 : --30--> railway_111.jpg | 32.82dB
25-05-12 18:19:14.941 : --31--> railway_station_111.jpg | 33.72dB
25-05-12 18:19:15.066 : --32--> rectangular_farmland_111.jpg | 35.71dB
25-05-12 18:19:15.191 : --33--> river_111.jpg | 32.97dB
25-05-12 18:19:15.316 : --34--> roundabout_111.jpg | 33.48dB
25-05-12 18:19:15.441 : --35--> runway_111.jpg | 38.41dB
25-05-12 18:19:15.566 : --36--> sea_ice_111.jpg | 36.38dB
25-05-12 18:19:15.691 : --37--> ship_111.jpg | 40.06dB
25-05-12 18:19:15.817 : --38--> snowberg_111.jpg | 35.38dB
25-05-12 18:19:15.944 : --39--> sparse_residential_111.jpg | 33.04dB
25-05-12 18:19:16.068 : --40--> stadium_111.jpg | 33.23dB
25-05-12 18:19:16.194 : --41--> storage_tank_111.jpg | 34.18dB
25-05-12 18:19:16.321 : --42--> tennis_court_111.jpg | 33.57dB
25-05-12 18:19:16.445 : --43--> terrace_111.jpg | 35.03dB
25-05-12 18:19:16.570 : --44--> thermal_power_station_111.jpg | 33.41dB
25-05-12 18:19:16.695 : --45--> wetland_111.jpg | 33.84dB
25-05-12 18:19:16.705 : <epoch:  0, iter:  30,000, Average PSNR : 34.60dB

25-05-12 19:25:05.771 : <epoch:  1, iter:  40,000, lr:1.000e-04> G_loss: 5.063e-05 
25-05-12 19:25:05.773 : Saving the model.
25-05-12 19:25:06.937 : ---1--> airplane_111.jpg | 35.08dB
25-05-12 19:25:07.063 : ---2--> airport_111.jpg | 35.34dB
25-05-12 19:25:07.188 : ---3--> baseball_diamond_111.jpg | 36.00dB
25-05-12 19:25:07.312 : ---4--> basketball_court_111.jpg | 34.18dB
25-05-12 19:25:07.437 : ---5--> beach_111.jpg | 33.43dB
25-05-12 19:25:07.562 : ---6--> bridge_111.jpg | 37.79dB
25-05-12 19:25:07.687 : ---7--> chaparral_111.jpg | 32.92dB
25-05-12 19:25:07.813 : ---8--> church_111.jpg | 34.22dB
25-05-12 19:25:07.941 : ---9--> circular_farmland_111.jpg | 36.25dB
25-05-12 19:25:08.068 : --10--> cloud_111.jpg | 39.50dB
25-05-12 19:25:08.195 : --11--> commercial_area_111.jpg | 35.64dB
25-05-12 19:25:08.321 : --12--> dense_residential_111.jpg | 32.42dB
25-05-12 19:25:08.446 : --13--> desert_111.jpg | 38.78dB
25-05-12 19:25:08.572 : --14--> forest_111.jpg | 34.77dB
25-05-12 19:25:08.697 : --15--> freeway_111.jpg | 36.57dB
25-05-12 19:25:08.823 : --16--> golf_course_111.jpg | 35.57dB
25-05-12 19:25:08.949 : --17--> ground_track_field_111.jpg | 33.40dB
25-05-12 19:25:09.074 : --18--> harbor_111.jpg | 34.32dB
25-05-12 19:25:09.201 : --19--> industrial_area_111.jpg | 34.10dB
25-05-12 19:25:09.328 : --20--> intersection_111.jpg | 33.31dB
25-05-12 19:25:09.453 : --21--> island_111.jpg | 35.09dB
25-05-12 19:25:09.578 : --22--> lake_111.jpg | 34.41dB
25-05-12 19:25:09.704 : --23--> meadow_111.jpg | 33.00dB
25-05-12 19:25:09.833 : --24--> medium_residential_111.jpg | 31.63dB
25-05-12 19:25:09.967 : --25--> mobile_home_park_111.jpg | 34.23dB
25-05-12 19:25:10.096 : --26--> mountain_111.jpg | 32.30dB
25-05-12 19:25:10.230 : --27--> overpass_111.jpg | 33.13dB
25-05-12 19:25:10.356 : --28--> palace_111.jpg | 32.82dB
25-05-12 19:25:10.484 : --29--> parking_lot_111.jpg | 32.92dB
25-05-12 19:25:10.611 : --30--> railway_111.jpg | 32.88dB
25-05-12 19:25:10.741 : --31--> railway_station_111.jpg | 33.76dB
25-05-12 19:25:10.866 : --32--> rectangular_farmland_111.jpg | 35.78dB
25-05-12 19:25:10.996 : --33--> river_111.jpg | 33.00dB
25-05-12 19:25:11.123 : --34--> roundabout_111.jpg | 33.50dB
25-05-12 19:25:11.249 : --35--> runway_111.jpg | 38.46dB
25-05-12 19:25:09.923 : --36--> sea_ice_111.jpg | 36.48dB
25-05-12 19:25:10.050 : --37--> ship_111.jpg | 40.09dB
25-05-12 19:25:10.178 : --38--> snowberg_111.jpg | 35.42dB
25-05-12 19:25:10.306 : --39--> sparse_residential_111.jpg | 33.10dB
25-05-12 19:25:10.433 : --40--> stadium_111.jpg | 33.28dB
25-05-12 19:25:10.559 : --41--> storage_tank_111.jpg | 34.20dB
25-05-12 19:25:10.686 : --42--> tennis_court_111.jpg | 33.66dB
25-05-12 19:25:10.812 : --43--> terrace_111.jpg | 35.10dB
25-05-12 19:25:10.939 : --44--> thermal_power_station_111.jpg | 33.48dB
25-05-12 19:25:11.066 : --45--> wetland_111.jpg | 33.89dB
25-05-12 19:25:11.075 : <epoch:  1, iter:  40,000, Average PSNR : 34.65dB

25-05-12 20:31:01.036 : <epoch:  1, iter:  50,000, lr:1.000e-04> G_loss: 4.488e-05 
25-05-12 20:31:01.038 : Saving the model.
25-05-12 20:31:02.420 : ---1--> airplane_111.jpg | 35.09dB
25-05-12 20:31:02.546 : ---2--> airport_111.jpg | 35.32dB
25-05-12 20:31:02.670 : ---3--> baseball_diamond_111.jpg | 35.99dB
25-05-12 20:31:02.796 : ---4--> basketball_court_111.jpg | 34.18dB
25-05-12 20:31:02.921 : ---5--> beach_111.jpg | 33.46dB
25-05-12 20:31:03.045 : ---6--> bridge_111.jpg | 37.77dB
25-05-12 20:31:03.168 : ---7--> chaparral_111.jpg | 32.95dB
25-05-12 20:31:03.292 : ---8--> church_111.jpg | 34.22dB
25-05-12 20:31:03.417 : ---9--> circular_farmland_111.jpg | 36.26dB
25-05-12 20:31:03.541 : --10--> cloud_111.jpg | 39.56dB
25-05-12 20:31:03.666 : --11--> commercial_area_111.jpg | 35.65dB
25-05-12 20:31:03.790 : --12--> dense_residential_111.jpg | 32.44dB
25-05-12 20:31:03.916 : --13--> desert_111.jpg | 38.76dB
25-05-12 20:31:04.041 : --14--> forest_111.jpg | 34.78dB
25-05-12 20:31:04.170 : --15--> freeway_111.jpg | 36.56dB
25-05-12 20:31:04.304 : --16--> golf_course_111.jpg | 35.58dB
25-05-12 20:31:04.429 : --17--> ground_track_field_111.jpg | 33.43dB
25-05-12 20:31:04.557 : --18--> harbor_111.jpg | 34.31dB
25-05-12 20:31:04.683 : --19--> industrial_area_111.jpg | 34.14dB
25-05-12 20:31:04.808 : --20--> intersection_111.jpg | 33.31dB
25-05-12 20:31:04.933 : --21--> island_111.jpg | 35.12dB
25-05-12 20:31:05.060 : --22--> lake_111.jpg | 34.42dB
25-05-12 20:31:05.185 : --23--> meadow_111.jpg | 33.03dB
25-05-12 20:31:05.310 : --24--> medium_residential_111.jpg | 31.64dB
25-05-12 20:31:05.435 : --25--> mobile_home_park_111.jpg | 34.21dB
25-05-12 20:31:05.561 : --26--> mountain_111.jpg | 32.32dB
25-05-12 20:31:05.686 : --27--> overpass_111.jpg | 33.16dB
25-05-12 20:31:05.812 : --28--> palace_111.jpg | 32.82dB
25-05-12 20:31:05.938 : --29--> parking_lot_111.jpg | 32.89dB
25-05-12 20:31:06.063 : --30--> railway_111.jpg | 32.90dB
25-05-12 20:31:06.189 : --31--> railway_station_111.jpg | 33.78dB
25-05-12 20:31:06.314 : --32--> rectangular_farmland_111.jpg | 35.75dB
25-05-12 20:31:06.441 : --33--> river_111.jpg | 33.03dB
25-05-12 20:31:06.567 : --34--> roundabout_111.jpg | 33.52dB
25-05-12 20:31:06.698 : --35--> runway_111.jpg | 38.43dB
25-05-12 20:31:06.833 : --36--> sea_ice_111.jpg | 36.48dB
25-05-12 20:31:06.959 : --37--> ship_111.jpg | 40.09dB
25-05-12 20:31:07.085 : --38--> snowberg_111.jpg | 35.45dB
25-05-12 20:31:07.211 : --39--> sparse_residential_111.jpg | 33.10dB
25-05-12 20:31:07.338 : --40--> stadium_111.jpg | 33.30dB
25-05-12 20:31:07.465 : --41--> storage_tank_111.jpg | 34.23dB
25-05-12 20:31:07.591 : --42--> tennis_court_111.jpg | 33.66dB
25-05-12 20:31:07.717 : --43--> terrace_111.jpg | 35.10dB
25-05-12 20:31:07.844 : --44--> thermal_power_station_111.jpg | 33.47dB
25-05-12 20:31:07.969 : --45--> wetland_111.jpg | 33.89dB
25-05-12 20:31:07.982 : <epoch:  1, iter:  50,000, Average PSNR : 34.66dB

25-05-12 21:36:23.460 : <epoch:  1, iter:  60,000, lr:2.500e-05> G_loss: 6.829e-05 
25-05-12 21:36:23.461 : Saving the model.
25-05-12 21:36:24.659 : ---1--> airplane_111.jpg | 35.16dB
25-05-12 21:36:24.785 : ---2--> airport_111.jpg | 35.38dB
25-05-12 21:36:24.908 : ---3--> baseball_diamond_111.jpg | 36.05dB
25-05-12 21:36:25.032 : ---4--> basketball_court_111.jpg | 34.20dB
25-05-12 21:36:25.157 : ---5--> beach_111.jpg | 33.51dB
25-05-12 21:36:25.288 : ---6--> bridge_111.jpg | 37.83dB
25-05-12 21:36:25.422 : ---7--> chaparral_111.jpg | 33.00dB
25-05-12 21:36:25.548 : ---8--> church_111.jpg | 34.28dB
25-05-12 21:36:25.673 : ---9--> circular_farmland_111.jpg | 36.32dB
25-05-12 21:36:25.798 : --10--> cloud_111.jpg | 39.60dB
25-05-12 21:36:25.925 : --11--> commercial_area_111.jpg | 35.67dB
25-05-12 21:36:26.050 : --12--> dense_residential_111.jpg | 32.50dB
25-05-12 21:36:26.176 : --13--> desert_111.jpg | 38.83dB
25-05-12 21:36:26.302 : --14--> forest_111.jpg | 34.81dB
25-05-12 21:36:26.429 : --15--> freeway_111.jpg | 36.63dB
25-05-12 21:36:26.554 : --16--> golf_course_111.jpg | 35.63dB
25-05-12 21:36:26.680 : --17--> ground_track_field_111.jpg | 33.47dB
25-05-12 21:36:26.806 : --18--> harbor_111.jpg | 34.37dB
25-05-12 21:36:26.932 : --19--> industrial_area_111.jpg | 34.19dB
25-05-12 21:36:27.057 : --20--> intersection_111.jpg | 33.38dB
25-05-12 21:36:27.183 : --21--> island_111.jpg | 35.17dB
25-05-12 21:36:27.308 : --22--> lake_111.jpg | 34.47dB
25-05-12 21:36:27.432 : --23--> meadow_111.jpg | 33.05dB
25-05-12 21:36:27.556 : --24--> medium_residential_111.jpg | 31.70dB
25-05-12 21:36:27.679 : --25--> mobile_home_park_111.jpg | 34.28dB
25-05-12 21:36:27.803 : --26--> mountain_111.jpg | 32.37dB
25-05-12 21:36:27.927 : --27--> overpass_111.jpg | 33.19dB
25-05-12 21:36:28.051 : --28--> palace_111.jpg | 32.87dB
25-05-12 21:36:28.175 : --29--> parking_lot_111.jpg | 32.97dB
25-05-12 21:36:28.299 : --30--> railway_111.jpg | 32.94dB
25-05-12 21:36:28.423 : --31--> railway_station_111.jpg | 33.82dB
25-05-12 21:36:28.548 : --32--> rectangular_farmland_111.jpg | 35.82dB
25-05-12 21:36:28.674 : --33--> river_111.jpg | 33.08dB
25-05-12 21:36:28.798 : --34--> roundabout_111.jpg | 33.56dB
25-05-12 21:36:28.922 : --35--> runway_111.jpg | 38.51dB
25-05-12 21:36:29.046 : --36--> sea_ice_111.jpg | 36.54dB
25-05-12 21:36:29.170 : --37--> ship_111.jpg | 40.11dB
25-05-12 21:36:29.293 : --38--> snowberg_111.jpg | 35.51dB
25-05-12 21:36:29.416 : --39--> sparse_residential_111.jpg | 33.14dB
25-05-12 21:36:29.540 : --40--> stadium_111.jpg | 33.34dB
25-05-12 21:36:29.663 : --41--> storage_tank_111.jpg | 34.26dB
25-05-12 21:36:29.787 : --42--> tennis_court_111.jpg | 33.74dB
25-05-12 21:36:29.911 : --43--> terrace_111.jpg | 35.12dB
25-05-12 21:36:30.034 : --44--> thermal_power_station_111.jpg | 33.53dB
25-05-12 21:36:30.157 : --45--> wetland_111.jpg | 33.94dB
25-05-12 21:36:30.169 : <epoch:  1, iter:  60,000, Average PSNR : 34.71dB

25-05-12 22:41:26.371 : <epoch:  2, iter:  70,000, lr:5.000e-05> G_loss: 2.748e-05 
25-05-12 22:41:26.373 : Saving the model.
25-05-12 22:41:27.367 : ---1--> airplane_111.jpg | 35.19dB
25-05-12 22:41:27.498 : ---2--> airport_111.jpg | 35.41dB
25-05-12 22:41:27.624 : ---3--> baseball_diamond_111.jpg | 36.09dB
25-05-12 22:41:27.747 : ---4--> basketball_court_111.jpg | 34.22dB
25-05-12 22:41:27.871 : ---5--> beach_111.jpg | 33.53dB
25-05-12 22:41:27.995 : ---6--> bridge_111.jpg | 37.87dB
25-05-12 22:41:28.119 : ---7--> chaparral_111.jpg | 33.00dB
25-05-12 22:41:28.243 : ---8--> church_111.jpg | 34.30dB
25-05-12 22:41:28.367 : ---9--> circular_farmland_111.jpg | 36.35dB
25-05-12 22:41:28.490 : --10--> cloud_111.jpg | 39.59dB
25-05-12 22:41:28.614 : --11--> commercial_area_111.jpg | 35.71dB
25-05-12 22:41:28.739 : --12--> dense_residential_111.jpg | 32.51dB
25-05-12 22:41:28.863 : --13--> desert_111.jpg | 38.88dB
25-05-12 22:41:28.988 : --14--> forest_111.jpg | 34.82dB
25-05-12 22:41:29.112 : --15--> freeway_111.jpg | 36.66dB
25-05-12 22:41:29.235 : --16--> golf_course_111.jpg | 35.64dB
25-05-12 22:41:29.360 : --17--> ground_track_field_111.jpg | 33.50dB
25-05-12 22:41:29.485 : --18--> harbor_111.jpg | 34.37dB
25-05-12 22:41:29.609 : --19--> industrial_area_111.jpg | 34.23dB
25-05-12 22:41:29.734 : --20--> intersection_111.jpg | 33.40dB
25-05-12 22:41:29.859 : --21--> island_111.jpg | 35.20dB
25-05-12 22:41:29.984 : --22--> lake_111.jpg | 34.48dB
25-05-12 22:41:30.110 : --23--> meadow_111.jpg | 33.07dB
25-05-12 22:41:30.236 : --24--> medium_residential_111.jpg | 31.70dB
25-05-12 22:41:30.360 : --25--> mobile_home_park_111.jpg | 34.29dB
25-05-12 22:41:30.484 : --26--> mountain_111.jpg | 32.38dB
25-05-12 22:41:30.610 : --27--> overpass_111.jpg | 33.19dB
25-05-12 22:41:30.734 : --28--> palace_111.jpg | 32.89dB
25-05-12 22:41:30.860 : --29--> parking_lot_111.jpg | 32.98dB
25-05-12 22:41:30.985 : --30--> railway_111.jpg | 32.96dB
25-05-12 22:41:31.109 : --31--> railway_station_111.jpg | 33.85dB
25-05-12 22:41:31.234 : --32--> rectangular_farmland_111.jpg | 35.84dB
25-05-12 22:41:31.360 : --33--> river_111.jpg | 33.09dB
25-05-12 22:41:31.484 : --34--> roundabout_111.jpg | 33.59dB
25-05-12 22:41:31.608 : --35--> runway_111.jpg | 38.56dB
25-05-12 22:41:31.732 : --36--> sea_ice_111.jpg | 36.56dB
25-05-12 22:41:31.857 : --37--> ship_111.jpg | 40.18dB
25-05-12 22:41:31.982 : --38--> snowberg_111.jpg | 35.51dB
25-05-12 22:41:32.108 : --39--> sparse_residential_111.jpg | 33.14dB
25-05-12 22:41:32.233 : --40--> stadium_111.jpg | 33.36dB
25-05-12 22:41:32.358 : --41--> storage_tank_111.jpg | 34.26dB
25-05-12 22:41:32.482 : --42--> tennis_court_111.jpg | 33.75dB
25-05-12 22:41:32.607 : --43--> terrace_111.jpg | 35.14dB
25-05-12 22:41:32.730 : --44--> thermal_power_station_111.jpg | 33.55dB
25-05-12 22:41:32.855 : --45--> wetland_111.jpg | 33.95dB
25-05-12 22:41:32.862 : <epoch:  2, iter:  70,000, Average PSNR : 34.73dB

25-05-12 23:46:29.688 : <epoch:  2, iter:  80,000, lr:5.000e-05> G_loss: 5.112e-05 
25-05-12 23:46:29.690 : Saving the model.
25-05-12 23:46:30.694 : ---1--> airplane_111.jpg | 35.20dB
25-05-12 23:46:30.821 : ---2--> airport_111.jpg | 35.41dB
25-05-12 23:46:30.944 : ---3--> baseball_diamond_111.jpg | 36.09dB
25-05-12 23:46:31.069 : ---4--> basketball_court_111.jpg | 34.24dB
25-05-12 23:46:31.200 : ---5--> beach_111.jpg | 33.54dB
25-05-12 23:46:31.325 : ---6--> bridge_111.jpg | 37.89dB
25-05-12 23:46:31.449 : ---7--> chaparral_111.jpg | 33.02dB
25-05-12 23:46:31.573 : ---8--> church_111.jpg | 34.32dB
25-05-12 23:46:31.697 : ---9--> circular_farmland_111.jpg | 36.36dB
25-05-12 23:46:31.822 : --10--> cloud_111.jpg | 39.64dB
25-05-12 23:46:31.945 : --11--> commercial_area_111.jpg | 35.71dB
25-05-12 23:46:32.069 : --12--> dense_residential_111.jpg | 32.53dB
25-05-12 23:46:32.194 : --13--> desert_111.jpg | 38.89dB
25-05-12 23:46:32.318 : --14--> forest_111.jpg | 34.83dB
25-05-12 23:46:32.442 : --15--> freeway_111.jpg | 36.68dB
25-05-12 23:46:32.565 : --16--> golf_course_111.jpg | 35.65dB
25-05-12 23:46:32.689 : --17--> ground_track_field_111.jpg | 33.51dB
25-05-12 23:46:32.813 : --18--> harbor_111.jpg | 34.40dB
25-05-12 23:46:32.938 : --19--> industrial_area_111.jpg | 34.23dB
25-05-12 23:46:33.061 : --20--> intersection_111.jpg | 33.41dB
25-05-12 23:46:33.186 : --21--> island_111.jpg | 35.21dB
25-05-12 23:46:33.310 : --22--> lake_111.jpg | 34.50dB
25-05-12 23:46:33.434 : --23--> meadow_111.jpg | 33.07dB
25-05-12 23:46:33.558 : --24--> medium_residential_111.jpg | 31.71dB
25-05-12 23:46:33.682 : --25--> mobile_home_park_111.jpg | 34.31dB
25-05-12 23:46:33.806 : --26--> mountain_111.jpg | 32.39dB
25-05-12 23:46:33.931 : --27--> overpass_111.jpg | 33.22dB
25-05-12 23:46:34.054 : --28--> palace_111.jpg | 32.90dB
25-05-12 23:46:34.178 : --29--> parking_lot_111.jpg | 32.99dB
25-05-12 23:46:34.303 : --30--> railway_111.jpg | 32.98dB
25-05-12 23:46:34.427 : --31--> railway_station_111.jpg | 33.86dB
25-05-12 23:46:34.551 : --32--> rectangular_farmland_111.jpg | 35.85dB
25-05-12 23:46:34.676 : --33--> river_111.jpg | 33.10dB
25-05-12 23:46:34.801 : --34--> roundabout_111.jpg | 33.61dB
25-05-12 23:46:34.926 : --35--> runway_111.jpg | 38.56dB
25-05-12 23:46:35.052 : --36--> sea_ice_111.jpg | 36.59dB
25-05-12 23:46:35.176 : --37--> ship_111.jpg | 40.19dB
25-05-12 23:46:35.300 : --38--> snowberg_111.jpg | 35.54dB
25-05-12 23:46:35.425 : --39--> sparse_residential_111.jpg | 33.15dB
25-05-12 23:46:35.560 : --40--> stadium_111.jpg | 33.37dB
25-05-12 23:46:35.686 : --41--> storage_tank_111.jpg | 34.28dB
25-05-12 23:46:35.811 : --42--> tennis_court_111.jpg | 33.77dB
25-05-12 23:46:35.935 : --43--> terrace_111.jpg | 35.16dB
25-05-12 23:46:36.059 : --44--> thermal_power_station_111.jpg | 33.56dB
25-05-12 23:46:36.185 : --45--> wetland_111.jpg | 33.95dB
25-05-12 23:46:36.197 : <epoch:  2, iter:  80,000, Average PSNR : 34.74dB

25-05-13 00:51:30.807 : <epoch:  2, iter:  90,000, lr:1.250e-05> G_loss: 4.662e-05 
25-05-13 00:51:30.808 : Saving the model.
25-05-13 00:51:31.826 : ---1--> airplane_111.jpg | 35.21dB
25-05-13 00:51:31.949 : ---2--> airport_111.jpg | 35.41dB
25-05-13 00:51:32.072 : ---3--> baseball_diamond_111.jpg | 36.08dB
25-05-13 00:51:32.195 : ---4--> basketball_court_111.jpg | 34.23dB
25-05-13 00:51:32.320 : ---5--> beach_111.jpg | 33.54dB
25-05-13 00:51:32.443 : ---6--> bridge_111.jpg | 37.87dB
25-05-13 00:51:32.565 : ---7--> chaparral_111.jpg | 33.00dB
25-05-13 00:51:32.687 : ---8--> church_111.jpg | 34.32dB
25-05-13 00:51:32.810 : ---9--> circular_farmland_111.jpg | 36.34dB
25-05-13 00:51:32.933 : --10--> cloud_111.jpg | 39.61dB
25-05-13 00:51:33.059 : --11--> commercial_area_111.jpg | 35.70dB
25-05-13 00:51:33.180 : --12--> dense_residential_111.jpg | 32.54dB
25-05-13 00:51:33.301 : --13--> desert_111.jpg | 38.89dB
25-05-13 00:51:33.424 : --14--> forest_111.jpg | 34.83dB
25-05-13 00:51:33.546 : --15--> freeway_111.jpg | 36.68dB
25-05-13 00:51:33.673 : --16--> golf_course_111.jpg | 35.65dB
25-05-13 00:51:33.796 : --17--> ground_track_field_111.jpg | 33.51dB
25-05-13 00:51:33.918 : --18--> harbor_111.jpg | 34.38dB
25-05-13 00:51:34.040 : --19--> industrial_area_111.jpg | 34.25dB
25-05-13 00:51:34.163 : --20--> intersection_111.jpg | 33.40dB
25-05-13 00:51:34.286 : --21--> island_111.jpg | 35.22dB
25-05-13 00:51:34.409 : --22--> lake_111.jpg | 34.48dB
25-05-13 00:51:34.533 : --23--> meadow_111.jpg | 33.06dB
25-05-13 00:51:34.656 : --24--> medium_residential_111.jpg | 31.72dB
25-05-13 00:51:34.779 : --25--> mobile_home_park_111.jpg | 34.31dB
25-05-13 00:51:34.902 : --26--> mountain_111.jpg | 32.38dB
25-05-13 00:51:35.025 : --27--> overpass_111.jpg | 33.22dB
25-05-13 00:51:35.148 : --28--> palace_111.jpg | 32.90dB
25-05-13 00:51:35.271 : --29--> parking_lot_111.jpg | 33.00dB
25-05-13 00:51:35.393 : --30--> railway_111.jpg | 32.98dB
25-05-13 00:51:35.515 : --31--> railway_station_111.jpg | 33.86dB
25-05-13 00:51:35.639 : --32--> rectangular_farmland_111.jpg | 35.86dB
25-05-13 00:51:35.763 : --33--> river_111.jpg | 33.10dB
25-05-13 00:51:35.886 : --34--> roundabout_111.jpg | 33.60dB
25-05-13 00:51:36.009 : --35--> runway_111.jpg | 38.57dB
25-05-13 00:51:36.132 : --36--> sea_ice_111.jpg | 36.57dB
25-05-13 00:51:36.255 : --37--> ship_111.jpg | 40.17dB
25-05-13 00:51:36.379 : --38--> snowberg_111.jpg | 35.52dB
25-05-13 00:51:36.501 : --39--> sparse_residential_111.jpg | 33.16dB
25-05-13 00:51:36.625 : --40--> stadium_111.jpg | 33.38dB
25-05-13 00:51:36.746 : --41--> storage_tank_111.jpg | 34.26dB
25-05-13 00:51:36.869 : --42--> tennis_court_111.jpg | 33.76dB
25-05-13 00:51:36.992 : --43--> terrace_111.jpg | 35.14dB
25-05-13 00:51:37.115 : --44--> thermal_power_station_111.jpg | 33.56dB
25-05-13 00:51:37.238 : --45--> wetland_111.jpg | 33.95dB
25-05-13 00:51:37.245 : <epoch:  2, iter:  90,000, Average PSNR : 34.74dB

25-05-13 01:56:32.434 : <epoch:  3, iter: 100,000, lr:2.500e-05> G_loss: 6.040e-05 
25-05-13 01:56:32.436 : Saving the model.
25-05-13 01:56:33.425 : ---1--> airplane_111.jpg | 35.23dB
25-05-13 01:56:33.542 : ---2--> airport_111.jpg | 35.44dB
25-05-13 01:56:33.660 : ---3--> baseball_diamond_111.jpg | 36.11dB
25-05-13 01:56:33.777 : ---4--> basketball_court_111.jpg | 34.25dB
25-05-13 01:56:33.895 : ---5--> beach_111.jpg | 33.55dB
25-05-13 01:56:34.013 : ---6--> bridge_111.jpg | 37.91dB
25-05-13 01:56:34.131 : ---7--> chaparral_111.jpg | 33.02dB
25-05-13 01:56:34.254 : ---8--> church_111.jpg | 34.34dB
25-05-13 01:56:34.380 : ---9--> circular_farmland_111.jpg | 36.38dB
25-05-13 01:56:34.505 : --10--> cloud_111.jpg | 39.65dB
25-05-13 01:56:34.630 : --11--> commercial_area_111.jpg | 35.73dB
25-05-13 01:56:34.754 : --12--> dense_residential_111.jpg | 32.56dB
25-05-13 01:56:34.881 : --13--> desert_111.jpg | 38.92dB
25-05-13 01:56:35.007 : --14--> forest_111.jpg | 34.84dB
25-05-13 01:56:35.132 : --15--> freeway_111.jpg | 36.70dB
25-05-13 01:56:35.257 : --16--> golf_course_111.jpg | 35.67dB
25-05-13 01:56:35.383 : --17--> ground_track_field_111.jpg | 33.53dB
25-05-13 01:56:35.508 : --18--> harbor_111.jpg | 34.40dB
25-05-13 01:56:35.633 : --19--> industrial_area_111.jpg | 34.26dB
25-05-13 01:56:35.760 : --20--> intersection_111.jpg | 33.43dB
25-05-13 01:56:35.886 : --21--> island_111.jpg | 35.24dB
25-05-13 01:56:36.012 : --22--> lake_111.jpg | 34.51dB
25-05-13 01:56:36.138 : --23--> meadow_111.jpg | 33.09dB
25-05-13 01:56:36.263 : --24--> medium_residential_111.jpg | 31.73dB
25-05-13 01:56:36.389 : --25--> mobile_home_park_111.jpg | 34.33dB
25-05-13 01:56:36.515 : --26--> mountain_111.jpg | 32.41dB
25-05-13 01:56:36.641 : --27--> overpass_111.jpg | 33.24dB
25-05-13 01:56:36.766 : --28--> palace_111.jpg | 32.92dB
25-05-13 01:56:36.891 : --29--> parking_lot_111.jpg | 33.02dB
25-05-13 01:56:37.017 : --30--> railway_111.jpg | 33.00dB
25-05-13 01:56:37.143 : --31--> railway_station_111.jpg | 33.89dB
25-05-13 01:56:37.270 : --32--> rectangular_farmland_111.jpg | 35.86dB
25-05-13 01:56:37.395 : --33--> river_111.jpg | 33.12dB
25-05-13 01:56:37.520 : --34--> roundabout_111.jpg | 33.62dB
25-05-13 01:56:37.645 : --35--> runway_111.jpg | 38.58dB
25-05-13 01:56:37.771 : --36--> sea_ice_111.jpg | 36.59dB
25-05-13 01:56:37.897 : --37--> ship_111.jpg | 40.21dB
25-05-13 01:56:38.025 : --38--> snowberg_111.jpg | 35.56dB
25-05-13 01:56:38.150 : --39--> sparse_residential_111.jpg | 33.17dB
25-05-13 01:56:38.277 : --40--> stadium_111.jpg | 33.38dB
25-05-13 01:56:38.403 : --41--> storage_tank_111.jpg | 34.29dB
25-05-13 01:56:38.528 : --42--> tennis_court_111.jpg | 33.80dB
25-05-13 01:56:38.654 : --43--> terrace_111.jpg | 35.18dB
25-05-13 01:56:38.780 : --44--> thermal_power_station_111.jpg | 33.58dB
25-05-13 01:56:38.906 : --45--> wetland_111.jpg | 33.97dB
25-05-13 01:56:38.919 : <epoch:  3, iter: 100,000, Average PSNR : 34.76dB

25-05-13 03:01:34.373 : <epoch:  3, iter: 110,000, lr:2.500e-05> G_loss: 2.757e-05 
25-05-13 03:01:34.374 : Saving the model.
25-05-13 03:01:35.399 : ---1--> airplane_111.jpg | 35.25dB
25-05-13 03:01:35.523 : ---2--> airport_111.jpg | 35.43dB
25-05-13 03:01:35.648 : ---3--> baseball_diamond_111.jpg | 36.12dB
25-05-13 03:01:35.772 : ---4--> basketball_court_111.jpg | 34.25dB
25-05-13 03:01:35.897 : ---5--> beach_111.jpg | 33.57dB
25-05-13 03:01:36.022 : ---6--> bridge_111.jpg | 37.91dB
25-05-13 03:01:36.147 : ---7--> chaparral_111.jpg | 33.04dB
25-05-13 03:01:36.273 : ---8--> church_111.jpg | 34.35dB
25-05-13 03:01:36.397 : ---9--> circular_farmland_111.jpg | 36.39dB
25-05-13 03:01:36.522 : --10--> cloud_111.jpg | 39.64dB
25-05-13 03:01:36.647 : --11--> commercial_area_111.jpg | 35.73dB
25-05-13 03:01:36.772 : --12--> dense_residential_111.jpg | 32.56dB
25-05-13 03:01:36.897 : --13--> desert_111.jpg | 38.92dB
25-05-13 03:01:37.027 : --14--> forest_111.jpg | 34.85dB
25-05-13 03:01:37.154 : --15--> freeway_111.jpg | 36.70dB
25-05-13 03:01:37.280 : --16--> golf_course_111.jpg | 35.67dB
25-05-13 03:01:37.404 : --17--> ground_track_field_111.jpg | 33.54dB
25-05-13 03:01:35.696 : --18--> harbor_111.jpg | 34.41dB
25-05-13 03:01:35.820 : --19--> industrial_area_111.jpg | 34.28dB
25-05-13 03:01:35.945 : --20--> intersection_111.jpg | 33.43dB
25-05-13 03:01:36.071 : --21--> island_111.jpg | 35.25dB
25-05-13 03:01:36.197 : --22--> lake_111.jpg | 34.51dB
25-05-13 03:01:36.322 : --23--> meadow_111.jpg | 33.09dB
25-05-13 03:01:36.449 : --24--> medium_residential_111.jpg | 31.74dB
25-05-13 03:01:36.575 : --25--> mobile_home_park_111.jpg | 34.33dB
25-05-13 03:01:36.709 : --26--> mountain_111.jpg | 32.42dB
25-05-13 03:01:36.840 : --27--> overpass_111.jpg | 33.24dB
25-05-13 03:01:36.966 : --28--> palace_111.jpg | 32.92dB
25-05-13 03:01:37.092 : --29--> parking_lot_111.jpg | 33.02dB
25-05-13 03:01:37.226 : --30--> railway_111.jpg | 33.00dB
25-05-13 03:01:37.356 : --31--> railway_station_111.jpg | 33.90dB
25-05-13 03:01:37.480 : --32--> rectangular_farmland_111.jpg | 35.87dB
25-05-13 03:01:37.607 : --33--> river_111.jpg | 33.14dB
25-05-13 03:01:37.734 : --34--> roundabout_111.jpg | 33.64dB
25-05-13 03:01:37.860 : --35--> runway_111.jpg | 38.59dB
25-05-13 03:01:37.985 : --36--> sea_ice_111.jpg | 36.60dB
25-05-13 03:01:38.110 : --37--> ship_111.jpg | 40.22dB
25-05-13 03:01:38.238 : --38--> snowberg_111.jpg | 35.56dB
25-05-13 03:01:38.363 : --39--> sparse_residential_111.jpg | 33.18dB
25-05-13 03:01:38.488 : --40--> stadium_111.jpg | 33.39dB
25-05-13 03:01:38.612 : --41--> storage_tank_111.jpg | 34.30dB
25-05-13 03:01:38.737 : --42--> tennis_court_111.jpg | 33.80dB
25-05-13 03:01:38.862 : --43--> terrace_111.jpg | 35.18dB
25-05-13 03:01:38.986 : --44--> thermal_power_station_111.jpg | 33.58dB
25-05-13 03:01:39.111 : --45--> wetland_111.jpg | 33.97dB
25-05-13 03:01:39.120 : <epoch:  3, iter: 110,000, Average PSNR : 34.77dB

25-05-13 04:06:33.738 : <epoch:  3, iter: 120,000, lr:6.250e-06> G_loss: 4.961e-05 
25-05-13 04:06:33.739 : Saving the model.
25-05-13 04:06:34.782 : ---1--> airplane_111.jpg | 35.26dB
25-05-13 04:06:34.907 : ---2--> airport_111.jpg | 35.44dB
25-05-13 04:06:35.032 : ---3--> baseball_diamond_111.jpg | 36.12dB
25-05-13 04:06:35.158 : ---4--> basketball_court_111.jpg | 34.25dB
25-05-13 04:06:35.283 : ---5--> beach_111.jpg | 33.57dB
25-05-13 04:06:35.408 : ---6--> bridge_111.jpg | 37.91dB
25-05-13 04:06:35.532 : ---7--> chaparral_111.jpg | 33.04dB
25-05-13 04:06:35.659 : ---8--> church_111.jpg | 34.35dB
25-05-13 04:06:35.783 : ---9--> circular_farmland_111.jpg | 36.39dB
25-05-13 04:06:35.907 : --10--> cloud_111.jpg | 39.65dB
25-05-13 04:06:36.033 : --11--> commercial_area_111.jpg | 35.73dB
25-05-13 04:06:36.158 : --12--> dense_residential_111.jpg | 32.56dB
25-05-13 04:06:36.283 : --13--> desert_111.jpg | 38.90dB
25-05-13 04:06:36.409 : --14--> forest_111.jpg | 34.85dB
25-05-13 04:06:36.533 : --15--> freeway_111.jpg | 36.72dB
25-05-13 04:06:36.657 : --16--> golf_course_111.jpg | 35.68dB
25-05-13 04:06:36.782 : --17--> ground_track_field_111.jpg | 33.54dB
25-05-13 04:06:36.907 : --18--> harbor_111.jpg | 34.42dB
25-05-13 04:06:37.032 : --19--> industrial_area_111.jpg | 34.28dB
25-05-13 04:06:37.162 : --20--> intersection_111.jpg | 33.44dB
25-05-13 04:06:37.287 : --21--> island_111.jpg | 35.25dB
25-05-13 04:06:37.412 : --22--> lake_111.jpg | 34.52dB
25-05-13 04:06:37.538 : --23--> meadow_111.jpg | 33.10dB
25-05-13 04:06:37.662 : --24--> medium_residential_111.jpg | 31.75dB
25-05-13 04:06:37.787 : --25--> mobile_home_park_111.jpg | 34.33dB
25-05-13 04:06:37.911 : --26--> mountain_111.jpg | 32.42dB
25-05-13 04:06:38.037 : --27--> overpass_111.jpg | 33.26dB
25-05-13 04:06:38.166 : --28--> palace_111.jpg | 32.93dB
25-05-13 04:06:38.291 : --29--> parking_lot_111.jpg | 33.03dB
25-05-13 04:06:38.417 : --30--> railway_111.jpg | 33.01dB
25-05-13 04:06:38.544 : --31--> railway_station_111.jpg | 33.89dB
25-05-13 04:06:38.670 : --32--> rectangular_farmland_111.jpg | 35.87dB
25-05-13 04:06:38.796 : --33--> river_111.jpg | 33.14dB
25-05-13 04:06:38.921 : --34--> roundabout_111.jpg | 33.64dB
25-05-13 04:06:39.047 : --35--> runway_111.jpg | 38.57dB
25-05-13 04:06:39.173 : --36--> sea_ice_111.jpg | 36.60dB
25-05-13 04:06:39.299 : --37--> ship_111.jpg | 40.20dB
25-05-13 04:06:39.425 : --38--> snowberg_111.jpg | 35.57dB
25-05-13 04:06:39.551 : --39--> sparse_residential_111.jpg | 33.18dB
25-05-13 04:06:39.677 : --40--> stadium_111.jpg | 33.39dB
25-05-13 04:06:39.804 : --41--> storage_tank_111.jpg | 34.30dB
25-05-13 04:06:39.930 : --42--> tennis_court_111.jpg | 33.81dB
25-05-13 04:06:40.057 : --43--> terrace_111.jpg | 35.18dB
25-05-13 04:06:40.181 : --44--> thermal_power_station_111.jpg | 33.59dB
25-05-13 04:06:40.307 : --45--> wetland_111.jpg | 33.98dB
25-05-13 04:06:40.315 : <epoch:  3, iter: 120,000, Average PSNR : 34.77dB

25-05-13 05:11:33.742 : <epoch:  4, iter: 130,000, lr:1.250e-05> G_loss: 3.215e-05 
25-05-13 05:11:33.745 : Saving the model.
25-05-13 05:11:34.704 : ---1--> airplane_111.jpg | 35.25dB
25-05-13 05:11:34.823 : ---2--> airport_111.jpg | 35.44dB
25-05-13 05:11:34.944 : ---3--> baseball_diamond_111.jpg | 36.12dB
25-05-13 05:11:35.069 : ---4--> basketball_court_111.jpg | 34.27dB
25-05-13 05:11:35.195 : ---5--> beach_111.jpg | 33.58dB
25-05-13 05:11:35.326 : ---6--> bridge_111.jpg | 37.92dB
25-05-13 05:11:35.452 : ---7--> chaparral_111.jpg | 33.04dB
25-05-13 05:11:35.578 : ---8--> church_111.jpg | 34.36dB
25-05-13 05:11:35.704 : ---9--> circular_farmland_111.jpg | 36.39dB
25-05-13 05:11:35.830 : --10--> cloud_111.jpg | 39.63dB
25-05-13 05:11:35.957 : --11--> commercial_area_111.jpg | 35.74dB
25-05-13 05:11:36.082 : --12--> dense_residential_111.jpg | 32.57dB
25-05-13 05:11:36.208 : --13--> desert_111.jpg | 38.94dB
25-05-13 05:11:36.333 : --14--> forest_111.jpg | 34.85dB
25-05-13 05:11:36.459 : --15--> freeway_111.jpg | 36.73dB
25-05-13 05:11:36.585 : --16--> golf_course_111.jpg | 35.68dB
25-05-13 05:11:36.711 : --17--> ground_track_field_111.jpg | 33.54dB
25-05-13 05:11:36.836 : --18--> harbor_111.jpg | 34.42dB
25-05-13 05:11:36.961 : --19--> industrial_area_111.jpg | 34.29dB
25-05-13 05:11:37.087 : --20--> intersection_111.jpg | 33.44dB
25-05-13 05:11:37.213 : --21--> island_111.jpg | 35.26dB
25-05-13 05:11:37.340 : --22--> lake_111.jpg | 34.52dB
25-05-13 05:11:37.465 : --23--> meadow_111.jpg | 33.10dB
25-05-13 05:11:37.592 : --24--> medium_residential_111.jpg | 31.75dB
25-05-13 05:11:37.717 : --25--> mobile_home_park_111.jpg | 34.34dB
25-05-13 05:11:37.845 : --26--> mountain_111.jpg | 32.41dB
25-05-13 05:11:37.977 : --27--> overpass_111.jpg | 33.27dB
25-05-13 05:11:38.103 : --28--> palace_111.jpg | 32.93dB
25-05-13 05:11:38.229 : --29--> parking_lot_111.jpg | 33.03dB
25-05-13 05:11:38.356 : --30--> railway_111.jpg | 33.02dB
25-05-13 05:11:38.484 : --31--> railway_station_111.jpg | 33.89dB
25-05-13 05:11:38.611 : --32--> rectangular_farmland_111.jpg | 35.87dB
25-05-13 05:11:38.738 : --33--> river_111.jpg | 33.14dB
25-05-13 05:11:38.864 : --34--> roundabout_111.jpg | 33.64dB
25-05-13 05:11:38.990 : --35--> runway_111.jpg | 38.59dB
25-05-13 05:11:39.115 : --36--> sea_ice_111.jpg | 36.62dB
25-05-13 05:11:39.241 : --37--> ship_111.jpg | 40.22dB
25-05-13 05:11:39.368 : --38--> snowberg_111.jpg | 35.57dB
25-05-13 05:11:39.496 : --39--> sparse_residential_111.jpg | 33.19dB
25-05-13 05:11:39.623 : --40--> stadium_111.jpg | 33.41dB
25-05-13 05:11:39.749 : --41--> storage_tank_111.jpg | 34.31dB
25-05-13 05:11:39.876 : --42--> tennis_court_111.jpg | 33.81dB
25-05-13 05:11:40.008 : --43--> terrace_111.jpg | 35.18dB
25-05-13 05:11:40.137 : --44--> thermal_power_station_111.jpg | 33.59dB
25-05-13 05:11:40.255 : --45--> wetland_111.jpg | 33.97dB
25-05-13 05:11:40.264 : <epoch:  4, iter: 130,000, Average PSNR : 34.77dB

25-05-13 06:16:32.569 : <epoch:  4, iter: 140,000, lr:1.250e-05> G_loss: 5.009e-05 
25-05-13 06:16:32.570 : Saving the model.
25-05-13 06:16:33.478 : ---1--> airplane_111.jpg | 35.26dB
25-05-13 06:16:33.596 : ---2--> airport_111.jpg | 35.45dB
25-05-13 06:16:33.713 : ---3--> baseball_diamond_111.jpg | 36.13dB
25-05-13 06:16:33.831 : ---4--> basketball_court_111.jpg | 34.27dB
25-05-13 06:16:33.948 : ---5--> beach_111.jpg | 33.58dB
25-05-13 06:16:34.067 : ---6--> bridge_111.jpg | 37.93dB
25-05-13 06:16:34.186 : ---7--> chaparral_111.jpg | 33.06dB
25-05-13 06:16:34.303 : ---8--> church_111.jpg | 34.36dB
25-05-13 06:16:34.421 : ---9--> circular_farmland_111.jpg | 36.40dB
25-05-13 06:16:34.539 : --10--> cloud_111.jpg | 39.65dB
25-05-13 06:16:34.656 : --11--> commercial_area_111.jpg | 35.74dB
25-05-13 06:16:34.773 : --12--> dense_residential_111.jpg | 32.58dB
25-05-13 06:16:34.891 : --13--> desert_111.jpg | 38.93dB
25-05-13 06:16:35.011 : --14--> forest_111.jpg | 34.85dB
25-05-13 06:16:35.128 : --15--> freeway_111.jpg | 36.73dB
25-05-13 06:16:35.246 : --16--> golf_course_111.jpg | 35.69dB
25-05-13 06:16:35.364 : --17--> ground_track_field_111.jpg | 33.55dB
25-05-13 06:16:35.481 : --18--> harbor_111.jpg | 34.42dB
25-05-13 06:16:35.599 : --19--> industrial_area_111.jpg | 34.29dB
25-05-13 06:16:35.716 : --20--> intersection_111.jpg | 33.45dB
25-05-13 06:16:35.833 : --21--> island_111.jpg | 35.26dB
25-05-13 06:16:35.952 : --22--> lake_111.jpg | 34.53dB
25-05-13 06:16:36.070 : --23--> meadow_111.jpg | 33.11dB
25-05-13 06:16:36.189 : --24--> medium_residential_111.jpg | 31.76dB
25-05-13 06:16:36.307 : --25--> mobile_home_park_111.jpg | 34.35dB
25-05-13 06:16:36.425 : --26--> mountain_111.jpg | 32.43dB
25-05-13 06:16:36.543 : --27--> overpass_111.jpg | 33.27dB
25-05-13 06:16:36.661 : --28--> palace_111.jpg | 32.93dB
25-05-13 06:16:36.779 : --29--> parking_lot_111.jpg | 33.03dB
25-05-13 06:16:36.897 : --30--> railway_111.jpg | 33.02dB
25-05-13 06:16:37.015 : --31--> railway_station_111.jpg | 33.90dB
25-05-13 06:16:37.133 : --32--> rectangular_farmland_111.jpg | 35.88dB
25-05-13 06:16:37.251 : --33--> river_111.jpg | 33.15dB
25-05-13 06:16:37.368 : --34--> roundabout_111.jpg | 33.65dB
25-05-13 06:16:37.487 : --35--> runway_111.jpg | 38.60dB
25-05-13 06:16:37.606 : --36--> sea_ice_111.jpg | 36.62dB
25-05-13 06:16:37.723 : --37--> ship_111.jpg | 40.24dB
25-05-13 06:16:37.841 : --38--> snowberg_111.jpg | 35.59dB
25-05-13 06:16:37.959 : --39--> sparse_residential_111.jpg | 33.19dB
25-05-13 06:16:38.078 : --40--> stadium_111.jpg | 33.40dB
25-05-13 06:16:38.196 : --41--> storage_tank_111.jpg | 34.31dB
25-05-13 06:16:38.315 : --42--> tennis_court_111.jpg | 33.82dB
25-05-13 06:16:38.433 : --43--> terrace_111.jpg | 35.19dB
25-05-13 06:16:38.551 : --44--> thermal_power_station_111.jpg | 33.60dB
25-05-13 06:16:38.669 : --45--> wetland_111.jpg | 33.99dB
25-05-13 06:16:38.682 : <epoch:  4, iter: 140,000, Average PSNR : 34.78dB

25-05-13 07:21:32.699 : <epoch:  4, iter: 150,000, lr:1.250e-05> G_loss: 4.828e-05 
25-05-13 07:21:32.701 : Saving the model.
25-05-13 07:21:33.574 : ---1--> airplane_111.jpg | 35.27dB
25-05-13 07:21:33.693 : ---2--> airport_111.jpg | 35.45dB
25-05-13 07:21:33.811 : ---3--> baseball_diamond_111.jpg | 36.13dB
25-05-13 07:21:33.930 : ---4--> basketball_court_111.jpg | 34.27dB
25-05-13 07:21:34.049 : ---5--> beach_111.jpg | 33.59dB
25-05-13 07:21:34.166 : ---6--> bridge_111.jpg | 37.94dB
25-05-13 07:21:34.282 : ---7--> chaparral_111.jpg | 33.06dB
25-05-13 07:21:34.400 : ---8--> church_111.jpg | 34.36dB
25-05-13 07:21:34.517 : ---9--> circular_farmland_111.jpg | 36.40dB
25-05-13 07:21:34.635 : --10--> cloud_111.jpg | 39.65dB
25-05-13 07:21:34.752 : --11--> commercial_area_111.jpg | 35.74dB
25-05-13 07:21:34.868 : --12--> dense_residential_111.jpg | 32.58dB
25-05-13 07:21:34.985 : --13--> desert_111.jpg | 38.93dB
25-05-13 07:21:35.107 : --14--> forest_111.jpg | 34.86dB
25-05-13 07:21:35.225 : --15--> freeway_111.jpg | 36.73dB
25-05-13 07:21:35.342 : --16--> golf_course_111.jpg | 35.69dB
25-05-13 07:21:35.459 : --17--> ground_track_field_111.jpg | 33.55dB
25-05-13 07:21:35.578 : --18--> harbor_111.jpg | 34.43dB
25-05-13 07:21:35.697 : --19--> industrial_area_111.jpg | 34.30dB
25-05-13 07:21:35.814 : --20--> intersection_111.jpg | 33.45dB
25-05-13 07:21:35.932 : --21--> island_111.jpg | 35.27dB
25-05-13 07:21:36.051 : --22--> lake_111.jpg | 34.53dB
25-05-13 07:21:36.168 : --23--> meadow_111.jpg | 33.11dB
25-05-13 07:21:36.286 : --24--> medium_residential_111.jpg | 31.76dB
25-05-13 07:21:36.405 : --25--> mobile_home_park_111.jpg | 34.35dB
25-05-13 07:21:36.523 : --26--> mountain_111.jpg | 32.43dB
25-05-13 07:21:36.643 : --27--> overpass_111.jpg | 33.27dB
25-05-13 07:21:36.762 : --28--> palace_111.jpg | 32.94dB
25-05-13 07:21:36.882 : --29--> parking_lot_111.jpg | 33.04dB
25-05-13 07:21:37.002 : --30--> railway_111.jpg | 33.02dB
25-05-13 07:21:37.121 : --31--> railway_station_111.jpg | 33.91dB
25-05-13 07:21:37.239 : --32--> rectangular_farmland_111.jpg | 35.90dB
25-05-13 07:21:37.358 : --33--> river_111.jpg | 33.15dB
25-05-13 07:21:37.475 : --34--> roundabout_111.jpg | 33.65dB
25-05-13 07:21:37.594 : --35--> runway_111.jpg | 38.61dB
25-05-13 07:21:37.714 : --36--> sea_ice_111.jpg | 36.62dB
25-05-13 07:21:37.832 : --37--> ship_111.jpg | 40.24dB
25-05-13 07:21:37.950 : --38--> snowberg_111.jpg | 35.58dB
25-05-13 07:21:38.067 : --39--> sparse_residential_111.jpg | 33.19dB
25-05-13 07:21:38.186 : --40--> stadium_111.jpg | 33.41dB
25-05-13 07:21:38.304 : --41--> storage_tank_111.jpg | 34.31dB
25-05-13 07:21:38.421 : --42--> tennis_court_111.jpg | 33.82dB
25-05-13 07:21:38.539 : --43--> terrace_111.jpg | 35.19dB
25-05-13 07:21:38.657 : --44--> thermal_power_station_111.jpg | 33.60dB
25-05-13 07:21:38.776 : --45--> wetland_111.jpg | 33.99dB
25-05-13 07:21:38.788 : <epoch:  4, iter: 150,000, Average PSNR : 34.78dB

25-05-13 08:26:34.516 : <epoch:  5, iter: 160,000, lr:1.250e-05> G_loss: 2.772e-05 
25-05-13 08:26:34.517 : Saving the model.
25-05-13 08:26:35.421 : ---1--> airplane_111.jpg | 35.26dB
25-05-13 08:26:35.539 : ---2--> airport_111.jpg | 35.45dB
25-05-13 08:26:35.655 : ---3--> baseball_diamond_111.jpg | 36.13dB
25-05-13 08:26:35.773 : ---4--> basketball_court_111.jpg | 34.27dB
25-05-13 08:26:35.890 : ---5--> beach_111.jpg | 33.58dB
25-05-13 08:26:36.007 : ---6--> bridge_111.jpg | 37.94dB
25-05-13 08:26:36.126 : ---7--> chaparral_111.jpg | 33.06dB
25-05-13 08:26:36.242 : ---8--> church_111.jpg | 34.37dB
25-05-13 08:26:36.360 : ---9--> circular_farmland_111.jpg | 36.41dB
25-05-13 08:26:36.476 : --10--> cloud_111.jpg | 39.66dB
25-05-13 08:26:36.594 : --11--> commercial_area_111.jpg | 35.74dB
25-05-13 08:26:36.711 : --12--> dense_residential_111.jpg | 32.58dB
25-05-13 08:26:36.828 : --13--> desert_111.jpg | 38.94dB
25-05-13 08:26:36.945 : --14--> forest_111.jpg | 34.86dB
25-05-13 08:26:37.062 : --15--> freeway_111.jpg | 36.74dB
25-05-13 08:26:37.178 : --16--> golf_course_111.jpg | 35.69dB
25-05-13 08:26:37.295 : --17--> ground_track_field_111.jpg | 33.55dB
25-05-13 08:26:37.412 : --18--> harbor_111.jpg | 34.43dB
25-05-13 08:26:37.529 : --19--> industrial_area_111.jpg | 34.31dB
25-05-13 08:26:37.647 : --20--> intersection_111.jpg | 33.45dB
25-05-13 08:26:37.768 : --21--> island_111.jpg | 35.27dB
25-05-13 08:26:37.886 : --22--> lake_111.jpg | 34.53dB
25-05-13 08:26:38.003 : --23--> meadow_111.jpg | 33.11dB
25-05-13 08:26:38.121 : --24--> medium_residential_111.jpg | 31.76dB
25-05-13 08:26:38.239 : --25--> mobile_home_park_111.jpg | 34.35dB
25-05-13 08:26:38.356 : --26--> mountain_111.jpg | 32.43dB
25-05-13 08:26:38.473 : --27--> overpass_111.jpg | 33.27dB
25-05-13 08:26:38.590 : --28--> palace_111.jpg | 32.94dB
25-05-13 08:26:38.707 : --29--> parking_lot_111.jpg | 33.04dB
25-05-13 08:26:38.825 : --30--> railway_111.jpg | 33.02dB
25-05-13 08:26:38.942 : --31--> railway_station_111.jpg | 33.91dB
25-05-13 08:26:39.061 : --32--> rectangular_farmland_111.jpg | 35.89dB
25-05-13 08:26:39.179 : --33--> river_111.jpg | 33.16dB
25-05-13 08:26:39.298 : --34--> roundabout_111.jpg | 33.65dB
25-05-13 08:26:39.417 : --35--> runway_111.jpg | 38.60dB
25-05-13 08:26:39.535 : --36--> sea_ice_111.jpg | 36.62dB
25-05-13 08:26:39.653 : --37--> ship_111.jpg | 40.23dB
25-05-13 08:26:39.770 : --38--> snowberg_111.jpg | 35.59dB
25-05-13 08:26:39.889 : --39--> sparse_residential_111.jpg | 33.19dB
25-05-13 08:26:40.006 : --40--> stadium_111.jpg | 33.41dB
25-05-13 08:26:40.123 : --41--> storage_tank_111.jpg | 34.32dB
25-05-13 08:26:40.241 : --42--> tennis_court_111.jpg | 33.82dB
25-05-13 08:26:40.358 : --43--> terrace_111.jpg | 35.20dB
25-05-13 08:26:40.476 : --44--> thermal_power_station_111.jpg | 33.60dB
25-05-13 08:26:40.593 : --45--> wetland_111.jpg | 33.98dB
25-05-13 08:26:40.606 : <epoch:  5, iter: 160,000, Average PSNR : 34.78dB

25-05-13 09:42:15.458 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/150000_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 25
      sigma_test: 25
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 25
      sigma_test: 25
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 10000
    checkpoint_save: 10000
    checkpoint_print: 10000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-13 09:42:15.458 : Random seed: 2007
25-05-13 09:42:15.598 : Number of train images: 31,005, iters: 31,005
25-05-13 09:42:16.732 : 
Networks name: DRNet
Params number: 35274045
Net structure:
DRNet(
  (endconv): outconv(
    (conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
  )
  (FE1): FE(
    (fe): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
    (1): PReLU(num_parameters=1)
  )
  (Deep_FE1): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (FCN_SFT1): FCN_SFT(
    (fcn1): FCN(
      (fcn): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
      )
    )
    (fcn2): FCN(
      (fcn): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
      )
    )
    (sft1): SFTLayer(
      (SFT_scale_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (Sigmoid): Sigmoid()
    )
    (sft2): SFTLayer(
      (SFT_scale_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (Sigmoid): Sigmoid()
    )
    (con): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (JTF1): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF11): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
  (Deep_FE2): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (JTF2): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF21): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (conv_noise2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  (Deep_FE3): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (JTF3): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF31): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (conv_noise3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  (conv_noise4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
  (JTF4): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF41): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (up1): up(
    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
  )
  (JTF5): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF51): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (up2): up(
    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
  )
  (JTF6): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF61): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
)

25-05-13 09:42:17.915 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.000 | -0.040 |  0.058 |  0.018 | torch.Size([3, 64, 1, 1]) || endconv.conv.weight
 | -0.003 | -0.004 | -0.002 |  0.001 | torch.Size([3]) || endconv.conv.bias
 | -0.000 | -0.286 |  0.167 |  0.044 | torch.Size([64, 3, 3, 3]) || FE1.fe.0.weight
 |  0.053 | -0.048 |  0.112 |  0.021 | torch.Size([64]) || FE1.fe.0.bias
 |  0.163 |  0.163 |  0.163 |    nan | torch.Size([1]) || FE1.fe.1.weight
 |  0.001 | -0.202 |  0.271 |  0.030 | torch.Size([64, 64, 3, 3]) || FE1.fe.2.weight
 |  0.025 | -0.003 |  0.070 |  0.013 | torch.Size([64]) || FE1.fe.2.bias
 |  0.929 |  0.929 |  0.929 |    nan | torch.Size([1]) || FE1.fe.3.weight
 |  0.005 | -0.197 |  0.276 |  0.026 | torch.Size([64, 64, 3, 3]) || FE1.fe.4.weight
 |  0.022 | -0.014 |  0.042 |  0.011 | torch.Size([64]) || FE1.fe.4.bias
 |  0.420 |  0.420 |  0.420 |    nan | torch.Size([1]) || FE1.fe.5.weight
 | -0.001 | -0.090 |  0.064 |  0.025 | torch.Size([64, 3, 1, 1]) || conv1.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv1.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || conv1.1.weight
 | -0.001 | -0.278 |  0.375 |  0.037 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.0.weight
 |  0.014 | -0.097 |  0.113 |  0.042 | torch.Size([64]) || Deep_FE1.fe.0.bias
 |  0.121 |  0.121 |  0.121 |    nan | torch.Size([1]) || Deep_FE1.fe.1.weight
 | -0.000 | -0.238 |  0.381 |  0.042 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.2.weight
 |  0.008 | -0.063 |  0.091 |  0.036 | torch.Size([64]) || Deep_FE1.fe.2.bias
 |  0.091 |  0.091 |  0.091 |    nan | torch.Size([1]) || Deep_FE1.fe.3.weight
 | -0.000 | -0.293 |  0.297 |  0.042 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.4.weight
 |  0.015 | -0.056 |  0.071 |  0.041 | torch.Size([64]) || Deep_FE1.fe.4.bias
 |  0.022 |  0.022 |  0.022 |    nan | torch.Size([1]) || Deep_FE1.fe.5.weight
 | -0.002 | -0.315 |  0.230 |  0.042 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.6.weight
 |  0.016 | -0.055 |  0.060 |  0.026 | torch.Size([64]) || Deep_FE1.fe.6.bias
 |  0.012 |  0.012 |  0.012 |    nan | torch.Size([1]) || Deep_FE1.fe.7.weight
 | -0.008 | -0.231 |  0.269 |  0.055 | torch.Size([64, 64, 1, 1]) || Deep_FE1.fe.8.weight
 | -0.007 | -0.022 |  0.011 |  0.006 | torch.Size([64]) || Deep_FE1.fe.8.bias
 | -0.000 | -0.033 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.1.weight
 | -0.000 | -0.036 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.3.weight
 | -0.000 | -0.032 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.4.weight
 | -0.000 | -0.001 |  0.002 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.5.weight
 |  0.000 | -0.036 |  0.044 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.1.weight
 | -0.000 | -0.035 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.3.weight
 |  0.000 | -0.039 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.4.weight
 |  0.000 | -0.001 |  0.002 |  0.001 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.5.weight
 |  0.000 | -0.082 |  0.092 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_scale_conv0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_scale_conv0.bias
 |  0.000 | -0.085 |  0.090 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_scale_conv1.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_scale_conv1.bias
 | -0.000 | -0.089 |  0.087 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_shift_conv0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_shift_conv0.bias
 |  0.000 | -0.091 |  0.082 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_shift_conv1.weight
 | -0.000 | -0.002 |  0.001 |  0.001 | torch.Size([64]) || FCN_SFT1.sft1.SFT_shift_conv1.bias
 | -0.000 | -0.081 |  0.081 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_scale_conv0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_scale_conv0.bias
 |  0.000 | -0.083 |  0.096 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_scale_conv1.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_scale_conv1.bias
 | -0.000 | -0.090 |  0.086 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_shift_conv0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_shift_conv0.bias
 | -0.000 | -0.087 |  0.079 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_shift_conv1.weight
 | -0.000 | -0.001 |  0.001 |  0.001 | torch.Size([64]) || FCN_SFT1.sft2.SFT_shift_conv1.bias
 | -0.000 | -0.066 |  0.062 |  0.018 | torch.Size([64, 128, 1, 1]) || FCN_SFT1.con.weight
 |  0.001 | -0.008 |  0.007 |  0.004 | torch.Size([64]) || FCN_SFT1.con.bias
 | -0.000 | -0.043 |  0.046 |  0.010 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.0.weight
 | -0.005 | -0.030 |  0.031 |  0.013 | torch.Size([64]) || JTF1.target_kg.conv_first.0.bias
 |  0.292 |  0.292 |  0.292 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.1.weight
 |  0.000 | -0.045 |  0.040 |  0.010 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.2.weight
 |  0.010 | -0.017 |  0.041 |  0.015 | torch.Size([64]) || JTF1.target_kg.conv_first.2.bias
 |  0.292 |  0.292 |  0.292 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.3.weight
 |  0.001 | -0.037 |  0.042 |  0.010 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.4.weight
 |  0.014 | -0.047 |  0.078 |  0.038 | torch.Size([64]) || JTF1.target_kg.conv_first.4.bias
 |  0.292 |  0.292 |  0.292 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.5.weight
 |  0.001 | -0.041 |  0.055 |  0.012 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.6.weight
 |  0.012 | -0.054 |  0.087 |  0.055 | torch.Size([64]) || JTF1.target_kg.conv_first.6.bias
 |  0.292 |  0.292 |  0.292 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.7.weight
 | -0.000 | -0.114 |  0.107 |  0.022 | torch.Size([144, 64, 1, 1]) || JTF1.target_kg.conv_first.8.weight
 |  0.004 | -0.132 |  0.131 |  0.037 | torch.Size([144]) || JTF1.target_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.041 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.0.weight
 | -0.001 | -0.004 |  0.006 |  0.002 | torch.Size([64]) || JTF1.guidance_kg.conv_first.0.bias
 |  0.303 |  0.303 |  0.303 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.1.weight
 | -0.000 | -0.034 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.2.weight
 |  0.000 | -0.001 |  0.004 |  0.001 | torch.Size([64]) || JTF1.guidance_kg.conv_first.2.bias
 |  0.303 |  0.303 |  0.303 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.3.weight
 | -0.000 | -0.033 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.4.weight
 |  0.012 | -0.048 |  0.073 |  0.039 | torch.Size([64]) || JTF1.guidance_kg.conv_first.4.bias
 |  0.303 |  0.303 |  0.303 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.5.weight
 |  0.001 | -0.043 |  0.054 |  0.012 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.6.weight
 |  0.014 | -0.053 |  0.089 |  0.060 | torch.Size([64]) || JTF1.guidance_kg.conv_first.6.bias
 |  0.303 |  0.303 |  0.303 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.7.weight
 | -0.000 | -0.101 |  0.106 |  0.022 | torch.Size([144, 64, 1, 1]) || JTF1.guidance_kg.conv_first.8.weight
 | -0.002 | -0.124 |  0.129 |  0.038 | torch.Size([144]) || JTF1.guidance_kg.conv_first.8.bias
 | -0.001 | -0.156 |  0.139 |  0.016 | torch.Size([64, 64, 3, 3]) || JTF1.jbf_conv.0.weight
 | -0.023 | -0.056 |  0.023 |  0.017 | torch.Size([64]) || JTF1.jbf_conv.0.bias
 |  0.068 |  0.068 |  0.068 |    nan | torch.Size([1]) || JTF1.jbf_conv.1.weight
 |  0.012 | -0.100 |  0.100 |  0.017 | torch.Size([64, 64, 3, 3]) || JTF1.jbf_conv.2.weight
 | -0.022 | -0.042 |  0.020 |  0.012 | torch.Size([64]) || JTF1.jbf_conv.2.bias
 | -0.001 | -0.068 |  0.069 |  0.013 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.0.weight
 | -0.017 | -0.039 |  0.033 |  0.014 | torch.Size([64]) || JTF11.target_kg.conv_first.0.bias
 |  0.231 |  0.231 |  0.231 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.1.weight
 |  0.002 | -0.053 |  0.070 |  0.013 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.2.weight
 |  0.009 | -0.039 |  0.054 |  0.016 | torch.Size([64]) || JTF11.target_kg.conv_first.2.bias
 |  0.231 |  0.231 |  0.231 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.3.weight
 |  0.002 | -0.044 |  0.062 |  0.013 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.4.weight
 |  0.008 | -0.060 |  0.094 |  0.057 | torch.Size([64]) || JTF11.target_kg.conv_first.4.bias
 |  0.231 |  0.231 |  0.231 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.5.weight
 | -0.002 | -0.057 |  0.072 |  0.017 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.6.weight
 | -0.024 | -0.079 |  0.116 |  0.066 | torch.Size([64]) || JTF11.target_kg.conv_first.6.bias
 |  0.231 |  0.231 |  0.231 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.7.weight
 | -0.001 | -0.107 |  0.111 |  0.025 | torch.Size([144, 64, 1, 1]) || JTF11.target_kg.conv_first.8.weight
 |  0.005 | -0.098 |  0.124 |  0.044 | torch.Size([144]) || JTF11.target_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.0.weight
 |  0.000 | -0.003 |  0.005 |  0.002 | torch.Size([64]) || JTF11.guidance_kg.conv_first.0.bias
 |  0.332 |  0.332 |  0.332 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.1.weight
 |  0.000 | -0.037 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.2.weight
 | -0.004 | -0.036 |  0.006 |  0.010 | torch.Size([64]) || JTF11.guidance_kg.conv_first.2.bias
 |  0.332 |  0.332 |  0.332 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.3.weight
 | -0.000 | -0.042 |  0.037 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.4.weight
 | -0.004 | -0.066 |  0.087 |  0.052 | torch.Size([64]) || JTF11.guidance_kg.conv_first.4.bias
 |  0.332 |  0.332 |  0.332 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.5.weight
 | -0.001 | -0.061 |  0.077 |  0.015 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.6.weight
 |  0.000 | -0.080 |  0.115 |  0.081 | torch.Size([64]) || JTF11.guidance_kg.conv_first.6.bias
 |  0.332 |  0.332 |  0.332 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.7.weight
 | -0.000 | -0.108 |  0.100 |  0.026 | torch.Size([144, 64, 1, 1]) || JTF11.guidance_kg.conv_first.8.weight
 | -0.001 | -0.122 |  0.110 |  0.042 | torch.Size([144]) || JTF11.guidance_kg.conv_first.8.bias
 |  0.002 | -0.182 |  0.145 |  0.020 | torch.Size([64, 64, 3, 3]) || JTF11.jbf_conv.0.weight
 | -0.029 | -0.102 |  0.057 |  0.035 | torch.Size([64]) || JTF11.jbf_conv.0.bias
 |  0.055 |  0.055 |  0.055 |    nan | torch.Size([1]) || JTF11.jbf_conv.1.weight
 |  0.010 | -0.189 |  0.185 |  0.020 | torch.Size([64, 64, 3, 3]) || JTF11.jbf_conv.2.weight
 | -0.023 | -0.043 |  0.017 |  0.012 | torch.Size([64]) || JTF11.jbf_conv.2.bias
 | -0.000 | -0.221 |  0.205 |  0.049 | torch.Size([128, 64, 1, 1]) || conv2.weight
 |  0.002 | -0.027 |  0.026 |  0.009 | torch.Size([128]) || conv2.bias
 | -0.001 | -0.281 |  0.286 |  0.037 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.0.weight
 | -0.013 | -0.094 |  0.041 |  0.026 | torch.Size([128]) || Deep_FE2.fe.0.bias
 |  0.112 |  0.112 |  0.112 |    nan | torch.Size([1]) || Deep_FE2.fe.1.weight
 | -0.001 | -0.311 |  0.291 |  0.036 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.2.weight
 | -0.007 | -0.098 |  0.059 |  0.031 | torch.Size([128]) || Deep_FE2.fe.2.bias
 |  0.105 |  0.105 |  0.105 |    nan | torch.Size([1]) || Deep_FE2.fe.3.weight
 | -0.002 | -0.345 |  0.341 |  0.036 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.4.weight
 | -0.004 | -0.086 |  0.061 |  0.029 | torch.Size([128]) || Deep_FE2.fe.4.bias
 |  0.126 |  0.126 |  0.126 |    nan | torch.Size([1]) || Deep_FE2.fe.5.weight
 | -0.003 | -0.242 |  0.316 |  0.032 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.6.weight
 |  0.009 | -0.053 |  0.036 |  0.015 | torch.Size([128]) || Deep_FE2.fe.6.bias
 |  0.209 |  0.209 |  0.209 |    nan | torch.Size([1]) || Deep_FE2.fe.7.weight
 | -0.000 | -0.181 |  0.192 |  0.040 | torch.Size([128, 128, 1, 1]) || Deep_FE2.fe.8.weight
 | -0.000 | -0.015 |  0.009 |  0.004 | torch.Size([128]) || Deep_FE2.fe.8.bias
 |  0.000 | -0.028 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.1.weight
 |  0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.3.weight
 | -0.000 | -0.027 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.5.weight
 |  0.000 | -0.032 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.7.weight
 |  0.000 | -0.064 |  0.066 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF2.target_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF2.target_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.1.weight
 | -0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.3.weight
 | -0.000 | -0.027 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.5.weight
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.7.weight
 | -0.000 | -0.058 |  0.066 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF2.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF2.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.jbf_conv.0.weight
 | -0.002 | -0.007 | -0.000 |  0.001 | torch.Size([128]) || JTF2.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF2.jbf_conv.1.weight
 | -0.000 | -0.030 |  0.032 |  0.007 | torch.Size([128, 128, 3, 3]) || JTF2.jbf_conv.2.weight
 | -0.001 | -0.016 |  0.009 |  0.004 | torch.Size([128]) || JTF2.jbf_conv.2.bias
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.1.weight
 | -0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.3.weight
 | -0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.5.weight
 |  0.000 | -0.031 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.7.weight
 | -0.000 | -0.067 |  0.063 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF21.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF21.target_kg.conv_first.8.bias
 | -0.000 | -0.024 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.1.weight
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.3.weight
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.5.weight
 | -0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.7.weight
 |  0.000 | -0.067 |  0.060 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF21.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF21.guidance_kg.conv_first.8.bias
 | -0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.jbf_conv.0.weight
 | -0.002 | -0.006 | -0.000 |  0.002 | torch.Size([128]) || JTF21.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF21.jbf_conv.1.weight
 | -0.000 | -0.035 |  0.031 |  0.007 | torch.Size([128, 128, 3, 3]) || JTF21.jbf_conv.2.weight
 | -0.001 | -0.016 |  0.009 |  0.004 | torch.Size([128]) || JTF21.jbf_conv.2.bias
 | -0.000 | -0.195 |  0.216 |  0.045 | torch.Size([256, 128, 1, 1]) || conv3.weight
 |  0.001 | -0.022 |  0.022 |  0.009 | torch.Size([256]) || conv3.bias
 | -0.000 | -0.070 |  0.068 |  0.018 | torch.Size([64, 128, 1, 1]) || conv_noise2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv_noise2.bias
 | -0.000 | -0.201 |  0.194 |  0.028 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.0.weight
 | -0.018 | -0.062 |  0.059 |  0.018 | torch.Size([256]) || Deep_FE3.fe.0.bias
 |  0.152 |  0.152 |  0.152 |    nan | torch.Size([1]) || Deep_FE3.fe.1.weight
 | -0.003 | -0.258 |  0.204 |  0.029 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.2.weight
 | -0.011 | -0.136 |  0.050 |  0.030 | torch.Size([256]) || Deep_FE3.fe.2.bias
 |  0.110 |  0.110 |  0.110 |    nan | torch.Size([1]) || Deep_FE3.fe.3.weight
 | -0.003 | -0.314 |  0.176 |  0.029 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.4.weight
 | -0.008 | -0.185 |  0.064 |  0.030 | torch.Size([256]) || Deep_FE3.fe.4.bias
 |  0.107 |  0.107 |  0.107 |    nan | torch.Size([1]) || Deep_FE3.fe.5.weight
 | -0.002 | -0.243 |  0.172 |  0.027 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.6.weight
 |  0.012 | -0.063 |  0.058 |  0.019 | torch.Size([256]) || Deep_FE3.fe.6.bias
 |  0.154 |  0.154 |  0.154 |    nan | torch.Size([1]) || Deep_FE3.fe.7.weight
 | -0.000 | -0.119 |  0.115 |  0.025 | torch.Size([256, 256, 1, 1]) || Deep_FE3.fe.8.weight
 | -0.000 | -0.019 |  0.016 |  0.007 | torch.Size([256]) || Deep_FE3.fe.8.bias
 |  0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.1.weight
 |  0.000 | -0.018 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.3.weight
 |  0.000 | -0.021 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.5.weight
 | -0.000 | -0.021 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.7.weight
 | -0.000 | -0.053 |  0.050 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF3.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF3.target_kg.conv_first.8.bias
 | -0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.1.weight
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.5.weight
 | -0.000 | -0.022 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.7.weight
 |  0.000 | -0.051 |  0.052 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF3.guidance_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF3.guidance_kg.conv_first.8.bias
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.jbf_conv.0.weight
 | -0.003 | -0.012 | -0.000 |  0.002 | torch.Size([256]) || JTF3.jbf_conv.0.bias
 |  0.004 |  0.004 |  0.004 |    nan | torch.Size([1]) || JTF3.jbf_conv.1.weight
 | -0.000 | -0.029 |  0.027 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF3.jbf_conv.2.weight
 | -0.000 | -0.020 |  0.017 |  0.007 | torch.Size([256]) || JTF3.jbf_conv.2.bias
 | -0.000 | -0.022 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.1.weight
 | -0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.5.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.7.weight
 | -0.000 | -0.053 |  0.054 |  0.012 | torch.Size([144, 256, 1, 1]) || JTF31.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF31.target_kg.conv_first.8.bias
 |  0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.1.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.3.weight
 | -0.000 | -0.019 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.5.weight
 |  0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.7.weight
 |  0.000 | -0.048 |  0.054 |  0.012 | torch.Size([144, 256, 1, 1]) || JTF31.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF31.guidance_kg.conv_first.8.bias
 | -0.000 | -0.020 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.jbf_conv.0.weight
 | -0.002 | -0.009 | -0.000 |  0.002 | torch.Size([256]) || JTF31.jbf_conv.0.bias
 |  0.004 |  0.004 |  0.004 |    nan | torch.Size([1]) || JTF31.jbf_conv.1.weight
 | -0.000 | -0.034 |  0.035 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF31.jbf_conv.2.weight
 | -0.000 | -0.020 |  0.017 |  0.007 | torch.Size([256]) || JTF31.jbf_conv.2.bias
 | -0.000 | -0.052 |  0.047 |  0.013 | torch.Size([64, 256, 1, 1]) || conv_noise3.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv_noise3.bias
 |  0.000 | -0.047 |  0.046 |  0.013 | torch.Size([256, 64, 1, 1]) || conv_noise4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || conv_noise4.bias
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.1.weight
 |  0.000 | -0.021 |  0.025 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.3.weight
 |  0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.5.weight
 | -0.000 | -0.021 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.7.weight
 |  0.000 | -0.051 |  0.053 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF4.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF4.target_kg.conv_first.8.bias
 |  0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.1.weight
 | -0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.3.weight
 | -0.000 | -0.021 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.5.weight
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.7.weight
 | -0.000 | -0.056 |  0.050 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF4.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF4.guidance_kg.conv_first.8.bias
 | -0.000 | -0.021 |  0.022 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.jbf_conv.0.weight
 | -0.004 | -0.015 | -0.000 |  0.003 | torch.Size([256]) || JTF4.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF4.jbf_conv.1.weight
 |  0.000 | -0.031 |  0.029 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF4.jbf_conv.2.weight
 | -0.000 | -0.046 |  0.019 |  0.009 | torch.Size([256]) || JTF4.jbf_conv.2.bias
 |  0.000 | -0.018 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.1.weight
 | -0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.3.weight
 |  0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.5.weight
 | -0.000 | -0.019 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.7.weight
 | -0.000 | -0.048 |  0.048 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF41.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF41.target_kg.conv_first.8.bias
 | -0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.1.weight
 |  0.000 | -0.019 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.5.weight
 |  0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.7.weight
 |  0.000 | -0.050 |  0.051 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF41.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF41.guidance_kg.conv_first.8.bias
 | -0.000 | -0.021 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.jbf_conv.0.weight
 | -0.004 | -0.011 | -0.000 |  0.003 | torch.Size([256]) || JTF41.jbf_conv.0.bias
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || JTF41.jbf_conv.1.weight
 |  0.000 | -0.035 |  0.032 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF41.jbf_conv.2.weight
 | -0.000 | -0.046 |  0.019 |  0.009 | torch.Size([256]) || JTF41.jbf_conv.2.bias
 | -0.000 | -0.128 |  0.117 |  0.022 | torch.Size([256, 128, 2, 2]) || up1.up.weight
 | -0.000 | -0.029 |  0.032 |  0.013 | torch.Size([128]) || up1.up.bias
 | -0.000 | -0.025 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.1.weight
 |  0.000 | -0.024 |  0.029 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.3.weight
 |  0.000 | -0.025 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.5.weight
 | -0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.7.weight
 | -0.000 | -0.072 |  0.067 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF5.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF5.target_kg.conv_first.8.bias
 | -0.000 | -0.025 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.1.weight
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.3.weight
 | -0.000 | -0.028 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.5.weight
 |  0.000 | -0.027 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.7.weight
 |  0.000 | -0.063 |  0.061 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF5.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF5.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.jbf_conv.0.weight
 | -0.004 | -0.011 | -0.000 |  0.002 | torch.Size([128]) || JTF5.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF5.jbf_conv.1.weight
 | -0.000 | -0.029 |  0.029 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.jbf_conv.2.weight
 | -0.000 | -0.021 |  0.026 |  0.008 | torch.Size([128]) || JTF5.jbf_conv.2.bias
 | -0.000 | -0.025 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.1.weight
 |  0.000 | -0.024 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.3.weight
 | -0.000 | -0.028 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.5.weight
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.7.weight
 |  0.000 | -0.067 |  0.083 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF51.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF51.target_kg.conv_first.8.bias
 | -0.000 | -0.027 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.1.weight
 |  0.000 | -0.029 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.3.weight
 | -0.000 | -0.025 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.5.weight
 |  0.000 | -0.025 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.7.weight
 | -0.000 | -0.072 |  0.069 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF51.guidance_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF51.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.jbf_conv.0.weight
 | -0.004 | -0.009 | -0.000 |  0.002 | torch.Size([128]) || JTF51.jbf_conv.0.bias
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || JTF51.jbf_conv.1.weight
 | -0.000 | -0.028 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.jbf_conv.2.weight
 | -0.000 | -0.021 |  0.026 |  0.008 | torch.Size([128]) || JTF51.jbf_conv.2.bias
 | -0.001 | -0.154 |  0.197 |  0.031 | torch.Size([128, 64, 2, 2]) || up2.up.weight
 | -0.011 | -0.037 |  0.016 |  0.011 | torch.Size([64]) || up2.up.bias
 | -0.000 | -0.034 |  0.032 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.1.weight
 |  0.000 | -0.033 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.3.weight
 | -0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.5.weight
 |  0.000 | -0.039 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.7.weight
 |  0.000 | -0.061 |  0.061 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF6.target_kg.conv_first.8.weight
 |  0.000 | -0.001 |  0.002 |  0.000 | torch.Size([144]) || JTF6.target_kg.conv_first.8.bias
 |  0.000 | -0.034 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.1.weight
 |  0.000 | -0.036 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.3.weight
 | -0.000 | -0.037 |  0.038 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.5.weight
 |  0.000 | -0.035 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.7.weight
 | -0.000 | -0.058 |  0.061 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF6.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.002 |  0.000 | torch.Size([144]) || JTF6.guidance_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.jbf_conv.0.weight
 | -0.002 | -0.009 | -0.000 |  0.002 | torch.Size([64]) || JTF6.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF6.jbf_conv.1.weight
 |  0.000 | -0.033 |  0.035 |  0.009 | torch.Size([64, 64, 3, 3]) || JTF6.jbf_conv.2.weight
 |  0.003 | -0.006 |  0.022 |  0.005 | torch.Size([64]) || JTF6.jbf_conv.2.bias
 |  0.000 | -0.033 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.1.weight
 | -0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.3.weight
 | -0.000 | -0.035 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.5.weight
 | -0.000 | -0.036 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.001 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.7.weight
 |  0.000 | -0.065 |  0.074 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF61.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.015 |  0.001 | torch.Size([144]) || JTF61.target_kg.conv_first.8.bias
 | -0.000 | -0.033 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.1.weight
 |  0.000 | -0.036 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.3.weight
 | -0.000 | -0.033 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.5.weight
 |  0.000 | -0.034 |  0.037 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.001 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.7.weight
 |  0.000 | -0.059 |  0.060 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF61.guidance_kg.conv_first.8.weight
 |  0.000 | -0.001 |  0.015 |  0.001 | torch.Size([144]) || JTF61.guidance_kg.conv_first.8.bias
 | -0.000 | -0.032 |  0.032 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.jbf_conv.0.weight
 | -0.003 | -0.009 | -0.000 |  0.002 | torch.Size([64]) || JTF61.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF61.jbf_conv.1.weight
 |  0.000 | -0.037 |  0.039 |  0.009 | torch.Size([64, 64, 3, 3]) || JTF61.jbf_conv.2.weight
 |  0.003 | -0.006 |  0.022 |  0.005 | torch.Size([64]) || JTF61.jbf_conv.2.bias

25-05-13 10:00:11.168 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/10_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 25
      sigma_test: 25
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 25
      sigma_test: 25
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 10000
    checkpoint_save: 10000
    checkpoint_print: 10000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-13 10:00:11.169 : Random seed: 7878
25-05-13 10:00:11.308 : Number of train images: 31,005, iters: 31,005
25-05-13 10:00:12.266 : 
Networks name: DRNet
Params number: 35274045
Net structure:
DRNet(
  (endconv): outconv(
    (conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
  )
  (FE1): FE(
    (fe): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
    (1): PReLU(num_parameters=1)
  )
  (Deep_FE1): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (FCN_SFT1): FCN_SFT(
    (fcn1): FCN(
      (fcn): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
      )
    )
    (fcn2): FCN(
      (fcn): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
      )
    )
    (sft1): SFTLayer(
      (SFT_scale_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (Sigmoid): Sigmoid()
    )
    (sft2): SFTLayer(
      (SFT_scale_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (Sigmoid): Sigmoid()
    )
    (con): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (JTF1): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF11): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
  (Deep_FE2): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (JTF2): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF21): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (conv_noise2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  (Deep_FE3): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (JTF3): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF31): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (conv_noise3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  (conv_noise4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
  (JTF4): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF41): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (up1): up(
    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
  )
  (JTF5): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF51): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (up2): up(
    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
  )
  (JTF6): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF61): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
)

25-05-13 10:00:13.118 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.000 | -0.040 |  0.058 |  0.018 | torch.Size([3, 64, 1, 1]) || endconv.conv.weight
 | -0.003 | -0.004 | -0.002 |  0.001 | torch.Size([3]) || endconv.conv.bias
 | -0.000 | -0.286 |  0.167 |  0.044 | torch.Size([64, 3, 3, 3]) || FE1.fe.0.weight
 |  0.053 | -0.048 |  0.112 |  0.021 | torch.Size([64]) || FE1.fe.0.bias
 |  0.163 |  0.163 |  0.163 |    nan | torch.Size([1]) || FE1.fe.1.weight
 |  0.001 | -0.202 |  0.271 |  0.030 | torch.Size([64, 64, 3, 3]) || FE1.fe.2.weight
 |  0.025 | -0.003 |  0.070 |  0.013 | torch.Size([64]) || FE1.fe.2.bias
 |  0.929 |  0.929 |  0.929 |    nan | torch.Size([1]) || FE1.fe.3.weight
 |  0.005 | -0.197 |  0.276 |  0.026 | torch.Size([64, 64, 3, 3]) || FE1.fe.4.weight
 |  0.022 | -0.014 |  0.042 |  0.011 | torch.Size([64]) || FE1.fe.4.bias
 |  0.420 |  0.420 |  0.420 |    nan | torch.Size([1]) || FE1.fe.5.weight
 | -0.001 | -0.090 |  0.064 |  0.025 | torch.Size([64, 3, 1, 1]) || conv1.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv1.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || conv1.1.weight
 | -0.001 | -0.278 |  0.375 |  0.037 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.0.weight
 |  0.014 | -0.097 |  0.113 |  0.042 | torch.Size([64]) || Deep_FE1.fe.0.bias
 |  0.121 |  0.121 |  0.121 |    nan | torch.Size([1]) || Deep_FE1.fe.1.weight
 | -0.000 | -0.238 |  0.381 |  0.042 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.2.weight
 |  0.008 | -0.063 |  0.091 |  0.036 | torch.Size([64]) || Deep_FE1.fe.2.bias
 |  0.091 |  0.091 |  0.091 |    nan | torch.Size([1]) || Deep_FE1.fe.3.weight
 | -0.000 | -0.293 |  0.297 |  0.042 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.4.weight
 |  0.015 | -0.056 |  0.071 |  0.041 | torch.Size([64]) || Deep_FE1.fe.4.bias
 |  0.022 |  0.022 |  0.022 |    nan | torch.Size([1]) || Deep_FE1.fe.5.weight
 | -0.002 | -0.315 |  0.230 |  0.042 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.6.weight
 |  0.016 | -0.055 |  0.060 |  0.026 | torch.Size([64]) || Deep_FE1.fe.6.bias
 |  0.012 |  0.012 |  0.012 |    nan | torch.Size([1]) || Deep_FE1.fe.7.weight
 | -0.008 | -0.231 |  0.269 |  0.055 | torch.Size([64, 64, 1, 1]) || Deep_FE1.fe.8.weight
 | -0.007 | -0.022 |  0.011 |  0.006 | torch.Size([64]) || Deep_FE1.fe.8.bias
 | -0.000 | -0.033 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.1.weight
 | -0.000 | -0.036 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.3.weight
 | -0.000 | -0.032 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.4.weight
 | -0.000 | -0.001 |  0.002 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.5.weight
 |  0.000 | -0.036 |  0.044 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.1.weight
 | -0.000 | -0.035 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.3.weight
 |  0.000 | -0.039 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.4.weight
 |  0.000 | -0.001 |  0.002 |  0.001 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.5.weight
 |  0.000 | -0.082 |  0.092 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_scale_conv0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_scale_conv0.bias
 |  0.000 | -0.085 |  0.090 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_scale_conv1.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_scale_conv1.bias
 | -0.000 | -0.089 |  0.087 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_shift_conv0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_shift_conv0.bias
 |  0.000 | -0.091 |  0.082 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_shift_conv1.weight
 | -0.000 | -0.002 |  0.001 |  0.001 | torch.Size([64]) || FCN_SFT1.sft1.SFT_shift_conv1.bias
 | -0.000 | -0.081 |  0.081 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_scale_conv0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_scale_conv0.bias
 |  0.000 | -0.083 |  0.096 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_scale_conv1.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_scale_conv1.bias
 | -0.000 | -0.090 |  0.086 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_shift_conv0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_shift_conv0.bias
 | -0.000 | -0.087 |  0.079 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_shift_conv1.weight
 | -0.000 | -0.001 |  0.001 |  0.001 | torch.Size([64]) || FCN_SFT1.sft2.SFT_shift_conv1.bias
 | -0.000 | -0.066 |  0.062 |  0.018 | torch.Size([64, 128, 1, 1]) || FCN_SFT1.con.weight
 |  0.001 | -0.008 |  0.007 |  0.004 | torch.Size([64]) || FCN_SFT1.con.bias
 | -0.000 | -0.043 |  0.046 |  0.010 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.0.weight
 | -0.005 | -0.030 |  0.031 |  0.013 | torch.Size([64]) || JTF1.target_kg.conv_first.0.bias
 |  0.292 |  0.292 |  0.292 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.1.weight
 |  0.000 | -0.045 |  0.040 |  0.010 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.2.weight
 |  0.010 | -0.017 |  0.041 |  0.015 | torch.Size([64]) || JTF1.target_kg.conv_first.2.bias
 |  0.292 |  0.292 |  0.292 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.3.weight
 |  0.001 | -0.037 |  0.042 |  0.010 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.4.weight
 |  0.014 | -0.047 |  0.078 |  0.038 | torch.Size([64]) || JTF1.target_kg.conv_first.4.bias
 |  0.292 |  0.292 |  0.292 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.5.weight
 |  0.001 | -0.041 |  0.055 |  0.012 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.6.weight
 |  0.012 | -0.054 |  0.087 |  0.055 | torch.Size([64]) || JTF1.target_kg.conv_first.6.bias
 |  0.292 |  0.292 |  0.292 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.7.weight
 | -0.000 | -0.114 |  0.107 |  0.022 | torch.Size([144, 64, 1, 1]) || JTF1.target_kg.conv_first.8.weight
 |  0.004 | -0.132 |  0.131 |  0.037 | torch.Size([144]) || JTF1.target_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.041 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.0.weight
 | -0.001 | -0.004 |  0.006 |  0.002 | torch.Size([64]) || JTF1.guidance_kg.conv_first.0.bias
 |  0.303 |  0.303 |  0.303 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.1.weight
 | -0.000 | -0.034 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.2.weight
 |  0.000 | -0.001 |  0.004 |  0.001 | torch.Size([64]) || JTF1.guidance_kg.conv_first.2.bias
 |  0.303 |  0.303 |  0.303 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.3.weight
 | -0.000 | -0.033 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.4.weight
 |  0.012 | -0.048 |  0.073 |  0.039 | torch.Size([64]) || JTF1.guidance_kg.conv_first.4.bias
 |  0.303 |  0.303 |  0.303 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.5.weight
 |  0.001 | -0.043 |  0.054 |  0.012 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.6.weight
 |  0.014 | -0.053 |  0.089 |  0.060 | torch.Size([64]) || JTF1.guidance_kg.conv_first.6.bias
 |  0.303 |  0.303 |  0.303 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.7.weight
 | -0.000 | -0.101 |  0.106 |  0.022 | torch.Size([144, 64, 1, 1]) || JTF1.guidance_kg.conv_first.8.weight
 | -0.002 | -0.124 |  0.129 |  0.038 | torch.Size([144]) || JTF1.guidance_kg.conv_first.8.bias
 | -0.001 | -0.156 |  0.139 |  0.016 | torch.Size([64, 64, 3, 3]) || JTF1.jbf_conv.0.weight
 | -0.023 | -0.056 |  0.023 |  0.017 | torch.Size([64]) || JTF1.jbf_conv.0.bias
 |  0.068 |  0.068 |  0.068 |    nan | torch.Size([1]) || JTF1.jbf_conv.1.weight
 |  0.012 | -0.100 |  0.100 |  0.017 | torch.Size([64, 64, 3, 3]) || JTF1.jbf_conv.2.weight
 | -0.022 | -0.042 |  0.020 |  0.012 | torch.Size([64]) || JTF1.jbf_conv.2.bias
 | -0.001 | -0.068 |  0.069 |  0.013 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.0.weight
 | -0.017 | -0.039 |  0.033 |  0.014 | torch.Size([64]) || JTF11.target_kg.conv_first.0.bias
 |  0.231 |  0.231 |  0.231 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.1.weight
 |  0.002 | -0.053 |  0.070 |  0.013 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.2.weight
 |  0.009 | -0.039 |  0.054 |  0.016 | torch.Size([64]) || JTF11.target_kg.conv_first.2.bias
 |  0.231 |  0.231 |  0.231 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.3.weight
 |  0.002 | -0.044 |  0.062 |  0.013 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.4.weight
 |  0.008 | -0.060 |  0.094 |  0.057 | torch.Size([64]) || JTF11.target_kg.conv_first.4.bias
 |  0.231 |  0.231 |  0.231 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.5.weight
 | -0.002 | -0.057 |  0.072 |  0.017 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.6.weight
 | -0.024 | -0.079 |  0.116 |  0.066 | torch.Size([64]) || JTF11.target_kg.conv_first.6.bias
 |  0.231 |  0.231 |  0.231 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.7.weight
 | -0.001 | -0.107 |  0.111 |  0.025 | torch.Size([144, 64, 1, 1]) || JTF11.target_kg.conv_first.8.weight
 |  0.005 | -0.098 |  0.124 |  0.044 | torch.Size([144]) || JTF11.target_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.0.weight
 |  0.000 | -0.003 |  0.005 |  0.002 | torch.Size([64]) || JTF11.guidance_kg.conv_first.0.bias
 |  0.332 |  0.332 |  0.332 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.1.weight
 |  0.000 | -0.037 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.2.weight
 | -0.004 | -0.036 |  0.006 |  0.010 | torch.Size([64]) || JTF11.guidance_kg.conv_first.2.bias
 |  0.332 |  0.332 |  0.332 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.3.weight
 | -0.000 | -0.042 |  0.037 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.4.weight
 | -0.004 | -0.066 |  0.087 |  0.052 | torch.Size([64]) || JTF11.guidance_kg.conv_first.4.bias
 |  0.332 |  0.332 |  0.332 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.5.weight
 | -0.001 | -0.061 |  0.077 |  0.015 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.6.weight
 |  0.000 | -0.080 |  0.115 |  0.081 | torch.Size([64]) || JTF11.guidance_kg.conv_first.6.bias
 |  0.332 |  0.332 |  0.332 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.7.weight
 | -0.000 | -0.108 |  0.100 |  0.026 | torch.Size([144, 64, 1, 1]) || JTF11.guidance_kg.conv_first.8.weight
 | -0.001 | -0.122 |  0.110 |  0.042 | torch.Size([144]) || JTF11.guidance_kg.conv_first.8.bias
 |  0.002 | -0.182 |  0.145 |  0.020 | torch.Size([64, 64, 3, 3]) || JTF11.jbf_conv.0.weight
 | -0.029 | -0.102 |  0.057 |  0.035 | torch.Size([64]) || JTF11.jbf_conv.0.bias
 |  0.055 |  0.055 |  0.055 |    nan | torch.Size([1]) || JTF11.jbf_conv.1.weight
 |  0.010 | -0.189 |  0.185 |  0.020 | torch.Size([64, 64, 3, 3]) || JTF11.jbf_conv.2.weight
 | -0.023 | -0.043 |  0.017 |  0.012 | torch.Size([64]) || JTF11.jbf_conv.2.bias
 | -0.000 | -0.221 |  0.205 |  0.049 | torch.Size([128, 64, 1, 1]) || conv2.weight
 |  0.002 | -0.027 |  0.026 |  0.009 | torch.Size([128]) || conv2.bias
 | -0.001 | -0.281 |  0.286 |  0.037 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.0.weight
 | -0.013 | -0.094 |  0.041 |  0.026 | torch.Size([128]) || Deep_FE2.fe.0.bias
 |  0.112 |  0.112 |  0.112 |    nan | torch.Size([1]) || Deep_FE2.fe.1.weight
 | -0.001 | -0.311 |  0.291 |  0.036 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.2.weight
 | -0.007 | -0.098 |  0.059 |  0.031 | torch.Size([128]) || Deep_FE2.fe.2.bias
 |  0.105 |  0.105 |  0.105 |    nan | torch.Size([1]) || Deep_FE2.fe.3.weight
 | -0.002 | -0.345 |  0.341 |  0.036 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.4.weight
 | -0.004 | -0.086 |  0.061 |  0.029 | torch.Size([128]) || Deep_FE2.fe.4.bias
 |  0.126 |  0.126 |  0.126 |    nan | torch.Size([1]) || Deep_FE2.fe.5.weight
 | -0.003 | -0.242 |  0.316 |  0.032 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.6.weight
 |  0.009 | -0.053 |  0.036 |  0.015 | torch.Size([128]) || Deep_FE2.fe.6.bias
 |  0.209 |  0.209 |  0.209 |    nan | torch.Size([1]) || Deep_FE2.fe.7.weight
 | -0.000 | -0.181 |  0.192 |  0.040 | torch.Size([128, 128, 1, 1]) || Deep_FE2.fe.8.weight
 | -0.000 | -0.015 |  0.009 |  0.004 | torch.Size([128]) || Deep_FE2.fe.8.bias
 |  0.000 | -0.028 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.1.weight
 |  0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.3.weight
 | -0.000 | -0.027 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.5.weight
 |  0.000 | -0.032 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.7.weight
 |  0.000 | -0.064 |  0.066 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF2.target_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF2.target_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.1.weight
 | -0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.3.weight
 | -0.000 | -0.027 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.5.weight
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.7.weight
 | -0.000 | -0.058 |  0.066 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF2.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF2.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.jbf_conv.0.weight
 | -0.002 | -0.007 | -0.000 |  0.001 | torch.Size([128]) || JTF2.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF2.jbf_conv.1.weight
 | -0.000 | -0.030 |  0.032 |  0.007 | torch.Size([128, 128, 3, 3]) || JTF2.jbf_conv.2.weight
 | -0.001 | -0.016 |  0.009 |  0.004 | torch.Size([128]) || JTF2.jbf_conv.2.bias
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.1.weight
 | -0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.3.weight
 | -0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.5.weight
 |  0.000 | -0.031 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.7.weight
 | -0.000 | -0.067 |  0.063 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF21.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF21.target_kg.conv_first.8.bias
 | -0.000 | -0.024 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.1.weight
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.3.weight
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.5.weight
 | -0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.7.weight
 |  0.000 | -0.067 |  0.060 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF21.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF21.guidance_kg.conv_first.8.bias
 | -0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.jbf_conv.0.weight
 | -0.002 | -0.006 | -0.000 |  0.002 | torch.Size([128]) || JTF21.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF21.jbf_conv.1.weight
 | -0.000 | -0.035 |  0.031 |  0.007 | torch.Size([128, 128, 3, 3]) || JTF21.jbf_conv.2.weight
 | -0.001 | -0.016 |  0.009 |  0.004 | torch.Size([128]) || JTF21.jbf_conv.2.bias
 | -0.000 | -0.195 |  0.216 |  0.045 | torch.Size([256, 128, 1, 1]) || conv3.weight
 |  0.001 | -0.022 |  0.022 |  0.009 | torch.Size([256]) || conv3.bias
 | -0.000 | -0.070 |  0.068 |  0.018 | torch.Size([64, 128, 1, 1]) || conv_noise2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv_noise2.bias
 | -0.000 | -0.201 |  0.194 |  0.028 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.0.weight
 | -0.018 | -0.062 |  0.059 |  0.018 | torch.Size([256]) || Deep_FE3.fe.0.bias
 |  0.152 |  0.152 |  0.152 |    nan | torch.Size([1]) || Deep_FE3.fe.1.weight
 | -0.003 | -0.258 |  0.204 |  0.029 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.2.weight
 | -0.011 | -0.136 |  0.050 |  0.030 | torch.Size([256]) || Deep_FE3.fe.2.bias
 |  0.110 |  0.110 |  0.110 |    nan | torch.Size([1]) || Deep_FE3.fe.3.weight
 | -0.003 | -0.314 |  0.176 |  0.029 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.4.weight
 | -0.008 | -0.185 |  0.064 |  0.030 | torch.Size([256]) || Deep_FE3.fe.4.bias
 |  0.107 |  0.107 |  0.107 |    nan | torch.Size([1]) || Deep_FE3.fe.5.weight
 | -0.002 | -0.243 |  0.172 |  0.027 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.6.weight
 |  0.012 | -0.063 |  0.058 |  0.019 | torch.Size([256]) || Deep_FE3.fe.6.bias
 |  0.154 |  0.154 |  0.154 |    nan | torch.Size([1]) || Deep_FE3.fe.7.weight
 | -0.000 | -0.119 |  0.115 |  0.025 | torch.Size([256, 256, 1, 1]) || Deep_FE3.fe.8.weight
 | -0.000 | -0.019 |  0.016 |  0.007 | torch.Size([256]) || Deep_FE3.fe.8.bias
 |  0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.1.weight
 |  0.000 | -0.018 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.3.weight
 |  0.000 | -0.021 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.5.weight
 | -0.000 | -0.021 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.7.weight
 | -0.000 | -0.053 |  0.050 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF3.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF3.target_kg.conv_first.8.bias
 | -0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.1.weight
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.5.weight
 | -0.000 | -0.022 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.7.weight
 |  0.000 | -0.051 |  0.052 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF3.guidance_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF3.guidance_kg.conv_first.8.bias
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.jbf_conv.0.weight
 | -0.003 | -0.012 | -0.000 |  0.002 | torch.Size([256]) || JTF3.jbf_conv.0.bias
 |  0.004 |  0.004 |  0.004 |    nan | torch.Size([1]) || JTF3.jbf_conv.1.weight
 | -0.000 | -0.029 |  0.027 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF3.jbf_conv.2.weight
 | -0.000 | -0.020 |  0.017 |  0.007 | torch.Size([256]) || JTF3.jbf_conv.2.bias
 | -0.000 | -0.022 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.1.weight
 | -0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.5.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.7.weight
 | -0.000 | -0.053 |  0.054 |  0.012 | torch.Size([144, 256, 1, 1]) || JTF31.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF31.target_kg.conv_first.8.bias
 |  0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.1.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.3.weight
 | -0.000 | -0.019 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.5.weight
 |  0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.7.weight
 |  0.000 | -0.048 |  0.054 |  0.012 | torch.Size([144, 256, 1, 1]) || JTF31.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF31.guidance_kg.conv_first.8.bias
 | -0.000 | -0.020 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.jbf_conv.0.weight
 | -0.002 | -0.009 | -0.000 |  0.002 | torch.Size([256]) || JTF31.jbf_conv.0.bias
 |  0.004 |  0.004 |  0.004 |    nan | torch.Size([1]) || JTF31.jbf_conv.1.weight
 | -0.000 | -0.034 |  0.035 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF31.jbf_conv.2.weight
 | -0.000 | -0.020 |  0.017 |  0.007 | torch.Size([256]) || JTF31.jbf_conv.2.bias
 | -0.000 | -0.052 |  0.047 |  0.013 | torch.Size([64, 256, 1, 1]) || conv_noise3.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv_noise3.bias
 |  0.000 | -0.047 |  0.046 |  0.013 | torch.Size([256, 64, 1, 1]) || conv_noise4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || conv_noise4.bias
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.1.weight
 |  0.000 | -0.021 |  0.025 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.3.weight
 |  0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.5.weight
 | -0.000 | -0.021 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.7.weight
 |  0.000 | -0.051 |  0.053 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF4.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF4.target_kg.conv_first.8.bias
 |  0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.1.weight
 | -0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.3.weight
 | -0.000 | -0.021 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.5.weight
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.7.weight
 | -0.000 | -0.056 |  0.050 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF4.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF4.guidance_kg.conv_first.8.bias
 | -0.000 | -0.021 |  0.022 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.jbf_conv.0.weight
 | -0.004 | -0.015 | -0.000 |  0.003 | torch.Size([256]) || JTF4.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF4.jbf_conv.1.weight
 |  0.000 | -0.031 |  0.029 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF4.jbf_conv.2.weight
 | -0.000 | -0.046 |  0.019 |  0.009 | torch.Size([256]) || JTF4.jbf_conv.2.bias
 |  0.000 | -0.018 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.1.weight
 | -0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.3.weight
 |  0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.5.weight
 | -0.000 | -0.019 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.7.weight
 | -0.000 | -0.048 |  0.048 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF41.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF41.target_kg.conv_first.8.bias
 | -0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.1.weight
 |  0.000 | -0.019 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.5.weight
 |  0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.7.weight
 |  0.000 | -0.050 |  0.051 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF41.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF41.guidance_kg.conv_first.8.bias
 | -0.000 | -0.021 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.jbf_conv.0.weight
 | -0.004 | -0.011 | -0.000 |  0.003 | torch.Size([256]) || JTF41.jbf_conv.0.bias
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || JTF41.jbf_conv.1.weight
 |  0.000 | -0.035 |  0.032 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF41.jbf_conv.2.weight
 | -0.000 | -0.046 |  0.019 |  0.009 | torch.Size([256]) || JTF41.jbf_conv.2.bias
 | -0.000 | -0.128 |  0.117 |  0.022 | torch.Size([256, 128, 2, 2]) || up1.up.weight
 | -0.000 | -0.029 |  0.032 |  0.013 | torch.Size([128]) || up1.up.bias
 | -0.000 | -0.025 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.1.weight
 |  0.000 | -0.024 |  0.029 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.3.weight
 |  0.000 | -0.025 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.5.weight
 | -0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.7.weight
 | -0.000 | -0.072 |  0.067 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF5.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF5.target_kg.conv_first.8.bias
 | -0.000 | -0.025 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.1.weight
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.3.weight
 | -0.000 | -0.028 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.5.weight
 |  0.000 | -0.027 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.7.weight
 |  0.000 | -0.063 |  0.061 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF5.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF5.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.jbf_conv.0.weight
 | -0.004 | -0.011 | -0.000 |  0.002 | torch.Size([128]) || JTF5.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF5.jbf_conv.1.weight
 | -0.000 | -0.029 |  0.029 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.jbf_conv.2.weight
 | -0.000 | -0.021 |  0.026 |  0.008 | torch.Size([128]) || JTF5.jbf_conv.2.bias
 | -0.000 | -0.025 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.1.weight
 |  0.000 | -0.024 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.3.weight
 | -0.000 | -0.028 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.5.weight
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.7.weight
 |  0.000 | -0.067 |  0.083 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF51.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF51.target_kg.conv_first.8.bias
 | -0.000 | -0.027 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.1.weight
 |  0.000 | -0.029 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.3.weight
 | -0.000 | -0.025 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.5.weight
 |  0.000 | -0.025 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.7.weight
 | -0.000 | -0.072 |  0.069 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF51.guidance_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF51.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.jbf_conv.0.weight
 | -0.004 | -0.009 | -0.000 |  0.002 | torch.Size([128]) || JTF51.jbf_conv.0.bias
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || JTF51.jbf_conv.1.weight
 | -0.000 | -0.028 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.jbf_conv.2.weight
 | -0.000 | -0.021 |  0.026 |  0.008 | torch.Size([128]) || JTF51.jbf_conv.2.bias
 | -0.001 | -0.154 |  0.197 |  0.031 | torch.Size([128, 64, 2, 2]) || up2.up.weight
 | -0.011 | -0.037 |  0.016 |  0.011 | torch.Size([64]) || up2.up.bias
 | -0.000 | -0.034 |  0.032 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.1.weight
 |  0.000 | -0.033 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.3.weight
 | -0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.5.weight
 |  0.000 | -0.039 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.7.weight
 |  0.000 | -0.061 |  0.061 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF6.target_kg.conv_first.8.weight
 |  0.000 | -0.001 |  0.002 |  0.000 | torch.Size([144]) || JTF6.target_kg.conv_first.8.bias
 |  0.000 | -0.034 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.1.weight
 |  0.000 | -0.036 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.3.weight
 | -0.000 | -0.037 |  0.038 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.5.weight
 |  0.000 | -0.035 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.7.weight
 | -0.000 | -0.058 |  0.061 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF6.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.002 |  0.000 | torch.Size([144]) || JTF6.guidance_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.jbf_conv.0.weight
 | -0.002 | -0.009 | -0.000 |  0.002 | torch.Size([64]) || JTF6.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF6.jbf_conv.1.weight
 |  0.000 | -0.033 |  0.035 |  0.009 | torch.Size([64, 64, 3, 3]) || JTF6.jbf_conv.2.weight
 |  0.003 | -0.006 |  0.022 |  0.005 | torch.Size([64]) || JTF6.jbf_conv.2.bias
 |  0.000 | -0.033 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.1.weight
 | -0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.3.weight
 | -0.000 | -0.035 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.5.weight
 | -0.000 | -0.036 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.001 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.7.weight
 |  0.000 | -0.065 |  0.074 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF61.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.015 |  0.001 | torch.Size([144]) || JTF61.target_kg.conv_first.8.bias
 | -0.000 | -0.033 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.1.weight
 |  0.000 | -0.036 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.3.weight
 | -0.000 | -0.033 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.5.weight
 |  0.000 | -0.034 |  0.037 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.001 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.7.weight
 |  0.000 | -0.059 |  0.060 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF61.guidance_kg.conv_first.8.weight
 |  0.000 | -0.001 |  0.015 |  0.001 | torch.Size([144]) || JTF61.guidance_kg.conv_first.8.bias
 | -0.000 | -0.032 |  0.032 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.jbf_conv.0.weight
 | -0.003 | -0.009 | -0.000 |  0.002 | torch.Size([64]) || JTF61.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF61.jbf_conv.1.weight
 |  0.000 | -0.037 |  0.039 |  0.009 | torch.Size([64, 64, 3, 3]) || JTF61.jbf_conv.2.weight
 |  0.003 | -0.006 |  0.022 |  0.005 | torch.Size([64]) || JTF61.jbf_conv.2.bias

25-05-13 11:06:01.430 : <epoch:  0, iter:  10,000, lr:1.000e-04> G_loss: 3.422e-05 
25-05-13 11:06:01.431 : Saving the model.
25-05-13 11:06:02.746 : ---1--> airplane_111.jpg | 32.42dB
25-05-13 11:06:02.865 : ---2--> airport_111.jpg | 32.82dB
25-05-13 11:06:02.984 : ---3--> baseball_diamond_111.jpg | 33.56dB
25-05-13 11:06:03.104 : ---4--> basketball_court_111.jpg | 31.25dB
25-05-13 11:06:03.224 : ---5--> beach_111.jpg | 30.50dB
25-05-13 11:06:03.344 : ---6--> bridge_111.jpg | 35.35dB
25-05-13 11:06:03.463 : ---7--> chaparral_111.jpg | 29.95dB
25-05-13 11:06:03.584 : ---8--> church_111.jpg | 31.42dB
25-05-13 11:06:03.705 : ---9--> circular_farmland_111.jpg | 33.73dB
25-05-13 11:06:03.834 : --10--> cloud_111.jpg | 37.09dB
25-05-13 11:06:03.959 : --11--> commercial_area_111.jpg | 32.91dB
25-05-13 11:06:04.081 : --12--> dense_residential_111.jpg | 29.46dB
25-05-13 11:06:04.203 : --13--> desert_111.jpg | 36.80dB
25-05-13 11:06:04.323 : --14--> forest_111.jpg | 32.21dB
25-05-13 11:06:04.442 : --15--> freeway_111.jpg | 34.47dB
25-05-13 11:06:04.563 : --16--> golf_course_111.jpg | 33.00dB
25-05-13 11:06:04.683 : --17--> ground_track_field_111.jpg | 30.53dB
25-05-13 11:06:04.804 : --18--> harbor_111.jpg | 31.67dB
25-05-13 11:06:04.923 : --19--> industrial_area_111.jpg | 31.50dB
25-05-13 11:06:05.042 : --20--> intersection_111.jpg | 30.45dB
25-05-13 11:06:05.162 : --21--> island_111.jpg | 32.26dB
25-05-13 11:06:05.283 : --22--> lake_111.jpg | 31.83dB
25-05-13 11:06:05.403 : --23--> meadow_111.jpg | 30.10dB
25-05-13 11:06:05.524 : --24--> medium_residential_111.jpg | 28.51dB
25-05-13 11:06:05.645 : --25--> mobile_home_park_111.jpg | 31.37dB
25-05-13 11:06:05.767 : --26--> mountain_111.jpg | 29.33dB
25-05-13 11:06:05.888 : --27--> overpass_111.jpg | 30.30dB
25-05-13 11:06:06.007 : --28--> palace_111.jpg | 29.82dB
25-05-13 11:06:06.126 : --29--> parking_lot_111.jpg | 29.79dB
25-05-13 11:06:06.246 : --30--> railway_111.jpg | 30.04dB
25-05-13 11:06:06.368 : --31--> railway_station_111.jpg | 31.14dB
25-05-13 11:06:06.489 : --32--> rectangular_farmland_111.jpg | 33.18dB
25-05-13 11:06:06.610 : --33--> river_111.jpg | 30.15dB
25-05-13 11:06:06.731 : --34--> roundabout_111.jpg | 30.77dB
25-05-13 11:06:06.853 : --35--> runway_111.jpg | 36.37dB
25-05-13 11:06:06.974 : --36--> sea_ice_111.jpg | 33.97dB
25-05-13 11:06:07.096 : --37--> ship_111.jpg | 37.81dB
25-05-13 11:06:07.216 : --38--> snowberg_111.jpg | 32.56dB
25-05-13 11:06:07.336 : --39--> sparse_residential_111.jpg | 30.15dB
25-05-13 11:06:07.456 : --40--> stadium_111.jpg | 30.37dB
25-05-13 11:06:07.575 : --41--> storage_tank_111.jpg | 31.45dB
25-05-13 11:06:07.696 : --42--> tennis_court_111.jpg | 31.00dB
25-05-13 11:06:07.816 : --43--> terrace_111.jpg | 32.40dB
25-05-13 11:06:07.937 : --44--> thermal_power_station_111.jpg | 30.48dB
25-05-13 11:06:08.058 : --45--> wetland_111.jpg | 31.24dB
25-05-13 11:06:08.071 : <epoch:  0, iter:  10,000, Average PSNR : 31.94dB

25-05-13 12:11:54.013 : <epoch:  0, iter:  20,000, lr:1.000e-04> G_loss: 9.465e-05 
25-05-13 12:11:54.015 : Saving the model.
25-05-13 12:11:55.071 : ---1--> airplane_111.jpg | 32.47dB
25-05-13 12:11:55.190 : ---2--> airport_111.jpg | 32.84dB
25-05-13 12:11:55.311 : ---3--> baseball_diamond_111.jpg | 33.58dB
25-05-13 12:11:55.430 : ---4--> basketball_court_111.jpg | 31.24dB
25-05-13 12:11:55.549 : ---5--> beach_111.jpg | 30.51dB
25-05-13 12:11:55.667 : ---6--> bridge_111.jpg | 35.36dB
25-05-13 12:11:55.787 : ---7--> chaparral_111.jpg | 30.00dB
25-05-13 12:11:55.909 : ---8--> church_111.jpg | 31.46dB
25-05-13 12:11:56.029 : ---9--> circular_farmland_111.jpg | 33.74dB
25-05-13 12:11:56.149 : --10--> cloud_111.jpg | 37.22dB
25-05-13 12:11:56.268 : --11--> commercial_area_111.jpg | 32.93dB
25-05-13 12:11:56.387 : --12--> dense_residential_111.jpg | 29.49dB
25-05-13 12:11:56.507 : --13--> desert_111.jpg | 36.78dB
25-05-13 12:11:56.626 : --14--> forest_111.jpg | 32.23dB
25-05-13 12:11:56.746 : --15--> freeway_111.jpg | 34.51dB
25-05-13 12:11:56.865 : --16--> golf_course_111.jpg | 33.03dB
25-05-13 12:11:56.984 : --17--> ground_track_field_111.jpg | 30.54dB
25-05-13 12:11:57.103 : --18--> harbor_111.jpg | 31.72dB
25-05-13 12:11:57.223 : --19--> industrial_area_111.jpg | 31.49dB
25-05-13 12:11:57.343 : --20--> intersection_111.jpg | 30.49dB
25-05-13 12:11:57.464 : --21--> island_111.jpg | 32.27dB
25-05-13 12:11:57.586 : --22--> lake_111.jpg | 31.85dB
25-05-13 12:11:57.707 : --23--> meadow_111.jpg | 30.09dB
25-05-13 12:11:57.828 : --24--> medium_residential_111.jpg | 28.52dB
25-05-13 12:11:57.949 : --25--> mobile_home_park_111.jpg | 31.36dB
25-05-13 12:11:58.069 : --26--> mountain_111.jpg | 29.36dB
25-05-13 12:11:58.190 : --27--> overpass_111.jpg | 30.30dB
25-05-13 12:11:58.314 : --28--> palace_111.jpg | 29.87dB
25-05-13 12:11:58.436 : --29--> parking_lot_111.jpg | 29.82dB
25-05-13 12:11:58.556 : --30--> railway_111.jpg | 30.08dB
25-05-13 12:11:58.676 : --31--> railway_station_111.jpg | 31.18dB
25-05-13 12:11:58.796 : --32--> rectangular_farmland_111.jpg | 33.19dB
25-05-13 12:11:58.918 : --33--> river_111.jpg | 30.16dB
25-05-13 12:11:59.039 : --34--> roundabout_111.jpg | 30.83dB
25-05-13 12:11:59.161 : --35--> runway_111.jpg | 36.37dB
25-05-13 12:11:59.281 : --36--> sea_ice_111.jpg | 33.99dB
25-05-13 12:11:59.405 : --37--> ship_111.jpg | 37.83dB
25-05-13 12:11:59.524 : --38--> snowberg_111.jpg | 32.64dB
25-05-13 12:11:59.644 : --39--> sparse_residential_111.jpg | 30.15dB
25-05-13 12:11:59.766 : --40--> stadium_111.jpg | 30.37dB
25-05-13 12:11:59.886 : --41--> storage_tank_111.jpg | 31.47dB
25-05-13 12:12:00.006 : --42--> tennis_court_111.jpg | 31.02dB
25-05-13 12:12:00.128 : --43--> terrace_111.jpg | 32.44dB
25-05-13 12:12:00.248 : --44--> thermal_power_station_111.jpg | 30.49dB
25-05-13 12:12:00.367 : --45--> wetland_111.jpg | 31.26dB
25-05-13 12:12:00.375 : <epoch:  0, iter:  20,000, Average PSNR : 31.97dB

25-05-13 13:17:45.049 : <epoch:  0, iter:  30,000, lr:1.000e-04> G_loss: 6.600e-05 
25-05-13 13:17:45.050 : Saving the model.
25-05-13 13:17:46.025 : ---1--> airplane_111.jpg | 32.46dB
25-05-13 13:17:46.146 : ---2--> airport_111.jpg | 32.84dB
25-05-13 13:17:46.266 : ---3--> baseball_diamond_111.jpg | 33.57dB
25-05-13 13:17:46.385 : ---4--> basketball_court_111.jpg | 31.25dB
25-05-13 13:17:46.505 : ---5--> beach_111.jpg | 30.51dB
25-05-13 13:17:46.626 : ---6--> bridge_111.jpg | 35.39dB
25-05-13 13:17:46.749 : ---7--> chaparral_111.jpg | 29.99dB
25-05-13 13:17:46.870 : ---8--> church_111.jpg | 31.45dB
25-05-13 13:17:46.991 : ---9--> circular_farmland_111.jpg | 33.73dB
25-05-13 13:17:47.113 : --10--> cloud_111.jpg | 37.13dB
25-05-13 13:17:47.235 : --11--> commercial_area_111.jpg | 32.93dB
25-05-13 13:17:47.357 : --12--> dense_residential_111.jpg | 29.49dB
25-05-13 13:17:47.478 : --13--> desert_111.jpg | 36.76dB
25-05-13 13:17:47.599 : --14--> forest_111.jpg | 32.19dB
25-05-13 13:17:47.720 : --15--> freeway_111.jpg | 34.49dB
25-05-13 13:17:47.841 : --16--> golf_course_111.jpg | 33.01dB
25-05-13 13:17:47.961 : --17--> ground_track_field_111.jpg | 30.54dB
25-05-13 13:17:48.083 : --18--> harbor_111.jpg | 31.72dB
25-05-13 13:17:48.204 : --19--> industrial_area_111.jpg | 31.53dB
25-05-13 13:17:48.326 : --20--> intersection_111.jpg | 30.48dB
25-05-13 13:17:48.449 : --21--> island_111.jpg | 32.29dB
25-05-13 13:17:48.571 : --22--> lake_111.jpg | 31.85dB
25-05-13 13:17:48.694 : --23--> meadow_111.jpg | 30.11dB
25-05-13 13:17:48.816 : --24--> medium_residential_111.jpg | 28.53dB
25-05-13 13:17:48.937 : --25--> mobile_home_park_111.jpg | 31.40dB
25-05-13 13:17:49.065 : --26--> mountain_111.jpg | 29.33dB
25-05-13 13:17:49.187 : --27--> overpass_111.jpg | 30.35dB
25-05-13 13:17:49.308 : --28--> palace_111.jpg | 29.87dB
25-05-13 13:17:49.428 : --29--> parking_lot_111.jpg | 29.85dB
25-05-13 13:17:49.550 : --30--> railway_111.jpg | 30.07dB
25-05-13 13:17:49.671 : --31--> railway_station_111.jpg | 31.16dB
25-05-13 13:17:49.793 : --32--> rectangular_farmland_111.jpg | 33.21dB
25-05-13 13:17:49.915 : --33--> river_111.jpg | 30.15dB
25-05-13 13:17:50.036 : --34--> roundabout_111.jpg | 30.80dB
25-05-13 13:17:50.158 : --35--> runway_111.jpg | 36.39dB
25-05-13 13:17:50.279 : --36--> sea_ice_111.jpg | 34.02dB
25-05-13 13:17:50.400 : --37--> ship_111.jpg | 37.86dB
25-05-13 13:17:50.522 : --38--> snowberg_111.jpg | 32.66dB
25-05-13 13:17:50.643 : --39--> sparse_residential_111.jpg | 30.16dB
25-05-13 13:17:50.763 : --40--> stadium_111.jpg | 30.39dB
25-05-13 13:17:50.886 : --41--> storage_tank_111.jpg | 31.45dB
25-05-13 13:17:51.019 : --42--> tennis_court_111.jpg | 31.05dB
25-05-13 13:17:51.141 : --43--> terrace_111.jpg | 32.42dB
25-05-13 13:17:51.262 : --44--> thermal_power_station_111.jpg | 30.48dB
25-05-13 13:17:51.385 : --45--> wetland_111.jpg | 31.26dB
25-05-13 13:17:51.393 : <epoch:  0, iter:  30,000, Average PSNR : 31.97dB

25-05-13 14:23:36.403 : <epoch:  1, iter:  40,000, lr:1.000e-04> G_loss: 6.133e-05 
25-05-13 14:23:36.404 : Saving the model.
25-05-13 14:23:37.427 : ---1--> airplane_111.jpg | 32.48dB
25-05-13 14:23:37.549 : ---2--> airport_111.jpg | 32.84dB
25-05-13 14:23:37.668 : ---3--> baseball_diamond_111.jpg | 33.59dB
25-05-13 14:23:37.788 : ---4--> basketball_court_111.jpg | 31.29dB
25-05-13 14:23:37.908 : ---5--> beach_111.jpg | 30.53dB
25-05-13 14:23:38.028 : ---6--> bridge_111.jpg | 35.40dB
25-05-13 14:23:38.148 : ---7--> chaparral_111.jpg | 29.96dB
25-05-13 14:23:38.269 : ---8--> church_111.jpg | 31.47dB
25-05-13 14:23:38.391 : ---9--> circular_farmland_111.jpg | 33.74dB
25-05-13 14:23:38.511 : --10--> cloud_111.jpg | 37.26dB
25-05-13 14:23:38.632 : --11--> commercial_area_111.jpg | 32.96dB
25-05-13 14:23:38.755 : --12--> dense_residential_111.jpg | 29.49dB
25-05-13 14:23:38.875 : --13--> desert_111.jpg | 36.82dB
25-05-13 14:23:38.995 : --14--> forest_111.jpg | 32.25dB
25-05-13 14:23:39.117 : --15--> freeway_111.jpg | 34.51dB
25-05-13 14:23:39.240 : --16--> golf_course_111.jpg | 33.04dB
25-05-13 14:23:39.362 : --17--> ground_track_field_111.jpg | 30.55dB
25-05-13 14:23:39.486 : --18--> harbor_111.jpg | 31.72dB
25-05-13 14:23:39.608 : --19--> industrial_area_111.jpg | 31.54dB
25-05-13 14:23:39.731 : --20--> intersection_111.jpg | 30.48dB
25-05-13 14:23:39.853 : --21--> island_111.jpg | 32.30dB
25-05-13 14:23:39.975 : --22--> lake_111.jpg | 31.84dB
25-05-13 14:23:40.096 : --23--> meadow_111.jpg | 30.12dB
25-05-13 14:23:40.219 : --24--> medium_residential_111.jpg | 28.53dB
25-05-13 14:23:40.341 : --25--> mobile_home_park_111.jpg | 31.38dB
25-05-13 14:23:40.463 : --26--> mountain_111.jpg | 29.35dB
25-05-13 14:23:40.585 : --27--> overpass_111.jpg | 30.36dB
25-05-13 14:23:40.710 : --28--> palace_111.jpg | 29.85dB
25-05-13 14:23:40.836 : --29--> parking_lot_111.jpg | 29.83dB
25-05-13 14:23:40.958 : --30--> railway_111.jpg | 30.07dB
25-05-13 14:23:41.079 : --31--> railway_station_111.jpg | 31.17dB
25-05-13 14:23:41.201 : --32--> rectangular_farmland_111.jpg | 33.21dB
25-05-13 14:23:41.330 : --33--> river_111.jpg | 30.16dB
25-05-13 14:23:41.457 : --34--> roundabout_111.jpg | 30.82dB
25-05-13 14:23:41.580 : --35--> runway_111.jpg | 36.43dB
25-05-13 14:23:41.703 : --36--> sea_ice_111.jpg | 34.02dB
25-05-13 14:23:41.825 : --37--> ship_111.jpg | 37.89dB
25-05-13 14:23:41.948 : --38--> snowberg_111.jpg | 32.62dB
25-05-13 14:23:42.070 : --39--> sparse_residential_111.jpg | 30.17dB
25-05-13 14:23:42.191 : --40--> stadium_111.jpg | 30.41dB
25-05-13 14:23:42.316 : --41--> storage_tank_111.jpg | 31.49dB
25-05-13 14:23:42.437 : --42--> tennis_court_111.jpg | 31.04dB
25-05-13 14:23:42.558 : --43--> terrace_111.jpg | 32.45dB
25-05-13 14:23:42.679 : --44--> thermal_power_station_111.jpg | 30.49dB
25-05-13 14:23:42.801 : --45--> wetland_111.jpg | 31.27dB
25-05-13 14:23:42.812 : <epoch:  1, iter:  40,000, Average PSNR : 31.98dB

25-05-13 15:29:30.185 : <epoch:  1, iter:  50,000, lr:1.000e-04> G_loss: 1.806e-05 
25-05-13 15:29:30.186 : Saving the model.
25-05-13 15:29:31.588 : ---1--> airplane_111.jpg | 32.48dB
25-05-13 15:29:31.708 : ---2--> airport_111.jpg | 32.87dB
25-05-13 15:29:31.831 : ---3--> baseball_diamond_111.jpg | 33.61dB
25-05-13 15:29:31.959 : ---4--> basketball_court_111.jpg | 31.28dB
25-05-13 15:29:32.080 : ---5--> beach_111.jpg | 30.53dB
25-05-13 15:29:32.202 : ---6--> bridge_111.jpg | 35.42dB
25-05-13 15:29:32.324 : ---7--> chaparral_111.jpg | 29.99dB
25-05-13 15:29:32.446 : ---8--> church_111.jpg | 31.48dB
25-05-13 15:29:32.570 : ---9--> circular_farmland_111.jpg | 33.75dB
25-05-13 15:29:32.694 : --10--> cloud_111.jpg | 37.22dB
25-05-13 15:29:32.817 : --11--> commercial_area_111.jpg | 32.97dB
25-05-13 15:29:32.938 : --12--> dense_residential_111.jpg | 29.54dB
25-05-13 15:29:33.062 : --13--> desert_111.jpg | 36.79dB
25-05-13 15:29:33.184 : --14--> forest_111.jpg | 32.25dB
25-05-13 15:29:33.307 : --15--> freeway_111.jpg | 34.53dB
25-05-13 15:29:33.429 : --16--> golf_course_111.jpg | 33.05dB
25-05-13 15:29:33.551 : --17--> ground_track_field_111.jpg | 30.56dB
25-05-13 15:29:33.675 : --18--> harbor_111.jpg | 31.74dB
25-05-13 15:29:33.798 : --19--> industrial_area_111.jpg | 31.56dB
25-05-13 15:29:33.920 : --20--> intersection_111.jpg | 30.52dB
25-05-13 15:29:34.044 : --21--> island_111.jpg | 32.34dB
25-05-13 15:29:34.165 : --22--> lake_111.jpg | 31.85dB
25-05-13 15:29:34.289 : --23--> meadow_111.jpg | 30.11dB
25-05-13 15:29:34.415 : --24--> medium_residential_111.jpg | 28.54dB
25-05-13 15:29:34.538 : --25--> mobile_home_park_111.jpg | 31.39dB
25-05-13 15:29:34.662 : --26--> mountain_111.jpg | 29.36dB
25-05-13 15:29:34.784 : --27--> overpass_111.jpg | 30.35dB
25-05-13 15:29:34.907 : --28--> palace_111.jpg | 29.88dB
25-05-13 15:29:35.029 : --29--> parking_lot_111.jpg | 29.86dB
25-05-13 15:29:35.153 : --30--> railway_111.jpg | 30.11dB
25-05-13 15:29:35.277 : --31--> railway_station_111.jpg | 31.20dB
25-05-13 15:29:35.398 : --32--> rectangular_farmland_111.jpg | 33.21dB
25-05-13 15:29:35.521 : --33--> river_111.jpg | 30.17dB
25-05-13 15:29:35.645 : --34--> roundabout_111.jpg | 30.83dB
25-05-13 15:29:35.769 : --35--> runway_111.jpg | 36.43dB
25-05-13 15:29:35.894 : --36--> sea_ice_111.jpg | 33.99dB
25-05-13 15:29:36.018 : --37--> ship_111.jpg | 37.88dB
25-05-13 15:29:36.142 : --38--> snowberg_111.jpg | 32.67dB
25-05-13 15:29:36.261 : --39--> sparse_residential_111.jpg | 30.17dB
25-05-13 15:29:36.378 : --40--> stadium_111.jpg | 30.41dB
25-05-13 15:29:36.497 : --41--> storage_tank_111.jpg | 31.49dB
25-05-13 15:29:36.615 : --42--> tennis_court_111.jpg | 31.07dB
25-05-13 15:29:36.731 : --43--> terrace_111.jpg | 32.46dB
25-05-13 15:29:36.847 : --44--> thermal_power_station_111.jpg | 30.52dB
25-05-13 15:29:36.964 : --45--> wetland_111.jpg | 31.30dB
25-05-13 15:29:36.976 : <epoch:  1, iter:  50,000, Average PSNR : 31.99dB

25-05-13 16:35:31.372 : <epoch:  1, iter:  60,000, lr:2.500e-05> G_loss: 2.680e-05 
25-05-13 16:35:31.373 : Saving the model.
25-05-13 16:35:32.661 : ---1--> airplane_111.jpg | 32.45dB
25-05-13 16:35:32.783 : ---2--> airport_111.jpg | 32.81dB
25-05-13 16:35:32.904 : ---3--> baseball_diamond_111.jpg | 33.56dB
25-05-13 16:35:33.025 : ---4--> basketball_court_111.jpg | 31.22dB
25-05-13 16:35:33.147 : ---5--> beach_111.jpg | 30.49dB
25-05-13 16:35:33.267 : ---6--> bridge_111.jpg | 35.35dB
25-05-13 16:35:33.389 : ---7--> chaparral_111.jpg | 29.91dB
25-05-13 16:35:33.509 : ---8--> church_111.jpg | 31.41dB
25-05-13 16:35:33.629 : ---9--> circular_farmland_111.jpg | 33.73dB
25-05-13 16:35:33.749 : --10--> cloud_111.jpg | 37.23dB
25-05-13 16:35:33.871 : --11--> commercial_area_111.jpg | 32.92dB
25-05-13 16:35:33.995 : --12--> dense_residential_111.jpg | 29.47dB
25-05-13 16:35:34.117 : --13--> desert_111.jpg | 36.62dB
25-05-13 16:35:34.239 : --14--> forest_111.jpg | 32.23dB
25-05-13 16:35:34.360 : --15--> freeway_111.jpg | 34.47dB
25-05-13 16:35:34.482 : --16--> golf_course_111.jpg | 33.00dB
25-05-13 16:35:34.605 : --17--> ground_track_field_111.jpg | 30.55dB
25-05-13 16:35:34.726 : --18--> harbor_111.jpg | 31.69dB
25-05-13 16:35:34.847 : --19--> industrial_area_111.jpg | 31.54dB
25-05-13 16:35:34.969 : --20--> intersection_111.jpg | 30.47dB
25-05-13 16:35:35.092 : --21--> island_111.jpg | 32.24dB
25-05-13 16:35:35.220 : --22--> lake_111.jpg | 31.82dB
25-05-13 16:35:35.344 : --23--> meadow_111.jpg | 30.08dB
25-05-13 16:35:35.477 : --24--> medium_residential_111.jpg | 28.50dB
25-05-13 16:35:35.607 : --25--> mobile_home_park_111.jpg | 31.37dB
25-05-13 16:35:35.739 : --26--> mountain_111.jpg | 29.32dB
25-05-13 16:35:35.865 : --27--> overpass_111.jpg | 30.26dB
25-05-13 16:35:35.991 : --28--> palace_111.jpg | 29.82dB
25-05-13 16:35:36.114 : --29--> parking_lot_111.jpg | 29.80dB
25-05-13 16:35:36.238 : --30--> railway_111.jpg | 30.04dB
25-05-13 16:35:36.361 : --31--> railway_station_111.jpg | 31.17dB
25-05-13 16:35:36.485 : --32--> rectangular_farmland_111.jpg | 33.15dB
25-05-13 16:35:36.609 : --33--> river_111.jpg | 30.13dB
25-05-13 16:35:36.732 : --34--> roundabout_111.jpg | 30.80dB
25-05-13 16:35:36.856 : --35--> runway_111.jpg | 36.34dB
25-05-13 16:35:36.977 : --36--> sea_ice_111.jpg | 33.99dB
25-05-13 16:35:37.098 : --37--> ship_111.jpg | 37.82dB
25-05-13 16:35:37.228 : --38--> snowberg_111.jpg | 32.61dB
25-05-13 16:35:37.350 : --39--> sparse_residential_111.jpg | 30.11dB
25-05-13 16:35:37.473 : --40--> stadium_111.jpg | 30.37dB
25-05-13 16:35:37.597 : --41--> storage_tank_111.jpg | 31.46dB
25-05-13 16:35:37.720 : --42--> tennis_court_111.jpg | 30.98dB
25-05-13 16:35:37.843 : --43--> terrace_111.jpg | 32.42dB
25-05-13 16:35:37.965 : --44--> thermal_power_station_111.jpg | 30.46dB
25-05-13 16:35:38.088 : --45--> wetland_111.jpg | 31.23dB
25-05-13 16:35:38.095 : <epoch:  1, iter:  60,000, Average PSNR : 31.94dB

25-05-13 17:41:26.577 : <epoch:  2, iter:  70,000, lr:5.000e-05> G_loss: 7.066e-05 
25-05-13 17:41:26.578 : Saving the model.
25-05-13 17:41:27.636 : ---1--> airplane_111.jpg | 32.53dB
25-05-13 17:41:27.756 : ---2--> airport_111.jpg | 32.89dB
25-05-13 17:41:27.875 : ---3--> baseball_diamond_111.jpg | 33.63dB
25-05-13 17:41:27.998 : ---4--> basketball_court_111.jpg | 31.31dB
25-05-13 17:41:28.125 : ---5--> beach_111.jpg | 30.56dB
25-05-13 17:41:28.246 : ---6--> bridge_111.jpg | 35.47dB
25-05-13 17:41:28.366 : ---7--> chaparral_111.jpg | 30.03dB
25-05-13 17:41:28.490 : ---8--> church_111.jpg | 31.52dB
25-05-13 17:41:28.612 : ---9--> circular_farmland_111.jpg | 33.78dB
25-05-13 17:41:28.733 : --10--> cloud_111.jpg | 37.28dB
25-05-13 17:41:28.857 : --11--> commercial_area_111.jpg | 33.00dB
25-05-13 17:41:28.979 : --12--> dense_residential_111.jpg | 29.55dB
25-05-13 17:41:29.101 : --13--> desert_111.jpg | 36.87dB
25-05-13 17:41:29.223 : --14--> forest_111.jpg | 32.26dB
25-05-13 17:41:29.346 : --15--> freeway_111.jpg | 34.60dB
25-05-13 17:41:29.468 : --16--> golf_course_111.jpg | 33.07dB
25-05-13 17:41:29.590 : --17--> ground_track_field_111.jpg | 30.61dB
25-05-13 17:41:29.710 : --18--> harbor_111.jpg | 31.75dB
25-05-13 17:41:29.832 : --19--> industrial_area_111.jpg | 31.62dB
25-05-13 17:41:29.953 : --20--> intersection_111.jpg | 30.54dB
25-05-13 17:41:30.075 : --21--> island_111.jpg | 32.33dB
25-05-13 17:41:30.199 : --22--> lake_111.jpg | 31.88dB
25-05-13 17:41:30.321 : --23--> meadow_111.jpg | 30.15dB
25-05-13 17:41:30.443 : --24--> medium_residential_111.jpg | 28.56dB
25-05-13 17:41:30.564 : --25--> mobile_home_park_111.jpg | 31.43dB
25-05-13 17:41:30.689 : --26--> mountain_111.jpg | 29.37dB
25-05-13 17:41:30.811 : --27--> overpass_111.jpg | 30.40dB
25-05-13 17:41:30.932 : --28--> palace_111.jpg | 29.92dB
25-05-13 17:41:31.054 : --29--> parking_lot_111.jpg | 29.88dB
25-05-13 17:41:31.177 : --30--> railway_111.jpg | 30.14dB
25-05-13 17:41:31.300 : --31--> railway_station_111.jpg | 31.23dB
25-05-13 17:41:31.423 : --32--> rectangular_farmland_111.jpg | 33.27dB
25-05-13 17:41:31.546 : --33--> river_111.jpg | 30.18dB
25-05-13 17:41:31.669 : --34--> roundabout_111.jpg | 30.88dB
25-05-13 17:41:31.791 : --35--> runway_111.jpg | 36.46dB
25-05-13 17:41:31.915 : --36--> sea_ice_111.jpg | 34.09dB
25-05-13 17:41:32.037 : --37--> ship_111.jpg | 37.94dB
25-05-13 17:41:32.168 : --38--> snowberg_111.jpg | 32.68dB
25-05-13 17:41:32.301 : --39--> sparse_residential_111.jpg | 30.17dB
25-05-13 17:41:32.429 : --40--> stadium_111.jpg | 30.45dB
25-05-13 17:41:32.559 : --41--> storage_tank_111.jpg | 31.51dB
25-05-13 17:41:32.689 : --42--> tennis_court_111.jpg | 31.10dB
25-05-13 17:41:32.818 : --43--> terrace_111.jpg | 32.47dB
25-05-13 17:41:32.946 : --44--> thermal_power_station_111.jpg | 30.53dB
25-05-13 17:41:33.074 : --45--> wetland_111.jpg | 31.29dB
25-05-13 17:41:33.083 : <epoch:  2, iter:  70,000, Average PSNR : 32.03dB

25-05-13 18:47:20.207 : <epoch:  2, iter:  80,000, lr:5.000e-05> G_loss: 4.443e-05 
25-05-13 18:47:20.208 : Saving the model.
25-05-13 18:47:21.269 : ---1--> airplane_111.jpg | 32.52dB
25-05-13 18:47:21.391 : ---2--> airport_111.jpg | 32.88dB
25-05-13 18:47:21.513 : ---3--> baseball_diamond_111.jpg | 33.62dB
25-05-13 18:47:21.635 : ---4--> basketball_court_111.jpg | 31.29dB
25-05-13 18:47:21.756 : ---5--> beach_111.jpg | 30.55dB
25-05-13 18:47:21.879 : ---6--> bridge_111.jpg | 35.44dB
25-05-13 18:47:22.000 : ---7--> chaparral_111.jpg | 30.03dB
25-05-13 18:47:22.123 : ---8--> church_111.jpg | 31.52dB
25-05-13 18:47:22.245 : ---9--> circular_farmland_111.jpg | 33.78dB
25-05-13 18:47:22.367 : --10--> cloud_111.jpg | 37.28dB
25-05-13 18:47:22.491 : --11--> commercial_area_111.jpg | 33.00dB
25-05-13 18:47:22.614 : --12--> dense_residential_111.jpg | 29.55dB
25-05-13 18:47:22.737 : --13--> desert_111.jpg | 36.87dB
25-05-13 18:47:22.860 : --14--> forest_111.jpg | 32.26dB
25-05-13 18:47:22.322 : --15--> freeway_111.jpg | 34.58dB
25-05-13 18:47:22.445 : --16--> golf_course_111.jpg | 33.07dB
25-05-13 18:47:22.567 : --17--> ground_track_field_111.jpg | 30.59dB
25-05-13 18:47:22.690 : --18--> harbor_111.jpg | 31.77dB
25-05-13 18:47:22.812 : --19--> industrial_area_111.jpg | 31.60dB
25-05-13 18:47:22.935 : --20--> intersection_111.jpg | 30.53dB
25-05-13 18:47:23.057 : --21--> island_111.jpg | 32.32dB
25-05-13 18:47:23.179 : --22--> lake_111.jpg | 31.88dB
25-05-13 18:47:23.301 : --23--> meadow_111.jpg | 30.14dB
25-05-13 18:47:23.423 : --24--> medium_residential_111.jpg | 28.56dB
25-05-13 18:47:23.546 : --25--> mobile_home_park_111.jpg | 31.44dB
25-05-13 18:47:23.670 : --26--> mountain_111.jpg | 29.37dB
25-05-13 18:47:23.792 : --27--> overpass_111.jpg | 30.38dB
25-05-13 18:47:23.916 : --28--> palace_111.jpg | 29.92dB
25-05-13 18:47:24.039 : --29--> parking_lot_111.jpg | 29.90dB
25-05-13 18:47:24.163 : --30--> railway_111.jpg | 30.13dB
25-05-13 18:47:24.286 : --31--> railway_station_111.jpg | 31.23dB
25-05-13 18:47:24.409 : --32--> rectangular_farmland_111.jpg | 33.26dB
25-05-13 18:47:24.533 : --33--> river_111.jpg | 30.17dB
25-05-13 18:47:24.657 : --34--> roundabout_111.jpg | 30.88dB
25-05-13 18:47:24.780 : --35--> runway_111.jpg | 36.45dB
25-05-13 18:47:24.906 : --36--> sea_ice_111.jpg | 34.08dB
25-05-13 18:47:25.032 : --37--> ship_111.jpg | 37.90dB
25-05-13 18:47:25.157 : --38--> snowberg_111.jpg | 32.69dB
25-05-13 18:47:25.280 : --39--> sparse_residential_111.jpg | 30.17dB
25-05-13 18:47:25.403 : --40--> stadium_111.jpg | 30.42dB
25-05-13 18:47:25.526 : --41--> storage_tank_111.jpg | 31.51dB
25-05-13 18:47:25.649 : --42--> tennis_court_111.jpg | 31.11dB
25-05-13 18:47:25.773 : --43--> terrace_111.jpg | 32.48dB
25-05-13 18:47:25.896 : --44--> thermal_power_station_111.jpg | 30.53dB
25-05-13 18:47:26.020 : --45--> wetland_111.jpg | 31.31dB
25-05-13 18:47:26.033 : <epoch:  2, iter:  80,000, Average PSNR : 32.02dB

25-05-13 19:53:10.393 : <epoch:  2, iter:  90,000, lr:1.250e-05> G_loss: 4.510e-05 
25-05-13 19:53:10.394 : Saving the model.
25-05-13 19:53:11.491 : ---1--> airplane_111.jpg | 32.52dB
25-05-13 19:53:11.613 : ---2--> airport_111.jpg | 32.89dB
25-05-13 19:53:11.734 : ---3--> baseball_diamond_111.jpg | 33.64dB
25-05-13 19:53:11.857 : ---4--> basketball_court_111.jpg | 31.32dB
25-05-13 19:53:11.978 : ---5--> beach_111.jpg | 30.55dB
25-05-13 19:53:12.102 : ---6--> bridge_111.jpg | 35.46dB
25-05-13 19:53:12.222 : ---7--> chaparral_111.jpg | 30.04dB
25-05-13 19:53:12.344 : ---8--> church_111.jpg | 31.50dB
25-05-13 19:53:12.475 : ---9--> circular_farmland_111.jpg | 33.78dB
25-05-13 19:53:12.596 : --10--> cloud_111.jpg | 37.26dB
25-05-13 19:53:12.718 : --11--> commercial_area_111.jpg | 32.99dB
25-05-13 19:53:12.839 : --12--> dense_residential_111.jpg | 29.56dB
25-05-13 19:53:12.961 : --13--> desert_111.jpg | 36.86dB
25-05-13 19:53:13.085 : --14--> forest_111.jpg | 32.27dB
25-05-13 19:53:13.206 : --15--> freeway_111.jpg | 34.61dB
25-05-13 19:53:13.329 : --16--> golf_course_111.jpg | 33.07dB
25-05-13 19:53:13.451 : --17--> ground_track_field_111.jpg | 30.59dB
25-05-13 19:53:13.572 : --18--> harbor_111.jpg | 31.77dB
25-05-13 19:53:13.695 : --19--> industrial_area_111.jpg | 31.61dB
25-05-13 19:53:13.816 : --20--> intersection_111.jpg | 30.53dB
25-05-13 19:53:13.938 : --21--> island_111.jpg | 32.36dB
25-05-13 19:53:14.061 : --22--> lake_111.jpg | 31.87dB
25-05-13 19:53:14.182 : --23--> meadow_111.jpg | 30.16dB
25-05-13 19:53:14.303 : --24--> medium_residential_111.jpg | 28.56dB
25-05-13 19:53:14.425 : --25--> mobile_home_park_111.jpg | 31.45dB
25-05-13 19:53:14.546 : --26--> mountain_111.jpg | 29.37dB
25-05-13 19:53:14.667 : --27--> overpass_111.jpg | 30.40dB
25-05-13 19:53:14.789 : --28--> palace_111.jpg | 29.92dB
25-05-13 19:53:14.910 : --29--> parking_lot_111.jpg | 29.91dB
25-05-13 19:53:15.032 : --30--> railway_111.jpg | 30.11dB
25-05-13 19:53:15.154 : --31--> railway_station_111.jpg | 31.21dB
25-05-13 19:53:15.277 : --32--> rectangular_farmland_111.jpg | 33.26dB
25-05-13 19:53:15.399 : --33--> river_111.jpg | 30.18dB
25-05-13 19:53:15.520 : --34--> roundabout_111.jpg | 30.87dB
25-05-13 19:53:15.644 : --35--> runway_111.jpg | 36.45dB
25-05-13 19:53:15.768 : --36--> sea_ice_111.jpg | 34.06dB
25-05-13 19:53:15.890 : --37--> ship_111.jpg | 37.90dB
25-05-13 19:53:16.012 : --38--> snowberg_111.jpg | 32.68dB
25-05-13 19:53:16.144 : --39--> sparse_residential_111.jpg | 30.19dB
25-05-13 19:53:16.267 : --40--> stadium_111.jpg | 30.45dB
25-05-13 19:53:16.398 : --41--> storage_tank_111.jpg | 31.51dB
25-05-13 19:53:16.520 : --42--> tennis_court_111.jpg | 31.11dB
25-05-13 19:53:16.644 : --43--> terrace_111.jpg | 32.48dB
25-05-13 19:53:16.767 : --44--> thermal_power_station_111.jpg | 30.54dB
25-05-13 19:53:16.889 : --45--> wetland_111.jpg | 31.31dB
25-05-13 19:53:16.897 : <epoch:  2, iter:  90,000, Average PSNR : 32.02dB

25-05-13 20:52:09.222 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/10_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 10000
    checkpoint_save: 10000
    checkpoint_print: 10000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-13 20:52:09.223 : Random seed: 9635
25-05-13 20:52:09.363 : Number of train images: 31,005, iters: 31,005
25-05-13 20:52:10.734 : 
Networks name: DRNet
Params number: 35274045
Net structure:
DRNet(
  (endconv): outconv(
    (conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
  )
  (FE1): FE(
    (fe): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
    )
  )
  (conv1): Sequential(
    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
    (1): PReLU(num_parameters=1)
  )
  (Deep_FE1): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (FCN_SFT1): FCN_SFT(
    (fcn1): FCN(
      (fcn): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
      )
    )
    (fcn2): FCN(
      (fcn): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
      )
    )
    (sft1): SFTLayer(
      (SFT_scale_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (Sigmoid): Sigmoid()
    )
    (sft2): SFTLayer(
      (SFT_scale_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (Sigmoid): Sigmoid()
    )
    (con): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (JTF1): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF11): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
  (Deep_FE2): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (JTF2): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF21): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (conv_noise2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  (Deep_FE3): Deep_FE(
    (fe): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): PReLU(num_parameters=1)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): PReLU(num_parameters=1)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): PReLU(num_parameters=1)
      (8): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (JTF3): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF31): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (conv_noise3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  (conv_noise4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
  (JTF4): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF41): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (up1): up(
    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
  )
  (JTF5): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF51): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(128, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (up2): up(
    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
  )
  (JTF6): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (JTF61): JTF(
    (unfold): Unfold(kernel_size=3, dilation=1, padding=1, stride=1)
    (target_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (guidance_kg): KG(
      (conv_first): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): PReLU(num_parameters=1)
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): PReLU(num_parameters=1)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): PReLU(num_parameters=1)
        (8): Conv2d(64, 144, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (jbf_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PReLU(num_parameters=1)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
)

25-05-13 20:52:11.524 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.000 | -0.040 |  0.054 |  0.016 | torch.Size([3, 64, 1, 1]) || endconv.conv.weight
 | -0.004 | -0.006 | -0.003 |  0.001 | torch.Size([3]) || endconv.conv.bias
 | -0.000 | -0.309 |  0.177 |  0.043 | torch.Size([64, 3, 3, 3]) || FE1.fe.0.weight
 |  0.068 | -0.073 |  0.141 |  0.031 | torch.Size([64]) || FE1.fe.0.bias
 |  0.176 |  0.176 |  0.176 |    nan | torch.Size([1]) || FE1.fe.1.weight
 |  0.000 | -0.236 |  0.296 |  0.033 | torch.Size([64, 64, 3, 3]) || FE1.fe.2.weight
 |  0.030 | -0.002 |  0.076 |  0.016 | torch.Size([64]) || FE1.fe.2.bias
 |  0.995 |  0.995 |  0.995 |    nan | torch.Size([1]) || FE1.fe.3.weight
 |  0.008 | -0.228 |  0.312 |  0.029 | torch.Size([64, 64, 3, 3]) || FE1.fe.4.weight
 |  0.034 | -0.038 |  0.072 |  0.020 | torch.Size([64]) || FE1.fe.4.bias
 |  0.569 |  0.569 |  0.569 |    nan | torch.Size([1]) || FE1.fe.5.weight
 | -0.001 | -0.090 |  0.064 |  0.025 | torch.Size([64, 3, 1, 1]) || conv1.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv1.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || conv1.1.weight
 | -0.001 | -0.299 |  0.389 |  0.040 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.0.weight
 |  0.003 | -0.132 |  0.135 |  0.053 | torch.Size([64]) || Deep_FE1.fe.0.bias
 |  0.107 |  0.107 |  0.107 |    nan | torch.Size([1]) || Deep_FE1.fe.1.weight
 | -0.000 | -0.268 |  0.388 |  0.046 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.2.weight
 | -0.005 | -0.087 |  0.110 |  0.047 | torch.Size([64]) || Deep_FE1.fe.2.bias
 |  0.086 |  0.086 |  0.086 |    nan | torch.Size([1]) || Deep_FE1.fe.3.weight
 | -0.001 | -0.333 |  0.329 |  0.045 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.4.weight
 |  0.013 | -0.093 |  0.090 |  0.055 | torch.Size([64]) || Deep_FE1.fe.4.bias
 |  0.023 |  0.023 |  0.023 |    nan | torch.Size([1]) || Deep_FE1.fe.5.weight
 | -0.003 | -0.373 |  0.229 |  0.046 | torch.Size([64, 64, 3, 3]) || Deep_FE1.fe.6.weight
 |  0.020 | -0.082 |  0.080 |  0.038 | torch.Size([64]) || Deep_FE1.fe.6.bias
 |  0.012 |  0.012 |  0.012 |    nan | torch.Size([1]) || Deep_FE1.fe.7.weight
 | -0.010 | -0.297 |  0.270 |  0.058 | torch.Size([64, 64, 1, 1]) || Deep_FE1.fe.8.weight
 | -0.010 | -0.028 |  0.013 |  0.008 | torch.Size([64]) || Deep_FE1.fe.8.bias
 | -0.000 | -0.033 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.1.weight
 | -0.000 | -0.036 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.3.weight
 | -0.000 | -0.032 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn1.fcn.4.weight
 | -0.000 | -0.001 |  0.002 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn1.fcn.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn1.fcn.5.weight
 |  0.000 | -0.036 |  0.044 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.1.weight
 | -0.000 | -0.035 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.3.weight
 |  0.000 | -0.039 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || FCN_SFT1.fcn2.fcn.4.weight
 |  0.000 | -0.001 |  0.002 |  0.001 | torch.Size([64]) || FCN_SFT1.fcn2.fcn.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || FCN_SFT1.fcn2.fcn.5.weight
 |  0.000 | -0.082 |  0.092 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_scale_conv0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_scale_conv0.bias
 |  0.000 | -0.085 |  0.090 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_scale_conv1.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_scale_conv1.bias
 | -0.000 | -0.089 |  0.087 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_shift_conv0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft1.SFT_shift_conv0.bias
 |  0.000 | -0.091 |  0.082 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft1.SFT_shift_conv1.weight
 | -0.000 | -0.002 |  0.001 |  0.001 | torch.Size([64]) || FCN_SFT1.sft1.SFT_shift_conv1.bias
 | -0.000 | -0.081 |  0.081 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_scale_conv0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_scale_conv0.bias
 |  0.000 | -0.083 |  0.096 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_scale_conv1.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_scale_conv1.bias
 | -0.000 | -0.090 |  0.086 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_shift_conv0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || FCN_SFT1.sft2.SFT_shift_conv0.bias
 | -0.000 | -0.087 |  0.079 |  0.025 | torch.Size([64, 64, 1, 1]) || FCN_SFT1.sft2.SFT_shift_conv1.weight
 | -0.000 | -0.002 |  0.002 |  0.001 | torch.Size([64]) || FCN_SFT1.sft2.SFT_shift_conv1.bias
 | -0.000 | -0.066 |  0.062 |  0.018 | torch.Size([64, 128, 1, 1]) || FCN_SFT1.con.weight
 |  0.001 | -0.009 |  0.008 |  0.004 | torch.Size([64]) || FCN_SFT1.con.bias
 | -0.000 | -0.044 |  0.051 |  0.011 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.0.weight
 | -0.004 | -0.029 |  0.036 |  0.011 | torch.Size([64]) || JTF1.target_kg.conv_first.0.bias
 |  0.272 |  0.272 |  0.272 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.1.weight
 |  0.000 | -0.044 |  0.040 |  0.010 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.2.weight
 |  0.008 | -0.021 |  0.034 |  0.012 | torch.Size([64]) || JTF1.target_kg.conv_first.2.bias
 |  0.272 |  0.272 |  0.272 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.3.weight
 |  0.001 | -0.039 |  0.040 |  0.010 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.4.weight
 |  0.016 | -0.053 |  0.086 |  0.042 | torch.Size([64]) || JTF1.target_kg.conv_first.4.bias
 |  0.272 |  0.272 |  0.272 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.5.weight
 |  0.001 | -0.041 |  0.055 |  0.012 | torch.Size([64, 64, 3, 3]) || JTF1.target_kg.conv_first.6.weight
 |  0.014 | -0.058 |  0.099 |  0.061 | torch.Size([64]) || JTF1.target_kg.conv_first.6.bias
 |  0.272 |  0.272 |  0.272 |    nan | torch.Size([1]) || JTF1.target_kg.conv_first.7.weight
 | -0.000 | -0.122 |  0.109 |  0.023 | torch.Size([144, 64, 1, 1]) || JTF1.target_kg.conv_first.8.weight
 |  0.003 | -0.126 |  0.137 |  0.040 | torch.Size([144]) || JTF1.target_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.041 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.0.weight
 | -0.001 | -0.004 |  0.006 |  0.002 | torch.Size([64]) || JTF1.guidance_kg.conv_first.0.bias
 |  0.306 |  0.306 |  0.306 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.1.weight
 | -0.000 | -0.034 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.2.weight
 | -0.000 | -0.002 |  0.001 |  0.001 | torch.Size([64]) || JTF1.guidance_kg.conv_first.2.bias
 |  0.306 |  0.306 |  0.306 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.3.weight
 | -0.000 | -0.033 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.4.weight
 |  0.012 | -0.051 |  0.078 |  0.042 | torch.Size([64]) || JTF1.guidance_kg.conv_first.4.bias
 |  0.306 |  0.306 |  0.306 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.5.weight
 |  0.001 | -0.043 |  0.055 |  0.012 | torch.Size([64, 64, 3, 3]) || JTF1.guidance_kg.conv_first.6.weight
 |  0.016 | -0.054 |  0.099 |  0.064 | torch.Size([64]) || JTF1.guidance_kg.conv_first.6.bias
 |  0.306 |  0.306 |  0.306 |    nan | torch.Size([1]) || JTF1.guidance_kg.conv_first.7.weight
 | -0.000 | -0.104 |  0.107 |  0.023 | torch.Size([144, 64, 1, 1]) || JTF1.guidance_kg.conv_first.8.weight
 | -0.002 | -0.121 |  0.133 |  0.041 | torch.Size([144]) || JTF1.guidance_kg.conv_first.8.bias
 | -0.001 | -0.183 |  0.170 |  0.019 | torch.Size([64, 64, 3, 3]) || JTF1.jbf_conv.0.weight
 | -0.027 | -0.065 |  0.030 |  0.020 | torch.Size([64]) || JTF1.jbf_conv.0.bias
 |  0.059 |  0.059 |  0.059 |    nan | torch.Size([1]) || JTF1.jbf_conv.1.weight
 |  0.014 | -0.110 |  0.134 |  0.020 | torch.Size([64, 64, 3, 3]) || JTF1.jbf_conv.2.weight
 | -0.029 | -0.052 |  0.030 |  0.015 | torch.Size([64]) || JTF1.jbf_conv.2.bias
 | -0.001 | -0.067 |  0.088 |  0.013 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.0.weight
 | -0.011 | -0.066 |  0.027 |  0.018 | torch.Size([64]) || JTF11.target_kg.conv_first.0.bias
 |  0.194 |  0.194 |  0.194 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.1.weight
 |  0.002 | -0.056 |  0.069 |  0.013 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.2.weight
 |  0.002 | -0.035 |  0.044 |  0.013 | torch.Size([64]) || JTF11.target_kg.conv_first.2.bias
 |  0.194 |  0.194 |  0.194 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.3.weight
 |  0.002 | -0.045 |  0.061 |  0.012 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.4.weight
 |  0.008 | -0.061 |  0.094 |  0.057 | torch.Size([64]) || JTF11.target_kg.conv_first.4.bias
 |  0.194 |  0.194 |  0.194 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.5.weight
 | -0.002 | -0.056 |  0.068 |  0.016 | torch.Size([64, 64, 3, 3]) || JTF11.target_kg.conv_first.6.weight
 | -0.025 | -0.085 |  0.129 |  0.071 | torch.Size([64]) || JTF11.target_kg.conv_first.6.bias
 |  0.194 |  0.194 |  0.194 |    nan | torch.Size([1]) || JTF11.target_kg.conv_first.7.weight
 | -0.001 | -0.104 |  0.114 |  0.026 | torch.Size([144, 64, 1, 1]) || JTF11.target_kg.conv_first.8.weight
 |  0.006 | -0.096 |  0.133 |  0.047 | torch.Size([144]) || JTF11.target_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.0.weight
 |  0.001 | -0.004 |  0.006 |  0.002 | torch.Size([64]) || JTF11.guidance_kg.conv_first.0.bias
 |  0.321 |  0.321 |  0.321 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.1.weight
 |  0.000 | -0.037 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.2.weight
 | -0.002 | -0.019 |  0.001 |  0.004 | torch.Size([64]) || JTF11.guidance_kg.conv_first.2.bias
 |  0.321 |  0.321 |  0.321 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.3.weight
 | -0.000 | -0.038 |  0.037 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.4.weight
 | -0.003 | -0.057 |  0.077 |  0.044 | torch.Size([64]) || JTF11.guidance_kg.conv_first.4.bias
 |  0.321 |  0.321 |  0.321 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.5.weight
 | -0.001 | -0.060 |  0.075 |  0.014 | torch.Size([64, 64, 3, 3]) || JTF11.guidance_kg.conv_first.6.weight
 | -0.000 | -0.083 |  0.118 |  0.082 | torch.Size([64]) || JTF11.guidance_kg.conv_first.6.bias
 |  0.321 |  0.321 |  0.321 |    nan | torch.Size([1]) || JTF11.guidance_kg.conv_first.7.weight
 | -0.000 | -0.112 |  0.099 |  0.026 | torch.Size([144, 64, 1, 1]) || JTF11.guidance_kg.conv_first.8.weight
 | -0.001 | -0.134 |  0.113 |  0.045 | torch.Size([144]) || JTF11.guidance_kg.conv_first.8.bias
 |  0.002 | -0.201 |  0.189 |  0.024 | torch.Size([64, 64, 3, 3]) || JTF11.jbf_conv.0.weight
 | -0.042 | -0.159 |  0.064 |  0.042 | torch.Size([64]) || JTF11.jbf_conv.0.bias
 |  0.039 |  0.039 |  0.039 |    nan | torch.Size([1]) || JTF11.jbf_conv.1.weight
 |  0.010 | -0.210 |  0.214 |  0.025 | torch.Size([64, 64, 3, 3]) || JTF11.jbf_conv.2.weight
 | -0.029 | -0.055 |  0.011 |  0.014 | torch.Size([64]) || JTF11.jbf_conv.2.bias
 | -0.000 | -0.242 |  0.220 |  0.054 | torch.Size([128, 64, 1, 1]) || conv2.weight
 |  0.003 | -0.035 |  0.038 |  0.013 | torch.Size([128]) || conv2.bias
 | -0.001 | -0.302 |  0.311 |  0.039 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.0.weight
 | -0.017 | -0.116 |  0.055 |  0.034 | torch.Size([128]) || Deep_FE2.fe.0.bias
 |  0.103 |  0.103 |  0.103 |    nan | torch.Size([1]) || Deep_FE2.fe.1.weight
 | -0.002 | -0.387 |  0.295 |  0.038 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.2.weight
 | -0.014 | -0.135 |  0.074 |  0.044 | torch.Size([128]) || Deep_FE2.fe.2.bias
 |  0.084 |  0.084 |  0.084 |    nan | torch.Size([1]) || Deep_FE2.fe.3.weight
 | -0.003 | -0.409 |  0.355 |  0.039 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.4.weight
 | -0.008 | -0.121 |  0.066 |  0.038 | torch.Size([128]) || Deep_FE2.fe.4.bias
 |  0.106 |  0.106 |  0.106 |    nan | torch.Size([1]) || Deep_FE2.fe.5.weight
 | -0.003 | -0.273 |  0.290 |  0.035 | torch.Size([128, 128, 3, 3]) || Deep_FE2.fe.6.weight
 |  0.005 | -0.078 |  0.050 |  0.020 | torch.Size([128]) || Deep_FE2.fe.6.bias
 |  0.168 |  0.168 |  0.168 |    nan | torch.Size([1]) || Deep_FE2.fe.7.weight
 | -0.000 | -0.192 |  0.202 |  0.043 | torch.Size([128, 128, 1, 1]) || Deep_FE2.fe.8.weight
 | -0.001 | -0.020 |  0.010 |  0.005 | torch.Size([128]) || Deep_FE2.fe.8.bias
 |  0.000 | -0.028 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.1.weight
 |  0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.3.weight
 | -0.000 | -0.027 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.5.weight
 |  0.000 | -0.032 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.target_kg.conv_first.7.weight
 |  0.000 | -0.064 |  0.066 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF2.target_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF2.target_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.1.weight
 | -0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.3.weight
 | -0.000 | -0.027 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.5.weight
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF2.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF2.guidance_kg.conv_first.7.weight
 | -0.000 | -0.058 |  0.066 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF2.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF2.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF2.jbf_conv.0.weight
 | -0.002 | -0.008 | -0.000 |  0.001 | torch.Size([128]) || JTF2.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF2.jbf_conv.1.weight
 | -0.000 | -0.030 |  0.032 |  0.007 | torch.Size([128, 128, 3, 3]) || JTF2.jbf_conv.2.weight
 | -0.001 | -0.020 |  0.009 |  0.005 | torch.Size([128]) || JTF2.jbf_conv.2.bias
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.1.weight
 | -0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.3.weight
 | -0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.5.weight
 |  0.000 | -0.031 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.target_kg.conv_first.7.weight
 | -0.000 | -0.067 |  0.063 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF21.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF21.target_kg.conv_first.8.bias
 | -0.000 | -0.024 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.1.weight
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.3.weight
 |  0.000 | -0.026 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.5.weight
 | -0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF21.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF21.guidance_kg.conv_first.7.weight
 |  0.000 | -0.067 |  0.060 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF21.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF21.guidance_kg.conv_first.8.bias
 | -0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF21.jbf_conv.0.weight
 | -0.002 | -0.006 | -0.000 |  0.001 | torch.Size([128]) || JTF21.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF21.jbf_conv.1.weight
 | -0.000 | -0.035 |  0.031 |  0.007 | torch.Size([128, 128, 3, 3]) || JTF21.jbf_conv.2.weight
 | -0.001 | -0.020 |  0.009 |  0.005 | torch.Size([128]) || JTF21.jbf_conv.2.bias
 | -0.000 | -0.200 |  0.217 |  0.046 | torch.Size([256, 128, 1, 1]) || conv3.weight
 |  0.001 | -0.025 |  0.027 |  0.010 | torch.Size([256]) || conv3.bias
 | -0.000 | -0.070 |  0.068 |  0.018 | torch.Size([64, 128, 1, 1]) || conv_noise2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv_noise2.bias
 | -0.000 | -0.222 |  0.196 |  0.029 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.0.weight
 | -0.024 | -0.080 |  0.069 |  0.021 | torch.Size([256]) || Deep_FE3.fe.0.bias
 |  0.145 |  0.145 |  0.145 |    nan | torch.Size([1]) || Deep_FE3.fe.1.weight
 | -0.003 | -0.278 |  0.215 |  0.030 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.2.weight
 | -0.016 | -0.168 |  0.060 |  0.039 | torch.Size([256]) || Deep_FE3.fe.2.bias
 |  0.103 |  0.103 |  0.103 |    nan | torch.Size([1]) || Deep_FE3.fe.3.weight
 | -0.003 | -0.330 |  0.213 |  0.030 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.4.weight
 | -0.011 | -0.225 |  0.086 |  0.037 | torch.Size([256]) || Deep_FE3.fe.4.bias
 |  0.099 |  0.099 |  0.099 |    nan | torch.Size([1]) || Deep_FE3.fe.5.weight
 | -0.002 | -0.276 |  0.183 |  0.028 | torch.Size([256, 256, 3, 3]) || Deep_FE3.fe.6.weight
 |  0.012 | -0.069 |  0.074 |  0.024 | torch.Size([256]) || Deep_FE3.fe.6.bias
 |  0.145 |  0.145 |  0.145 |    nan | torch.Size([1]) || Deep_FE3.fe.7.weight
 | -0.000 | -0.117 |  0.118 |  0.028 | torch.Size([256, 256, 1, 1]) || Deep_FE3.fe.8.weight
 | -0.000 | -0.018 |  0.017 |  0.007 | torch.Size([256]) || Deep_FE3.fe.8.bias
 |  0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.1.weight
 |  0.000 | -0.018 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.3.weight
 |  0.000 | -0.021 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.5.weight
 | -0.000 | -0.021 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.target_kg.conv_first.7.weight
 | -0.000 | -0.053 |  0.050 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF3.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF3.target_kg.conv_first.8.bias
 | -0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.1.weight
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.5.weight
 | -0.000 | -0.022 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF3.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF3.guidance_kg.conv_first.7.weight
 |  0.000 | -0.051 |  0.052 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF3.guidance_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF3.guidance_kg.conv_first.8.bias
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF3.jbf_conv.0.weight
 | -0.003 | -0.012 | -0.000 |  0.002 | torch.Size([256]) || JTF3.jbf_conv.0.bias
 |  0.002 |  0.002 |  0.002 |    nan | torch.Size([1]) || JTF3.jbf_conv.1.weight
 | -0.000 | -0.029 |  0.027 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF3.jbf_conv.2.weight
 | -0.000 | -0.021 |  0.019 |  0.007 | torch.Size([256]) || JTF3.jbf_conv.2.bias
 | -0.000 | -0.022 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.1.weight
 | -0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.5.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.target_kg.conv_first.7.weight
 | -0.000 | -0.053 |  0.054 |  0.012 | torch.Size([144, 256, 1, 1]) || JTF31.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF31.target_kg.conv_first.8.bias
 |  0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.1.weight
 | -0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.3.weight
 | -0.000 | -0.019 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.5.weight
 |  0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF31.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF31.guidance_kg.conv_first.7.weight
 |  0.000 | -0.048 |  0.054 |  0.012 | torch.Size([144, 256, 1, 1]) || JTF31.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF31.guidance_kg.conv_first.8.bias
 | -0.000 | -0.020 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF31.jbf_conv.0.weight
 | -0.002 | -0.010 | -0.000 |  0.002 | torch.Size([256]) || JTF31.jbf_conv.0.bias
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || JTF31.jbf_conv.1.weight
 | -0.000 | -0.034 |  0.035 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF31.jbf_conv.2.weight
 | -0.000 | -0.021 |  0.019 |  0.007 | torch.Size([256]) || JTF31.jbf_conv.2.bias
 | -0.000 | -0.052 |  0.047 |  0.013 | torch.Size([64, 256, 1, 1]) || conv_noise3.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || conv_noise3.bias
 |  0.000 | -0.047 |  0.046 |  0.013 | torch.Size([256, 64, 1, 1]) || conv_noise4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || conv_noise4.bias
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.1.weight
 |  0.000 | -0.021 |  0.025 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.3.weight
 |  0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.5.weight
 | -0.000 | -0.021 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.target_kg.conv_first.7.weight
 |  0.000 | -0.051 |  0.053 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF4.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF4.target_kg.conv_first.8.bias
 |  0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.1.weight
 | -0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.3.weight
 | -0.000 | -0.021 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.5.weight
 |  0.000 | -0.019 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF4.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF4.guidance_kg.conv_first.7.weight
 | -0.000 | -0.056 |  0.050 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF4.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF4.guidance_kg.conv_first.8.bias
 | -0.000 | -0.021 |  0.022 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF4.jbf_conv.0.weight
 | -0.004 | -0.014 | -0.000 |  0.003 | torch.Size([256]) || JTF4.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF4.jbf_conv.1.weight
 |  0.000 | -0.031 |  0.029 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF4.jbf_conv.2.weight
 | -0.000 | -0.042 |  0.024 |  0.009 | torch.Size([256]) || JTF4.jbf_conv.2.bias
 |  0.000 | -0.018 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.1.weight
 | -0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.3.weight
 |  0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.5.weight
 | -0.000 | -0.019 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.target_kg.conv_first.7.weight
 | -0.000 | -0.048 |  0.048 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF41.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF41.target_kg.conv_first.8.bias
 | -0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.0.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.1.weight
 |  0.000 | -0.019 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.3.weight
 | -0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.5.weight
 |  0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || JTF41.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF41.guidance_kg.conv_first.7.weight
 |  0.000 | -0.050 |  0.051 |  0.013 | torch.Size([144, 256, 1, 1]) || JTF41.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF41.guidance_kg.conv_first.8.bias
 | -0.000 | -0.021 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || JTF41.jbf_conv.0.weight
 | -0.004 | -0.012 | -0.000 |  0.003 | torch.Size([256]) || JTF41.jbf_conv.0.bias
 |  0.000 |  0.000 |  0.000 |    nan | torch.Size([1]) || JTF41.jbf_conv.1.weight
 |  0.000 | -0.035 |  0.032 |  0.005 | torch.Size([256, 256, 3, 3]) || JTF41.jbf_conv.2.weight
 | -0.000 | -0.042 |  0.024 |  0.009 | torch.Size([256]) || JTF41.jbf_conv.2.bias
 | -0.000 | -0.149 |  0.140 |  0.024 | torch.Size([256, 128, 2, 2]) || up1.up.weight
 | -0.000 | -0.033 |  0.041 |  0.016 | torch.Size([128]) || up1.up.bias
 | -0.000 | -0.025 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.1.weight
 |  0.000 | -0.024 |  0.029 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.3.weight
 |  0.000 | -0.025 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.5.weight
 | -0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.target_kg.conv_first.7.weight
 | -0.000 | -0.072 |  0.067 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF5.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF5.target_kg.conv_first.8.bias
 | -0.000 | -0.025 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.1.weight
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.3.weight
 | -0.000 | -0.028 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.5.weight
 |  0.000 | -0.027 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF5.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF5.guidance_kg.conv_first.7.weight
 |  0.000 | -0.063 |  0.061 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF5.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF5.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.jbf_conv.0.weight
 | -0.004 | -0.011 | -0.000 |  0.002 | torch.Size([128]) || JTF5.jbf_conv.0.bias
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || JTF5.jbf_conv.1.weight
 | -0.000 | -0.029 |  0.029 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF5.jbf_conv.2.weight
 |  0.000 | -0.024 |  0.033 |  0.010 | torch.Size([128]) || JTF5.jbf_conv.2.bias
 | -0.000 | -0.025 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.1.weight
 |  0.000 | -0.024 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.3.weight
 | -0.000 | -0.028 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.5.weight
 |  0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.target_kg.conv_first.7.weight
 |  0.000 | -0.067 |  0.083 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF51.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF51.target_kg.conv_first.8.bias
 | -0.000 | -0.027 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.1.weight
 |  0.000 | -0.029 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.3.weight
 | -0.000 | -0.025 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.5.weight
 |  0.000 | -0.025 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([128]) || JTF51.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF51.guidance_kg.conv_first.7.weight
 | -0.000 | -0.072 |  0.069 |  0.017 | torch.Size([144, 128, 1, 1]) || JTF51.guidance_kg.conv_first.8.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([144]) || JTF51.guidance_kg.conv_first.8.bias
 |  0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.jbf_conv.0.weight
 | -0.004 | -0.009 | -0.000 |  0.002 | torch.Size([128]) || JTF51.jbf_conv.0.bias
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || JTF51.jbf_conv.1.weight
 | -0.000 | -0.028 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || JTF51.jbf_conv.2.weight
 |  0.000 | -0.024 |  0.033 |  0.010 | torch.Size([128]) || JTF51.jbf_conv.2.bias
 | -0.001 | -0.180 |  0.184 |  0.033 | torch.Size([128, 64, 2, 2]) || up2.up.weight
 | -0.014 | -0.052 |  0.024 |  0.016 | torch.Size([64]) || up2.up.bias
 | -0.000 | -0.034 |  0.032 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.1.weight
 |  0.000 | -0.033 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.3.weight
 | -0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.5.weight
 |  0.000 | -0.039 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.target_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.target_kg.conv_first.7.weight
 |  0.000 | -0.061 |  0.061 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF6.target_kg.conv_first.8.weight
 |  0.000 | -0.001 |  0.002 |  0.000 | torch.Size([144]) || JTF6.target_kg.conv_first.8.bias
 |  0.000 | -0.034 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.1.weight
 |  0.000 | -0.036 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.3.weight
 | -0.000 | -0.037 |  0.038 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.5.weight
 |  0.000 | -0.035 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.guidance_kg.conv_first.6.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF6.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF6.guidance_kg.conv_first.7.weight
 | -0.000 | -0.058 |  0.061 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF6.guidance_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.002 |  0.000 | torch.Size([144]) || JTF6.guidance_kg.conv_first.8.bias
 | -0.000 | -0.034 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF6.jbf_conv.0.weight
 | -0.002 | -0.009 | -0.000 |  0.002 | torch.Size([64]) || JTF6.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF6.jbf_conv.1.weight
 |  0.000 | -0.033 |  0.035 |  0.009 | torch.Size([64, 64, 3, 3]) || JTF6.jbf_conv.2.weight
 |  0.006 | -0.017 |  0.037 |  0.008 | torch.Size([64]) || JTF6.jbf_conv.2.bias
 |  0.000 | -0.033 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.1.weight
 | -0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.2.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.3.weight
 | -0.000 | -0.035 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.4.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.5.weight
 | -0.000 | -0.036 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.target_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.001 |  0.000 | torch.Size([64]) || JTF61.target_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.target_kg.conv_first.7.weight
 |  0.000 | -0.065 |  0.074 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF61.target_kg.conv_first.8.weight
 |  0.000 | -0.000 |  0.015 |  0.001 | torch.Size([144]) || JTF61.target_kg.conv_first.8.bias
 | -0.000 | -0.033 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.0.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.0.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.1.weight
 |  0.000 | -0.036 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.2.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.2.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.3.weight
 | -0.000 | -0.033 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.4.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.4.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.5.weight
 |  0.000 | -0.034 |  0.037 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.guidance_kg.conv_first.6.weight
 |  0.000 | -0.000 |  0.001 |  0.000 | torch.Size([64]) || JTF61.guidance_kg.conv_first.6.bias
 |  0.250 |  0.250 |  0.250 |    nan | torch.Size([1]) || JTF61.guidance_kg.conv_first.7.weight
 |  0.000 | -0.059 |  0.060 |  0.017 | torch.Size([144, 64, 1, 1]) || JTF61.guidance_kg.conv_first.8.weight
 |  0.000 | -0.001 |  0.015 |  0.001 | torch.Size([144]) || JTF61.guidance_kg.conv_first.8.bias
 | -0.000 | -0.032 |  0.032 |  0.008 | torch.Size([64, 64, 3, 3]) || JTF61.jbf_conv.0.weight
 | -0.003 | -0.009 | -0.000 |  0.002 | torch.Size([64]) || JTF61.jbf_conv.0.bias
 | -0.000 | -0.000 | -0.000 |    nan | torch.Size([1]) || JTF61.jbf_conv.1.weight
 |  0.000 | -0.037 |  0.039 |  0.009 | torch.Size([64, 64, 3, 3]) || JTF61.jbf_conv.2.weight
 |  0.006 | -0.017 |  0.037 |  0.008 | torch.Size([64]) || JTF61.jbf_conv.2.bias

25-05-13 21:57:56.285 : <epoch:  0, iter:  10,000, lr:1.000e-04> G_loss: 1.339e-04 
25-05-13 21:57:56.286 : Saving the model.
25-05-13 21:57:57.265 : ---1--> airplane_111.jpg | 29.28dB
25-05-13 21:57:57.386 : ---2--> airport_111.jpg | 29.98dB
25-05-13 21:57:57.507 : ---3--> baseball_diamond_111.jpg | 30.70dB
25-05-13 21:57:57.630 : ---4--> basketball_court_111.jpg | 28.06dB
25-05-13 21:57:57.752 : ---5--> beach_111.jpg | 27.52dB
25-05-13 21:57:57.874 : ---6--> bridge_111.jpg | 32.26dB
25-05-13 21:57:57.997 : ---7--> chaparral_111.jpg | 26.82dB
25-05-13 21:57:58.120 : ---8--> church_111.jpg | 28.15dB
25-05-13 21:57:58.244 : ---9--> circular_farmland_111.jpg | 30.59dB
25-05-13 21:57:58.368 : --10--> cloud_111.jpg | 34.16dB
25-05-13 21:57:58.496 : --11--> commercial_area_111.jpg | 29.63dB
25-05-13 21:57:58.620 : --12--> dense_residential_111.jpg | 25.97dB
25-05-13 21:57:58.744 : --13--> desert_111.jpg | 33.83dB
25-05-13 21:57:58.869 : --14--> forest_111.jpg | 29.43dB
25-05-13 21:57:58.993 : --15--> freeway_111.jpg | 31.75dB
25-05-13 21:57:59.116 : --16--> golf_course_111.jpg | 29.97dB
25-05-13 21:57:59.240 : --17--> ground_track_field_111.jpg | 27.18dB
25-05-13 21:57:59.372 : --18--> harbor_111.jpg | 28.74dB
25-05-13 21:57:59.504 : --19--> industrial_area_111.jpg | 28.36dB
25-05-13 21:57:59.627 : --20--> intersection_111.jpg | 27.19dB
25-05-13 21:57:59.751 : --21--> island_111.jpg | 28.91dB
25-05-13 21:57:59.875 : --22--> lake_111.jpg | 29.15dB
25-05-13 21:57:59.999 : --23--> meadow_111.jpg | 27.30dB
25-05-13 21:58:00.125 : --24--> medium_residential_111.jpg | 25.01dB
25-05-13 21:58:00.249 : --25--> mobile_home_park_111.jpg | 27.92dB
25-05-13 21:58:00.374 : --26--> mountain_111.jpg | 26.12dB
25-05-13 21:58:00.501 : --27--> overpass_111.jpg | 27.35dB
25-05-13 21:58:00.626 : --28--> palace_111.jpg | 26.46dB
25-05-13 21:58:00.750 : --29--> parking_lot_111.jpg | 26.13dB
25-05-13 21:58:00.875 : --30--> railway_111.jpg | 27.00dB
25-05-13 21:58:01.000 : --31--> railway_station_111.jpg | 28.31dB
25-05-13 21:58:01.125 : --32--> rectangular_farmland_111.jpg | 30.05dB
25-05-13 21:58:01.250 : --33--> river_111.jpg | 26.96dB
25-05-13 21:58:01.376 : --34--> roundabout_111.jpg | 27.73dB
25-05-13 21:58:01.501 : --35--> runway_111.jpg | 33.56dB
25-05-13 21:58:01.626 : --36--> sea_ice_111.jpg | 30.55dB
25-05-13 21:58:01.751 : --37--> ship_111.jpg | 34.81dB
25-05-13 21:58:01.877 : --38--> snowberg_111.jpg | 28.99dB
25-05-13 21:58:02.004 : --39--> sparse_residential_111.jpg | 27.02dB
25-05-13 21:58:02.129 : --40--> stadium_111.jpg | 26.82dB
25-05-13 21:58:02.254 : --41--> storage_tank_111.jpg | 28.28dB
25-05-13 21:58:02.378 : --42--> tennis_court_111.jpg | 28.16dB
25-05-13 21:58:02.503 : --43--> terrace_111.jpg | 29.29dB
25-05-13 21:58:02.627 : --44--> thermal_power_station_111.jpg | 26.99dB
25-05-13 21:58:02.752 : --45--> wetland_111.jpg | 28.39dB
25-05-13 21:58:02.759 : <epoch:  0, iter:  10,000, Average PSNR : 28.82dB

25-05-13 23:03:52.909 : <epoch:  0, iter:  20,000, lr:1.000e-04> G_loss: 1.280e-04 
25-05-13 23:03:52.911 : Saving the model.
25-05-13 23:03:53.867 : ---1--> airplane_111.jpg | 29.30dB
25-05-13 23:03:53.991 : ---2--> airport_111.jpg | 29.97dB
25-05-13 23:03:54.117 : ---3--> baseball_diamond_111.jpg | 30.69dB
25-05-13 23:03:54.250 : ---4--> basketball_court_111.jpg | 28.04dB
25-05-13 23:03:54.374 : ---5--> beach_111.jpg | 27.50dB
25-05-13 23:03:54.499 : ---6--> bridge_111.jpg | 32.22dB
25-05-13 23:03:54.624 : ---7--> chaparral_111.jpg | 26.85dB
25-05-13 23:03:54.747 : ---8--> church_111.jpg | 28.17dB
25-05-13 23:03:54.871 : ---9--> circular_farmland_111.jpg | 30.54dB
25-05-13 23:03:54.996 : --10--> cloud_111.jpg | 33.91dB
25-05-13 23:03:55.120 : --11--> commercial_area_111.jpg | 29.60dB
25-05-13 23:03:55.243 : --12--> dense_residential_111.jpg | 26.00dB
25-05-13 23:03:55.367 : --13--> desert_111.jpg | 34.07dB
25-05-13 23:03:55.492 : --14--> forest_111.jpg | 29.41dB
25-05-13 23:03:55.617 : --15--> freeway_111.jpg | 31.81dB
25-05-13 23:03:55.741 : --16--> golf_course_111.jpg | 29.96dB
25-05-13 23:03:55.864 : --17--> ground_track_field_111.jpg | 27.17dB
25-05-13 23:03:55.987 : --18--> harbor_111.jpg | 28.74dB
25-05-13 23:03:56.109 : --19--> industrial_area_111.jpg | 28.36dB
25-05-13 23:03:56.241 : --20--> intersection_111.jpg | 27.19dB
25-05-13 23:03:56.369 : --21--> island_111.jpg | 28.94dB
25-05-13 23:03:56.493 : --22--> lake_111.jpg | 29.16dB
25-05-13 23:03:56.617 : --23--> meadow_111.jpg | 27.31dB
25-05-13 23:03:56.742 : --24--> medium_residential_111.jpg | 25.02dB
25-05-13 23:03:56.867 : --25--> mobile_home_park_111.jpg | 27.83dB
25-05-13 23:03:56.991 : --26--> mountain_111.jpg | 26.16dB
25-05-13 23:03:57.115 : --27--> overpass_111.jpg | 27.41dB
25-05-13 23:03:57.238 : --28--> palace_111.jpg | 26.42dB
25-05-13 23:03:57.363 : --29--> parking_lot_111.jpg | 26.14dB
25-05-13 23:03:57.487 : --30--> railway_111.jpg | 27.01dB
25-05-13 23:03:57.613 : --31--> railway_station_111.jpg | 28.32dB
25-05-13 23:03:57.738 : --32--> rectangular_farmland_111.jpg | 30.05dB
25-05-13 23:03:57.864 : --33--> river_111.jpg | 26.96dB
25-05-13 23:03:57.996 : --34--> roundabout_111.jpg | 27.74dB
25-05-13 23:03:58.120 : --35--> runway_111.jpg | 33.55dB
25-05-13 23:03:58.243 : --36--> sea_ice_111.jpg | 30.51dB
25-05-13 23:03:58.367 : --37--> ship_111.jpg | 34.62dB
25-05-13 23:03:58.492 : --38--> snowberg_111.jpg | 29.05dB
25-05-13 23:03:58.616 : --39--> sparse_residential_111.jpg | 27.03dB
25-05-13 23:03:58.741 : --40--> stadium_111.jpg | 26.84dB
25-05-13 23:03:58.864 : --41--> storage_tank_111.jpg | 28.30dB
25-05-13 23:03:58.992 : --42--> tennis_court_111.jpg | 28.17dB
25-05-13 23:03:59.117 : --43--> terrace_111.jpg | 29.27dB
25-05-13 23:03:59.240 : --44--> thermal_power_station_111.jpg | 26.98dB
25-05-13 23:03:59.364 : --45--> wetland_111.jpg | 28.41dB
25-05-13 23:03:59.373 : <epoch:  0, iter:  20,000, Average PSNR : 28.82dB

25-05-14 00:09:46.282 : <epoch:  0, iter:  30,000, lr:1.000e-04> G_loss: 1.469e-04 
25-05-14 00:09:46.283 : Saving the model.
25-05-14 00:09:47.231 : ---1--> airplane_111.jpg | 29.34dB
25-05-14 00:09:47.356 : ---2--> airport_111.jpg | 30.01dB
25-05-14 00:09:47.479 : ---3--> baseball_diamond_111.jpg | 30.75dB
25-05-14 00:09:47.602 : ---4--> basketball_court_111.jpg | 28.05dB
25-05-14 00:09:47.724 : ---5--> beach_111.jpg | 27.53dB
25-05-14 00:09:47.847 : ---6--> bridge_111.jpg | 32.33dB
25-05-14 00:09:47.970 : ---7--> chaparral_111.jpg | 26.78dB
25-05-14 00:09:48.095 : ---8--> church_111.jpg | 28.21dB
25-05-14 00:09:48.219 : ---9--> circular_farmland_111.jpg | 30.62dB
25-05-14 00:09:48.343 : --10--> cloud_111.jpg | 34.20dB
25-05-14 00:09:48.476 : --11--> commercial_area_111.jpg | 29.64dB
25-05-14 00:09:48.605 : --12--> dense_residential_111.jpg | 26.01dB
25-05-14 00:09:48.736 : --13--> desert_111.jpg | 33.92dB
25-05-14 00:09:48.861 : --14--> forest_111.jpg | 29.42dB
25-05-14 00:09:48.986 : --15--> freeway_111.jpg | 31.95dB
25-05-14 00:09:49.109 : --16--> golf_course_111.jpg | 30.01dB
25-05-14 00:09:49.234 : --17--> ground_track_field_111.jpg | 27.21dB
25-05-14 00:09:49.357 : --18--> harbor_111.jpg | 28.75dB
25-05-14 00:09:49.481 : --19--> industrial_area_111.jpg | 28.38dB
25-05-14 00:09:49.606 : --20--> intersection_111.jpg | 27.19dB
25-05-14 00:09:49.731 : --21--> island_111.jpg | 28.96dB
25-05-14 00:09:49.854 : --22--> lake_111.jpg | 29.12dB
25-05-14 00:09:49.978 : --23--> meadow_111.jpg | 27.31dB
25-05-14 00:09:50.102 : --24--> medium_residential_111.jpg | 25.02dB
25-05-14 00:09:50.226 : --25--> mobile_home_park_111.jpg | 27.92dB
25-05-14 00:09:50.351 : --26--> mountain_111.jpg | 26.14dB
25-05-14 00:09:50.475 : --27--> overpass_111.jpg | 27.41dB
25-05-14 00:09:50.600 : --28--> palace_111.jpg | 26.46dB
25-05-14 00:09:50.724 : --29--> parking_lot_111.jpg | 26.15dB
25-05-14 00:09:50.848 : --30--> railway_111.jpg | 27.01dB
25-05-14 00:09:50.975 : --31--> railway_station_111.jpg | 28.33dB
25-05-14 00:09:51.099 : --32--> rectangular_farmland_111.jpg | 30.09dB
25-05-14 00:09:51.223 : --33--> river_111.jpg | 26.94dB
25-05-14 00:09:51.348 : --34--> roundabout_111.jpg | 27.77dB
25-05-14 00:09:51.472 : --35--> runway_111.jpg | 33.61dB
25-05-14 00:09:51.596 : --36--> sea_ice_111.jpg | 30.57dB
25-05-14 00:09:51.720 : --37--> ship_111.jpg | 34.83dB
25-05-14 00:09:51.844 : --38--> snowberg_111.jpg | 29.04dB
25-05-14 00:09:51.968 : --39--> sparse_residential_111.jpg | 27.02dB
25-05-14 00:09:52.092 : --40--> stadium_111.jpg | 26.85dB
25-05-14 00:09:52.214 : --41--> storage_tank_111.jpg | 28.31dB
25-05-14 00:09:52.339 : --42--> tennis_court_111.jpg | 28.21dB
25-05-14 00:09:52.463 : --43--> terrace_111.jpg | 29.28dB
25-05-14 00:09:52.587 : --44--> thermal_power_station_111.jpg | 27.00dB
25-05-14 00:09:52.711 : --45--> wetland_111.jpg | 28.39dB
25-05-14 00:09:52.721 : <epoch:  0, iter:  30,000, Average PSNR : 28.85dB

25-05-14 01:15:40.122 : <epoch:  1, iter:  40,000, lr:1.000e-04> G_loss: 1.175e-04 
25-05-14 01:15:40.123 : Saving the model.
25-05-14 01:15:41.133 : ---1--> airplane_111.jpg | 29.32dB
25-05-14 01:15:41.256 : ---2--> airport_111.jpg | 29.97dB
25-05-14 01:15:41.381 : ---3--> baseball_diamond_111.jpg | 30.74dB
25-05-14 01:15:41.505 : ---4--> basketball_court_111.jpg | 28.07dB
25-05-14 01:15:41.627 : ---5--> beach_111.jpg | 27.49dB
25-05-14 01:15:41.749 : ---6--> bridge_111.jpg | 32.35dB
25-05-14 01:15:41.872 : ---7--> chaparral_111.jpg | 26.82dB
25-05-14 01:15:41.996 : ---8--> church_111.jpg | 28.12dB
25-05-14 01:15:42.119 : ---9--> circular_farmland_111.jpg | 30.55dB
25-05-14 01:15:42.242 : --10--> cloud_111.jpg | 34.15dB
25-05-14 01:15:42.374 : --11--> commercial_area_111.jpg | 29.66dB
25-05-14 01:15:42.497 : --12--> dense_residential_111.jpg | 25.93dB
25-05-14 01:15:42.620 : --13--> desert_111.jpg | 34.14dB
25-05-14 01:15:42.743 : --14--> forest_111.jpg | 29.41dB
25-05-14 01:15:42.867 : --15--> freeway_111.jpg | 31.92dB
25-05-14 01:15:42.993 : --16--> golf_course_111.jpg | 30.01dB
25-05-14 01:15:43.117 : --17--> ground_track_field_111.jpg | 27.19dB
25-05-14 01:15:43.247 : --18--> harbor_111.jpg | 28.74dB
25-05-14 01:15:43.370 : --19--> industrial_area_111.jpg | 28.38dB
25-05-14 01:15:43.495 : --20--> intersection_111.jpg | 27.17dB
25-05-14 01:15:43.619 : --21--> island_111.jpg | 28.91dB
25-05-14 01:15:43.745 : --22--> lake_111.jpg | 29.14dB
25-05-14 01:15:43.869 : --23--> meadow_111.jpg | 27.35dB
25-05-14 01:15:43.994 : --24--> medium_residential_111.jpg | 24.97dB
25-05-14 01:15:44.119 : --25--> mobile_home_park_111.jpg | 27.96dB
25-05-14 01:15:44.243 : --26--> mountain_111.jpg | 26.12dB
25-05-14 01:15:44.374 : --27--> overpass_111.jpg | 27.40dB
25-05-14 01:15:44.498 : --28--> palace_111.jpg | 26.45dB
25-05-14 01:15:44.622 : --29--> parking_lot_111.jpg | 26.11dB
25-05-14 01:15:44.746 : --30--> railway_111.jpg | 26.92dB
25-05-14 01:15:44.870 : --31--> railway_station_111.jpg | 28.31dB
25-05-14 01:15:44.995 : --32--> rectangular_farmland_111.jpg | 30.10dB
25-05-14 01:15:45.120 : --33--> river_111.jpg | 26.93dB
25-05-14 01:15:45.245 : --34--> roundabout_111.jpg | 27.74dB
25-05-14 01:15:45.376 : --35--> runway_111.jpg | 33.70dB
25-05-14 01:15:45.502 : --36--> sea_ice_111.jpg | 30.56dB
25-05-14 01:15:45.626 : --37--> ship_111.jpg | 34.78dB
25-05-14 01:15:45.750 : --38--> snowberg_111.jpg | 29.05dB
25-05-14 01:15:45.876 : --39--> sparse_residential_111.jpg | 27.01dB
25-05-14 01:15:46.000 : --40--> stadium_111.jpg | 26.83dB
25-05-14 01:15:46.125 : --41--> storage_tank_111.jpg | 28.30dB
25-05-14 01:15:46.248 : --42--> tennis_court_111.jpg | 28.15dB
25-05-14 01:15:46.383 : --43--> terrace_111.jpg | 29.36dB
25-05-14 01:15:46.509 : --44--> thermal_power_station_111.jpg | 26.98dB
25-05-14 01:15:46.634 : --45--> wetland_111.jpg | 28.37dB
25-05-14 01:15:46.647 : <epoch:  1, iter:  40,000, Average PSNR : 28.84dB

25-05-14 02:21:32.804 : <epoch:  1, iter:  50,000, lr:1.000e-04> G_loss: 2.697e-04 
25-05-14 02:21:32.805 : Saving the model.
25-05-14 02:21:33.760 : ---1--> airplane_111.jpg | 29.36dB
25-05-14 02:21:33.883 : ---2--> airport_111.jpg | 30.01dB
25-05-14 02:21:34.006 : ---3--> baseball_diamond_111.jpg | 30.76dB
25-05-14 02:21:34.128 : ---4--> basketball_court_111.jpg | 28.08dB
25-05-14 02:21:34.251 : ---5--> beach_111.jpg | 27.54dB
25-05-14 02:21:34.376 : ---6--> bridge_111.jpg | 32.38dB
25-05-14 02:21:34.501 : ---7--> chaparral_111.jpg | 26.87dB
25-05-14 02:21:34.626 : ---8--> church_111.jpg | 28.18dB
25-05-14 02:21:34.760 : ---9--> circular_farmland_111.jpg | 30.64dB
25-05-14 02:21:34.885 : --10--> cloud_111.jpg | 34.19dB
25-05-14 02:21:35.010 : --11--> commercial_area_111.jpg | 29.66dB
25-05-14 02:21:35.136 : --12--> dense_residential_111.jpg | 26.02dB
25-05-14 02:21:35.260 : --13--> desert_111.jpg | 34.10dB
25-05-14 02:21:35.384 : --14--> forest_111.jpg | 29.46dB
25-05-14 02:21:35.510 : --15--> freeway_111.jpg | 31.95dB
25-05-14 02:21:35.633 : --16--> golf_course_111.jpg | 30.04dB
25-05-14 02:21:35.758 : --17--> ground_track_field_111.jpg | 27.23dB
25-05-14 02:21:35.884 : --18--> harbor_111.jpg | 28.78dB
25-05-14 02:21:36.009 : --19--> industrial_area_111.jpg | 28.40dB
25-05-14 02:21:36.133 : --20--> intersection_111.jpg | 27.21dB
25-05-14 02:21:36.257 : --21--> island_111.jpg | 28.99dB
25-05-14 02:21:36.386 : --22--> lake_111.jpg | 29.17dB
25-05-14 02:21:36.511 : --23--> meadow_111.jpg | 27.30dB
25-05-14 02:21:36.636 : --24--> medium_residential_111.jpg | 25.02dB
25-05-14 02:21:36.763 : --25--> mobile_home_park_111.jpg | 27.98dB
25-05-14 02:21:36.890 : --26--> mountain_111.jpg | 26.16dB
25-05-14 02:21:37.015 : --27--> overpass_111.jpg | 27.45dB
25-05-14 02:21:37.140 : --28--> palace_111.jpg | 26.51dB
25-05-14 02:21:37.267 : --29--> parking_lot_111.jpg | 26.20dB
25-05-14 02:21:37.393 : --30--> railway_111.jpg | 26.99dB
25-05-14 02:21:37.520 : --31--> railway_station_111.jpg | 28.36dB
25-05-14 02:21:37.645 : --32--> rectangular_farmland_111.jpg | 30.19dB
25-05-14 02:21:37.771 : --33--> river_111.jpg | 26.96dB
25-05-14 02:21:37.897 : --34--> roundabout_111.jpg | 27.80dB
25-05-14 02:21:38.023 : --35--> runway_111.jpg | 33.64dB
25-05-14 02:21:38.149 : --36--> sea_ice_111.jpg | 30.64dB
25-05-14 02:21:38.274 : --37--> ship_111.jpg | 34.83dB
25-05-14 02:21:38.400 : --38--> snowberg_111.jpg | 29.13dB
25-05-14 02:21:38.529 : --39--> sparse_residential_111.jpg | 27.02dB
25-05-14 02:21:38.654 : --40--> stadium_111.jpg | 26.86dB
25-05-14 02:21:38.782 : --41--> storage_tank_111.jpg | 28.34dB
25-05-14 02:21:38.917 : --42--> tennis_court_111.jpg | 28.23dB
25-05-14 02:21:39.042 : --43--> terrace_111.jpg | 29.33dB
25-05-14 02:21:39.167 : --44--> thermal_power_station_111.jpg | 27.02dB
25-05-14 02:21:39.293 : --45--> wetland_111.jpg | 28.41dB
25-05-14 02:21:39.305 : <epoch:  1, iter:  50,000, Average PSNR : 28.88dB

25-05-14 03:27:26.472 : <epoch:  1, iter:  60,000, lr:2.500e-05> G_loss: 1.041e-04 
25-05-14 03:27:26.474 : Saving the model.
25-05-14 03:27:27.451 : ---1--> airplane_111.jpg | 29.36dB
25-05-14 03:27:27.574 : ---2--> airport_111.jpg | 30.02dB
25-05-14 03:27:27.696 : ---3--> baseball_diamond_111.jpg | 30.76dB
25-05-14 03:27:27.820 : ---4--> basketball_court_111.jpg | 28.06dB
25-05-14 03:27:27.942 : ---5--> beach_111.jpg | 27.52dB
25-05-14 03:27:28.066 : ---6--> bridge_111.jpg | 32.33dB
25-05-14 03:27:28.188 : ---7--> chaparral_111.jpg | 26.82dB
25-05-14 03:27:28.311 : ---8--> church_111.jpg | 28.19dB
25-05-14 03:27:28.435 : ---9--> circular_farmland_111.jpg | 30.67dB
25-05-14 03:27:28.565 : --10--> cloud_111.jpg | 34.21dB
25-05-14 03:27:28.697 : --11--> commercial_area_111.jpg | 29.65dB
25-05-14 03:27:28.821 : --12--> dense_residential_111.jpg | 26.01dB
25-05-14 03:27:28.945 : --13--> desert_111.jpg | 34.25dB
25-05-14 03:27:29.070 : --14--> forest_111.jpg | 29.41dB
25-05-14 03:27:29.195 : --15--> freeway_111.jpg | 31.91dB
25-05-14 03:27:29.321 : --16--> golf_course_111.jpg | 30.01dB
25-05-14 03:27:29.446 : --17--> ground_track_field_111.jpg | 27.24dB
25-05-14 03:27:29.571 : --18--> harbor_111.jpg | 28.79dB
25-05-14 03:27:29.695 : --19--> industrial_area_111.jpg | 28.39dB
25-05-14 03:27:29.820 : --20--> intersection_111.jpg | 27.22dB
25-05-14 03:27:29.944 : --21--> island_111.jpg | 28.97dB
25-05-14 03:27:30.070 : --22--> lake_111.jpg | 29.14dB
25-05-14 03:27:30.194 : --23--> meadow_111.jpg | 27.22dB
25-05-14 03:27:30.321 : --24--> medium_residential_111.jpg | 25.01dB
25-05-14 03:27:30.447 : --25--> mobile_home_park_111.jpg | 27.97dB
25-05-14 03:27:30.572 : --26--> mountain_111.jpg | 26.14dB
25-05-14 03:27:30.699 : --27--> overpass_111.jpg | 27.43dB
25-05-14 03:27:30.825 : --28--> palace_111.jpg | 26.49dB
25-05-14 03:27:30.950 : --29--> parking_lot_111.jpg | 26.20dB
25-05-14 03:27:31.074 : --30--> railway_111.jpg | 26.97dB
25-05-14 03:27:31.202 : --31--> railway_station_111.jpg | 28.34dB
25-05-14 03:27:31.327 : --32--> rectangular_farmland_111.jpg | 30.16dB
25-05-14 03:27:31.451 : --33--> river_111.jpg | 26.94dB
25-05-14 03:27:31.575 : --34--> roundabout_111.jpg | 27.79dB
25-05-14 03:27:31.701 : --35--> runway_111.jpg | 33.63dB
25-05-14 03:27:31.830 : --36--> sea_ice_111.jpg | 30.61dB
25-05-14 03:27:31.955 : --37--> ship_111.jpg | 34.85dB
25-05-14 03:27:32.090 : --38--> snowberg_111.jpg | 29.10dB
25-05-14 03:27:32.218 : --39--> sparse_residential_111.jpg | 27.01dB
25-05-14 03:27:32.343 : --40--> stadium_111.jpg | 26.86dB
25-05-14 03:27:32.475 : --41--> storage_tank_111.jpg | 28.33dB
25-05-14 03:27:32.601 : --42--> tennis_court_111.jpg | 28.22dB
25-05-14 03:27:32.725 : --43--> terrace_111.jpg | 29.37dB
25-05-14 03:27:32.850 : --44--> thermal_power_station_111.jpg | 26.99dB
25-05-14 03:27:32.990 : --45--> wetland_111.jpg | 28.42dB
25-05-14 03:27:32.997 : <epoch:  1, iter:  60,000, Average PSNR : 28.87dB

25-05-14 04:33:17.987 : <epoch:  2, iter:  70,000, lr:5.000e-05> G_loss: 1.762e-04 
25-05-14 04:33:17.989 : Saving the model.
25-05-14 04:33:18.915 : ---1--> airplane_111.jpg | 29.40dB
25-05-14 04:33:19.040 : ---2--> airport_111.jpg | 30.04dB
25-05-14 04:33:19.165 : ---3--> baseball_diamond_111.jpg | 30.81dB
25-05-14 04:33:19.290 : ---4--> basketball_court_111.jpg | 28.11dB
25-05-14 04:33:19.413 : ---5--> beach_111.jpg | 27.57dB
25-05-14 04:33:19.538 : ---6--> bridge_111.jpg | 32.43dB
25-05-14 04:33:19.662 : ---7--> chaparral_111.jpg | 26.87dB
25-05-14 04:33:19.786 : ---8--> church_111.jpg | 28.24dB
25-05-14 04:33:19.918 : ---9--> circular_farmland_111.jpg | 30.68dB
25-05-14 04:33:20.046 : --10--> cloud_111.jpg | 34.29dB
25-05-14 04:33:20.171 : --11--> commercial_area_111.jpg | 29.72dB
25-05-14 04:33:20.295 : --12--> dense_residential_111.jpg | 26.03dB
25-05-14 04:33:20.420 : --13--> desert_111.jpg | 34.04dB
25-05-14 04:33:20.546 : --14--> forest_111.jpg | 29.47dB
25-05-14 04:33:20.671 : --15--> freeway_111.jpg | 32.07dB
25-05-14 04:33:20.796 : --16--> golf_course_111.jpg | 30.06dB
25-05-14 04:33:20.921 : --17--> ground_track_field_111.jpg | 27.26dB
25-05-14 04:33:21.046 : --18--> harbor_111.jpg | 28.82dB
25-05-14 04:33:21.170 : --19--> industrial_area_111.jpg | 28.46dB
25-05-14 04:33:21.295 : --20--> intersection_111.jpg | 27.25dB
25-05-14 04:33:21.421 : --21--> island_111.jpg | 29.01dB
25-05-14 04:33:21.547 : --22--> lake_111.jpg | 29.20dB
25-05-14 04:33:21.672 : --23--> meadow_111.jpg | 27.36dB
25-05-14 04:33:21.795 : --24--> medium_residential_111.jpg | 25.04dB
25-05-14 04:33:21.922 : --25--> mobile_home_park_111.jpg | 28.00dB
25-05-14 04:33:22.047 : --26--> mountain_111.jpg | 26.16dB
25-05-14 04:33:22.172 : --27--> overpass_111.jpg | 27.49dB
25-05-14 04:33:22.297 : --28--> palace_111.jpg | 26.52dB
25-05-14 04:33:22.421 : --29--> parking_lot_111.jpg | 26.23dB
25-05-14 04:33:22.545 : --30--> railway_111.jpg | 27.06dB
25-05-14 04:33:22.670 : --31--> railway_station_111.jpg | 28.40dB
25-05-14 04:33:22.794 : --32--> rectangular_farmland_111.jpg | 30.19dB
25-05-14 04:33:22.921 : --33--> river_111.jpg | 26.96dB
25-05-14 04:33:23.047 : --34--> roundabout_111.jpg | 27.84dB
25-05-14 04:33:23.173 : --35--> runway_111.jpg | 33.82dB
25-05-14 04:33:23.298 : --36--> sea_ice_111.jpg | 30.71dB
25-05-14 04:33:23.423 : --37--> ship_111.jpg | 34.95dB
25-05-14 04:33:23.548 : --38--> snowberg_111.jpg | 29.15dB
25-05-14 04:33:23.675 : --39--> sparse_residential_111.jpg | 27.04dB
25-05-14 04:33:23.801 : --40--> stadium_111.jpg | 26.90dB
25-05-14 04:33:23.927 : --41--> storage_tank_111.jpg | 28.36dB
25-05-14 04:33:24.052 : --42--> tennis_court_111.jpg | 28.28dB
25-05-14 04:33:24.180 : --43--> terrace_111.jpg | 29.34dB
25-05-14 04:33:24.308 : --44--> thermal_power_station_111.jpg | 27.03dB
25-05-14 04:33:24.433 : --45--> wetland_111.jpg | 28.42dB
25-05-14 04:33:24.440 : <epoch:  2, iter:  70,000, Average PSNR : 28.91dB

25-05-14 05:39:08.372 : <epoch:  2, iter:  80,000, lr:5.000e-05> G_loss: 3.019e-04 
25-05-14 05:39:08.373 : Saving the model.
25-05-14 05:39:09.369 : ---1--> airplane_111.jpg | 29.40dB
25-05-14 05:39:09.494 : ---2--> airport_111.jpg | 30.07dB
25-05-14 05:39:09.619 : ---3--> baseball_diamond_111.jpg | 30.81dB
25-05-14 05:39:09.742 : ---4--> basketball_court_111.jpg | 28.12dB
25-05-14 05:39:09.867 : ---5--> beach_111.jpg | 27.58dB
25-05-14 05:39:09.995 : ---6--> bridge_111.jpg | 32.43dB
25-05-14 05:39:10.118 : ---7--> chaparral_111.jpg | 26.87dB
25-05-14 05:39:10.242 : ---8--> church_111.jpg | 28.24dB
25-05-14 05:39:10.367 : ---9--> circular_farmland_111.jpg | 30.71dB
25-05-14 05:39:10.490 : --10--> cloud_111.jpg | 34.36dB
25-05-14 05:39:10.615 : --11--> commercial_area_111.jpg | 29.70dB
25-05-14 05:39:10.738 : --12--> dense_residential_111.jpg | 26.03dB
25-05-14 05:39:10.863 : --13--> desert_111.jpg | 34.36dB
25-05-14 05:39:10.989 : --14--> forest_111.jpg | 29.46dB
25-05-14 05:39:11.114 : --15--> freeway_111.jpg | 32.07dB
25-05-14 05:39:11.239 : --16--> golf_course_111.jpg | 30.07dB
25-05-14 05:39:11.363 : --17--> ground_track_field_111.jpg | 27.26dB
25-05-14 05:39:11.488 : --18--> harbor_111.jpg | 28.81dB
25-05-14 05:39:11.614 : --19--> industrial_area_111.jpg | 28.43dB
25-05-14 05:39:11.739 : --20--> intersection_111.jpg | 27.24dB
25-05-14 05:39:11.864 : --21--> island_111.jpg | 29.02dB
25-05-14 05:39:11.989 : --22--> lake_111.jpg | 29.21dB
25-05-14 05:39:12.114 : --23--> meadow_111.jpg | 27.36dB
25-05-14 05:39:12.240 : --24--> medium_residential_111.jpg | 25.04dB
25-05-14 05:39:12.370 : --25--> mobile_home_park_111.jpg | 28.01dB
25-05-14 05:39:12.498 : --26--> mountain_111.jpg | 26.17dB
25-05-14 05:39:12.628 : --27--> overpass_111.jpg | 27.41dB
25-05-14 05:39:12.754 : --28--> palace_111.jpg | 26.53dB
25-05-14 05:39:12.882 : --29--> parking_lot_111.jpg | 26.24dB
25-05-14 05:39:13.007 : --30--> railway_111.jpg | 27.04dB
25-05-14 05:39:13.132 : --31--> railway_station_111.jpg | 28.40dB
25-05-14 05:39:13.258 : --32--> rectangular_farmland_111.jpg | 30.21dB
25-05-14 05:39:13.384 : --33--> river_111.jpg | 26.97dB
25-05-14 05:39:13.511 : --34--> roundabout_111.jpg | 27.84dB
25-05-14 05:39:13.637 : --35--> runway_111.jpg | 33.81dB
25-05-14 05:39:13.764 : --36--> sea_ice_111.jpg | 30.70dB
25-05-14 05:39:13.889 : --37--> ship_111.jpg | 34.90dB
25-05-14 05:39:14.015 : --38--> snowberg_111.jpg | 29.16dB
25-05-14 05:39:14.140 : --39--> sparse_residential_111.jpg | 27.06dB
25-05-14 05:39:14.266 : --40--> stadium_111.jpg | 26.90dB
25-05-14 05:39:14.391 : --41--> storage_tank_111.jpg | 28.37dB
25-05-14 05:39:14.517 : --42--> tennis_court_111.jpg | 28.28dB
25-05-14 05:39:14.644 : --43--> terrace_111.jpg | 29.37dB
25-05-14 05:39:14.772 : --44--> thermal_power_station_111.jpg | 27.04dB
25-05-14 05:39:14.897 : --45--> wetland_111.jpg | 28.44dB
25-05-14 05:39:14.905 : <epoch:  2, iter:  80,000, Average PSNR : 28.92dB

25-05-14 06:44:58.062 : <epoch:  2, iter:  90,000, lr:1.250e-05> G_loss: 2.438e-04 
25-05-14 06:44:58.063 : Saving the model.
25-05-14 06:44:59.032 : ---1--> airplane_111.jpg | 29.41dB
25-05-14 06:44:59.158 : ---2--> airport_111.jpg | 30.05dB
25-05-14 06:44:59.282 : ---3--> baseball_diamond_111.jpg | 30.79dB
25-05-14 06:44:59.406 : ---4--> basketball_court_111.jpg | 28.11dB
25-05-14 06:44:59.530 : ---5--> beach_111.jpg | 27.59dB
25-05-14 06:44:59.655 : ---6--> bridge_111.jpg | 32.43dB
25-05-14 06:44:59.780 : ---7--> chaparral_111.jpg | 26.85dB
25-05-14 06:44:59.904 : ---8--> church_111.jpg | 28.23dB
25-05-14 06:45:00.028 : ---9--> circular_farmland_111.jpg | 30.67dB
25-05-14 06:45:00.152 : --10--> cloud_111.jpg | 34.24dB
25-05-14 06:45:00.276 : --11--> commercial_area_111.jpg | 29.69dB
25-05-14 06:45:00.400 : --12--> dense_residential_111.jpg | 26.03dB
25-05-14 06:45:00.523 : --13--> desert_111.jpg | 34.26dB
25-05-14 06:45:00.647 : --14--> forest_111.jpg | 29.47dB
25-05-14 06:45:00.773 : --15--> freeway_111.jpg | 32.01dB
25-05-14 06:45:00.898 : --16--> golf_course_111.jpg | 30.06dB
25-05-14 06:45:01.024 : --17--> ground_track_field_111.jpg | 27.25dB
25-05-14 06:45:01.155 : --18--> harbor_111.jpg | 28.81dB
25-05-14 06:45:01.281 : --19--> industrial_area_111.jpg | 28.46dB
25-05-14 06:45:01.409 : --20--> intersection_111.jpg | 27.24dB
25-05-14 06:45:01.535 : --21--> island_111.jpg | 29.03dB
25-05-14 06:45:01.661 : --22--> lake_111.jpg | 29.20dB
25-05-14 06:45:01.787 : --23--> meadow_111.jpg | 27.40dB
25-05-14 06:45:01.914 : --24--> medium_residential_111.jpg | 25.02dB
25-05-14 06:45:02.040 : --25--> mobile_home_park_111.jpg | 27.98dB
25-05-14 06:45:02.168 : --26--> mountain_111.jpg | 26.16dB
25-05-14 06:45:02.292 : --27--> overpass_111.jpg | 27.44dB
25-05-14 06:45:02.419 : --28--> palace_111.jpg | 26.51dB
25-05-14 06:45:02.546 : --29--> parking_lot_111.jpg | 26.22dB
25-05-14 06:45:02.672 : --30--> railway_111.jpg | 27.05dB
25-05-14 06:45:02.797 : --31--> railway_station_111.jpg | 28.37dB
25-05-14 06:45:02.924 : --32--> rectangular_farmland_111.jpg | 30.16dB
25-05-14 06:45:03.050 : --33--> river_111.jpg | 26.97dB
25-05-14 06:45:03.176 : --34--> roundabout_111.jpg | 27.81dB
25-05-14 06:45:03.303 : --35--> runway_111.jpg | 33.88dB
25-05-14 06:45:03.429 : --36--> sea_ice_111.jpg | 30.67dB
25-05-14 06:45:03.553 : --37--> ship_111.jpg | 34.89dB
25-05-14 06:45:03.679 : --38--> snowberg_111.jpg | 29.13dB
25-05-14 06:45:03.804 : --39--> sparse_residential_111.jpg | 27.05dB
25-05-14 06:45:03.931 : --40--> stadium_111.jpg | 26.88dB
25-05-14 06:45:04.058 : --41--> storage_tank_111.jpg | 28.36dB
25-05-14 06:45:04.184 : --42--> tennis_court_111.jpg | 28.27dB
25-05-14 06:45:04.314 : --43--> terrace_111.jpg | 29.31dB
25-05-14 06:45:04.440 : --44--> thermal_power_station_111.jpg | 27.03dB
25-05-14 06:45:04.565 : --45--> wetland_111.jpg | 28.43dB
25-05-14 06:45:04.574 : <epoch:  2, iter:  90,000, Average PSNR : 28.91dB

25-05-14 07:50:49.604 : <epoch:  3, iter: 100,000, lr:2.500e-05> G_loss: 1.507e-04 
25-05-14 07:50:49.605 : Saving the model.
25-05-14 07:50:50.606 : ---1--> airplane_111.jpg | 29.42dB
25-05-14 07:50:50.729 : ---2--> airport_111.jpg | 30.07dB
25-05-14 07:50:50.852 : ---3--> baseball_diamond_111.jpg | 30.84dB
25-05-14 07:50:50.977 : ---4--> basketball_court_111.jpg | 28.12dB
25-05-14 07:50:51.101 : ---5--> beach_111.jpg | 27.58dB
25-05-14 07:50:51.225 : ---6--> bridge_111.jpg | 32.48dB
25-05-14 07:50:51.349 : ---7--> chaparral_111.jpg | 26.88dB
25-05-14 07:50:51.474 : ---8--> church_111.jpg | 28.24dB
25-05-14 07:50:51.599 : ---9--> circular_farmland_111.jpg | 30.71dB
25-05-14 07:50:51.725 : --10--> cloud_111.jpg | 34.37dB
25-05-14 07:50:51.851 : --11--> commercial_area_111.jpg | 29.71dB
25-05-14 07:50:51.976 : --12--> dense_residential_111.jpg | 26.06dB
25-05-14 07:50:52.102 : --13--> desert_111.jpg | 34.32dB
25-05-14 07:50:52.227 : --14--> forest_111.jpg | 29.47dB
25-05-14 07:50:52.353 : --15--> freeway_111.jpg | 32.10dB
25-05-14 07:50:52.478 : --16--> golf_course_111.jpg | 30.08dB
25-05-14 07:50:52.603 : --17--> ground_track_field_111.jpg | 27.27dB
25-05-14 07:50:52.728 : --18--> harbor_111.jpg | 28.83dB
25-05-14 07:50:52.852 : --19--> industrial_area_111.jpg | 28.48dB
25-05-14 07:50:52.977 : --20--> intersection_111.jpg | 27.26dB
25-05-14 07:50:53.104 : --21--> island_111.jpg | 29.04dB
25-05-14 07:50:53.230 : --22--> lake_111.jpg | 29.21dB
25-05-14 07:50:53.356 : --23--> meadow_111.jpg | 27.37dB
25-05-14 07:50:53.483 : --24--> medium_residential_111.jpg | 25.05dB
25-05-14 07:50:53.609 : --25--> mobile_home_park_111.jpg | 28.01dB
25-05-14 07:50:53.735 : --26--> mountain_111.jpg | 26.17dB
25-05-14 07:50:53.867 : --27--> overpass_111.jpg | 27.53dB
25-05-14 07:50:53.992 : --28--> palace_111.jpg | 26.54dB
25-05-14 07:50:54.125 : --29--> parking_lot_111.jpg | 26.25dB
25-05-14 07:50:54.260 : --30--> railway_111.jpg | 27.07dB
25-05-14 07:50:54.395 : --31--> railway_station_111.jpg | 28.41dB
25-05-14 07:50:54.525 : --32--> rectangular_farmland_111.jpg | 30.23dB
25-05-14 07:50:54.653 : --33--> river_111.jpg | 26.98dB
25-05-14 07:50:54.779 : --34--> roundabout_111.jpg | 27.85dB
25-05-14 07:50:54.905 : --35--> runway_111.jpg | 33.88dB
25-05-14 07:50:55.032 : --36--> sea_ice_111.jpg | 30.75dB
25-05-14 07:50:55.159 : --37--> ship_111.jpg | 34.96dB
25-05-14 07:50:55.284 : --38--> snowberg_111.jpg | 29.17dB
25-05-14 07:50:55.410 : --39--> sparse_residential_111.jpg | 27.05dB
25-05-14 07:50:55.539 : --40--> stadium_111.jpg | 26.92dB
25-05-14 07:50:55.665 : --41--> storage_tank_111.jpg | 28.39dB
25-05-14 07:50:55.795 : --42--> tennis_court_111.jpg | 28.29dB
25-05-14 07:50:55.920 : --43--> terrace_111.jpg | 29.37dB
25-05-14 07:50:56.055 : --44--> thermal_power_station_111.jpg | 27.04dB
25-05-14 07:50:56.185 : --45--> wetland_111.jpg | 28.45dB
25-05-14 07:50:56.197 : <epoch:  3, iter: 100,000, Average PSNR : 28.94dB

25-05-14 08:56:45.145 : <epoch:  3, iter: 110,000, lr:2.500e-05> G_loss: 5.677e-05 
25-05-14 08:56:45.147 : Saving the model.
25-05-14 08:56:46.168 : ---1--> airplane_111.jpg | 29.39dB
25-05-14 08:56:46.292 : ---2--> airport_111.jpg | 30.08dB
25-05-14 08:56:46.416 : ---3--> baseball_diamond_111.jpg | 30.83dB
25-05-14 08:56:46.541 : ---4--> basketball_court_111.jpg | 28.15dB
25-05-14 08:56:46.665 : ---5--> beach_111.jpg | 27.57dB
25-05-14 08:56:46.789 : ---6--> bridge_111.jpg | 32.48dB
25-05-14 08:56:46.913 : ---7--> chaparral_111.jpg | 26.89dB
25-05-14 08:56:47.037 : ---8--> church_111.jpg | 28.25dB
25-05-14 08:56:47.163 : ---9--> circular_farmland_111.jpg | 30.69dB
25-05-14 08:56:47.290 : --10--> cloud_111.jpg | 34.36dB
25-05-14 08:56:47.414 : --11--> commercial_area_111.jpg | 29.73dB
25-05-14 08:56:47.538 : --12--> dense_residential_111.jpg | 26.05dB
25-05-14 08:56:47.663 : --13--> desert_111.jpg | 34.37dB
25-05-14 08:56:47.788 : --14--> forest_111.jpg | 29.49dB
25-05-14 08:56:47.913 : --15--> freeway_111.jpg | 32.10dB
25-05-14 08:56:48.039 : --16--> golf_course_111.jpg | 30.08dB
25-05-14 08:56:48.165 : --17--> ground_track_field_111.jpg | 27.26dB
25-05-14 08:56:48.290 : --18--> harbor_111.jpg | 28.81dB
25-05-14 08:56:48.417 : --19--> industrial_area_111.jpg | 28.47dB
25-05-14 08:56:48.543 : --20--> intersection_111.jpg | 27.26dB
25-05-14 08:56:48.669 : --21--> island_111.jpg | 29.03dB
25-05-14 08:56:48.798 : --22--> lake_111.jpg | 29.22dB
25-05-14 08:56:48.922 : --23--> meadow_111.jpg | 27.39dB
25-05-14 08:56:49.051 : --24--> medium_residential_111.jpg | 25.04dB
25-05-14 08:56:49.175 : --25--> mobile_home_park_111.jpg | 28.04dB
25-05-14 08:56:49.301 : --26--> mountain_111.jpg | 26.18dB
25-05-14 08:56:49.428 : --27--> overpass_111.jpg | 27.52dB
25-05-14 08:56:49.553 : --28--> palace_111.jpg | 26.52dB
25-05-14 08:56:49.679 : --29--> parking_lot_111.jpg | 26.24dB
25-05-14 08:56:49.805 : --30--> railway_111.jpg | 27.04dB
25-05-14 08:56:49.930 : --31--> railway_station_111.jpg | 28.41dB
25-05-14 08:56:50.056 : --32--> rectangular_farmland_111.jpg | 30.23dB
25-05-14 08:56:50.180 : --33--> river_111.jpg | 26.98dB
25-05-14 08:56:50.305 : --34--> roundabout_111.jpg | 27.84dB
25-05-14 08:56:50.430 : --35--> runway_111.jpg | 33.90dB
25-05-14 08:56:50.554 : --36--> sea_ice_111.jpg | 30.73dB
25-05-14 08:56:50.679 : --37--> ship_111.jpg | 34.98dB
25-05-14 08:56:50.803 : --38--> snowberg_111.jpg | 29.16dB
25-05-14 08:56:50.929 : --39--> sparse_residential_111.jpg | 27.07dB
25-05-14 08:56:51.054 : --40--> stadium_111.jpg | 26.92dB
25-05-14 08:56:51.179 : --41--> storage_tank_111.jpg | 28.39dB
25-05-14 08:56:51.304 : --42--> tennis_court_111.jpg | 28.31dB
25-05-14 08:56:51.429 : --43--> terrace_111.jpg | 29.38dB
25-05-14 08:56:51.553 : --44--> thermal_power_station_111.jpg | 27.04dB
25-05-14 08:56:51.678 : --45--> wetland_111.jpg | 28.46dB
25-05-14 08:56:51.685 : <epoch:  3, iter: 110,000, Average PSNR : 28.94dB

25-05-14 15:09:46.962 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/110000_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 10000
    checkpoint_save: 10000
    checkpoint_print: 10000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-14 15:09:46.963 : Random seed: 6995
25-05-14 15:09:47.396 : Number of train images: 31,005, iters: 31,005
25-05-14 15:09:49.504 : 
Networks name: DRNet
Params number: 3016467
Net structure:
DRNet(
  (conv_first): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): PSA_Group(
      (residual_group): BasicLayer(
        dim=96, input_resolution=(256, 256), depth=6
        (blocks): ModuleList(
          (0): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=0, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
          (1): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=4, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
          (2): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=0, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
          (3): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=4, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
          (4): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=0, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
          (5): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=4, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
        )
      )
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
      (before_PSA_Group_conv): emptyModule()
      (after_PSA_Group_conv): emptyModule()
      (after_PSA_Group_Residual): emptyModule()
    )
    (1-3): 3 x PSA_Group(
      (residual_group): BasicLayer(
        dim=96, input_resolution=(256, 256), depth=6
        (blocks): ModuleList(
          (0): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=0, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
          (1): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=4, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
          (2): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=0, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
          (3): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=4, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
          (4): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=0, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
          (5): PSA_Block(
            dim=96, input_resolution=(256, 256), num_heads=6, window_size=8, shift_size=4, mlp_ratio=4.0
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): PSA(
              dim=96, window_size=(4, 4), num_heads=6
              (kv): Linear(in_features=96, out_features=48, bias=True)
              (q): Linear(in_features=96, out_features=96, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): ConvFFN(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (before_add): emptyModule()
              (after_add): emptyModule()
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (after_norm1): emptyModule()
            (after_attention): emptyModule()
            (residual_after_attention): emptyModule()
            (after_norm2): emptyModule()
            (after_mlp): emptyModule()
            (residual_after_mlp): emptyModule()
          )
        )
      )
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
      (before_PSA_Group_conv): emptyModule()
      (after_PSA_Group_conv): emptyModule()
      (after_PSA_Group_Residual): emptyModule()
    )
  )
  (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_last): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-14 15:09:52.848 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.001 | -0.192 |  0.192 |  0.111 | torch.Size([96, 3, 3, 3]) || conv_first.weight
 |  0.007 | -0.191 |  0.189 |  0.105 | torch.Size([96]) || conv_first.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || patch_embed.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || patch_embed.norm.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.0.norm1.bias
 |  0.001 | -0.058 |  0.063 |  0.021 | torch.Size([49, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.0.residual_group.blocks.0.attn.aligned_relative_position_index
 |  0.001 | -0.070 |  0.069 |  0.020 | torch.Size([48, 96]) || layers.0.residual_group.blocks.0.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.0.residual_group.blocks.0.attn.kv.bias
 | -0.000 | -0.082 |  0.067 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.0.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.0.attn.q.bias
 |  0.000 | -0.077 |  0.076 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.081 |  0.078 |  0.020 | torch.Size([384, 96]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 | -0.000 | -0.200 |  0.200 |  0.116 | torch.Size([384, 1, 5, 5]) || layers.0.residual_group.blocks.0.mlp.dwconv.depthwise_conv.0.weight
 | -0.000 | -0.200 |  0.200 |  0.115 | torch.Size([384]) || layers.0.residual_group.blocks.0.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.082 |  0.072 |  0.020 | torch.Size([96, 384]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.1.norm1.bias
 |  0.000 | -0.050 |  0.060 |  0.019 | torch.Size([49, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.0.residual_group.blocks.1.attn.aligned_relative_position_index
 |  0.000 | -0.065 |  0.071 |  0.020 | torch.Size([48, 96]) || layers.0.residual_group.blocks.1.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.0.residual_group.blocks.1.attn.kv.bias
 | -0.000 | -0.078 |  0.085 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.1.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.1.attn.q.bias
 |  0.000 | -0.086 |  0.080 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.1.norm2.bias
 | -0.000 | -0.081 |  0.090 |  0.020 | torch.Size([384, 96]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 |  0.002 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.0.residual_group.blocks.1.mlp.dwconv.depthwise_conv.0.weight
 |  0.001 | -0.200 |  0.199 |  0.119 | torch.Size([384]) || layers.0.residual_group.blocks.1.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.092 |  0.091 |  0.020 | torch.Size([96, 384]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.2.norm1.bias
 |  0.001 | -0.066 |  0.057 |  0.021 | torch.Size([49, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.0.residual_group.blocks.2.attn.aligned_relative_position_index
 | -0.000 | -0.086 |  0.081 |  0.020 | torch.Size([48, 96]) || layers.0.residual_group.blocks.2.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.0.residual_group.blocks.2.attn.kv.bias
 |  0.000 | -0.073 |  0.092 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.2.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.2.attn.q.bias
 | -0.000 | -0.072 |  0.071 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.081 |  0.089 |  0.020 | torch.Size([384, 96]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 |  0.000 | -0.200 |  0.200 |  0.116 | torch.Size([384, 1, 5, 5]) || layers.0.residual_group.blocks.2.mlp.dwconv.depthwise_conv.0.weight
 | -0.003 | -0.196 |  0.195 |  0.119 | torch.Size([384]) || layers.0.residual_group.blocks.2.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.088 |  0.078 |  0.020 | torch.Size([96, 384]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.3.norm1.bias
 | -0.001 | -0.051 |  0.055 |  0.021 | torch.Size([49, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.0.residual_group.blocks.3.attn.aligned_relative_position_index
 |  0.000 | -0.099 |  0.065 |  0.020 | torch.Size([48, 96]) || layers.0.residual_group.blocks.3.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.0.residual_group.blocks.3.attn.kv.bias
 | -0.000 | -0.077 |  0.078 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.3.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.3.attn.q.bias
 |  0.000 | -0.068 |  0.070 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.3.norm2.bias
 | -0.000 | -0.078 |  0.106 |  0.020 | torch.Size([384, 96]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 |  0.000 | -0.200 |  0.200 |  0.116 | torch.Size([384, 1, 5, 5]) || layers.0.residual_group.blocks.3.mlp.dwconv.depthwise_conv.0.weight
 | -0.006 | -0.200 |  0.198 |  0.117 | torch.Size([384]) || layers.0.residual_group.blocks.3.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.077 |  0.090 |  0.020 | torch.Size([96, 384]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.4.norm1.bias
 |  0.001 | -0.060 |  0.060 |  0.020 | torch.Size([49, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.0.residual_group.blocks.4.attn.aligned_relative_position_index
 | -0.000 | -0.071 |  0.063 |  0.020 | torch.Size([48, 96]) || layers.0.residual_group.blocks.4.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.0.residual_group.blocks.4.attn.kv.bias
 | -0.000 | -0.081 |  0.077 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.4.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.4.attn.q.bias
 | -0.000 | -0.067 |  0.069 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.090 |  0.084 |  0.020 | torch.Size([384, 96]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 |  0.001 | -0.200 |  0.200 |  0.116 | torch.Size([384, 1, 5, 5]) || layers.0.residual_group.blocks.4.mlp.dwconv.depthwise_conv.0.weight
 | -0.002 | -0.200 |  0.198 |  0.114 | torch.Size([384]) || layers.0.residual_group.blocks.4.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.080 |  0.082 |  0.020 | torch.Size([96, 384]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.5.norm1.bias
 |  0.001 | -0.063 |  0.055 |  0.020 | torch.Size([49, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.0.residual_group.blocks.5.attn.aligned_relative_position_index
 | -0.000 | -0.071 |  0.077 |  0.020 | torch.Size([48, 96]) || layers.0.residual_group.blocks.5.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.0.residual_group.blocks.5.attn.kv.bias
 | -0.000 | -0.081 |  0.073 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.5.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.5.attn.q.bias
 | -0.000 | -0.079 |  0.074 |  0.020 | torch.Size([96, 96]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.085 |  0.093 |  0.020 | torch.Size([384, 96]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 | -0.000 | -0.200 |  0.200 |  0.116 | torch.Size([384, 1, 5, 5]) || layers.0.residual_group.blocks.5.mlp.dwconv.depthwise_conv.0.weight
 | -0.001 | -0.199 |  0.200 |  0.114 | torch.Size([384]) || layers.0.residual_group.blocks.5.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.080 |  0.091 |  0.020 | torch.Size([96, 384]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.034 |  0.034 |  0.020 | torch.Size([96, 96, 3, 3]) || layers.0.conv.weight
 |  0.004 | -0.034 |  0.034 |  0.019 | torch.Size([96]) || layers.0.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.0.norm1.bias
 |  0.001 | -0.046 |  0.053 |  0.020 | torch.Size([49, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.1.residual_group.blocks.0.attn.aligned_relative_position_index
 |  0.000 | -0.072 |  0.069 |  0.020 | torch.Size([48, 96]) || layers.1.residual_group.blocks.0.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.1.residual_group.blocks.0.attn.kv.bias
 |  0.000 | -0.078 |  0.075 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.0.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.0.attn.q.bias
 |  0.000 | -0.070 |  0.077 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.0.norm2.bias
 | -0.000 | -0.076 |  0.103 |  0.020 | torch.Size([384, 96]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 |  0.001 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.1.residual_group.blocks.0.mlp.dwconv.depthwise_conv.0.weight
 | -0.006 | -0.200 |  0.199 |  0.116 | torch.Size([384]) || layers.1.residual_group.blocks.0.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.075 |  0.079 |  0.020 | torch.Size([96, 384]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.1.norm1.bias
 | -0.001 | -0.057 |  0.068 |  0.021 | torch.Size([49, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.1.residual_group.blocks.1.attn.aligned_relative_position_index
 |  0.000 | -0.076 |  0.079 |  0.020 | torch.Size([48, 96]) || layers.1.residual_group.blocks.1.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.1.residual_group.blocks.1.attn.kv.bias
 | -0.000 | -0.077 |  0.074 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.1.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.1.attn.q.bias
 | -0.000 | -0.079 |  0.075 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.079 |  0.078 |  0.020 | torch.Size([384, 96]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 |  0.001 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.1.residual_group.blocks.1.mlp.dwconv.depthwise_conv.0.weight
 | -0.001 | -0.199 |  0.198 |  0.112 | torch.Size([384]) || layers.1.residual_group.blocks.1.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.084 |  0.079 |  0.020 | torch.Size([96, 384]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.2.norm1.bias
 |  0.001 | -0.054 |  0.066 |  0.020 | torch.Size([49, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.1.residual_group.blocks.2.attn.aligned_relative_position_index
 |  0.000 | -0.070 |  0.078 |  0.020 | torch.Size([48, 96]) || layers.1.residual_group.blocks.2.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.1.residual_group.blocks.2.attn.kv.bias
 |  0.000 | -0.073 |  0.082 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.2.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.2.attn.q.bias
 |  0.000 | -0.079 |  0.070 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.088 |  0.070 |  0.020 | torch.Size([384, 96]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 |  0.001 | -0.200 |  0.200 |  0.116 | torch.Size([384, 1, 5, 5]) || layers.1.residual_group.blocks.2.mlp.dwconv.depthwise_conv.0.weight
 | -0.012 | -0.199 |  0.200 |  0.121 | torch.Size([384]) || layers.1.residual_group.blocks.2.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.082 |  0.088 |  0.020 | torch.Size([96, 384]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.3.norm1.bias
 | -0.001 | -0.057 |  0.066 |  0.021 | torch.Size([49, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.1.residual_group.blocks.3.attn.aligned_relative_position_index
 |  0.000 | -0.075 |  0.067 |  0.020 | torch.Size([48, 96]) || layers.1.residual_group.blocks.3.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.1.residual_group.blocks.3.attn.kv.bias
 |  0.000 | -0.076 |  0.087 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.3.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.3.attn.q.bias
 |  0.001 | -0.085 |  0.072 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.3.norm2.bias
 | -0.000 | -0.086 |  0.087 |  0.020 | torch.Size([384, 96]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 | -0.000 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.1.residual_group.blocks.3.mlp.dwconv.depthwise_conv.0.weight
 | -0.002 | -0.200 |  0.200 |  0.118 | torch.Size([384]) || layers.1.residual_group.blocks.3.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.081 |  0.089 |  0.020 | torch.Size([96, 384]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.4.norm1.bias
 | -0.001 | -0.059 |  0.067 |  0.019 | torch.Size([49, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.1.residual_group.blocks.4.attn.aligned_relative_position_index
 |  0.000 | -0.064 |  0.069 |  0.020 | torch.Size([48, 96]) || layers.1.residual_group.blocks.4.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.1.residual_group.blocks.4.attn.kv.bias
 |  0.000 | -0.086 |  0.076 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.4.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.4.attn.q.bias
 | -0.000 | -0.085 |  0.078 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.094 |  0.083 |  0.020 | torch.Size([384, 96]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 |  0.001 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.1.residual_group.blocks.4.mlp.dwconv.depthwise_conv.0.weight
 | -0.000 | -0.200 |  0.199 |  0.115 | torch.Size([384]) || layers.1.residual_group.blocks.4.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.092 |  0.098 |  0.020 | torch.Size([96, 384]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.5.norm1.bias
 | -0.000 | -0.061 |  0.060 |  0.020 | torch.Size([49, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.1.residual_group.blocks.5.attn.aligned_relative_position_index
 |  0.001 | -0.064 |  0.073 |  0.020 | torch.Size([48, 96]) || layers.1.residual_group.blocks.5.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.1.residual_group.blocks.5.attn.kv.bias
 |  0.000 | -0.073 |  0.076 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.5.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.5.attn.q.bias
 | -0.000 | -0.072 |  0.079 |  0.020 | torch.Size([96, 96]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.083 |  0.092 |  0.020 | torch.Size([384, 96]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.000 | -0.200 |  0.200 |  0.116 | torch.Size([384, 1, 5, 5]) || layers.1.residual_group.blocks.5.mlp.dwconv.depthwise_conv.0.weight
 |  0.008 | -0.200 |  0.195 |  0.117 | torch.Size([384]) || layers.1.residual_group.blocks.5.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.093 |  0.079 |  0.020 | torch.Size([96, 384]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.034 |  0.034 |  0.020 | torch.Size([96, 96, 3, 3]) || layers.1.conv.weight
 | -0.001 | -0.034 |  0.033 |  0.019 | torch.Size([96]) || layers.1.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.0.norm1.bias
 |  0.001 | -0.052 |  0.069 |  0.019 | torch.Size([49, 6]) || layers.2.residual_group.blocks.0.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.2.residual_group.blocks.0.attn.aligned_relative_position_index
 | -0.000 | -0.073 |  0.075 |  0.020 | torch.Size([48, 96]) || layers.2.residual_group.blocks.0.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.2.residual_group.blocks.0.attn.kv.bias
 | -0.000 | -0.076 |  0.082 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.0.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.0.attn.q.bias
 |  0.000 | -0.079 |  0.076 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.0.norm2.bias
 | -0.000 | -0.093 |  0.075 |  0.020 | torch.Size([384, 96]) || layers.2.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.2.residual_group.blocks.0.mlp.fc1.bias
 |  0.002 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.2.residual_group.blocks.0.mlp.dwconv.depthwise_conv.0.weight
 |  0.002 | -0.200 |  0.200 |  0.119 | torch.Size([384]) || layers.2.residual_group.blocks.0.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.079 |  0.084 |  0.020 | torch.Size([96, 384]) || layers.2.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.0.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.2.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.1.norm1.bias
 |  0.001 | -0.046 |  0.057 |  0.021 | torch.Size([49, 6]) || layers.2.residual_group.blocks.1.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.2.residual_group.blocks.1.attn.aligned_relative_position_index
 |  0.000 | -0.068 |  0.071 |  0.020 | torch.Size([48, 96]) || layers.2.residual_group.blocks.1.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.2.residual_group.blocks.1.attn.kv.bias
 |  0.000 | -0.069 |  0.082 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.1.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.1.attn.q.bias
 |  0.000 | -0.081 |  0.074 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.085 |  0.077 |  0.020 | torch.Size([384, 96]) || layers.2.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.2.residual_group.blocks.1.mlp.fc1.bias
 | -0.000 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.2.residual_group.blocks.1.mlp.dwconv.depthwise_conv.0.weight
 |  0.002 | -0.199 |  0.198 |  0.115 | torch.Size([384]) || layers.2.residual_group.blocks.1.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.079 |  0.079 |  0.020 | torch.Size([96, 384]) || layers.2.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.2.norm1.bias
 |  0.001 | -0.055 |  0.069 |  0.021 | torch.Size([49, 6]) || layers.2.residual_group.blocks.2.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.2.residual_group.blocks.2.attn.aligned_relative_position_index
 | -0.000 | -0.074 |  0.081 |  0.020 | torch.Size([48, 96]) || layers.2.residual_group.blocks.2.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.2.residual_group.blocks.2.attn.kv.bias
 | -0.000 | -0.081 |  0.075 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.2.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.2.attn.q.bias
 | -0.001 | -0.076 |  0.068 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.2.norm2.bias
 |  0.000 | -0.084 |  0.078 |  0.020 | torch.Size([384, 96]) || layers.2.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.2.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.2.residual_group.blocks.2.mlp.dwconv.depthwise_conv.0.weight
 | -0.003 | -0.200 |  0.199 |  0.115 | torch.Size([384]) || layers.2.residual_group.blocks.2.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.079 |  0.084 |  0.020 | torch.Size([96, 384]) || layers.2.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.2.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.2.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.3.norm1.bias
 | -0.002 | -0.062 |  0.059 |  0.021 | torch.Size([49, 6]) || layers.2.residual_group.blocks.3.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.2.residual_group.blocks.3.attn.aligned_relative_position_index
 |  0.000 | -0.067 |  0.103 |  0.020 | torch.Size([48, 96]) || layers.2.residual_group.blocks.3.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.2.residual_group.blocks.3.attn.kv.bias
 |  0.000 | -0.068 |  0.081 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.3.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.3.attn.q.bias
 |  0.000 | -0.079 |  0.072 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.3.norm2.bias
 | -0.000 | -0.083 |  0.093 |  0.020 | torch.Size([384, 96]) || layers.2.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.2.residual_group.blocks.3.mlp.fc1.bias
 | -0.000 | -0.200 |  0.200 |  0.116 | torch.Size([384, 1, 5, 5]) || layers.2.residual_group.blocks.3.mlp.dwconv.depthwise_conv.0.weight
 |  0.008 | -0.198 |  0.200 |  0.114 | torch.Size([384]) || layers.2.residual_group.blocks.3.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.086 |  0.070 |  0.020 | torch.Size([96, 384]) || layers.2.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.4.norm1.bias
 |  0.000 | -0.060 |  0.061 |  0.019 | torch.Size([49, 6]) || layers.2.residual_group.blocks.4.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.2.residual_group.blocks.4.attn.aligned_relative_position_index
 |  0.000 | -0.064 |  0.061 |  0.020 | torch.Size([48, 96]) || layers.2.residual_group.blocks.4.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.2.residual_group.blocks.4.attn.kv.bias
 |  0.000 | -0.069 |  0.078 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.4.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.4.attn.q.bias
 |  0.000 | -0.077 |  0.084 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.084 |  0.086 |  0.020 | torch.Size([384, 96]) || layers.2.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.2.residual_group.blocks.4.mlp.fc1.bias
 | -0.001 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.2.residual_group.blocks.4.mlp.dwconv.depthwise_conv.0.weight
 |  0.003 | -0.198 |  0.199 |  0.116 | torch.Size([384]) || layers.2.residual_group.blocks.4.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.082 |  0.081 |  0.020 | torch.Size([96, 384]) || layers.2.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.4.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.2.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.5.norm1.bias
 | -0.000 | -0.049 |  0.064 |  0.019 | torch.Size([49, 6]) || layers.2.residual_group.blocks.5.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.2.residual_group.blocks.5.attn.aligned_relative_position_index
 |  0.001 | -0.063 |  0.069 |  0.020 | torch.Size([48, 96]) || layers.2.residual_group.blocks.5.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.2.residual_group.blocks.5.attn.kv.bias
 | -0.000 | -0.066 |  0.087 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.5.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.5.attn.q.bias
 |  0.000 | -0.077 |  0.089 |  0.020 | torch.Size([96, 96]) || layers.2.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.087 |  0.077 |  0.020 | torch.Size([384, 96]) || layers.2.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.2.residual_group.blocks.5.mlp.fc1.bias
 |  0.001 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.2.residual_group.blocks.5.mlp.dwconv.depthwise_conv.0.weight
 |  0.011 | -0.199 |  0.200 |  0.113 | torch.Size([384]) || layers.2.residual_group.blocks.5.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.092 |  0.084 |  0.020 | torch.Size([96, 384]) || layers.2.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.2.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.034 |  0.034 |  0.020 | torch.Size([96, 96, 3, 3]) || layers.2.conv.weight
 | -0.001 | -0.033 |  0.033 |  0.019 | torch.Size([96]) || layers.2.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.0.norm1.bias
 | -0.000 | -0.063 |  0.053 |  0.021 | torch.Size([49, 6]) || layers.3.residual_group.blocks.0.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.3.residual_group.blocks.0.attn.aligned_relative_position_index
 | -0.000 | -0.071 |  0.074 |  0.020 | torch.Size([48, 96]) || layers.3.residual_group.blocks.0.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.3.residual_group.blocks.0.attn.kv.bias
 | -0.000 | -0.069 |  0.076 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.0.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.0.attn.q.bias
 | -0.000 | -0.076 |  0.074 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.0.norm2.bias
 | -0.000 | -0.082 |  0.077 |  0.020 | torch.Size([384, 96]) || layers.3.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.3.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.3.residual_group.blocks.0.mlp.dwconv.depthwise_conv.0.weight
 | -0.002 | -0.200 |  0.199 |  0.118 | torch.Size([384]) || layers.3.residual_group.blocks.0.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.078 |  0.086 |  0.020 | torch.Size([96, 384]) || layers.3.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.0.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.3.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.1.norm1.bias
 | -0.000 | -0.059 |  0.045 |  0.019 | torch.Size([49, 6]) || layers.3.residual_group.blocks.1.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.3.residual_group.blocks.1.attn.aligned_relative_position_index
 |  0.001 | -0.078 |  0.071 |  0.020 | torch.Size([48, 96]) || layers.3.residual_group.blocks.1.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.3.residual_group.blocks.1.attn.kv.bias
 | -0.000 | -0.073 |  0.075 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.1.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.1.attn.q.bias
 | -0.000 | -0.079 |  0.072 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.086 |  0.083 |  0.020 | torch.Size([384, 96]) || layers.3.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.3.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.3.residual_group.blocks.1.mlp.dwconv.depthwise_conv.0.weight
 |  0.001 | -0.200 |  0.199 |  0.112 | torch.Size([384]) || layers.3.residual_group.blocks.1.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.086 |  0.079 |  0.020 | torch.Size([96, 384]) || layers.3.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.2.norm1.bias
 | -0.001 | -0.048 |  0.074 |  0.019 | torch.Size([49, 6]) || layers.3.residual_group.blocks.2.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.3.residual_group.blocks.2.attn.aligned_relative_position_index
 | -0.000 | -0.066 |  0.073 |  0.020 | torch.Size([48, 96]) || layers.3.residual_group.blocks.2.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.3.residual_group.blocks.2.attn.kv.bias
 |  0.000 | -0.083 |  0.077 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.2.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.2.attn.q.bias
 | -0.000 | -0.087 |  0.070 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.2.norm2.bias
 |  0.000 | -0.087 |  0.081 |  0.020 | torch.Size([384, 96]) || layers.3.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.3.residual_group.blocks.2.mlp.fc1.bias
 | -0.001 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.3.residual_group.blocks.2.mlp.dwconv.depthwise_conv.0.weight
 |  0.000 | -0.199 |  0.199 |  0.118 | torch.Size([384]) || layers.3.residual_group.blocks.2.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.086 |  0.083 |  0.020 | torch.Size([96, 384]) || layers.3.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.2.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.3.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.3.norm1.bias
 | -0.001 | -0.052 |  0.052 |  0.020 | torch.Size([49, 6]) || layers.3.residual_group.blocks.3.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.3.residual_group.blocks.3.attn.aligned_relative_position_index
 | -0.000 | -0.081 |  0.075 |  0.020 | torch.Size([48, 96]) || layers.3.residual_group.blocks.3.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.3.residual_group.blocks.3.attn.kv.bias
 | -0.000 | -0.079 |  0.091 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.3.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.3.attn.q.bias
 |  0.000 | -0.082 |  0.078 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.3.norm2.bias
 | -0.000 | -0.088 |  0.081 |  0.020 | torch.Size([384, 96]) || layers.3.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.3.residual_group.blocks.3.mlp.fc1.bias
 |  0.000 | -0.200 |  0.200 |  0.115 | torch.Size([384, 1, 5, 5]) || layers.3.residual_group.blocks.3.mlp.dwconv.depthwise_conv.0.weight
 |  0.008 | -0.198 |  0.199 |  0.116 | torch.Size([384]) || layers.3.residual_group.blocks.3.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.079 |  0.079 |  0.020 | torch.Size([96, 384]) || layers.3.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.4.norm1.bias
 |  0.000 | -0.053 |  0.048 |  0.020 | torch.Size([49, 6]) || layers.3.residual_group.blocks.4.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.3.residual_group.blocks.4.attn.aligned_relative_position_index
 | -0.000 | -0.064 |  0.067 |  0.020 | torch.Size([48, 96]) || layers.3.residual_group.blocks.4.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.3.residual_group.blocks.4.attn.kv.bias
 |  0.000 | -0.087 |  0.103 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.4.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.4.attn.q.bias
 |  0.000 | -0.083 |  0.067 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.075 |  0.086 |  0.020 | torch.Size([384, 96]) || layers.3.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.3.residual_group.blocks.4.mlp.fc1.bias
 | -0.002 | -0.200 |  0.200 |  0.116 | torch.Size([384, 1, 5, 5]) || layers.3.residual_group.blocks.4.mlp.dwconv.depthwise_conv.0.weight
 |  0.006 | -0.200 |  0.199 |  0.115 | torch.Size([384]) || layers.3.residual_group.blocks.4.mlp.dwconv.depthwise_conv.0.bias
 |  0.000 | -0.095 |  0.086 |  0.020 | torch.Size([96, 384]) || layers.3.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.4.mlp.fc2.bias
 | -3.101 | -100.000 |  0.000 | 17.333 | torch.Size([1024, 64, 16]) || layers.3.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.5.norm1.bias
 | -0.002 | -0.061 |  0.060 |  0.020 | torch.Size([49, 6]) || layers.3.residual_group.blocks.5.attn.relative_position_bias_table
 | 24.000 |  0.000 | 48.000 | 11.186 | torch.Size([64, 16]) || layers.3.residual_group.blocks.5.attn.aligned_relative_position_index
 | -0.000 | -0.076 |  0.075 |  0.020 | torch.Size([48, 96]) || layers.3.residual_group.blocks.5.attn.kv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([48]) || layers.3.residual_group.blocks.5.attn.kv.bias
 |  0.000 | -0.072 |  0.084 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.5.attn.q.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.5.attn.q.bias
 | -0.000 | -0.072 |  0.076 |  0.020 | torch.Size([96, 96]) || layers.3.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.5.norm2.bias
 |  0.000 | -0.097 |  0.093 |  0.020 | torch.Size([384, 96]) || layers.3.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([384]) || layers.3.residual_group.blocks.5.mlp.fc1.bias
 | -0.000 | -0.200 |  0.200 |  0.117 | torch.Size([384, 1, 5, 5]) || layers.3.residual_group.blocks.5.mlp.dwconv.depthwise_conv.0.weight
 |  0.000 | -0.196 |  0.200 |  0.115 | torch.Size([384]) || layers.3.residual_group.blocks.5.mlp.dwconv.depthwise_conv.0.bias
 | -0.000 | -0.091 |  0.092 |  0.020 | torch.Size([96, 384]) || layers.3.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || layers.3.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.034 |  0.034 |  0.020 | torch.Size([96, 96, 3, 3]) || layers.3.conv.weight
 |  0.002 | -0.034 |  0.033 |  0.019 | torch.Size([96]) || layers.3.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([96]) || norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([96]) || norm.bias
 | -0.000 | -0.034 |  0.034 |  0.020 | torch.Size([96, 96, 3, 3]) || conv_after_body.weight
 |  0.000 | -0.033 |  0.034 |  0.021 | torch.Size([96]) || conv_after_body.bias
 |  0.001 | -0.034 |  0.034 |  0.020 | torch.Size([3, 96, 3, 3]) || conv_last.weight
 |  0.004 | -0.033 |  0.032 |  0.033 | torch.Size([3]) || conv_last.bias

25-05-14 18:45:31.379 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/10_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/RICE1
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 25
      sigma_test: 25
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 25
      sigma_test: 25
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 2e-05
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-14 18:45:31.380 : Random seed: 3666
25-05-14 18:45:31.400 : Number of train images: 385, iters: 385
25-05-14 18:45:33.080 : 
Networks name: DRNet
Params number: 18333721
Net structure:
DRNet(
  (m_head): Sequential(
    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (m_down1): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down2): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down3): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_body): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up3): Sequential(
    (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up2): Sequential(
    (0): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up1): Sequential(
    (0): ConvTranspose2d(192, 96, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_tail): Sequential(
    (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (fft): ResBlock_fft_bench(
    (mag): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
    (mag_bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (mag_relu): ReLU(inplace=True)
    (pha): Sequential(
      (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (4): Sigmoid()
    )
    (conv1): Conv2d(6, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
  (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (conv2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
  (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu2): ReLU()
  (conv3): Conv2d(96, 384, kernel_size=(4, 4), stride=(4, 4))
  (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu3): ReLU()
)

25-05-14 18:45:33.715 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.001 | -0.166 |  0.188 |  0.042 | torch.Size([96, 3, 3, 3]) || m_head.0.weight
 |  1.000 |  0.690 |  1.333 |  0.155 | torch.Size([32]) || m_down1.0.trans_block.ln1.weight
 | -0.026 | -0.272 |  0.279 |  0.131 | torch.Size([32]) || m_down1.0.trans_block.ln1.bias
 | -0.078 | -0.695 |  1.039 |  0.371 | torch.Size([1, 15, 15]) || m_down1.0.trans_block.msa.relative_position_params
 |  0.000 | -0.284 |  0.324 |  0.060 | torch.Size([96, 32, 1, 1]) || m_down1.0.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.110 |  0.107 |  0.047 | torch.Size([96]) || m_down1.0.trans_block.msa.embedding_layer1.bias
 |  0.002 | -0.174 |  0.223 |  0.053 | torch.Size([32, 32, 1, 1]) || m_down1.0.trans_block.msa.linear1.weight
 |  0.005 | -0.078 |  0.114 |  0.051 | torch.Size([32]) || m_down1.0.trans_block.msa.linear1.bias
 |  1.186 |  1.012 |  1.426 |  0.113 | torch.Size([32]) || m_down1.0.trans_block.ln2.weight
 | -0.010 | -0.165 |  0.135 |  0.059 | torch.Size([32]) || m_down1.0.trans_block.ln2.bias
 |  0.005 | -0.586 |  1.295 |  0.114 | torch.Size([128, 32]) || m_down1.0.trans_block.mlp.0.weight
 | -0.023 | -0.187 |  0.150 |  0.069 | torch.Size([128]) || m_down1.0.trans_block.mlp.0.bias
 |  0.000 | -0.460 |  0.717 |  0.086 | torch.Size([32, 128]) || m_down1.0.trans_block.mlp.2.weight
 | -0.004 | -0.113 |  0.275 |  0.090 | torch.Size([32]) || m_down1.0.trans_block.mlp.2.bias
 |  0.006 | -0.481 |  0.460 |  0.094 | torch.Size([96, 96, 1, 1]) || m_down1.0.conv1_1.weight
 | -0.003 | -0.432 |  0.406 |  0.110 | torch.Size([96]) || m_down1.0.conv1_1.bias
 | -0.092 | -0.180 |  0.001 |  0.090 | torch.Size([1, 1, 1, 1, 3]) || m_down1.0.conv3d.weight
 | -0.024 | -0.024 | -0.024 |    nan | torch.Size([1]) || m_down1.0.conv3d.bias
 |  0.006 | -0.337 |  0.475 |  0.073 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.0.weight
 | -0.004 | -0.470 |  0.358 |  0.072 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.2.weight
 |  1.906 | -2.333 |  2.825 |  0.813 | torch.Size([64, 16]) || m_down1.0.mamba_layers.0.mixer.A_log
 |  1.081 |  0.345 |  1.364 |  0.174 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.D
 | -0.000 | -0.468 |  0.530 |  0.121 | torch.Size([128, 32]) || m_down1.0.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.436 |  0.458 |  0.166 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.0.mixer.conv1d.weight
 | -0.011 | -0.234 |  0.181 |  0.088 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.889 |  0.703 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.0.mixer.x_proj.weight
 |  0.005 | -0.791 |  0.938 |  0.248 | torch.Size([64, 2]) || m_down1.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.077 | -1.579 |  0.442 |  0.373 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.629 |  0.546 |  0.115 | torch.Size([32, 64]) || m_down1.0.mamba_layers.0.mixer.out_proj.weight
 |  1.133 |  0.910 |  1.650 |  0.129 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.weight
 |  0.013 | -0.367 |  0.299 |  0.157 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.bias
 |  1.905 | -0.797 |  2.773 |  0.795 | torch.Size([64, 16]) || m_down1.0.mamba_layers.1.mixer.A_log
 |  1.161 |  0.905 |  1.359 |  0.086 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.D
 |  0.001 | -0.586 |  0.458 |  0.127 | torch.Size([128, 32]) || m_down1.0.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.365 |  0.485 |  0.156 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.1.mixer.conv1d.weight
 | -0.004 | -0.303 |  0.279 |  0.165 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.563 |  0.743 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.1.mixer.x_proj.weight
 |  0.013 | -0.312 |  0.472 |  0.146 | torch.Size([64, 2]) || m_down1.0.mamba_layers.1.mixer.dt_proj.weight
 |  0.052 | -0.313 |  0.269 |  0.122 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.003 | -0.367 |  0.425 |  0.118 | torch.Size([32, 64]) || m_down1.0.mamba_layers.1.mixer.out_proj.weight
 |  1.170 |  0.994 |  1.344 |  0.097 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.weight
 | -0.005 | -0.256 |  0.350 |  0.138 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.bias
 |  1.917 | -0.070 |  2.775 |  0.765 | torch.Size([64, 16]) || m_down1.0.mamba_layers.2.mixer.A_log
 |  1.018 |  0.941 |  1.120 |  0.038 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.D
 |  0.000 | -0.340 |  0.349 |  0.107 | torch.Size([128, 32]) || m_down1.0.mamba_layers.2.mixer.in_proj.weight
 | -0.012 | -0.582 |  0.568 |  0.294 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.2.mixer.conv1d.weight
 | -0.031 | -0.499 |  0.487 |  0.284 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.219 |  0.189 |  0.076 | torch.Size([34, 64]) || m_down1.0.mamba_layers.2.mixer.x_proj.weight
 | -0.055 | -0.705 |  0.714 |  0.417 | torch.Size([64, 2]) || m_down1.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.715 | -6.856 | -2.311 |  1.285 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.dt_proj.bias
 | -0.003 | -0.242 |  0.287 |  0.083 | torch.Size([32, 64]) || m_down1.0.mamba_layers.2.mixer.out_proj.weight
 |  1.005 |  0.927 |  1.096 |  0.037 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.weight
 |  0.006 | -0.039 |  0.061 |  0.023 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.bias
 |  1.916 | -0.244 |  2.776 |  0.766 | torch.Size([64, 16]) || m_down1.0.mamba_layers.3.mixer.A_log
 |  1.011 |  0.942 |  1.097 |  0.034 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.D
 |  0.003 | -0.276 |  0.271 |  0.106 | torch.Size([128, 32]) || m_down1.0.mamba_layers.3.mixer.in_proj.weight
 |  0.004 | -0.596 |  0.566 |  0.297 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.3.mixer.conv1d.weight
 | -0.071 | -0.626 |  0.545 |  0.307 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.201 |  0.214 |  0.076 | torch.Size([34, 64]) || m_down1.0.mamba_layers.3.mixer.x_proj.weight
 |  0.039 | -0.688 |  0.780 |  0.425 | torch.Size([64, 2]) || m_down1.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.400 | -7.091 | -2.271 |  1.482 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.241 |  0.288 |  0.083 | torch.Size([32, 64]) || m_down1.0.mamba_layers.3.mixer.out_proj.weight
 |  1.000 |  0.945 |  1.041 |  0.024 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.weight
 | -0.003 | -0.041 |  0.032 |  0.020 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.bias
 |  0.172 |  0.084 |  0.261 |  0.125 | torch.Size([2]) || m_down1.0.pcbam_module.h_cw.weight
 |  0.094 | -0.058 |  0.226 |  0.143 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.h_cw.conv.weight
 |  0.559 |  0.261 |  0.856 |  0.421 | torch.Size([2]) || m_down1.0.pcbam_module.w_hc.weight
 |  0.076 | -0.096 |  0.188 |  0.151 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.w_hc.conv.weight
 |  0.612 |  0.582 |  0.641 |  0.042 | torch.Size([2]) || m_down1.0.pcbam_module.c_hw.weight
 |  0.040 | -0.233 |  0.379 |  0.311 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.c_hw.conv.weight
 |  1.055 |  0.769 |  1.285 |  0.145 | torch.Size([32]) || m_down1.1.trans_block.ln1.weight
 |  0.019 | -0.283 |  0.280 |  0.134 | torch.Size([32]) || m_down1.1.trans_block.ln1.bias
 | -0.225 | -0.784 |  0.824 |  0.322 | torch.Size([1, 15, 15]) || m_down1.1.trans_block.msa.relative_position_params
 |  0.001 | -0.380 |  0.366 |  0.088 | torch.Size([96, 32, 1, 1]) || m_down1.1.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.193 |  0.185 |  0.052 | torch.Size([96]) || m_down1.1.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.196 |  0.207 |  0.053 | torch.Size([32, 32, 1, 1]) || m_down1.1.trans_block.msa.linear1.weight
 |  0.000 | -0.139 |  0.101 |  0.048 | torch.Size([32]) || m_down1.1.trans_block.msa.linear1.bias
 |  1.164 |  0.991 |  1.293 |  0.073 | torch.Size([32]) || m_down1.1.trans_block.ln2.weight
 | -0.000 | -0.123 |  0.174 |  0.067 | torch.Size([32]) || m_down1.1.trans_block.ln2.bias
 | -0.001 | -0.905 |  0.562 |  0.114 | torch.Size([128, 32]) || m_down1.1.trans_block.mlp.0.weight
 | -0.011 | -0.235 |  0.116 |  0.054 | torch.Size([128]) || m_down1.1.trans_block.mlp.0.bias
 | -0.000 | -0.661 |  0.622 |  0.099 | torch.Size([32, 128]) || m_down1.1.trans_block.mlp.2.weight
 | -0.009 | -0.120 |  0.228 |  0.080 | torch.Size([32]) || m_down1.1.trans_block.mlp.2.bias
 |  0.006 | -0.455 |  0.573 |  0.096 | torch.Size([96, 96, 1, 1]) || m_down1.1.conv1_1.weight
 | -0.008 | -0.200 |  0.272 |  0.064 | torch.Size([96]) || m_down1.1.conv1_1.bias
 | -0.077 | -0.289 |  0.036 |  0.183 | torch.Size([1, 1, 1, 1, 3]) || m_down1.1.conv3d.weight
 | -0.012 | -0.012 | -0.012 |    nan | torch.Size([1]) || m_down1.1.conv3d.bias
 | -0.002 | -0.406 |  0.342 |  0.064 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.0.weight
 | -0.006 | -0.314 |  0.292 |  0.064 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.2.weight
 |  1.917 | -0.011 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.0.mixer.A_log
 |  1.048 |  0.985 |  1.166 |  0.047 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.D
 | -0.000 | -0.443 |  0.430 |  0.086 | torch.Size([128, 32]) || m_down1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.015 | -0.304 |  0.314 |  0.114 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.0.mixer.conv1d.weight
 |  0.015 | -0.205 |  0.208 |  0.064 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.142 |  0.135 |  0.031 | torch.Size([34, 64]) || m_down1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.002 | -0.062 |  0.053 |  0.025 | torch.Size([64, 2]) || m_down1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.001 | -0.024 |  0.032 |  0.009 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.369 |  0.356 |  0.083 | torch.Size([32, 64]) || m_down1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.113 |  0.927 |  1.290 |  0.105 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.weight
 |  0.012 | -0.156 |  0.187 |  0.076 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.bias
 |  1.918 | -0.212 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.1.mixer.A_log
 |  1.091 |  0.987 |  1.491 |  0.090 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.D
 |  0.000 | -0.626 |  0.634 |  0.094 | torch.Size([128, 32]) || m_down1.1.mamba_layers.1.mixer.in_proj.weight
 |  0.001 | -0.329 |  0.372 |  0.124 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.196 |  0.186 |  0.088 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.001 | -0.183 |  0.294 |  0.048 | torch.Size([34, 64]) || m_down1.1.mamba_layers.1.mixer.x_proj.weight
 |  0.006 | -0.151 |  0.153 |  0.037 | torch.Size([64, 2]) || m_down1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.008 | -0.160 |  0.449 |  0.077 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.004 | -0.548 |  0.372 |  0.087 | torch.Size([32, 64]) || m_down1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.134 |  1.020 |  1.298 |  0.072 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.weight
 | -0.002 | -0.096 |  0.087 |  0.053 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.bias
 |  1.917 | -0.016 |  2.774 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.2.mixer.A_log
 |  1.000 |  0.959 |  1.044 |  0.021 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.D
 | -0.001 | -0.232 |  0.277 |  0.106 | torch.Size([128, 32]) || m_down1.1.mamba_layers.2.mixer.in_proj.weight
 | -0.024 | -0.515 |  0.512 |  0.285 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.2.mixer.conv1d.weight
 | -0.017 | -0.508 |  0.448 |  0.282 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.151 |  0.153 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.2.mixer.x_proj.weight
 |  0.092 | -0.700 |  0.704 |  0.396 | torch.Size([64, 2]) || m_down1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.418 | -6.864 | -2.343 |  1.239 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.223 |  0.208 |  0.075 | torch.Size([32, 64]) || m_down1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.000 |  0.965 |  1.039 |  0.021 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.weight
 |  0.002 | -0.037 |  0.031 |  0.016 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.bias
 |  1.917 | -0.041 |  2.777 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.3.mixer.A_log
 |  1.006 |  0.963 |  1.083 |  0.027 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.296 |  0.355 |  0.109 | torch.Size([128, 32]) || m_down1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.023 | -0.521 |  0.538 |  0.299 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.3.mixer.conv1d.weight
 |  0.047 | -0.418 |  0.512 |  0.241 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.156 |  0.181 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.694 |  0.699 |  0.380 | torch.Size([64, 2]) || m_down1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.585 | -6.892 | -2.263 |  1.350 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.001 | -0.238 |  0.246 |  0.078 | torch.Size([32, 64]) || m_down1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.025 |  0.962 |  1.116 |  0.037 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.weight
 | -0.001 | -0.048 |  0.055 |  0.028 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.bias
 |  0.133 |  0.115 |  0.151 |  0.025 | torch.Size([2]) || m_down1.1.pcbam_module.h_cw.weight
 |  0.159 |  0.056 |  0.311 |  0.134 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.h_cw.conv.weight
 |  0.356 |  0.181 |  0.530 |  0.247 | torch.Size([2]) || m_down1.1.pcbam_module.w_hc.weight
 |  0.196 |  0.121 |  0.253 |  0.068 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.w_hc.conv.weight
 |  0.723 |  0.569 |  0.877 |  0.218 | torch.Size([2]) || m_down1.1.pcbam_module.c_hw.weight
 | -0.098 | -0.318 |  0.113 |  0.215 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.322 |  0.291 |  0.051 | torch.Size([192, 96, 2, 2]) || m_down1.2.weight
 |  1.094 |  0.726 |  1.718 |  0.242 | torch.Size([64]) || m_down2.0.trans_block.ln1.weight
 | -0.005 | -0.464 |  0.477 |  0.219 | torch.Size([64]) || m_down2.0.trans_block.ln1.bias
 | -0.205 | -1.957 |  1.787 |  0.695 | torch.Size([2, 15, 15]) || m_down2.0.trans_block.msa.relative_position_params
 |  0.000 | -0.432 |  0.426 |  0.075 | torch.Size([192, 64, 1, 1]) || m_down2.0.trans_block.msa.embedding_layer1.weight
 | -0.005 | -0.203 |  0.184 |  0.046 | torch.Size([192]) || m_down2.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.243 |  0.233 |  0.051 | torch.Size([64, 64, 1, 1]) || m_down2.0.trans_block.msa.linear1.weight
 |  0.002 | -0.116 |  0.184 |  0.043 | torch.Size([64]) || m_down2.0.trans_block.msa.linear1.bias
 |  1.134 |  0.800 |  1.470 |  0.135 | torch.Size([64]) || m_down2.0.trans_block.ln2.weight
 |  0.008 | -0.138 |  0.250 |  0.071 | torch.Size([64]) || m_down2.0.trans_block.ln2.bias
 |  0.002 | -0.502 |  0.472 |  0.094 | torch.Size([256, 64]) || m_down2.0.trans_block.mlp.0.weight
 | -0.047 | -0.278 |  0.063 |  0.048 | torch.Size([256]) || m_down2.0.trans_block.mlp.0.bias
 |  0.001 | -0.387 |  0.367 |  0.072 | torch.Size([64, 256]) || m_down2.0.trans_block.mlp.2.weight
 |  0.022 | -0.105 |  0.114 |  0.048 | torch.Size([64]) || m_down2.0.trans_block.mlp.2.bias
 |  0.008 | -0.714 |  0.843 |  0.097 | torch.Size([192, 192, 1, 1]) || m_down2.0.conv1_1.weight
 |  0.003 | -0.553 |  0.627 |  0.115 | torch.Size([192]) || m_down2.0.conv1_1.bias
 | -0.075 | -0.231 |  0.012 |  0.135 | torch.Size([1, 1, 1, 1, 3]) || m_down2.0.conv3d.weight
 | -0.010 | -0.010 | -0.010 |    nan | torch.Size([1]) || m_down2.0.conv3d.bias
 |  0.001 | -0.403 |  0.407 |  0.059 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.0.weight
 | -0.000 | -0.270 |  0.382 |  0.060 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.0.mamba_layers.0.mixer.A_log
 |  1.008 |  0.996 |  1.123 |  0.022 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.D
 | -0.000 | -0.279 |  0.257 |  0.032 | torch.Size([256, 64]) || m_down2.0.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.288 |  0.301 |  0.062 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.138 |  0.069 |  0.025 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.062 |  0.058 |  0.018 | torch.Size([36, 128]) || m_down2.0.mamba_layers.0.mixer.x_proj.weight
 |  0.001 | -0.049 |  0.055 |  0.018 | torch.Size([128, 4]) || m_down2.0.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.001 |  0.001 |  0.000 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.224 |  0.271 |  0.033 | torch.Size([64, 128]) || m_down2.0.mamba_layers.0.mixer.out_proj.weight
 |  1.038 |  0.896 |  1.214 |  0.080 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.weight
 |  0.003 | -0.141 |  0.146 |  0.071 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.bias
 |  1.916 | -0.326 |  2.773 |  0.767 | torch.Size([128, 16]) || m_down2.0.mamba_layers.1.mixer.A_log
 |  1.033 |  0.993 |  1.252 |  0.053 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.D
 | -0.000 | -0.330 |  0.352 |  0.050 | torch.Size([256, 64]) || m_down2.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.333 |  0.428 |  0.092 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.1.mixer.conv1d.weight
 |  0.017 | -0.173 |  0.316 |  0.071 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.245 |  0.181 |  0.034 | torch.Size([36, 128]) || m_down2.0.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.093 |  0.087 |  0.021 | torch.Size([128, 4]) || m_down2.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.010 | -0.302 |  0.159 |  0.052 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.346 |  0.348 |  0.052 | torch.Size([64, 128]) || m_down2.0.mamba_layers.1.mixer.out_proj.weight
 |  1.053 |  0.926 |  1.208 |  0.072 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.weight
 |  0.002 | -0.248 |  0.239 |  0.129 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.bias
 |  1.917 | -0.026 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.2.mixer.A_log
 |  0.986 |  0.946 |  1.030 |  0.019 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.D
 |  0.000 | -0.205 |  0.194 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.2.mixer.in_proj.weight
 | -0.003 | -0.515 |  0.512 |  0.273 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.2.mixer.conv1d.weight
 | -0.026 | -0.511 |  0.497 |  0.296 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.130 |  0.212 |  0.052 | torch.Size([36, 128]) || m_down2.0.mamba_layers.2.mixer.x_proj.weight
 |  0.014 | -0.500 |  0.501 |  0.292 | torch.Size([128, 4]) || m_down2.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.641 | -6.908 | -2.258 |  1.372 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.205 |  0.194 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.2.mixer.out_proj.weight
 |  0.970 |  0.895 |  1.032 |  0.030 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.weight
 |  0.002 | -0.087 |  0.060 |  0.028 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.bias
 |  1.917 | -0.019 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.3.mixer.A_log
 |  0.989 |  0.936 |  1.054 |  0.017 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.D
 |  0.001 | -0.194 |  0.185 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.3.mixer.in_proj.weight
 | -0.001 | -0.548 |  0.520 |  0.274 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.486 |  0.485 |  0.289 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.199 |  0.242 |  0.053 | torch.Size([36, 128]) || m_down2.0.mamba_layers.3.mixer.x_proj.weight
 |  0.011 | -0.496 |  0.500 |  0.303 | torch.Size([128, 4]) || m_down2.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.465 | -6.853 | -2.276 |  1.292 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.187 |  0.229 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.3.mixer.out_proj.weight
 |  0.976 |  0.929 |  1.036 |  0.024 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.weight
 | -0.002 | -0.041 |  0.063 |  0.022 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.bias
 |  0.628 |  0.129 |  1.127 |  0.706 | torch.Size([2]) || m_down2.0.pcbam_module.h_cw.weight
 |  0.096 | -0.115 |  0.409 |  0.277 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.h_cw.conv.weight
 |  0.672 |  0.597 |  0.747 |  0.106 | torch.Size([2]) || m_down2.0.pcbam_module.w_hc.weight
 |  0.041 | -0.109 |  0.315 |  0.238 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.w_hc.conv.weight
 |  0.594 |  0.347 |  0.840 |  0.349 | torch.Size([2]) || m_down2.0.pcbam_module.c_hw.weight
 | -0.017 | -0.083 |  0.061 |  0.073 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.c_hw.conv.weight
 |  1.163 |  0.867 |  1.732 |  0.226 | torch.Size([64]) || m_down2.1.trans_block.ln1.weight
 |  0.012 | -0.364 |  0.465 |  0.164 | torch.Size([64]) || m_down2.1.trans_block.ln1.bias
 | -0.006 | -1.165 |  0.641 |  0.241 | torch.Size([2, 15, 15]) || m_down2.1.trans_block.msa.relative_position_params
 | -0.000 | -0.375 |  0.429 |  0.082 | torch.Size([192, 64, 1, 1]) || m_down2.1.trans_block.msa.embedding_layer1.weight
 | -0.003 | -0.287 |  0.230 |  0.062 | torch.Size([192]) || m_down2.1.trans_block.msa.embedding_layer1.bias
 |  0.001 | -0.174 |  0.169 |  0.045 | torch.Size([64, 64, 1, 1]) || m_down2.1.trans_block.msa.linear1.weight
 | -0.000 | -0.118 |  0.181 |  0.045 | torch.Size([64]) || m_down2.1.trans_block.msa.linear1.bias
 |  1.050 |  0.735 |  1.351 |  0.145 | torch.Size([64]) || m_down2.1.trans_block.ln2.weight
 |  0.004 | -0.187 |  0.243 |  0.100 | torch.Size([64]) || m_down2.1.trans_block.ln2.bias
 | -0.000 | -0.474 |  0.472 |  0.076 | torch.Size([256, 64]) || m_down2.1.trans_block.mlp.0.weight
 | -0.040 | -0.315 |  0.072 |  0.057 | torch.Size([256]) || m_down2.1.trans_block.mlp.0.bias
 | -0.000 | -0.415 |  0.464 |  0.053 | torch.Size([64, 256]) || m_down2.1.trans_block.mlp.2.weight
 |  0.000 | -0.071 |  0.066 |  0.032 | torch.Size([64]) || m_down2.1.trans_block.mlp.2.bias
 | -0.008 | -1.075 |  0.517 |  0.102 | torch.Size([192, 192, 1, 1]) || m_down2.1.conv1_1.weight
 |  0.001 | -0.346 |  0.336 |  0.087 | torch.Size([192]) || m_down2.1.conv1_1.bias
 |  0.084 | -0.019 |  0.274 |  0.165 | torch.Size([1, 1, 1, 1, 3]) || m_down2.1.conv3d.weight
 | -0.003 | -0.003 | -0.003 |    nan | torch.Size([1]) || m_down2.1.conv3d.bias
 | -0.003 | -0.386 |  0.295 |  0.058 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.0.weight
 |  0.001 | -0.299 |  0.306 |  0.057 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.2.weight
 |  1.917 | -0.006 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.0.mixer.A_log
 |  1.022 |  0.995 |  1.229 |  0.039 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.D
 |  0.000 | -0.262 |  0.250 |  0.039 | torch.Size([256, 64]) || m_down2.1.mamba_layers.0.mixer.in_proj.weight
 | -0.002 | -0.408 |  0.287 |  0.073 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.001 | -0.080 |  0.116 |  0.028 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.169 |  0.167 |  0.024 | torch.Size([36, 128]) || m_down2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.049 |  0.052 |  0.018 | torch.Size([128, 4]) || m_down2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.066 |  0.079 |  0.016 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.275 |  0.271 |  0.042 | torch.Size([64, 128]) || m_down2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.027 |  0.861 |  1.223 |  0.072 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.weight
 |  0.001 | -0.164 |  0.200 |  0.093 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.bias
 |  1.917 | -0.249 |  2.773 |  0.765 | torch.Size([128, 16]) || m_down2.1.mamba_layers.1.mixer.A_log
 |  1.038 |  0.996 |  1.246 |  0.065 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.D
 | -0.000 | -0.421 |  0.421 |  0.051 | torch.Size([256, 64]) || m_down2.1.mamba_layers.1.mixer.in_proj.weight
 |  0.004 | -0.332 |  0.368 |  0.094 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.009 | -0.132 |  0.248 |  0.046 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.257 |  0.268 |  0.037 | torch.Size([36, 128]) || m_down2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.255 |  0.251 |  0.029 | torch.Size([128, 4]) || m_down2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.002 | -0.301 |  0.161 |  0.044 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.384 |  0.375 |  0.052 | torch.Size([64, 128]) || m_down2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.056 |  0.955 |  1.390 |  0.090 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.weight
 | -0.007 | -0.214 |  0.198 |  0.125 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.027 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.2.mixer.A_log
 |  0.991 |  0.947 |  1.079 |  0.022 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.D
 | -0.001 | -0.227 |  0.203 |  0.076 | torch.Size([256, 64]) || m_down2.1.mamba_layers.2.mixer.in_proj.weight
 | -0.006 | -0.562 |  0.540 |  0.284 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.2.mixer.conv1d.weight
 |  0.016 | -0.490 |  0.503 |  0.266 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.167 |  0.167 |  0.053 | torch.Size([36, 128]) || m_down2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.021 | -0.500 |  0.499 |  0.284 | torch.Size([128, 4]) || m_down2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.836 | -6.905 | -2.270 |  1.399 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.173 |  0.187 |  0.055 | torch.Size([64, 128]) || m_down2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.987 |  0.919 |  1.065 |  0.029 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.weight
 |  0.003 | -0.065 |  0.078 |  0.025 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.036 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.3.mixer.A_log
 |  0.988 |  0.951 |  1.053 |  0.020 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.208 |  0.275 |  0.074 | torch.Size([256, 64]) || m_down2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.000 | -0.513 |  0.520 |  0.280 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.3.mixer.conv1d.weight
 |  0.056 | -0.522 |  0.494 |  0.264 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.144 |  0.130 |  0.052 | torch.Size([36, 128]) || m_down2.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.500 |  0.499 |  0.290 | torch.Size([128, 4]) || m_down2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.409 | -6.903 | -2.272 |  1.291 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.180 |  0.196 |  0.054 | torch.Size([64, 128]) || m_down2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.978 |  0.923 |  1.033 |  0.027 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.weight
 |  0.001 | -0.055 |  0.052 |  0.022 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.bias
 |  0.854 |  0.685 |  1.023 |  0.239 | torch.Size([2]) || m_down2.1.pcbam_module.h_cw.weight
 |  0.126 | -0.032 |  0.306 |  0.170 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.h_cw.conv.weight
 |  0.686 |  0.581 |  0.791 |  0.148 | torch.Size([2]) || m_down2.1.pcbam_module.w_hc.weight
 |  0.055 | -0.241 |  0.343 |  0.292 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.w_hc.conv.weight
 |  0.884 |  0.742 |  1.027 |  0.201 | torch.Size([2]) || m_down2.1.pcbam_module.c_hw.weight
 | -0.045 | -0.242 |  0.258 |  0.266 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.c_hw.conv.weight
 | -0.001 | -0.268 |  0.410 |  0.043 | torch.Size([384, 192, 2, 2]) || m_down2.2.weight
 |  0.985 |  0.619 |  1.644 |  0.229 | torch.Size([128]) || m_down3.0.trans_block.ln1.weight
 |  0.005 | -0.589 |  0.596 |  0.248 | torch.Size([128]) || m_down3.0.trans_block.ln1.bias
 |  0.053 | -2.559 |  0.993 |  0.349 | torch.Size([4, 15, 15]) || m_down3.0.trans_block.msa.relative_position_params
 | -0.000 | -0.396 |  0.385 |  0.051 | torch.Size([384, 128, 1, 1]) || m_down3.0.trans_block.msa.embedding_layer1.weight
 |  0.006 | -0.191 |  0.266 |  0.055 | torch.Size([384]) || m_down3.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.167 |  0.168 |  0.040 | torch.Size([128, 128, 1, 1]) || m_down3.0.trans_block.msa.linear1.weight
 |  0.001 | -0.112 |  0.102 |  0.043 | torch.Size([128]) || m_down3.0.trans_block.msa.linear1.bias
 |  0.899 |  0.460 |  1.325 |  0.165 | torch.Size([128]) || m_down3.0.trans_block.ln2.weight
 |  0.001 | -0.337 |  0.354 |  0.114 | torch.Size([128]) || m_down3.0.trans_block.ln2.bias
 | -0.000 | -0.404 |  0.379 |  0.046 | torch.Size([512, 128]) || m_down3.0.trans_block.mlp.0.weight
 | -0.027 | -0.351 |  0.066 |  0.044 | torch.Size([512]) || m_down3.0.trans_block.mlp.0.bias
 | -0.000 | -0.395 |  0.447 |  0.037 | torch.Size([128, 512]) || m_down3.0.trans_block.mlp.2.weight
 |  0.002 | -0.119 |  0.198 |  0.054 | torch.Size([128]) || m_down3.0.trans_block.mlp.2.bias
 |  0.004 | -0.535 |  1.740 |  0.081 | torch.Size([384, 384, 1, 1]) || m_down3.0.conv1_1.weight
 | -0.003 | -0.797 |  0.615 |  0.131 | torch.Size([384]) || m_down3.0.conv1_1.bias
 | -0.085 | -0.264 |  0.007 |  0.154 | torch.Size([1, 1, 1, 1, 3]) || m_down3.0.conv3d.weight
 | -0.004 | -0.004 | -0.004 |    nan | torch.Size([1]) || m_down3.0.conv3d.bias
 |  0.001 | -0.374 |  0.294 |  0.045 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.0.weight
 | -0.000 | -0.225 |  0.276 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.0.mixer.A_log
 |  1.001 |  0.991 |  1.096 |  0.010 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.D
 | -0.000 | -0.092 |  0.112 |  0.011 | torch.Size([512, 128]) || m_down3.0.mamba_layers.0.mixer.in_proj.weight
 | -0.002 | -0.147 |  0.116 |  0.023 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.0.mixer.conv1d.weight
 | -0.002 | -0.119 |  0.155 |  0.036 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.051 |  0.051 |  0.012 | torch.Size([40, 256]) || m_down3.0.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.041 |  0.047 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.001 |  0.000 |  0.000 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.173 |  0.134 |  0.016 | torch.Size([128, 256]) || m_down3.0.mamba_layers.0.mixer.out_proj.weight
 |  1.000 |  0.985 |  1.028 |  0.008 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.weight
 |  0.001 | -0.022 |  0.021 |  0.011 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.bias
 |  1.917 | -0.005 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.1.mixer.A_log
 |  1.013 |  0.998 |  1.312 |  0.045 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.D
 |  0.000 | -0.319 |  0.274 |  0.019 | torch.Size([512, 128]) || m_down3.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.291 |  0.278 |  0.042 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.1.mixer.conv1d.weight
 | -0.003 | -0.247 |  0.232 |  0.054 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.119 |  0.124 |  0.013 | torch.Size([40, 256]) || m_down3.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.039 |  0.058 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.096 |  0.024 |  0.006 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.404 |  0.294 |  0.024 | torch.Size([128, 256]) || m_down3.0.mamba_layers.1.mixer.out_proj.weight
 |  0.951 |  0.856 |  1.181 |  0.053 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.weight
 |  0.013 | -0.146 |  0.153 |  0.094 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.bias
 |  1.917 | -0.002 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.2.mixer.A_log
 |  0.980 |  0.949 |  1.021 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.D
 |  0.000 | -0.146 |  0.150 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.2.mixer.in_proj.weight
 | -0.015 | -0.540 |  0.508 |  0.280 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.2.mixer.conv1d.weight
 |  0.031 | -0.514 |  0.482 |  0.274 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.101 |  0.096 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.2.mixer.x_proj.weight
 | -0.000 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.489 | -6.888 | -2.309 |  1.322 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.133 |  0.164 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.2.mixer.out_proj.weight
 |  0.957 |  0.904 |  1.041 |  0.022 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.weight
 |  0.001 | -0.069 |  0.061 |  0.030 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.bias
 |  1.917 | -0.001 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.3.mixer.A_log
 |  0.981 |  0.942 |  1.030 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.D
 | -0.000 | -0.134 |  0.143 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.3.mixer.in_proj.weight
 |  0.006 | -0.505 |  0.531 |  0.280 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.489 |  0.493 |  0.255 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.088 |  0.090 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.3.mixer.x_proj.weight
 | -0.002 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.511 | -6.890 | -2.277 |  1.395 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.120 |  0.131 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.3.mixer.out_proj.weight
 |  0.956 |  0.898 |  1.003 |  0.020 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.weight
 | -0.000 | -0.063 |  0.066 |  0.028 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.bias
 |  0.708 |  0.548 |  0.869 |  0.227 | torch.Size([2]) || m_down3.0.pcbam_module.h_cw.weight
 |  0.052 | -0.055 |  0.193 |  0.128 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.h_cw.conv.weight
 |  0.294 |  0.254 |  0.335 |  0.058 | torch.Size([2]) || m_down3.0.pcbam_module.w_hc.weight
 |  0.018 | -0.114 |  0.228 |  0.184 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.w_hc.conv.weight
 |  0.568 |  0.250 |  0.886 |  0.450 | torch.Size([2]) || m_down3.0.pcbam_module.c_hw.weight
 | -0.089 | -0.353 |  0.103 |  0.166 | torch.Size([1, 1, 1, 5]) || m_down3.0.pcbam_module.c_hw.conv.weight
 |  1.082 |  0.617 |  1.594 |  0.241 | torch.Size([128]) || m_down3.1.trans_block.ln1.weight
 | -0.017 | -0.805 |  0.657 |  0.216 | torch.Size([128]) || m_down3.1.trans_block.ln1.bias
 |  0.002 | -2.820 |  1.248 |  0.323 | torch.Size([4, 15, 15]) || m_down3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.438 |  0.448 |  0.056 | torch.Size([384, 128, 1, 1]) || m_down3.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.231 |  0.239 |  0.048 | torch.Size([384]) || m_down3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.168 |  0.162 |  0.039 | torch.Size([128, 128, 1, 1]) || m_down3.1.trans_block.msa.linear1.weight
 |  0.000 | -0.134 |  0.142 |  0.053 | torch.Size([128]) || m_down3.1.trans_block.msa.linear1.bias
 |  0.906 |  0.434 |  1.276 |  0.188 | torch.Size([128]) || m_down3.1.trans_block.ln2.weight
 | -0.006 | -0.377 |  0.429 |  0.168 | torch.Size([128]) || m_down3.1.trans_block.ln2.bias
 | -0.000 | -0.444 |  0.369 |  0.058 | torch.Size([512, 128]) || m_down3.1.trans_block.mlp.0.weight
 | -0.044 | -0.237 |  0.033 |  0.052 | torch.Size([512]) || m_down3.1.trans_block.mlp.0.bias
 | -0.000 | -0.363 |  0.362 |  0.044 | torch.Size([128, 512]) || m_down3.1.trans_block.mlp.2.weight
 |  0.004 | -0.124 |  0.144 |  0.052 | torch.Size([128]) || m_down3.1.trans_block.mlp.2.bias
 | -0.003 | -1.792 |  0.663 |  0.088 | torch.Size([384, 384, 1, 1]) || m_down3.1.conv1_1.weight
 |  0.010 | -0.559 |  0.409 |  0.092 | torch.Size([384]) || m_down3.1.conv1_1.bias
 |  0.089 | -0.010 |  0.283 |  0.168 | torch.Size([1, 1, 1, 1, 3]) || m_down3.1.conv3d.weight
 | -0.001 | -0.001 | -0.001 |    nan | torch.Size([1]) || m_down3.1.conv3d.bias
 | -0.005 | -0.366 |  0.422 |  0.047 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.0.weight
 | -0.000 | -0.258 |  0.301 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.2.weight
 |  1.917 | -0.001 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.0.mixer.A_log
 |  1.011 |  0.995 |  1.145 |  0.025 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.299 |  0.306 |  0.026 | torch.Size([512, 128]) || m_down3.1.mamba_layers.0.mixer.in_proj.weight
 | -0.000 | -0.385 |  0.281 |  0.053 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.123 |  0.103 |  0.034 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.079 |  0.086 |  0.014 | torch.Size([40, 256]) || m_down3.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.039 |  0.057 |  0.012 | torch.Size([256, 8]) || m_down3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.025 |  0.011 |  0.002 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.217 |  0.221 |  0.028 | torch.Size([128, 256]) || m_down3.1.mamba_layers.0.mixer.out_proj.weight
 |  0.991 |  0.871 |  1.205 |  0.058 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.weight
 |  0.004 | -0.118 |  0.137 |  0.074 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.bias
 |  1.917 | -0.045 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.1.mixer.A_log
 |  1.021 |  0.951 |  1.316 |  0.049 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.D
 |  0.000 | -0.307 |  0.343 |  0.033 | torch.Size([512, 128]) || m_down3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.003 | -0.379 |  0.349 |  0.065 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.246 |  0.218 |  0.044 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.182 |  0.211 |  0.024 | torch.Size([40, 256]) || m_down3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.078 |  0.083 |  0.016 | torch.Size([256, 8]) || m_down3.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.010 | -0.109 |  0.196 |  0.031 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.282 |  0.299 |  0.034 | torch.Size([128, 256]) || m_down3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.013 |  0.833 |  1.240 |  0.080 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.weight
 | -0.003 | -0.171 |  0.186 |  0.102 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.083 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.2.mixer.A_log
 |  0.980 |  0.935 |  1.075 |  0.019 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.169 |  0.159 |  0.052 | torch.Size([512, 128]) || m_down3.1.mamba_layers.2.mixer.in_proj.weight
 | -0.011 | -0.553 |  0.567 |  0.278 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.2.mixer.conv1d.weight
 |  0.016 | -0.520 |  0.512 |  0.290 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.123 |  0.113 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.205 | torch.Size([256, 8]) || m_down3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.526 | -6.818 | -2.284 |  1.305 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.180 |  0.134 |  0.039 | torch.Size([128, 256]) || m_down3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.959 |  0.875 |  1.031 |  0.026 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.weight
 | -0.001 | -0.085 |  0.053 |  0.021 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.003 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.3.mixer.A_log
 |  0.980 |  0.933 |  1.019 |  0.014 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.D
 |  0.000 | -0.142 |  0.144 |  0.051 | torch.Size([512, 128]) || m_down3.1.mamba_layers.3.mixer.in_proj.weight
 |  0.010 | -0.543 |  0.539 |  0.277 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.3.mixer.conv1d.weight
 |  0.001 | -0.509 |  0.478 |  0.287 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.108 |  0.116 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.204 | torch.Size([256, 8]) || m_down3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.747 | -6.882 | -2.256 |  1.391 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.127 |  0.129 |  0.037 | torch.Size([128, 256]) || m_down3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.950 |  0.895 |  1.003 |  0.023 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.weight
 | -0.001 | -0.083 |  0.076 |  0.022 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.bias
 |  0.680 |  0.554 |  0.806 |  0.178 | torch.Size([2]) || m_down3.1.pcbam_module.h_cw.weight
 | -0.003 | -0.204 |  0.262 |  0.239 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.h_cw.conv.weight
 |  0.425 |  0.112 |  0.739 |  0.444 | torch.Size([2]) || m_down3.1.pcbam_module.w_hc.weight
 | -0.021 | -0.245 |  0.315 |  0.296 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.w_hc.conv.weight
 |  0.600 |  0.591 |  0.608 |  0.012 | torch.Size([2]) || m_down3.1.pcbam_module.c_hw.weight
 |  0.115 | -0.168 |  0.354 |  0.257 | torch.Size([1, 1, 1, 5]) || m_down3.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.486 |  0.307 |  0.032 | torch.Size([768, 384, 2, 2]) || m_down3.2.weight
 |  0.806 |  0.359 |  1.208 |  0.146 | torch.Size([256]) || m_body.0.trans_block.ln1.weight
 | -0.011 | -0.671 |  0.494 |  0.135 | torch.Size([256]) || m_body.0.trans_block.ln1.bias
 |  0.054 | -4.731 |  0.715 |  0.332 | torch.Size([8, 15, 15]) || m_body.0.trans_block.msa.relative_position_params
 | -0.000 | -0.386 |  0.387 |  0.037 | torch.Size([768, 256, 1, 1]) || m_body.0.trans_block.msa.embedding_layer1.weight
 |  0.002 | -0.203 |  0.206 |  0.053 | torch.Size([768]) || m_body.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.238 |  0.238 |  0.042 | torch.Size([256, 256, 1, 1]) || m_body.0.trans_block.msa.linear1.weight
 |  0.002 | -0.259 |  0.145 |  0.057 | torch.Size([256]) || m_body.0.trans_block.msa.linear1.bias
 |  0.853 |  0.381 |  1.185 |  0.123 | torch.Size([256]) || m_body.0.trans_block.ln2.weight
 |  0.002 | -0.200 |  0.276 |  0.081 | torch.Size([256]) || m_body.0.trans_block.ln2.bias
 |  0.000 | -0.256 |  0.283 |  0.034 | torch.Size([1024, 256]) || m_body.0.trans_block.mlp.0.weight
 | -0.011 | -0.233 |  0.103 |  0.042 | torch.Size([1024]) || m_body.0.trans_block.mlp.0.bias
 | -0.000 | -0.293 |  0.322 |  0.031 | torch.Size([256, 1024]) || m_body.0.trans_block.mlp.2.weight
 |  0.005 | -0.198 |  0.154 |  0.053 | torch.Size([256]) || m_body.0.trans_block.mlp.2.bias
 | -0.001 | -1.113 |  0.866 |  0.051 | torch.Size([768, 768, 1, 1]) || m_body.0.conv1_1.weight
 |  0.001 | -1.478 |  0.989 |  0.095 | torch.Size([768]) || m_body.0.conv1_1.bias
 |  0.074 | -0.007 |  0.234 |  0.138 | torch.Size([1, 1, 1, 1, 3]) || m_body.0.conv3d.weight
 |  0.027 |  0.027 |  0.027 |    nan | torch.Size([1]) || m_body.0.conv3d.bias
 |  0.000 | -0.236 |  0.257 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.0.weight
 | -0.000 | -0.237 |  0.211 |  0.036 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.D
 |  0.000 | -0.028 |  0.027 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.025 |  0.027 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.004 |  0.003 |  0.001 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.035 |  0.036 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.033 |  0.038 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.042 |  0.037 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.0.mixer.out_proj.weight
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.bias
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.001 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.D
 |  0.000 | -0.029 |  0.030 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.1.mixer.in_proj.weight
 |  0.000 | -0.035 |  0.059 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.1.mixer.conv1d.weight
 | -0.000 | -0.018 |  0.022 |  0.006 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.034 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.034 |  0.030 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.045 |  0.041 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.999 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.weight
 | -0.000 | -0.001 |  0.001 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.bias
 |  1.917 | -0.025 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.A_log
 |  0.999 |  0.976 |  1.013 |  0.004 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.D
 | -0.000 | -0.085 |  0.085 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.2.mixer.in_proj.weight
 | -0.007 | -0.504 |  0.517 |  0.289 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.2.mixer.conv1d.weight
 | -0.005 | -0.500 |  0.495 |  0.307 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.068 |  0.069 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.579 | -6.906 | -2.283 |  1.361 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.096 |  0.080 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.2.mixer.out_proj.weight
 |  0.995 |  0.985 |  1.008 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.weight
 |  0.000 | -0.013 |  0.007 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.bias
 |  1.917 | -0.015 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.A_log
 |  0.998 |  0.984 |  1.009 |  0.003 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.D
 |  0.000 | -0.082 |  0.078 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.3.mixer.in_proj.weight
 | -0.013 | -0.509 |  0.501 |  0.287 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.3.mixer.conv1d.weight
 |  0.003 | -0.501 |  0.496 |  0.280 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.070 |  0.067 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.3.mixer.x_proj.weight
 |  0.002 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.612 | -6.907 | -2.259 |  1.325 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.063 |  0.065 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.3.mixer.out_proj.weight
 |  0.995 |  0.986 |  1.006 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.weight
 | -0.000 | -0.009 |  0.009 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.bias
 |  1.123 |  0.893 |  1.353 |  0.326 | torch.Size([2]) || m_body.0.pcbam_module.h_cw.weight
 | -0.665 | -0.955 | -0.499 |  0.252 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.h_cw.conv.weight
 |  0.383 |  0.161 |  0.605 |  0.314 | torch.Size([2]) || m_body.0.pcbam_module.w_hc.weight
 | -0.519 | -0.608 | -0.346 |  0.150 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.w_hc.conv.weight
 |  1.013 |  0.112 |  1.913 |  1.274 | torch.Size([2]) || m_body.0.pcbam_module.c_hw.weight
 | -0.083 | -0.981 |  1.949 |  1.184 | torch.Size([1, 1, 1, 5]) || m_body.0.pcbam_module.c_hw.conv.weight
 |  0.747 |  0.306 |  1.000 |  0.127 | torch.Size([256]) || m_body.1.trans_block.ln1.weight
 |  0.028 | -0.815 |  0.540 |  0.165 | torch.Size([256]) || m_body.1.trans_block.ln1.bias
 |  0.052 | -3.909 |  0.815 |  0.351 | torch.Size([8, 15, 15]) || m_body.1.trans_block.msa.relative_position_params
 | -0.000 | -0.306 |  0.295 |  0.036 | torch.Size([768, 256, 1, 1]) || m_body.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.221 |  0.248 |  0.068 | torch.Size([768]) || m_body.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.278 |  0.275 |  0.037 | torch.Size([256, 256, 1, 1]) || m_body.1.trans_block.msa.linear1.weight
 | -0.003 | -0.193 |  0.214 |  0.058 | torch.Size([256]) || m_body.1.trans_block.msa.linear1.bias
 |  0.866 |  0.519 |  1.098 |  0.100 | torch.Size([256]) || m_body.1.trans_block.ln2.weight
 |  0.007 | -0.263 |  0.320 |  0.103 | torch.Size([256]) || m_body.1.trans_block.ln2.bias
 |  0.001 | -0.362 |  0.358 |  0.054 | torch.Size([1024, 256]) || m_body.1.trans_block.mlp.0.weight
 | -0.051 | -0.199 |  0.056 |  0.038 | torch.Size([1024]) || m_body.1.trans_block.mlp.0.bias
 | -0.001 | -0.438 |  0.395 |  0.051 | torch.Size([256, 1024]) || m_body.1.trans_block.mlp.2.weight
 | -0.000 | -0.218 |  0.139 |  0.051 | torch.Size([256]) || m_body.1.trans_block.mlp.2.bias
 | -0.001 | -1.065 |  0.764 |  0.056 | torch.Size([768, 768, 1, 1]) || m_body.1.conv1_1.weight
 |  0.000 | -0.311 |  0.925 |  0.086 | torch.Size([768]) || m_body.1.conv1_1.bias
 |  0.173 |  0.007 |  0.502 |  0.285 | torch.Size([1, 1, 1, 1, 3]) || m_body.1.conv3d.weight
 |  0.062 |  0.062 |  0.062 |    nan | torch.Size([1]) || m_body.1.conv3d.bias
 | -0.001 | -0.278 |  0.267 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.0.weight
 | -0.001 | -0.271 |  0.268 |  0.035 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.2.weight
 |  1.917 | -0.002 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.086 |  0.005 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.D
 | -0.000 | -0.126 |  0.113 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.085 |  0.292 |  0.012 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.016 |  0.060 |  0.003 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.055 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.035 |  0.029 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.006 |  0.004 |  0.000 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.153 |  0.095 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.0.mixer.out_proj.weight
 |  1.001 |  0.995 |  1.018 |  0.003 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.weight
 |  0.000 | -0.006 |  0.006 |  0.002 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.bias
 |  1.917 | -0.218 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.039 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.D
 |  0.000 | -0.169 |  0.149 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.1.mixer.in_proj.weight
 | -0.000 | -0.054 |  0.173 |  0.010 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.097 |  0.073 |  0.022 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.097 |  0.324 |  0.010 | torch.Size([48, 512]) || m_body.1.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.032 |  0.035 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.037 |  0.000 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.153 |  0.185 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.986 |  1.044 |  0.010 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.weight
 | -0.001 | -0.018 |  0.022 |  0.009 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.bias
 |  1.917 | -0.057 |  2.774 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.A_log
 |  0.998 |  0.962 |  1.045 |  0.005 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.D
 | -0.000 | -0.093 |  0.117 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.2.mixer.in_proj.weight
 |  0.004 | -0.511 |  0.502 |  0.282 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.2.mixer.conv1d.weight
 |  0.010 | -0.506 |  0.492 |  0.282 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.079 |  0.087 |  0.026 | torch.Size([48, 512]) || m_body.1.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.257 |  0.260 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.634 | -6.903 | -2.259 |  1.288 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.102 |  0.100 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.2.mixer.out_proj.weight
 |  0.995 |  0.958 |  1.009 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.weight
 |  0.000 | -0.023 |  0.021 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.bias
 |  1.917 | -0.068 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.A_log
 |  0.999 |  0.918 |  1.113 |  0.009 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.D
 |  0.000 | -0.121 |  0.118 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.530 |  0.505 |  0.292 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.3.mixer.conv1d.weight
 | -0.009 | -0.501 |  0.498 |  0.294 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.089 |  0.085 |  0.026 | torch.Size([48, 512]) || m_body.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.272 |  0.268 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.631 | -6.903 | -2.252 |  1.302 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.114 |  0.094 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.3.mixer.out_proj.weight
 |  0.999 |  0.970 |  1.027 |  0.008 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.weight
 |  0.000 | -0.015 |  0.017 |  0.006 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.bias
 |  1.209 |  0.870 |  1.547 |  0.479 | torch.Size([2]) || m_body.1.pcbam_module.h_cw.weight
 | -1.012 | -1.126 | -0.821 |  0.167 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.h_cw.conv.weight
 |  1.149 |  0.897 |  1.400 |  0.356 | torch.Size([2]) || m_body.1.pcbam_module.w_hc.weight
 | -0.941 | -1.056 | -0.784 |  0.141 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.w_hc.conv.weight
 |  1.486 |  0.077 |  2.894 |  1.992 | torch.Size([2]) || m_body.1.pcbam_module.c_hw.weight
 | -0.207 | -1.516 |  1.716 |  1.290 | torch.Size([1, 1, 1, 5]) || m_body.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.319 |  0.339 |  0.030 | torch.Size([768, 384, 2, 2]) || m_up3.0.weight
 |  0.962 |  0.584 |  1.379 |  0.156 | torch.Size([128]) || m_up3.1.trans_block.ln1.weight
 |  0.026 | -0.558 |  0.425 |  0.129 | torch.Size([128]) || m_up3.1.trans_block.ln1.bias
 |  0.050 | -3.792 |  0.658 |  0.308 | torch.Size([4, 15, 15]) || m_up3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.494 |  0.525 |  0.060 | torch.Size([384, 128, 1, 1]) || m_up3.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.260 |  0.243 |  0.069 | torch.Size([384]) || m_up3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.176 |  0.187 |  0.044 | torch.Size([128, 128, 1, 1]) || m_up3.1.trans_block.msa.linear1.weight
 | -0.001 | -0.100 |  0.216 |  0.043 | torch.Size([128]) || m_up3.1.trans_block.msa.linear1.bias
 |  0.882 |  0.709 |  1.047 |  0.070 | torch.Size([128]) || m_up3.1.trans_block.ln2.weight
 |  0.008 | -0.259 |  0.183 |  0.085 | torch.Size([128]) || m_up3.1.trans_block.ln2.bias
 |  0.000 | -0.341 |  0.316 |  0.059 | torch.Size([512, 128]) || m_up3.1.trans_block.mlp.0.weight
 | -0.038 | -0.192 |  0.067 |  0.044 | torch.Size([512]) || m_up3.1.trans_block.mlp.0.bias
 | -0.000 | -0.353 |  0.309 |  0.053 | torch.Size([128, 512]) || m_up3.1.trans_block.mlp.2.weight
 | -0.002 | -0.335 |  0.165 |  0.045 | torch.Size([128]) || m_up3.1.trans_block.mlp.2.bias
 | -0.001 | -2.353 |  0.670 |  0.086 | torch.Size([384, 384, 1, 1]) || m_up3.1.conv1_1.weight
 | -0.001 | -0.418 |  1.301 |  0.129 | torch.Size([384]) || m_up3.1.conv1_1.bias
 |  0.182 | -0.006 |  0.558 |  0.325 | torch.Size([1, 1, 1, 1, 3]) || m_up3.1.conv3d.weight
 | -0.005 | -0.005 | -0.005 |    nan | torch.Size([1]) || m_up3.1.conv3d.bias
 |  0.000 | -0.370 |  0.274 |  0.035 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.0.weight
 |  0.000 | -0.269 |  0.385 |  0.037 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.2.weight
 |  1.916 | -0.346 |  2.773 |  0.766 | torch.Size([256, 16]) || m_up3.1.mamba_layers.0.mixer.A_log
 |  1.051 |  0.998 |  1.320 |  0.072 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.398 |  0.382 |  0.043 | torch.Size([512, 128]) || m_up3.1.mamba_layers.0.mixer.in_proj.weight
 |  0.006 | -0.430 |  0.482 |  0.097 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.0.mixer.conv1d.weight
 |  0.011 | -0.171 |  0.346 |  0.065 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.171 |  0.228 |  0.025 | torch.Size([40, 256]) || m_up3.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.054 |  0.065 |  0.013 | torch.Size([256, 8]) || m_up3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.003 | -0.169 |  0.117 |  0.028 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.488 |  0.437 |  0.049 | torch.Size([128, 256]) || m_up3.1.mamba_layers.0.mixer.out_proj.weight
 |  1.031 |  0.912 |  1.168 |  0.064 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.weight
 | -0.002 | -0.272 |  0.275 |  0.119 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.bias
 |  1.916 | -0.849 |  3.034 |  0.769 | torch.Size([256, 16]) || m_up3.1.mamba_layers.1.mixer.A_log
 |  1.000 | -0.041 |  1.309 |  0.161 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.D
 | -0.000 | -0.424 |  0.423 |  0.055 | torch.Size([512, 128]) || m_up3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.004 | -0.463 |  0.365 |  0.108 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.019 | -0.292 |  0.284 |  0.171 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.555 |  0.538 |  0.074 | torch.Size([40, 256]) || m_up3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.002 | -0.605 |  0.692 |  0.095 | torch.Size([256, 8]) || m_up3.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.013 | -1.004 |  0.247 |  0.106 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.269 |  0.270 |  0.056 | torch.Size([128, 256]) || m_up3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.015 |  0.687 |  1.203 |  0.107 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.weight
 | -0.002 | -0.238 |  0.261 |  0.101 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.278 |  2.787 |  0.764 | torch.Size([256, 16]) || m_up3.1.mamba_layers.2.mixer.A_log
 |  0.982 |  0.690 |  1.037 |  0.038 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.181 |  0.193 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.2.mixer.in_proj.weight
 |  0.014 | -0.563 |  0.541 |  0.274 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.2.mixer.conv1d.weight
 | -0.029 | -0.525 |  0.491 |  0.291 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.164 |  0.147 |  0.042 | torch.Size([40, 256]) || m_up3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.000 | -0.413 |  0.371 |  0.205 | torch.Size([256, 8]) || m_up3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.530 | -6.922 | -2.275 |  1.363 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.000 | -0.153 |  0.157 |  0.040 | torch.Size([128, 256]) || m_up3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.958 |  0.882 |  1.029 |  0.026 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.weight
 |  0.002 | -0.054 |  0.074 |  0.021 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.033 |  2.773 |  0.765 | torch.Size([256, 16]) || m_up3.1.mamba_layers.3.mixer.A_log
 |  0.990 |  0.944 |  1.027 |  0.016 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.D
 | -0.000 | -0.162 |  0.159 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.3.mixer.in_proj.weight
 | -0.011 | -0.529 |  0.512 |  0.268 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.3.mixer.conv1d.weight
 | -0.005 | -0.548 |  0.532 |  0.309 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.119 |  0.118 |  0.038 | torch.Size([40, 256]) || m_up3.1.mamba_layers.3.mixer.x_proj.weight
 | -0.001 | -0.355 |  0.356 |  0.203 | torch.Size([256, 8]) || m_up3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.644 | -6.922 | -2.262 |  1.394 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.150 |  0.145 |  0.040 | torch.Size([128, 256]) || m_up3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.956 |  0.893 |  1.025 |  0.026 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.weight
 | -0.000 | -0.072 |  0.060 |  0.020 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.bias
 |  0.534 |  0.193 |  0.875 |  0.483 | torch.Size([2]) || m_up3.1.pcbam_module.h_cw.weight
 |  0.127 |  0.060 |  0.237 |  0.095 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.h_cw.conv.weight
 |  0.882 |  0.856 |  0.909 |  0.037 | torch.Size([2]) || m_up3.1.pcbam_module.w_hc.weight
 |  0.164 |  0.099 |  0.218 |  0.060 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.w_hc.conv.weight
 |  0.493 |  0.225 |  0.762 |  0.380 | torch.Size([2]) || m_up3.1.pcbam_module.c_hw.weight
 |  0.017 | -0.148 |  0.146 |  0.119 | torch.Size([1, 1, 1, 5]) || m_up3.1.pcbam_module.c_hw.conv.weight
 |  1.124 |  0.605 |  1.354 |  0.143 | torch.Size([128]) || m_up3.2.trans_block.ln1.weight
 | -0.004 | -0.493 |  0.500 |  0.122 | torch.Size([128]) || m_up3.2.trans_block.ln1.bias
 |  0.061 | -3.109 |  0.733 |  0.356 | torch.Size([4, 15, 15]) || m_up3.2.trans_block.msa.relative_position_params
 | -0.000 | -0.454 |  0.313 |  0.056 | torch.Size([384, 128, 1, 1]) || m_up3.2.trans_block.msa.embedding_layer1.weight
 | -0.001 | -0.182 |  0.190 |  0.057 | torch.Size([384]) || m_up3.2.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.191 |  0.200 |  0.047 | torch.Size([128, 128, 1, 1]) || m_up3.2.trans_block.msa.linear1.weight
 | -0.003 | -0.139 |  0.146 |  0.055 | torch.Size([128]) || m_up3.2.trans_block.msa.linear1.bias
 |  1.202 |  0.966 |  1.501 |  0.090 | torch.Size([128]) || m_up3.2.trans_block.ln2.weight
 | -0.000 | -0.268 |  0.288 |  0.113 | torch.Size([128]) || m_up3.2.trans_block.ln2.bias
 |  0.000 | -0.359 |  0.332 |  0.073 | torch.Size([512, 128]) || m_up3.2.trans_block.mlp.0.weight
 | -0.048 | -0.182 |  0.056 |  0.038 | torch.Size([512]) || m_up3.2.trans_block.mlp.0.bias
 |  0.000 | -0.345 |  0.389 |  0.070 | torch.Size([128, 512]) || m_up3.2.trans_block.mlp.2.weight
 | -0.002 | -0.141 |  0.214 |  0.052 | torch.Size([128]) || m_up3.2.trans_block.mlp.2.bias
 | -0.000 | -0.840 |  0.453 |  0.075 | torch.Size([384, 384, 1, 1]) || m_up3.2.conv1_1.weight
 |  0.001 | -0.553 |  1.061 |  0.104 | torch.Size([384]) || m_up3.2.conv1_1.bias
 | -0.065 | -0.203 |  0.006 |  0.120 | torch.Size([1, 1, 1, 1, 3]) || m_up3.2.conv3d.weight
 | -0.002 | -0.002 | -0.002 |    nan | torch.Size([1]) || m_up3.2.conv3d.bias
 | -0.001 | -0.316 |  0.352 |  0.051 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.0.weight
 |  0.000 | -0.439 |  0.398 |  0.051 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.2.weight
 |  1.916 | -1.142 |  2.794 |  0.767 | torch.Size([256, 16]) || m_up3.2.mamba_layers.0.mixer.A_log
 |  1.074 |  0.399 |  1.575 |  0.159 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.D
 | -0.000 | -0.326 |  0.326 |  0.071 | torch.Size([512, 128]) || m_up3.2.mamba_layers.0.mixer.in_proj.weight
 | -0.001 | -0.372 |  0.432 |  0.142 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.0.mixer.conv1d.weight
 | -0.010 | -0.303 |  0.267 |  0.104 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.666 |  0.471 |  0.075 | torch.Size([40, 256]) || m_up3.2.mamba_layers.0.mixer.x_proj.weight
 |  0.001 | -0.689 |  0.714 |  0.099 | torch.Size([256, 8]) || m_up3.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.019 | -1.178 |  0.291 |  0.120 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.587 |  0.443 |  0.076 | torch.Size([128, 256]) || m_up3.2.mamba_layers.0.mixer.out_proj.weight
 |  1.018 |  0.684 |  1.152 |  0.080 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.weight
 |  0.006 | -0.413 |  0.404 |  0.131 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.bias
 |  1.911 | -0.997 |  2.866 |  0.776 | torch.Size([256, 16]) || m_up3.2.mamba_layers.1.mixer.A_log
 |  1.070 | -0.093 |  1.506 |  0.137 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.D
 |  0.000 | -0.341 |  0.416 |  0.072 | torch.Size([512, 128]) || m_up3.2.mamba_layers.1.mixer.in_proj.weight
 |  0.005 | -0.536 |  0.448 |  0.147 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.1.mixer.conv1d.weight
 |  0.010 | -0.317 |  0.343 |  0.150 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.conv1d.bias
 |  0.002 | -0.720 |  1.146 |  0.091 | torch.Size([40, 256]) || m_up3.2.mamba_layers.1.mixer.x_proj.weight
 | -0.005 | -0.661 |  0.592 |  0.124 | torch.Size([256, 8]) || m_up3.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.014 | -0.455 |  0.173 |  0.107 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.430 |  0.404 |  0.075 | torch.Size([128, 256]) || m_up3.2.mamba_layers.1.mixer.out_proj.weight
 |  1.073 |  0.688 |  1.218 |  0.082 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.weight
 |  0.004 | -0.264 |  0.247 |  0.108 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.bias
 |  1.917 | -0.048 |  2.833 |  0.765 | torch.Size([256, 16]) || m_up3.2.mamba_layers.2.mixer.A_log
 |  1.027 |  0.972 |  1.345 |  0.035 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.D
 | -0.000 | -0.225 |  0.218 |  0.057 | torch.Size([512, 128]) || m_up3.2.mamba_layers.2.mixer.in_proj.weight
 |  0.002 | -0.647 |  0.629 |  0.294 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.2.mixer.conv1d.weight
 |  0.036 | -0.540 |  0.543 |  0.319 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.157 |  0.167 |  0.045 | torch.Size([40, 256]) || m_up3.2.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.440 |  0.466 |  0.205 | torch.Size([256, 8]) || m_up3.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.531 | -6.898 | -2.248 |  1.383 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.232 |  0.201 |  0.046 | torch.Size([128, 256]) || m_up3.2.mamba_layers.2.mixer.out_proj.weight
 |  1.023 |  0.970 |  1.089 |  0.025 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.weight
 |  0.000 | -0.092 |  0.101 |  0.038 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.bias
 |  1.917 | -0.027 |  2.774 |  0.764 | torch.Size([256, 16]) || m_up3.2.mamba_layers.3.mixer.A_log
 |  1.008 |  0.978 |  1.069 |  0.012 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.D
 | -0.000 | -0.197 |  0.174 |  0.054 | torch.Size([512, 128]) || m_up3.2.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.559 |  0.556 |  0.287 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.3.mixer.conv1d.weight
 | -0.022 | -0.537 |  0.538 |  0.301 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.176 |  0.175 |  0.041 | torch.Size([40, 256]) || m_up3.2.mamba_layers.3.mixer.x_proj.weight
 | -0.005 | -0.366 |  0.370 |  0.206 | torch.Size([256, 8]) || m_up3.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.526 | -6.891 | -2.236 |  1.228 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.182 |  0.181 |  0.043 | torch.Size([128, 256]) || m_up3.2.mamba_layers.3.mixer.out_proj.weight
 |  1.000 |  0.840 |  1.052 |  0.029 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.weight
 | -0.000 | -0.141 |  0.072 |  0.027 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.bias
 |  0.754 |  0.558 |  0.951 |  0.278 | torch.Size([2]) || m_up3.2.pcbam_module.h_cw.weight
 | -0.066 | -0.206 |  0.165 |  0.202 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.h_cw.conv.weight
 |  0.793 |  0.740 |  0.846 |  0.075 | torch.Size([2]) || m_up3.2.pcbam_module.w_hc.weight
 |  0.050 | -0.103 |  0.188 |  0.146 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.w_hc.conv.weight
 |  0.557 |  0.115 |  0.998 |  0.624 | torch.Size([2]) || m_up3.2.pcbam_module.c_hw.weight
 |  0.309 | -0.071 |  1.470 |  0.653 | torch.Size([1, 1, 1, 5]) || m_up3.2.pcbam_module.c_hw.conv.weight
 | -0.001 | -0.389 |  0.302 |  0.033 | torch.Size([384, 192, 2, 2]) || m_up2.0.weight
 |  1.337 |  1.001 |  1.550 |  0.134 | torch.Size([64]) || m_up2.1.trans_block.ln1.weight
 | -0.001 | -0.478 |  0.489 |  0.153 | torch.Size([64]) || m_up2.1.trans_block.ln1.bias
 |  0.173 | -2.433 |  0.911 |  0.344 | torch.Size([2, 15, 15]) || m_up2.1.trans_block.msa.relative_position_params
 |  0.000 | -0.498 |  0.523 |  0.107 | torch.Size([192, 64, 1, 1]) || m_up2.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.184 |  0.179 |  0.045 | torch.Size([192]) || m_up2.1.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.188 |  0.200 |  0.049 | torch.Size([64, 64, 1, 1]) || m_up2.1.trans_block.msa.linear1.weight
 | -0.002 | -0.169 |  0.195 |  0.049 | torch.Size([64]) || m_up2.1.trans_block.msa.linear1.bias
 |  1.060 |  0.803 |  1.204 |  0.076 | torch.Size([64]) || m_up2.1.trans_block.ln2.weight
 |  0.006 | -0.271 |  0.250 |  0.134 | torch.Size([64]) || m_up2.1.trans_block.ln2.bias
 | -0.000 | -0.354 |  0.340 |  0.091 | torch.Size([256, 64]) || m_up2.1.trans_block.mlp.0.weight
 | -0.045 | -0.342 |  0.221 |  0.073 | torch.Size([256]) || m_up2.1.trans_block.mlp.0.bias
 |  0.001 | -0.413 |  0.407 |  0.079 | torch.Size([64, 256]) || m_up2.1.trans_block.mlp.2.weight
 | -0.002 | -0.200 |  0.178 |  0.059 | torch.Size([64]) || m_up2.1.trans_block.mlp.2.bias
 |  0.002 | -0.430 |  2.089 |  0.100 | torch.Size([192, 192, 1, 1]) || m_up2.1.conv1_1.weight
 |  0.000 | -0.586 |  0.717 |  0.127 | torch.Size([192]) || m_up2.1.conv1_1.bias
 | -0.193 | -0.666 |  0.046 |  0.410 | torch.Size([1, 1, 1, 1, 3]) || m_up2.1.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_up2.1.conv3d.bias
 |  0.000 | -0.270 |  0.232 |  0.045 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.0.weight
 |  0.000 | -0.274 |  0.249 |  0.046 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.2.weight
 |  1.917 | -0.437 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.0.mixer.A_log
 |  1.111 |  0.999 |  1.283 |  0.057 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.D
 | -0.000 | -0.339 |  0.321 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.422 |  0.478 |  0.170 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.004 | -0.222 |  0.235 |  0.068 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.001 | -0.143 |  0.207 |  0.038 | torch.Size([36, 128]) || m_up2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.055 |  0.058 |  0.019 | torch.Size([128, 4]) || m_up2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.003 | -0.148 |  0.283 |  0.055 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.517 |  0.375 |  0.076 | torch.Size([64, 128]) || m_up2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.184 |  0.957 |  1.335 |  0.088 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.weight
 |  0.000 | -0.137 |  0.218 |  0.072 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.bias
 |  1.916 | -0.594 |  2.773 |  0.767 | torch.Size([128, 16]) || m_up2.1.mamba_layers.1.mixer.A_log
 |  1.147 |  0.999 |  1.410 |  0.066 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.D
 |  0.000 | -0.371 |  0.399 |  0.090 | torch.Size([256, 64]) || m_up2.1.mamba_layers.1.mixer.in_proj.weight
 | -0.007 | -0.484 |  0.666 |  0.184 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.009 | -0.303 |  0.277 |  0.118 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.235 |  0.301 |  0.063 | torch.Size([36, 128]) || m_up2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.113 |  0.278 |  0.041 | torch.Size([128, 4]) || m_up2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.031 | -0.147 |  0.237 |  0.062 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.001 | -0.380 |  0.459 |  0.089 | torch.Size([64, 128]) || m_up2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.202 |  0.868 |  1.356 |  0.106 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.weight
 |  0.001 | -0.216 |  0.245 |  0.083 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.042 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.2.mixer.A_log
 |  1.006 |  0.945 |  1.079 |  0.027 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.D
 |  0.001 | -0.231 |  0.260 |  0.075 | torch.Size([256, 64]) || m_up2.1.mamba_layers.2.mixer.in_proj.weight
 |  0.000 | -0.538 |  0.643 |  0.287 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.2.mixer.conv1d.weight
 | -0.027 | -0.537 |  0.491 |  0.306 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.176 |  0.172 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.016 | -0.497 |  0.500 |  0.287 | torch.Size([128, 4]) || m_up2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.802 | -6.895 | -2.292 |  1.396 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.207 |  0.193 |  0.059 | torch.Size([64, 128]) || m_up2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.996 |  0.934 |  1.139 |  0.034 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.weight
 | -0.000 | -0.056 |  0.047 |  0.017 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.015 |  2.775 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.3.mixer.A_log
 |  1.001 |  0.945 |  1.076 |  0.028 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.208 |  0.222 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.011 | -0.555 |  0.583 |  0.292 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.3.mixer.conv1d.weight
 | -0.014 | -0.564 |  0.564 |  0.316 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.223 |  0.174 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.3.mixer.x_proj.weight
 | -0.017 | -0.491 |  0.498 |  0.291 | torch.Size([128, 4]) || m_up2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.756 | -6.892 | -2.289 |  1.356 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.222 |  0.194 |  0.059 | torch.Size([64, 128]) || m_up2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.983 |  0.881 |  1.098 |  0.033 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.weight
 | -0.001 | -0.083 |  0.073 |  0.023 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.bias
 |  0.168 |  0.121 |  0.214 |  0.066 | torch.Size([2]) || m_up2.1.pcbam_module.h_cw.weight
 |  0.023 | -0.076 |  0.160 |  0.122 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.h_cw.conv.weight
 |  0.691 |  0.688 |  0.694 |  0.004 | torch.Size([2]) || m_up2.1.pcbam_module.w_hc.weight
 | -0.088 | -0.298 |  0.067 |  0.188 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.w_hc.conv.weight
 |  0.887 |  0.834 |  0.941 |  0.076 | torch.Size([2]) || m_up2.1.pcbam_module.c_hw.weight
 | -0.051 | -0.194 |  0.028 |  0.124 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.c_hw.conv.weight
 |  1.362 |  1.043 |  1.568 |  0.122 | torch.Size([64]) || m_up2.2.trans_block.ln1.weight
 |  0.036 | -0.424 |  0.509 |  0.136 | torch.Size([64]) || m_up2.2.trans_block.ln1.bias
 |  0.131 | -2.465 |  0.732 |  0.331 | torch.Size([2, 15, 15]) || m_up2.2.trans_block.msa.relative_position_params
 |  0.000 | -0.475 |  0.536 |  0.102 | torch.Size([192, 64, 1, 1]) || m_up2.2.trans_block.msa.embedding_layer1.weight
 |  0.000 | -0.259 |  0.292 |  0.069 | torch.Size([192]) || m_up2.2.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.270 |  0.234 |  0.050 | torch.Size([64, 64, 1, 1]) || m_up2.2.trans_block.msa.linear1.weight
 |  0.003 | -0.225 |  0.360 |  0.058 | torch.Size([64]) || m_up2.2.trans_block.msa.linear1.bias
 |  1.068 |  0.644 |  1.268 |  0.120 | torch.Size([64]) || m_up2.2.trans_block.ln2.weight
 |  0.014 | -0.399 |  0.391 |  0.121 | torch.Size([64]) || m_up2.2.trans_block.ln2.bias
 |  0.002 | -0.390 |  0.420 |  0.089 | torch.Size([256, 64]) || m_up2.2.trans_block.mlp.0.weight
 | -0.043 | -0.175 |  0.086 |  0.041 | torch.Size([256]) || m_up2.2.trans_block.mlp.0.bias
 | -0.001 | -0.329 |  0.367 |  0.077 | torch.Size([64, 256]) || m_up2.2.trans_block.mlp.2.weight
 |  0.002 | -0.234 |  0.236 |  0.058 | torch.Size([64]) || m_up2.2.trans_block.mlp.2.bias
 |  0.002 | -0.467 |  1.970 |  0.100 | torch.Size([192, 192, 1, 1]) || m_up2.2.conv1_1.weight
 | -0.002 | -0.390 |  0.749 |  0.114 | torch.Size([192]) || m_up2.2.conv1_1.bias
 | -0.201 | -0.641 |  0.023 |  0.381 | torch.Size([1, 1, 1, 1, 3]) || m_up2.2.conv3d.weight
 | -0.008 | -0.008 | -0.008 |    nan | torch.Size([1]) || m_up2.2.conv3d.bias
 |  0.001 | -0.420 |  0.426 |  0.055 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.0.weight
 | -0.000 | -0.317 |  0.428 |  0.056 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.2.weight
 |  1.915 | -0.421 |  2.782 |  0.770 | torch.Size([128, 16]) || m_up2.2.mamba_layers.0.mixer.A_log
 |  1.149 |  0.722 |  1.475 |  0.104 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.D
 |  0.000 | -0.491 |  0.397 |  0.095 | torch.Size([256, 64]) || m_up2.2.mamba_layers.0.mixer.in_proj.weight
 |  0.031 | -0.543 |  0.704 |  0.191 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.0.mixer.conv1d.weight
 |  0.038 | -0.235 |  0.277 |  0.095 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.conv1d.bias
 | -0.003 | -0.529 |  0.737 |  0.077 | torch.Size([36, 128]) || m_up2.2.mamba_layers.0.mixer.x_proj.weight
 | -0.007 | -0.441 |  0.322 |  0.103 | torch.Size([128, 4]) || m_up2.2.mamba_layers.0.mixer.dt_proj.weight
 | -0.015 | -0.607 |  0.316 |  0.119 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.371 |  0.539 |  0.097 | torch.Size([64, 128]) || m_up2.2.mamba_layers.0.mixer.out_proj.weight
 |  1.245 |  0.939 |  1.393 |  0.097 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.weight
 |  0.008 | -0.510 |  0.450 |  0.163 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.bias
 |  1.919 | -0.504 |  2.883 |  0.766 | torch.Size([128, 16]) || m_up2.2.mamba_layers.1.mixer.A_log
 |  1.150 |  0.792 |  1.461 |  0.097 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.D
 |  0.000 | -0.492 |  0.539 |  0.101 | torch.Size([256, 64]) || m_up2.2.mamba_layers.1.mixer.in_proj.weight
 |  0.011 | -0.651 |  1.011 |  0.203 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.1.mixer.conv1d.weight
 |  0.027 | -0.312 |  0.290 |  0.117 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.493 |  0.573 |  0.101 | torch.Size([36, 128]) || m_up2.2.mamba_layers.1.mixer.x_proj.weight
 |  0.002 | -0.484 |  0.386 |  0.105 | torch.Size([128, 4]) || m_up2.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.053 | -0.216 |  0.601 |  0.110 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.505 |  0.467 |  0.097 | torch.Size([64, 128]) || m_up2.2.mamba_layers.1.mixer.out_proj.weight
 |  1.273 |  0.857 |  1.483 |  0.127 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.weight
 |  0.003 | -0.171 |  0.342 |  0.088 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.bias
 |  1.917 | -0.028 |  2.774 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.2.mixer.A_log
 |  1.015 |  0.954 |  1.124 |  0.030 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.D
 | -0.000 | -0.321 |  0.293 |  0.077 | torch.Size([256, 64]) || m_up2.2.mamba_layers.2.mixer.in_proj.weight
 | -0.004 | -0.557 |  0.541 |  0.288 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.2.mixer.conv1d.weight
 |  0.065 | -0.557 |  0.560 |  0.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.213 |  0.186 |  0.054 | torch.Size([36, 128]) || m_up2.2.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.497 |  0.499 |  0.286 | torch.Size([128, 4]) || m_up2.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.495 | -6.884 | -2.259 |  1.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.277 |  0.259 |  0.064 | torch.Size([64, 128]) || m_up2.2.mamba_layers.2.mixer.out_proj.weight
 |  1.010 |  0.904 |  1.127 |  0.042 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.weight
 |  0.002 | -0.072 |  0.079 |  0.026 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.bias
 |  1.917 | -0.069 |  2.777 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.3.mixer.A_log
 |  1.022 |  0.961 |  1.195 |  0.040 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.D
 |  0.000 | -0.318 |  0.267 |  0.077 | torch.Size([256, 64]) || m_up2.2.mamba_layers.3.mixer.in_proj.weight
 |  0.008 | -0.609 |  0.585 |  0.287 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.3.mixer.conv1d.weight
 |  0.030 | -0.524 |  0.547 |  0.301 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.233 |  0.186 |  0.057 | torch.Size([36, 128]) || m_up2.2.mamba_layers.3.mixer.x_proj.weight
 |  0.004 | -0.568 |  0.579 |  0.290 | torch.Size([128, 4]) || m_up2.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.642 | -6.849 | -2.291 |  1.277 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.dt_proj.bias
 |  0.000 | -0.232 |  0.280 |  0.064 | torch.Size([64, 128]) || m_up2.2.mamba_layers.3.mixer.out_proj.weight
 |  1.010 |  0.913 |  1.117 |  0.042 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.weight
 |  0.003 | -0.068 |  0.065 |  0.026 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.bias
 |  0.309 |  0.187 |  0.430 |  0.172 | torch.Size([2]) || m_up2.2.pcbam_module.h_cw.weight
 |  0.113 | -0.026 |  0.206 |  0.123 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.h_cw.conv.weight
 |  0.821 |  0.758 |  0.884 |  0.089 | torch.Size([2]) || m_up2.2.pcbam_module.w_hc.weight
 |  0.060 | -0.076 |  0.129 |  0.118 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.w_hc.conv.weight
 |  0.737 |  0.713 |  0.762 |  0.035 | torch.Size([2]) || m_up2.2.pcbam_module.c_hw.weight
 |  0.146 |  0.098 |  0.187 |  0.045 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.178 |  0.175 |  0.027 | torch.Size([192, 96, 2, 2]) || m_up1.0.weight
 |  1.177 |  0.801 |  1.393 |  0.189 | torch.Size([32]) || m_up1.1.trans_block.ln1.weight
 | -0.009 | -0.335 |  0.483 |  0.202 | torch.Size([32]) || m_up1.1.trans_block.ln1.bias
 |  0.132 | -1.052 |  0.836 |  0.423 | torch.Size([1, 15, 15]) || m_up1.1.trans_block.msa.relative_position_params
 | -0.000 | -0.412 |  0.367 |  0.104 | torch.Size([96, 32, 1, 1]) || m_up1.1.trans_block.msa.embedding_layer1.weight
 | -0.010 | -0.345 |  0.346 |  0.156 | torch.Size([96]) || m_up1.1.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.271 |  0.239 |  0.073 | torch.Size([32, 32, 1, 1]) || m_up1.1.trans_block.msa.linear1.weight
 |  0.003 | -0.099 |  0.118 |  0.053 | torch.Size([32]) || m_up1.1.trans_block.msa.linear1.bias
 |  1.640 |  1.304 |  1.977 |  0.169 | torch.Size([32]) || m_up1.1.trans_block.ln2.weight
 | -0.005 | -0.307 |  0.292 |  0.175 | torch.Size([32]) || m_up1.1.trans_block.ln2.bias
 |  0.001 | -0.742 |  0.704 |  0.159 | torch.Size([128, 32]) || m_up1.1.trans_block.mlp.0.weight
 | -0.016 | -0.368 |  0.340 |  0.114 | torch.Size([128]) || m_up1.1.trans_block.mlp.0.bias
 | -0.000 | -0.648 |  0.814 |  0.127 | torch.Size([32, 128]) || m_up1.1.trans_block.mlp.2.weight
 | -0.032 | -0.416 |  0.259 |  0.167 | torch.Size([32]) || m_up1.1.trans_block.mlp.2.bias
 | -0.005 | -1.279 |  0.464 |  0.122 | torch.Size([96, 96, 1, 1]) || m_up1.1.conv1_1.weight
 | -0.001 | -0.241 |  0.276 |  0.079 | torch.Size([96]) || m_up1.1.conv1_1.bias
 |  0.020 | -0.254 |  0.396 |  0.337 | torch.Size([1, 1, 1, 1, 3]) || m_up1.1.conv3d.weight
 |  0.002 |  0.002 |  0.002 |    nan | torch.Size([1]) || m_up1.1.conv3d.bias
 | -0.001 | -0.571 |  0.715 |  0.085 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.0.weight
 |  0.000 | -0.610 |  0.792 |  0.093 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.2.weight
 |  1.912 | -0.265 |  2.774 |  0.773 | torch.Size([64, 16]) || m_up1.1.mamba_layers.0.mixer.A_log
 |  1.113 |  0.949 |  1.416 |  0.097 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.D
 | -0.001 | -0.468 |  0.608 |  0.124 | torch.Size([128, 32]) || m_up1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.013 | -0.520 |  0.407 |  0.168 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.0.mixer.conv1d.weight
 | -0.001 | -0.185 |  0.271 |  0.089 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.004 | -0.393 |  0.421 |  0.092 | torch.Size([34, 64]) || m_up1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.011 | -0.519 |  0.299 |  0.129 | torch.Size([64, 2]) || m_up1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.029 | -0.776 |  0.461 |  0.212 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.001 | -0.352 |  0.416 |  0.115 | torch.Size([32, 64]) || m_up1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.202 |  0.985 |  1.390 |  0.118 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.weight
 |  0.001 | -0.220 |  0.136 |  0.072 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.bias
 |  1.906 | -0.980 |  2.773 |  0.783 | torch.Size([64, 16]) || m_up1.1.mamba_layers.1.mixer.A_log
 |  1.176 |  1.062 |  1.330 |  0.056 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.D
 |  0.001 | -0.400 |  0.511 |  0.122 | torch.Size([128, 32]) || m_up1.1.mamba_layers.1.mixer.in_proj.weight
 | -0.008 | -0.489 |  0.367 |  0.155 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.1.mixer.conv1d.weight
 | -0.031 | -0.320 |  0.243 |  0.168 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.381 |  0.282 |  0.069 | torch.Size([34, 64]) || m_up1.1.mamba_layers.1.mixer.x_proj.weight
 | -0.012 | -0.374 |  0.249 |  0.085 | torch.Size([64, 2]) || m_up1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.090 | -0.090 |  0.505 |  0.090 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.004 | -0.603 |  0.486 |  0.128 | torch.Size([32, 64]) || m_up1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.171 |  0.931 |  1.352 |  0.086 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.weight
 |  0.005 | -0.152 |  0.203 |  0.097 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.bias
 |  1.916 | -0.065 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.2.mixer.A_log
 |  1.035 |  0.952 |  1.174 |  0.042 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.D
 | -0.002 | -0.349 |  0.357 |  0.112 | torch.Size([128, 32]) || m_up1.1.mamba_layers.2.mixer.in_proj.weight
 |  0.011 | -0.625 |  0.692 |  0.294 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.2.mixer.conv1d.weight
 |  0.007 | -0.517 |  0.487 |  0.303 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.213 |  0.240 |  0.082 | torch.Size([34, 64]) || m_up1.1.mamba_layers.2.mixer.x_proj.weight
 | -0.082 | -0.708 |  0.700 |  0.396 | torch.Size([64, 2]) || m_up1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.429 | -6.865 | -2.310 |  1.242 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.334 |  0.259 |  0.086 | torch.Size([32, 64]) || m_up1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.026 |  0.966 |  1.096 |  0.028 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.weight
 | -0.004 | -0.042 |  0.034 |  0.022 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.bias
 |  1.913 | -0.037 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.3.mixer.A_log
 |  1.027 |  0.965 |  1.117 |  0.034 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.265 |  0.315 |  0.107 | torch.Size([128, 32]) || m_up1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.011 | -0.514 |  0.564 |  0.295 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.3.mixer.conv1d.weight
 | -0.005 | -0.546 |  0.538 |  0.325 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.206 |  0.234 |  0.083 | torch.Size([34, 64]) || m_up1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.750 |  0.694 |  0.409 | torch.Size([64, 2]) || m_up1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.497 | -6.875 | -2.319 |  1.352 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.003 | -0.246 |  0.249 |  0.084 | torch.Size([32, 64]) || m_up1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.015 |  0.949 |  1.065 |  0.028 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.weight
 | -0.002 | -0.042 |  0.062 |  0.021 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.bias
 |  0.533 |  0.169 |  0.896 |  0.514 | torch.Size([2]) || m_up1.1.pcbam_module.h_cw.weight
 | -0.028 | -0.107 |  0.094 |  0.107 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.h_cw.conv.weight
 |  0.068 |  0.002 |  0.134 |  0.093 | torch.Size([2]) || m_up1.1.pcbam_module.w_hc.weight
 | -0.115 | -0.242 |  0.043 |  0.145 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.w_hc.conv.weight
 |  0.449 |  0.107 |  0.791 |  0.484 | torch.Size([2]) || m_up1.1.pcbam_module.c_hw.weight
 |  0.015 | -0.251 |  0.345 |  0.304 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.c_hw.conv.weight
 |  1.259 |  0.956 |  1.576 |  0.162 | torch.Size([32]) || m_up1.2.trans_block.ln1.weight
 |  0.011 | -0.395 |  0.459 |  0.171 | torch.Size([32]) || m_up1.2.trans_block.ln1.bias
 | -0.143 | -0.850 |  0.643 |  0.354 | torch.Size([1, 15, 15]) || m_up1.2.trans_block.msa.relative_position_params
 | -0.001 | -0.592 |  0.655 |  0.142 | torch.Size([96, 32, 1, 1]) || m_up1.2.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.217 |  0.139 |  0.041 | torch.Size([96]) || m_up1.2.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.157 |  0.161 |  0.047 | torch.Size([32, 32, 1, 1]) || m_up1.2.trans_block.msa.linear1.weight
 |  0.001 | -0.105 |  0.112 |  0.039 | torch.Size([32]) || m_up1.2.trans_block.msa.linear1.bias
 |  1.009 |  0.826 |  1.195 |  0.089 | torch.Size([32]) || m_up1.2.trans_block.ln2.weight
 | -0.005 | -0.150 |  0.195 |  0.075 | torch.Size([32]) || m_up1.2.trans_block.ln2.bias
 |  0.001 | -0.563 |  0.424 |  0.079 | torch.Size([128, 32]) || m_up1.2.trans_block.mlp.0.weight
 | -0.005 | -0.202 |  0.093 |  0.047 | torch.Size([128]) || m_up1.2.trans_block.mlp.0.bias
 | -0.001 | -0.341 |  0.371 |  0.085 | torch.Size([32, 128]) || m_up1.2.trans_block.mlp.2.weight
 | -0.003 | -0.105 |  0.207 |  0.057 | torch.Size([32]) || m_up1.2.trans_block.mlp.2.bias
 | -0.001 | -0.746 |  0.505 |  0.105 | torch.Size([96, 96, 1, 1]) || m_up1.2.conv1_1.weight
 | -0.002 | -0.225 |  0.383 |  0.064 | torch.Size([96]) || m_up1.2.conv1_1.bias
 |  0.103 | -0.055 |  0.356 |  0.221 | torch.Size([1, 1, 1, 1, 3]) || m_up1.2.conv3d.weight
 |  0.005 |  0.005 |  0.005 |    nan | torch.Size([1]) || m_up1.2.conv3d.bias
 |  0.002 | -0.323 |  0.610 |  0.079 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.0.weight
 | -0.000 | -0.555 |  0.757 |  0.095 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.2.weight
 |  1.913 | -0.746 |  2.773 |  0.775 | torch.Size([64, 16]) || m_up1.2.mamba_layers.0.mixer.A_log
 |  1.120 |  0.987 |  1.403 |  0.076 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.D
 |  0.001 | -0.492 |  0.513 |  0.123 | torch.Size([128, 32]) || m_up1.2.mamba_layers.0.mixer.in_proj.weight
 | -0.004 | -0.389 |  0.437 |  0.164 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.0.mixer.conv1d.weight
 |  0.006 | -0.089 |  0.131 |  0.050 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.528 |  0.348 |  0.102 | torch.Size([34, 64]) || m_up1.2.mamba_layers.0.mixer.x_proj.weight
 | -0.001 | -0.097 |  0.143 |  0.040 | torch.Size([64, 2]) || m_up1.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.028 | -0.378 |  0.653 |  0.187 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.352 |  0.395 |  0.110 | torch.Size([32, 64]) || m_up1.2.mamba_layers.0.mixer.out_proj.weight
 |  1.253 |  0.900 |  1.446 |  0.113 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.weight
 |  0.014 | -0.223 |  0.275 |  0.105 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.bias
 |  1.913 | -0.540 |  2.783 |  0.778 | torch.Size([64, 16]) || m_up1.2.mamba_layers.1.mixer.A_log
 |  1.193 |  0.974 |  1.458 |  0.106 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.D
 |  0.001 | -0.624 |  0.624 |  0.139 | torch.Size([128, 32]) || m_up1.2.mamba_layers.1.mixer.in_proj.weight
 |  0.012 | -0.574 |  0.689 |  0.185 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.1.mixer.conv1d.weight
 |  0.018 | -0.238 |  0.220 |  0.102 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.conv1d.bias
 |  0.001 | -0.540 |  0.579 |  0.122 | torch.Size([34, 64]) || m_up1.2.mamba_layers.1.mixer.x_proj.weight
 | -0.048 | -0.482 |  0.250 |  0.154 | torch.Size([64, 2]) || m_up1.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.042 | -0.451 |  0.549 |  0.160 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.dt_proj.bias
 | -0.002 | -0.732 |  0.578 |  0.146 | torch.Size([32, 64]) || m_up1.2.mamba_layers.1.mixer.out_proj.weight
 |  1.227 |  0.943 |  1.396 |  0.105 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.weight
 |  0.005 | -0.113 |  0.106 |  0.049 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.bias
 |  1.917 | -0.069 |  2.777 |  0.765 | torch.Size([64, 16]) || m_up1.2.mamba_layers.2.mixer.A_log
 |  1.014 |  0.955 |  1.170 |  0.043 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.D
 |  0.000 | -0.336 |  0.312 |  0.108 | torch.Size([128, 32]) || m_up1.2.mamba_layers.2.mixer.in_proj.weight
 | -0.022 | -0.580 |  0.575 |  0.281 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.2.mixer.conv1d.weight
 |  0.010 | -0.524 |  0.522 |  0.322 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.227 |  0.224 |  0.076 | torch.Size([34, 64]) || m_up1.2.mamba_layers.2.mixer.x_proj.weight
 |  0.070 | -0.709 |  0.670 |  0.392 | torch.Size([64, 2]) || m_up1.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.717 | -6.818 | -2.344 |  1.385 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.002 | -0.329 |  0.300 |  0.086 | torch.Size([32, 64]) || m_up1.2.mamba_layers.2.mixer.out_proj.weight
 |  1.009 |  0.916 |  1.089 |  0.042 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.weight
 |  0.001 | -0.039 |  0.026 |  0.018 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.bias
 |  1.916 | -0.057 |  2.776 |  0.766 | torch.Size([64, 16]) || m_up1.2.mamba_layers.3.mixer.A_log
 |  1.007 |  0.942 |  1.114 |  0.035 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.D
 | -0.002 | -0.361 |  0.428 |  0.109 | torch.Size([128, 32]) || m_up1.2.mamba_layers.3.mixer.in_proj.weight
 |  0.012 | -0.638 |  0.544 |  0.296 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.3.mixer.conv1d.weight
 |  0.083 | -0.442 |  0.552 |  0.280 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.conv1d.bias
 | -0.004 | -0.238 |  0.253 |  0.077 | torch.Size([34, 64]) || m_up1.2.mamba_layers.3.mixer.x_proj.weight
 | -0.115 | -0.707 |  0.686 |  0.390 | torch.Size([64, 2]) || m_up1.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.758 | -6.877 | -2.275 |  1.309 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.002 | -0.392 |  0.276 |  0.088 | torch.Size([32, 64]) || m_up1.2.mamba_layers.3.mixer.out_proj.weight
 |  1.018 |  0.968 |  1.186 |  0.043 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.weight
 | -0.002 | -0.043 |  0.055 |  0.018 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.bias
 |  0.666 |  0.459 |  0.874 |  0.294 | torch.Size([2]) || m_up1.2.pcbam_module.h_cw.weight
 |  0.147 |  0.087 |  0.185 |  0.053 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.h_cw.conv.weight
 |  0.182 |  0.079 |  0.285 |  0.146 | torch.Size([2]) || m_up1.2.pcbam_module.w_hc.weight
 | -0.014 | -0.144 |  0.210 |  0.194 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.w_hc.conv.weight
 |  0.236 |  0.093 |  0.378 |  0.201 | torch.Size([2]) || m_up1.2.pcbam_module.c_hw.weight
 |  0.078 | -0.043 |  0.183 |  0.114 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.c_hw.conv.weight
 |  0.000 | -0.061 |  0.067 |  0.014 | torch.Size([3, 96, 3, 3]) || m_tail.0.weight
 | -0.029 | -0.131 |  0.157 |  0.083 | torch.Size([3, 3, 1, 1]) || fft.mag.weight
 |  0.178 | -0.197 |  0.457 |  0.338 | torch.Size([3]) || fft.mag.bias
 |  0.162 |  0.028 |  0.320 |  0.148 | torch.Size([3]) || fft.mag_bn.weight
 | -0.796 | -2.134 | -0.114 |  1.159 | torch.Size([3]) || fft.mag_bn.bias
 | -2.340 | -7.169 |  3.582 |  5.458 | torch.Size([3]) || fft.mag_bn.running_mean
 | 440.826 | 196.210 | 869.354 | 372.355 | torch.Size([3]) || fft.mag_bn.running_var
 |  0.010 | -0.300 |  0.165 |  0.157 | torch.Size([3, 3, 1, 1]) || fft.pha.0.weight
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.0.bias
 |  1.177 |  0.834 |  1.432 |  0.308 | torch.Size([3]) || fft.pha.1.weight
 |  0.324 |  0.205 |  0.396 |  0.104 | torch.Size([3]) || fft.pha.1.bias
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.1.running_mean
 |  0.026 |  0.017 |  0.038 |  0.011 | torch.Size([3]) || fft.pha.1.running_var
 | -0.086 | -0.660 |  0.867 |  0.494 | torch.Size([3, 3, 1, 1]) || fft.pha.3.weight
 |  0.009 | -0.146 |  0.139 |  0.144 | torch.Size([3]) || fft.pha.3.bias
 |  0.311 | -0.158 |  2.024 |  0.841 | torch.Size([1, 6, 1, 1]) || fft.conv1.weight
 |  0.029 |  0.029 |  0.029 |    nan | torch.Size([1]) || fft.conv1.bias
 | -0.001 | -0.085 |  0.074 |  0.023 | torch.Size([96, 96, 1, 1]) || conv1.weight
 | -0.000 | -0.016 |  0.021 |  0.005 | torch.Size([96]) || conv1.bias
 |  0.415 |  0.004 |  0.891 |  0.224 | torch.Size([96]) || bn1.weight
 | -0.088 | -0.192 | -0.011 |  0.040 | torch.Size([96]) || bn1.bias
 | -0.002 | -0.042 |  0.056 |  0.028 | torch.Size([96]) || bn1.running_mean
 |  0.001 |  0.000 |  0.005 |  0.001 | torch.Size([96]) || bn1.running_var
 | -0.002 | -0.065 |  0.059 |  0.014 | torch.Size([192, 96, 2, 2]) || conv2.weight
 | -0.000 | -0.011 |  0.012 |  0.004 | torch.Size([192]) || conv2.bias
 |  0.415 |  0.019 |  0.895 |  0.226 | torch.Size([192]) || bn2.weight
 | -0.079 | -0.207 | -0.008 |  0.039 | torch.Size([192]) || bn2.bias
 | -0.025 | -0.117 |  0.091 |  0.047 | torch.Size([192]) || bn2.running_mean
 |  0.019 |  0.000 |  0.060 |  0.011 | torch.Size([192]) || bn2.running_var
 | -0.001 | -0.044 |  0.041 |  0.007 | torch.Size([384, 96, 4, 4]) || conv3.weight
 | -0.000 | -0.022 |  0.014 |  0.005 | torch.Size([384]) || conv3.bias
 |  0.439 |  0.046 |  0.919 |  0.222 | torch.Size([384]) || bn3.weight
 | -0.069 | -0.198 |  0.026 |  0.035 | torch.Size([384]) || bn3.bias
 | -0.063 | -0.188 |  0.156 |  0.042 | torch.Size([384]) || bn3.running_mean
 |  0.049 |  0.002 |  0.182 |  0.025 | torch.Size([384]) || bn3.running_var

25-05-14 19:30:04.221 : <epoch: 12, iter:   5,000, lr:2.000e-05> G_loss: 4.170e-06 
25-05-14 19:30:04.227 : Saving the model.
25-05-14 19:30:05.088 : ---1--> airplane_111.jpg | 32.60dB
25-05-14 19:30:05.259 : ---2--> airport_111.jpg | 32.97dB
25-05-14 19:30:05.434 : ---3--> baseball_diamond_111.jpg | 33.66dB
25-05-14 19:30:05.616 : ---4--> basketball_court_111.jpg | 31.32dB
25-05-14 19:30:05.801 : ---5--> beach_111.jpg | 30.53dB
25-05-14 19:30:05.972 : ---6--> bridge_111.jpg | 35.51dB
25-05-14 19:30:06.148 : ---7--> chaparral_111.jpg | 30.04dB
25-05-14 19:30:06.318 : ---8--> church_111.jpg | 31.54dB
25-05-14 19:30:06.492 : ---9--> circular_farmland_111.jpg | 33.80dB
25-05-14 19:30:06.660 : --10--> cloud_111.jpg | 37.36dB
25-05-14 19:30:06.829 : --11--> commercial_area_111.jpg | 33.05dB
25-05-14 19:30:06.998 : --12--> dense_residential_111.jpg | 29.59dB
25-05-14 19:30:07.175 : --13--> desert_111.jpg | 36.99dB
25-05-14 19:30:07.343 : --14--> forest_111.jpg | 32.30dB
25-05-14 19:30:07.517 : --15--> freeway_111.jpg | 34.66dB
25-05-14 19:30:07.683 : --16--> golf_course_111.jpg | 33.07dB
25-05-14 19:30:07.849 : --17--> ground_track_field_111.jpg | 30.59dB
25-05-14 19:30:08.016 : --18--> harbor_111.jpg | 31.73dB
25-05-14 19:30:08.182 : --19--> industrial_area_111.jpg | 31.63dB
25-05-14 19:30:08.355 : --20--> intersection_111.jpg | 30.57dB
25-05-14 19:30:08.533 : --21--> island_111.jpg | 32.35dB
25-05-14 19:30:08.713 : --22--> lake_111.jpg | 31.87dB
25-05-14 19:30:08.894 : --23--> meadow_111.jpg | 30.10dB
25-05-14 19:30:09.076 : --24--> medium_residential_111.jpg | 28.54dB
25-05-14 19:30:09.245 : --25--> mobile_home_park_111.jpg | 31.52dB
25-05-14 19:30:09.416 : --26--> mountain_111.jpg | 29.30dB
25-05-14 19:30:09.588 : --27--> overpass_111.jpg | 30.48dB
25-05-14 19:30:09.767 : --28--> palace_111.jpg | 29.95dB
25-05-14 19:30:09.938 : --29--> parking_lot_111.jpg | 29.89dB
25-05-14 19:30:10.107 : --30--> railway_111.jpg | 30.16dB
25-05-14 19:30:10.276 : --31--> railway_station_111.jpg | 31.23dB
25-05-14 19:30:10.446 : --32--> rectangular_farmland_111.jpg | 33.36dB
25-05-14 19:30:10.620 : --33--> river_111.jpg | 30.12dB
25-05-14 19:30:10.789 : --34--> roundabout_111.jpg | 30.93dB
25-05-14 19:30:10.965 : --35--> runway_111.jpg | 36.66dB
25-05-14 19:30:11.135 : --36--> sea_ice_111.jpg | 34.17dB
25-05-14 19:30:11.314 : --37--> ship_111.jpg | 38.12dB
25-05-14 19:30:11.490 : --38--> snowberg_111.jpg | 32.54dB
25-05-14 19:30:11.662 : --39--> sparse_residential_111.jpg | 30.14dB
25-05-14 19:30:11.832 : --40--> stadium_111.jpg | 30.44dB
25-05-14 19:30:12.000 : --41--> storage_tank_111.jpg | 31.50dB
25-05-14 19:30:12.168 : --42--> tennis_court_111.jpg | 31.18dB
25-05-14 19:30:12.333 : --43--> terrace_111.jpg | 32.54dB
25-05-14 19:30:12.515 : --44--> thermal_power_station_111.jpg | 30.45dB
25-05-14 19:30:12.697 : --45--> wetland_111.jpg | 31.28dB
25-05-14 19:30:12.716 : <epoch: 12, iter:   5,000, Average PSNR : 32.05dB

25-05-14 20:15:08.842 : <epoch: 25, iter:  10,000, lr:2.000e-05> G_loss: 4.468e-05 
25-05-14 20:15:08.844 : Saving the model.
25-05-14 20:15:09.685 : ---1--> airplane_111.jpg | 32.57dB
25-05-14 20:15:09.852 : ---2--> airport_111.jpg | 32.95dB
25-05-14 20:15:10.016 : ---3--> baseball_diamond_111.jpg | 33.65dB
25-05-14 20:15:10.183 : ---4--> basketball_court_111.jpg | 31.31dB
25-05-14 20:15:10.354 : ---5--> beach_111.jpg | 30.51dB
25-05-14 20:15:10.522 : ---6--> bridge_111.jpg | 35.50dB
25-05-14 20:15:10.693 : ---7--> chaparral_111.jpg | 30.03dB
25-05-14 20:15:10.863 : ---8--> church_111.jpg | 31.50dB
25-05-14 20:15:11.035 : ---9--> circular_farmland_111.jpg | 33.79dB
25-05-14 20:15:11.221 : --10--> cloud_111.jpg | 37.35dB
25-05-14 20:15:11.396 : --11--> commercial_area_111.jpg | 33.04dB
25-05-14 20:15:11.583 : --12--> dense_residential_111.jpg | 29.56dB
25-05-14 20:15:11.767 : --13--> desert_111.jpg | 36.96dB
25-05-14 20:15:11.946 : --14--> forest_111.jpg | 32.28dB
25-05-14 20:15:12.128 : --15--> freeway_111.jpg | 34.63dB
25-05-14 20:15:12.302 : --16--> golf_course_111.jpg | 33.05dB
25-05-14 20:15:12.480 : --17--> ground_track_field_111.jpg | 30.57dB
25-05-14 20:15:12.659 : --18--> harbor_111.jpg | 31.71dB
25-05-14 20:15:12.846 : --19--> industrial_area_111.jpg | 31.60dB
25-05-14 20:15:13.025 : --20--> intersection_111.jpg | 30.55dB
25-05-14 20:15:13.200 : --21--> island_111.jpg | 32.34dB
25-05-14 20:15:13.378 : --22--> lake_111.jpg | 31.85dB
25-05-14 20:15:13.550 : --23--> meadow_111.jpg | 30.09dB
25-05-14 20:15:13.733 : --24--> medium_residential_111.jpg | 28.50dB
25-05-14 20:15:13.918 : --25--> mobile_home_park_111.jpg | 31.50dB
25-05-14 20:15:14.102 : --26--> mountain_111.jpg | 29.28dB
25-05-14 20:15:14.278 : --27--> overpass_111.jpg | 30.43dB
25-05-14 20:15:14.462 : --28--> palace_111.jpg | 29.94dB
25-05-14 20:15:14.637 : --29--> parking_lot_111.jpg | 29.84dB
25-05-14 20:15:14.829 : --30--> railway_111.jpg | 30.13dB
25-05-14 20:15:15.013 : --31--> railway_station_111.jpg | 31.21dB
25-05-14 20:15:15.194 : --32--> rectangular_farmland_111.jpg | 33.35dB
25-05-14 20:15:15.386 : --33--> river_111.jpg | 30.11dB
25-05-14 20:15:15.557 : --34--> roundabout_111.jpg | 30.89dB
25-05-14 20:15:15.735 : --35--> runway_111.jpg | 36.64dB
25-05-14 20:15:15.923 : --36--> sea_ice_111.jpg | 34.13dB
25-05-14 20:15:16.102 : --37--> ship_111.jpg | 38.12dB
25-05-14 20:15:16.285 : --38--> snowberg_111.jpg | 32.52dB
25-05-14 20:15:16.474 : --39--> sparse_residential_111.jpg | 30.13dB
25-05-14 20:15:16.666 : --40--> stadium_111.jpg | 30.43dB
25-05-14 20:15:16.847 : --41--> storage_tank_111.jpg | 31.50dB
25-05-14 20:15:17.027 : --42--> tennis_court_111.jpg | 31.13dB
25-05-14 20:15:17.194 : --43--> terrace_111.jpg | 32.52dB
25-05-14 20:15:17.373 : --44--> thermal_power_station_111.jpg | 30.44dB
25-05-14 20:15:17.548 : --45--> wetland_111.jpg | 31.27dB
25-05-14 20:15:17.563 : <epoch: 25, iter:  10,000, Average PSNR : 32.03dB

25-05-15 09:20:48.978 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/13_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/RICE1
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 15
      sigma_test: 15
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 15
      sigma_test: 15
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-15 09:20:48.979 : Random seed: 6268
25-05-15 09:20:48.994 : Number of train images: 385, iters: 385
25-05-15 09:20:52.096 : 
Networks name: DRNet
Params number: 18333721
Net structure:
DRNet(
  (m_head): Sequential(
    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (m_down1): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down2): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down3): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_body): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up3): Sequential(
    (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up2): Sequential(
    (0): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up1): Sequential(
    (0): ConvTranspose2d(192, 96, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_tail): Sequential(
    (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (fft): ResBlock_fft_bench(
    (mag): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
    (mag_bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (mag_relu): ReLU(inplace=True)
    (pha): Sequential(
      (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (4): Sigmoid()
    )
    (conv1): Conv2d(6, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
  (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (conv2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
  (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu2): ReLU()
  (conv3): Conv2d(96, 384, kernel_size=(4, 4), stride=(4, 4))
  (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu3): ReLU()
)

25-05-15 09:20:52.928 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.001 | -0.175 |  0.200 |  0.043 | torch.Size([96, 3, 3, 3]) || m_head.0.weight
 |  0.987 |  0.660 |  1.331 |  0.161 | torch.Size([32]) || m_down1.0.trans_block.ln1.weight
 | -0.029 | -0.287 |  0.309 |  0.141 | torch.Size([32]) || m_down1.0.trans_block.ln1.bias
 | -0.078 | -0.697 |  0.996 |  0.367 | torch.Size([1, 15, 15]) || m_down1.0.trans_block.msa.relative_position_params
 |  0.000 | -0.306 |  0.340 |  0.061 | torch.Size([96, 32, 1, 1]) || m_down1.0.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.126 |  0.122 |  0.055 | torch.Size([96]) || m_down1.0.trans_block.msa.embedding_layer1.bias
 |  0.003 | -0.181 |  0.211 |  0.052 | torch.Size([32, 32, 1, 1]) || m_down1.0.trans_block.msa.linear1.weight
 |  0.008 | -0.087 |  0.126 |  0.059 | torch.Size([32]) || m_down1.0.trans_block.msa.linear1.bias
 |  1.183 |  0.995 |  1.457 |  0.126 | torch.Size([32]) || m_down1.0.trans_block.ln2.weight
 | -0.012 | -0.173 |  0.141 |  0.061 | torch.Size([32]) || m_down1.0.trans_block.ln2.bias
 |  0.005 | -0.539 |  1.337 |  0.115 | torch.Size([128, 32]) || m_down1.0.trans_block.mlp.0.weight
 | -0.023 | -0.193 |  0.157 |  0.072 | torch.Size([128]) || m_down1.0.trans_block.mlp.0.bias
 | -0.001 | -0.498 |  0.763 |  0.088 | torch.Size([32, 128]) || m_down1.0.trans_block.mlp.2.weight
 |  0.000 | -0.123 |  0.322 |  0.096 | torch.Size([32]) || m_down1.0.trans_block.mlp.2.bias
 |  0.007 | -0.513 |  0.480 |  0.098 | torch.Size([96, 96, 1, 1]) || m_down1.0.conv1_1.weight
 | -0.000 | -0.450 |  0.422 |  0.109 | torch.Size([96]) || m_down1.0.conv1_1.bias
 | -0.083 | -0.171 |  0.001 |  0.086 | torch.Size([1, 1, 1, 1, 3]) || m_down1.0.conv3d.weight
 | -0.019 | -0.019 | -0.019 |    nan | torch.Size([1]) || m_down1.0.conv3d.bias
 |  0.006 | -0.351 |  0.450 |  0.073 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.0.weight
 | -0.003 | -0.462 |  0.370 |  0.072 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.2.weight
 |  1.906 | -2.375 |  2.825 |  0.814 | torch.Size([64, 16]) || m_down1.0.mamba_layers.0.mixer.A_log
 |  1.080 |  0.335 |  1.366 |  0.177 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.D
 | -0.000 | -0.472 |  0.518 |  0.121 | torch.Size([128, 32]) || m_down1.0.mamba_layers.0.mixer.in_proj.weight
 |  0.001 | -0.451 |  0.468 |  0.166 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.0.mixer.conv1d.weight
 | -0.010 | -0.240 |  0.194 |  0.097 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.921 |  0.734 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.0.mixer.x_proj.weight
 |  0.004 | -0.791 |  1.048 |  0.250 | torch.Size([64, 2]) || m_down1.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.078 | -1.700 |  0.446 |  0.386 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.663 |  0.579 |  0.116 | torch.Size([32, 64]) || m_down1.0.mamba_layers.0.mixer.out_proj.weight
 |  1.126 |  0.901 |  1.630 |  0.129 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.weight
 |  0.014 | -0.392 |  0.312 |  0.163 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.bias
 |  1.905 | -0.803 |  2.773 |  0.795 | torch.Size([64, 16]) || m_down1.0.mamba_layers.1.mixer.A_log
 |  1.161 |  0.902 |  1.358 |  0.086 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.D
 |  0.001 | -0.592 |  0.466 |  0.128 | torch.Size([128, 32]) || m_down1.0.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.375 |  0.488 |  0.159 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.1.mixer.conv1d.weight
 | -0.003 | -0.307 |  0.272 |  0.168 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.565 |  0.739 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.1.mixer.x_proj.weight
 |  0.014 | -0.295 |  0.482 |  0.148 | torch.Size([64, 2]) || m_down1.0.mamba_layers.1.mixer.dt_proj.weight
 |  0.051 | -0.349 |  0.267 |  0.126 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.002 | -0.370 |  0.431 |  0.119 | torch.Size([32, 64]) || m_down1.0.mamba_layers.1.mixer.out_proj.weight
 |  1.169 |  0.987 |  1.348 |  0.100 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.weight
 | -0.005 | -0.265 |  0.353 |  0.141 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.bias
 |  1.917 | -0.076 |  2.775 |  0.765 | torch.Size([64, 16]) || m_down1.0.mamba_layers.2.mixer.A_log
 |  1.015 |  0.929 |  1.117 |  0.039 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.D
 |  0.000 | -0.336 |  0.347 |  0.107 | torch.Size([128, 32]) || m_down1.0.mamba_layers.2.mixer.in_proj.weight
 | -0.011 | -0.588 |  0.582 |  0.292 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.2.mixer.conv1d.weight
 | -0.032 | -0.507 |  0.490 |  0.285 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.221 |  0.197 |  0.076 | torch.Size([34, 64]) || m_down1.0.mamba_layers.2.mixer.x_proj.weight
 | -0.055 | -0.706 |  0.714 |  0.417 | torch.Size([64, 2]) || m_down1.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.715 | -6.856 | -2.310 |  1.285 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.dt_proj.bias
 | -0.003 | -0.250 |  0.275 |  0.085 | torch.Size([32, 64]) || m_down1.0.mamba_layers.2.mixer.out_proj.weight
 |  0.997 |  0.908 |  1.102 |  0.039 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.weight
 |  0.006 | -0.042 |  0.062 |  0.024 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.bias
 |  1.916 | -0.288 |  2.776 |  0.766 | torch.Size([64, 16]) || m_down1.0.mamba_layers.3.mixer.A_log
 |  1.008 |  0.930 |  1.107 |  0.037 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.D
 |  0.003 | -0.277 |  0.272 |  0.106 | torch.Size([128, 32]) || m_down1.0.mamba_layers.3.mixer.in_proj.weight
 |  0.003 | -0.595 |  0.551 |  0.295 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.3.mixer.conv1d.weight
 | -0.073 | -0.633 |  0.543 |  0.307 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.209 |  0.225 |  0.077 | torch.Size([34, 64]) || m_down1.0.mamba_layers.3.mixer.x_proj.weight
 |  0.039 | -0.688 |  0.780 |  0.425 | torch.Size([64, 2]) || m_down1.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.400 | -7.109 | -2.270 |  1.483 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.242 |  0.301 |  0.084 | torch.Size([32, 64]) || m_down1.0.mamba_layers.3.mixer.out_proj.weight
 |  0.992 |  0.929 |  1.040 |  0.027 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.weight
 | -0.004 | -0.050 |  0.035 |  0.021 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.bias
 |  0.172 |  0.082 |  0.262 |  0.127 | torch.Size([2]) || m_down1.0.pcbam_module.h_cw.weight
 |  0.077 | -0.087 |  0.186 |  0.145 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.h_cw.conv.weight
 |  0.561 |  0.266 |  0.856 |  0.418 | torch.Size([2]) || m_down1.0.pcbam_module.w_hc.weight
 |  0.077 | -0.128 |  0.187 |  0.178 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.w_hc.conv.weight
 |  0.613 |  0.589 |  0.638 |  0.034 | torch.Size([2]) || m_down1.0.pcbam_module.c_hw.weight
 |  0.046 | -0.255 |  0.385 |  0.322 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.c_hw.conv.weight
 |  1.047 |  0.723 |  1.284 |  0.157 | torch.Size([32]) || m_down1.1.trans_block.ln1.weight
 |  0.022 | -0.321 |  0.299 |  0.146 | torch.Size([32]) || m_down1.1.trans_block.ln1.bias
 | -0.224 | -0.785 |  0.840 |  0.324 | torch.Size([1, 15, 15]) || m_down1.1.trans_block.msa.relative_position_params
 |  0.001 | -0.389 |  0.378 |  0.091 | torch.Size([96, 32, 1, 1]) || m_down1.1.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.192 |  0.185 |  0.052 | torch.Size([96]) || m_down1.1.trans_block.msa.embedding_layer1.bias
 | -0.002 | -0.207 |  0.203 |  0.054 | torch.Size([32, 32, 1, 1]) || m_down1.1.trans_block.msa.linear1.weight
 |  0.001 | -0.174 |  0.116 |  0.058 | torch.Size([32]) || m_down1.1.trans_block.msa.linear1.bias
 |  1.159 |  0.962 |  1.324 |  0.078 | torch.Size([32]) || m_down1.1.trans_block.ln2.weight
 |  0.000 | -0.130 |  0.189 |  0.072 | torch.Size([32]) || m_down1.1.trans_block.ln2.bias
 | -0.001 | -0.971 |  0.583 |  0.116 | torch.Size([128, 32]) || m_down1.1.trans_block.mlp.0.weight
 | -0.012 | -0.254 |  0.114 |  0.055 | torch.Size([128]) || m_down1.1.trans_block.mlp.0.bias
 | -0.000 | -0.671 |  0.674 |  0.099 | torch.Size([32, 128]) || m_down1.1.trans_block.mlp.2.weight
 | -0.005 | -0.128 |  0.227 |  0.083 | torch.Size([32]) || m_down1.1.trans_block.mlp.2.bias
 |  0.008 | -0.460 |  0.572 |  0.100 | torch.Size([96, 96, 1, 1]) || m_down1.1.conv1_1.weight
 | -0.007 | -0.190 |  0.290 |  0.062 | torch.Size([96]) || m_down1.1.conv1_1.bias
 | -0.075 | -0.281 |  0.031 |  0.178 | torch.Size([1, 1, 1, 1, 3]) || m_down1.1.conv3d.weight
 | -0.007 | -0.007 | -0.007 |    nan | torch.Size([1]) || m_down1.1.conv3d.bias
 | -0.002 | -0.396 |  0.350 |  0.065 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.0.weight
 | -0.006 | -0.313 |  0.296 |  0.065 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.2.weight
 |  1.917 | -0.011 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.0.mixer.A_log
 |  1.048 |  0.985 |  1.173 |  0.047 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.D
 | -0.000 | -0.452 |  0.447 |  0.086 | torch.Size([128, 32]) || m_down1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.014 | -0.310 |  0.347 |  0.115 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.0.mixer.conv1d.weight
 |  0.015 | -0.205 |  0.218 |  0.064 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.143 |  0.135 |  0.031 | torch.Size([34, 64]) || m_down1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.002 | -0.062 |  0.053 |  0.025 | torch.Size([64, 2]) || m_down1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.001 | -0.024 |  0.032 |  0.009 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.371 |  0.361 |  0.083 | torch.Size([32, 64]) || m_down1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.116 |  0.916 |  1.300 |  0.106 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.weight
 |  0.012 | -0.169 |  0.191 |  0.080 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.bias
 |  1.918 | -0.212 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.1.mixer.A_log
 |  1.091 |  0.987 |  1.483 |  0.090 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.D
 |  0.000 | -0.628 |  0.637 |  0.095 | torch.Size([128, 32]) || m_down1.1.mamba_layers.1.mixer.in_proj.weight
 |  0.001 | -0.337 |  0.387 |  0.127 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.1.mixer.conv1d.weight
 |  0.002 | -0.197 |  0.192 |  0.089 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.001 | -0.185 |  0.297 |  0.049 | torch.Size([34, 64]) || m_down1.1.mamba_layers.1.mixer.x_proj.weight
 |  0.006 | -0.152 |  0.156 |  0.037 | torch.Size([64, 2]) || m_down1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.008 | -0.161 |  0.452 |  0.077 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.004 | -0.546 |  0.368 |  0.087 | torch.Size([32, 64]) || m_down1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.136 |  1.025 |  1.302 |  0.076 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.weight
 | -0.002 | -0.095 |  0.090 |  0.052 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.bias
 |  1.917 | -0.018 |  2.774 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.2.mixer.A_log
 |  1.001 |  0.959 |  1.048 |  0.022 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.D
 | -0.001 | -0.233 |  0.264 |  0.106 | torch.Size([128, 32]) || m_down1.1.mamba_layers.2.mixer.in_proj.weight
 | -0.022 | -0.509 |  0.513 |  0.285 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.2.mixer.conv1d.weight
 | -0.017 | -0.508 |  0.444 |  0.282 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.150 |  0.153 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.2.mixer.x_proj.weight
 |  0.092 | -0.700 |  0.704 |  0.396 | torch.Size([64, 2]) || m_down1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.418 | -6.864 | -2.343 |  1.239 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.259 |  0.279 |  0.077 | torch.Size([32, 64]) || m_down1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.000 |  0.960 |  1.041 |  0.024 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.weight
 |  0.002 | -0.040 |  0.032 |  0.017 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.bias
 |  1.917 | -0.045 |  2.777 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.3.mixer.A_log
 |  1.008 |  0.964 |  1.080 |  0.028 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.298 |  0.349 |  0.110 | torch.Size([128, 32]) || m_down1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.024 | -0.512 |  0.552 |  0.300 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.3.mixer.conv1d.weight
 |  0.050 | -0.424 |  0.517 |  0.242 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.166 |  0.183 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.694 |  0.699 |  0.380 | torch.Size([64, 2]) || m_down1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.585 | -6.892 | -2.263 |  1.350 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.002 | -0.232 |  0.284 |  0.080 | torch.Size([32, 64]) || m_down1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.029 |  0.951 |  1.119 |  0.040 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.weight
 | -0.001 | -0.048 |  0.061 |  0.031 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.bias
 |  0.147 |  0.115 |  0.180 |  0.046 | torch.Size([2]) || m_down1.1.pcbam_module.h_cw.weight
 |  0.199 |  0.033 |  0.468 |  0.235 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.h_cw.conv.weight
 |  0.368 |  0.181 |  0.554 |  0.264 | torch.Size([2]) || m_down1.1.pcbam_module.w_hc.weight
 |  0.247 |  0.094 |  0.417 |  0.162 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.w_hc.conv.weight
 |  0.722 |  0.569 |  0.875 |  0.216 | torch.Size([2]) || m_down1.1.pcbam_module.c_hw.weight
 | -0.100 | -0.294 |  0.117 |  0.206 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.324 |  0.289 |  0.052 | torch.Size([192, 96, 2, 2]) || m_down1.2.weight
 |  1.092 |  0.706 |  1.746 |  0.253 | torch.Size([64]) || m_down2.0.trans_block.ln1.weight
 | -0.006 | -0.504 |  0.511 |  0.232 | torch.Size([64]) || m_down2.0.trans_block.ln1.bias
 | -0.206 | -1.978 |  1.851 |  0.710 | torch.Size([2, 15, 15]) || m_down2.0.trans_block.msa.relative_position_params
 |  0.000 | -0.453 |  0.444 |  0.078 | torch.Size([192, 64, 1, 1]) || m_down2.0.trans_block.msa.embedding_layer1.weight
 | -0.006 | -0.213 |  0.192 |  0.048 | torch.Size([192]) || m_down2.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.275 |  0.255 |  0.051 | torch.Size([64, 64, 1, 1]) || m_down2.0.trans_block.msa.linear1.weight
 |  0.002 | -0.125 |  0.215 |  0.048 | torch.Size([64]) || m_down2.0.trans_block.msa.linear1.bias
 |  1.127 |  0.791 |  1.483 |  0.141 | torch.Size([64]) || m_down2.0.trans_block.ln2.weight
 |  0.008 | -0.139 |  0.265 |  0.075 | torch.Size([64]) || m_down2.0.trans_block.ln2.bias
 |  0.002 | -0.509 |  0.472 |  0.095 | torch.Size([256, 64]) || m_down2.0.trans_block.mlp.0.weight
 | -0.047 | -0.284 |  0.068 |  0.048 | torch.Size([256]) || m_down2.0.trans_block.mlp.0.bias
 |  0.001 | -0.385 |  0.374 |  0.073 | torch.Size([64, 256]) || m_down2.0.trans_block.mlp.2.weight
 |  0.022 | -0.110 |  0.110 |  0.048 | torch.Size([64]) || m_down2.0.trans_block.mlp.2.bias
 |  0.008 | -0.716 |  0.853 |  0.099 | torch.Size([192, 192, 1, 1]) || m_down2.0.conv1_1.weight
 |  0.004 | -0.578 |  0.629 |  0.112 | torch.Size([192]) || m_down2.0.conv1_1.bias
 | -0.065 | -0.203 |  0.011 |  0.120 | torch.Size([1, 1, 1, 1, 3]) || m_down2.0.conv3d.weight
 | -0.005 | -0.005 | -0.005 |    nan | torch.Size([1]) || m_down2.0.conv3d.bias
 |  0.001 | -0.399 |  0.406 |  0.060 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.0.weight
 | -0.000 | -0.276 |  0.394 |  0.061 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.0.mamba_layers.0.mixer.A_log
 |  1.008 |  0.984 |  1.121 |  0.021 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.D
 | -0.000 | -0.277 |  0.253 |  0.032 | torch.Size([256, 64]) || m_down2.0.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.294 |  0.306 |  0.062 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.138 |  0.072 |  0.025 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.062 |  0.058 |  0.018 | torch.Size([36, 128]) || m_down2.0.mamba_layers.0.mixer.x_proj.weight
 |  0.001 | -0.049 |  0.055 |  0.018 | torch.Size([128, 4]) || m_down2.0.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.001 |  0.002 |  0.000 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.221 |  0.279 |  0.033 | torch.Size([64, 128]) || m_down2.0.mamba_layers.0.mixer.out_proj.weight
 |  1.035 |  0.889 |  1.218 |  0.082 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.weight
 |  0.004 | -0.148 |  0.151 |  0.074 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.bias
 |  1.916 | -0.324 |  2.773 |  0.767 | torch.Size([128, 16]) || m_down2.0.mamba_layers.1.mixer.A_log
 |  1.032 |  0.993 |  1.248 |  0.052 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.D
 | -0.000 | -0.335 |  0.353 |  0.050 | torch.Size([256, 64]) || m_down2.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.328 |  0.432 |  0.092 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.1.mixer.conv1d.weight
 |  0.016 | -0.175 |  0.314 |  0.070 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.245 |  0.185 |  0.034 | torch.Size([36, 128]) || m_down2.0.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.093 |  0.087 |  0.021 | torch.Size([128, 4]) || m_down2.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.010 | -0.303 |  0.160 |  0.052 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.349 |  0.356 |  0.051 | torch.Size([64, 128]) || m_down2.0.mamba_layers.1.mixer.out_proj.weight
 |  1.051 |  0.926 |  1.211 |  0.073 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.weight
 |  0.002 | -0.255 |  0.246 |  0.132 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.bias
 |  1.917 | -0.027 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.2.mixer.A_log
 |  0.984 |  0.944 |  1.035 |  0.019 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.D
 |  0.000 | -0.209 |  0.202 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.2.mixer.in_proj.weight
 | -0.004 | -0.517 |  0.513 |  0.273 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.2.mixer.conv1d.weight
 | -0.026 | -0.510 |  0.485 |  0.296 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.133 |  0.215 |  0.052 | torch.Size([36, 128]) || m_down2.0.mamba_layers.2.mixer.x_proj.weight
 |  0.014 | -0.500 |  0.501 |  0.292 | torch.Size([128, 4]) || m_down2.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.641 | -6.908 | -2.258 |  1.372 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.206 |  0.195 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.2.mixer.out_proj.weight
 |  0.966 |  0.883 |  1.026 |  0.032 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.weight
 |  0.002 | -0.090 |  0.064 |  0.029 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.bias
 |  1.917 | -0.021 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.3.mixer.A_log
 |  0.988 |  0.931 |  1.049 |  0.017 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.D
 |  0.001 | -0.194 |  0.185 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.3.mixer.in_proj.weight
 | -0.001 | -0.549 |  0.519 |  0.273 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.487 |  0.483 |  0.290 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.199 |  0.253 |  0.053 | torch.Size([36, 128]) || m_down2.0.mamba_layers.3.mixer.x_proj.weight
 |  0.011 | -0.496 |  0.500 |  0.303 | torch.Size([128, 4]) || m_down2.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.465 | -6.853 | -2.277 |  1.292 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.dt_proj.bias
 |  0.000 | -0.191 |  0.236 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.3.mixer.out_proj.weight
 |  0.972 |  0.915 |  1.037 |  0.025 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.weight
 | -0.002 | -0.045 |  0.065 |  0.023 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.bias
 |  0.632 |  0.128 |  1.136 |  0.712 | torch.Size([2]) || m_down2.0.pcbam_module.h_cw.weight
 |  0.111 | -0.107 |  0.483 |  0.323 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.h_cw.conv.weight
 |  0.678 |  0.609 |  0.746 |  0.097 | torch.Size([2]) || m_down2.0.pcbam_module.w_hc.weight
 |  0.057 | -0.143 |  0.401 |  0.299 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.w_hc.conv.weight
 |  0.594 |  0.347 |  0.841 |  0.349 | torch.Size([2]) || m_down2.0.pcbam_module.c_hw.weight
 | -0.032 | -0.100 |  0.043 |  0.072 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.c_hw.conv.weight
 |  1.159 |  0.847 |  1.736 |  0.232 | torch.Size([64]) || m_down2.1.trans_block.ln1.weight
 |  0.012 | -0.395 |  0.490 |  0.174 | torch.Size([64]) || m_down2.1.trans_block.ln1.bias
 | -0.006 | -1.105 |  0.653 |  0.241 | torch.Size([2, 15, 15]) || m_down2.1.trans_block.msa.relative_position_params
 | -0.000 | -0.388 |  0.443 |  0.084 | torch.Size([192, 64, 1, 1]) || m_down2.1.trans_block.msa.embedding_layer1.weight
 | -0.003 | -0.295 |  0.236 |  0.064 | torch.Size([192]) || m_down2.1.trans_block.msa.embedding_layer1.bias
 |  0.001 | -0.195 |  0.176 |  0.044 | torch.Size([64, 64, 1, 1]) || m_down2.1.trans_block.msa.linear1.weight
 | -0.001 | -0.134 |  0.209 |  0.050 | torch.Size([64]) || m_down2.1.trans_block.msa.linear1.bias
 |  1.041 |  0.711 |  1.338 |  0.147 | torch.Size([64]) || m_down2.1.trans_block.ln2.weight
 |  0.004 | -0.197 |  0.255 |  0.103 | torch.Size([64]) || m_down2.1.trans_block.ln2.bias
 | -0.000 | -0.483 |  0.470 |  0.076 | torch.Size([256, 64]) || m_down2.1.trans_block.mlp.0.weight
 | -0.042 | -0.321 |  0.066 |  0.057 | torch.Size([256]) || m_down2.1.trans_block.mlp.0.bias
 | -0.000 | -0.417 |  0.463 |  0.053 | torch.Size([64, 256]) || m_down2.1.trans_block.mlp.2.weight
 | -0.001 | -0.077 |  0.068 |  0.034 | torch.Size([64]) || m_down2.1.trans_block.mlp.2.bias
 | -0.009 | -1.115 |  0.517 |  0.104 | torch.Size([192, 192, 1, 1]) || m_down2.1.conv1_1.weight
 |  0.001 | -0.333 |  0.324 |  0.084 | torch.Size([192]) || m_down2.1.conv1_1.bias
 |  0.075 | -0.017 |  0.245 |  0.148 | torch.Size([1, 1, 1, 1, 3]) || m_down2.1.conv3d.weight
 | -0.004 | -0.004 | -0.004 |    nan | torch.Size([1]) || m_down2.1.conv3d.bias
 | -0.003 | -0.377 |  0.308 |  0.059 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.0.weight
 |  0.000 | -0.309 |  0.315 |  0.058 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.2.weight
 |  1.917 | -0.006 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.0.mixer.A_log
 |  1.023 |  0.995 |  1.258 |  0.040 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.D
 |  0.000 | -0.275 |  0.252 |  0.039 | torch.Size([256, 64]) || m_down2.1.mamba_layers.0.mixer.in_proj.weight
 | -0.003 | -0.434 |  0.293 |  0.074 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.001 | -0.083 |  0.113 |  0.029 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.167 |  0.165 |  0.024 | torch.Size([36, 128]) || m_down2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.049 |  0.052 |  0.018 | torch.Size([128, 4]) || m_down2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.061 |  0.079 |  0.016 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.274 |  0.283 |  0.043 | torch.Size([64, 128]) || m_down2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.023 |  0.836 |  1.225 |  0.076 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.weight
 |  0.001 | -0.171 |  0.207 |  0.101 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.bias
 |  1.917 | -0.245 |  2.773 |  0.765 | torch.Size([128, 16]) || m_down2.1.mamba_layers.1.mixer.A_log
 |  1.038 |  0.996 |  1.244 |  0.064 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.D
 | -0.000 | -0.439 |  0.420 |  0.051 | torch.Size([256, 64]) || m_down2.1.mamba_layers.1.mixer.in_proj.weight
 |  0.004 | -0.311 |  0.379 |  0.094 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.009 | -0.127 |  0.231 |  0.045 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.260 |  0.271 |  0.038 | torch.Size([36, 128]) || m_down2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.256 |  0.251 |  0.029 | torch.Size([128, 4]) || m_down2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.002 | -0.300 |  0.165 |  0.044 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.394 |  0.374 |  0.052 | torch.Size([64, 128]) || m_down2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.054 |  0.948 |  1.401 |  0.092 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.weight
 | -0.007 | -0.220 |  0.195 |  0.127 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.027 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.2.mixer.A_log
 |  0.988 |  0.942 |  1.085 |  0.023 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.D
 | -0.001 | -0.241 |  0.207 |  0.076 | torch.Size([256, 64]) || m_down2.1.mamba_layers.2.mixer.in_proj.weight
 | -0.007 | -0.567 |  0.538 |  0.283 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.2.mixer.conv1d.weight
 |  0.014 | -0.490 |  0.506 |  0.266 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.169 |  0.171 |  0.053 | torch.Size([36, 128]) || m_down2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.021 | -0.500 |  0.499 |  0.284 | torch.Size([128, 4]) || m_down2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.836 | -6.905 | -2.270 |  1.399 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.185 |  0.208 |  0.055 | torch.Size([64, 128]) || m_down2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.980 |  0.905 |  1.059 |  0.032 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.weight
 |  0.003 | -0.070 |  0.080 |  0.028 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.043 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.3.mixer.A_log
 |  0.986 |  0.950 |  1.054 |  0.019 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.211 |  0.283 |  0.074 | torch.Size([256, 64]) || m_down2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.001 | -0.512 |  0.515 |  0.279 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.3.mixer.conv1d.weight
 |  0.054 | -0.523 |  0.489 |  0.264 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.163 |  0.134 |  0.052 | torch.Size([36, 128]) || m_down2.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.500 |  0.499 |  0.290 | torch.Size([128, 4]) || m_down2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.409 | -6.903 | -2.271 |  1.291 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.179 |  0.191 |  0.054 | torch.Size([64, 128]) || m_down2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.972 |  0.919 |  1.032 |  0.029 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.weight
 |  0.001 | -0.059 |  0.056 |  0.024 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.bias
 |  0.860 |  0.685 |  1.036 |  0.249 | torch.Size([2]) || m_down2.1.pcbam_module.h_cw.weight
 |  0.141 | -0.074 |  0.413 |  0.249 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.h_cw.conv.weight
 |  0.696 |  0.603 |  0.790 |  0.132 | torch.Size([2]) || m_down2.1.pcbam_module.w_hc.weight
 |  0.077 | -0.277 |  0.457 |  0.367 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.w_hc.conv.weight
 |  0.886 |  0.744 |  1.029 |  0.201 | torch.Size([2]) || m_down2.1.pcbam_module.c_hw.weight
 | -0.068 | -0.261 |  0.250 |  0.277 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.c_hw.conv.weight
 | -0.001 | -0.275 |  0.410 |  0.043 | torch.Size([384, 192, 2, 2]) || m_down2.2.weight
 |  0.980 |  0.604 |  1.641 |  0.232 | torch.Size([128]) || m_down3.0.trans_block.ln1.weight
 |  0.005 | -0.613 |  0.623 |  0.256 | torch.Size([128]) || m_down3.0.trans_block.ln1.bias
 |  0.053 | -2.558 |  0.994 |  0.348 | torch.Size([4, 15, 15]) || m_down3.0.trans_block.msa.relative_position_params
 | -0.000 | -0.407 |  0.396 |  0.052 | torch.Size([384, 128, 1, 1]) || m_down3.0.trans_block.msa.embedding_layer1.weight
 |  0.006 | -0.197 |  0.272 |  0.057 | torch.Size([384]) || m_down3.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.164 |  0.167 |  0.040 | torch.Size([128, 128, 1, 1]) || m_down3.0.trans_block.msa.linear1.weight
 |  0.002 | -0.116 |  0.103 |  0.043 | torch.Size([128]) || m_down3.0.trans_block.msa.linear1.bias
 |  0.891 |  0.453 |  1.359 |  0.169 | torch.Size([128]) || m_down3.0.trans_block.ln2.weight
 |  0.001 | -0.337 |  0.362 |  0.115 | torch.Size([128]) || m_down3.0.trans_block.ln2.bias
 | -0.000 | -0.412 |  0.380 |  0.046 | torch.Size([512, 128]) || m_down3.0.trans_block.mlp.0.weight
 | -0.027 | -0.353 |  0.068 |  0.044 | torch.Size([512]) || m_down3.0.trans_block.mlp.0.bias
 | -0.000 | -0.401 |  0.451 |  0.037 | torch.Size([128, 512]) || m_down3.0.trans_block.mlp.2.weight
 |  0.002 | -0.125 |  0.210 |  0.054 | torch.Size([128]) || m_down3.0.trans_block.mlp.2.bias
 |  0.004 | -0.550 |  1.751 |  0.081 | torch.Size([384, 384, 1, 1]) || m_down3.0.conv1_1.weight
 | -0.003 | -0.796 |  0.608 |  0.128 | torch.Size([384]) || m_down3.0.conv1_1.bias
 | -0.078 | -0.238 |  0.004 |  0.139 | torch.Size([1, 1, 1, 1, 3]) || m_down3.0.conv3d.weight
 | -0.003 | -0.003 | -0.003 |    nan | torch.Size([1]) || m_down3.0.conv3d.bias
 |  0.001 | -0.377 |  0.292 |  0.045 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.0.weight
 | -0.000 | -0.230 |  0.277 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.0.mixer.A_log
 |  1.001 |  0.991 |  1.093 |  0.009 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.D
 | -0.000 | -0.091 |  0.110 |  0.011 | torch.Size([512, 128]) || m_down3.0.mamba_layers.0.mixer.in_proj.weight
 | -0.002 | -0.147 |  0.111 |  0.023 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.0.mixer.conv1d.weight
 | -0.002 | -0.116 |  0.149 |  0.035 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.051 |  0.051 |  0.012 | torch.Size([40, 256]) || m_down3.0.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.041 |  0.047 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.001 |  0.000 |  0.000 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.187 |  0.140 |  0.016 | torch.Size([128, 256]) || m_down3.0.mamba_layers.0.mixer.out_proj.weight
 |  0.999 |  0.985 |  1.026 |  0.008 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.weight
 |  0.001 | -0.024 |  0.023 |  0.012 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.bias
 |  1.917 | -0.005 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.1.mixer.A_log
 |  1.013 |  0.998 |  1.310 |  0.045 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.D
 |  0.000 | -0.321 |  0.273 |  0.019 | torch.Size([512, 128]) || m_down3.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.290 |  0.285 |  0.041 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.1.mixer.conv1d.weight
 | -0.003 | -0.245 |  0.224 |  0.054 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.119 |  0.125 |  0.013 | torch.Size([40, 256]) || m_down3.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.039 |  0.058 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.101 |  0.024 |  0.007 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.407 |  0.294 |  0.024 | torch.Size([128, 256]) || m_down3.0.mamba_layers.1.mixer.out_proj.weight
 |  0.949 |  0.855 |  1.174 |  0.052 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.weight
 |  0.013 | -0.150 |  0.158 |  0.098 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.bias
 |  1.917 | -0.002 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.2.mixer.A_log
 |  0.979 |  0.950 |  1.016 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.D
 |  0.000 | -0.142 |  0.149 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.2.mixer.in_proj.weight
 | -0.015 | -0.545 |  0.511 |  0.279 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.2.mixer.conv1d.weight
 |  0.031 | -0.514 |  0.483 |  0.274 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.105 |  0.098 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.2.mixer.x_proj.weight
 | -0.000 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.489 | -6.888 | -2.309 |  1.322 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.138 |  0.151 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.2.mixer.out_proj.weight
 |  0.954 |  0.898 |  1.032 |  0.022 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.weight
 |  0.001 | -0.071 |  0.061 |  0.032 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.bias
 |  1.917 | -0.001 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.3.mixer.A_log
 |  0.980 |  0.942 |  1.026 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.D
 | -0.000 | -0.136 |  0.142 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.3.mixer.in_proj.weight
 |  0.006 | -0.506 |  0.531 |  0.279 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.489 |  0.499 |  0.256 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.089 |  0.091 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.3.mixer.x_proj.weight
 | -0.002 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.511 | -6.890 | -2.277 |  1.395 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.128 |  0.130 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.3.mixer.out_proj.weight
 |  0.953 |  0.892 |  0.999 |  0.021 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.weight
 | -0.000 | -0.065 |  0.066 |  0.029 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.bias
 |  0.711 |  0.548 |  0.874 |  0.231 | torch.Size([2]) || m_down3.0.pcbam_module.h_cw.weight
 |  0.063 | -0.051 |  0.247 |  0.161 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.h_cw.conv.weight
 |  0.298 |  0.253 |  0.343 |  0.064 | torch.Size([2]) || m_down3.0.pcbam_module.w_hc.weight
 |  0.032 | -0.136 |  0.278 |  0.217 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.w_hc.conv.weight
 |  0.573 |  0.260 |  0.886 |  0.443 | torch.Size([2]) || m_down3.0.pcbam_module.c_hw.weight
 | -0.105 | -0.399 |  0.106 |  0.186 | torch.Size([1, 1, 1, 5]) || m_down3.0.pcbam_module.c_hw.conv.weight
 |  1.079 |  0.600 |  1.607 |  0.247 | torch.Size([128]) || m_down3.1.trans_block.ln1.weight
 | -0.017 | -0.824 |  0.674 |  0.224 | torch.Size([128]) || m_down3.1.trans_block.ln1.bias
 |  0.002 | -2.704 |  1.290 |  0.321 | torch.Size([4, 15, 15]) || m_down3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.456 |  0.467 |  0.057 | torch.Size([384, 128, 1, 1]) || m_down3.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.241 |  0.247 |  0.049 | torch.Size([384]) || m_down3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.168 |  0.168 |  0.039 | torch.Size([128, 128, 1, 1]) || m_down3.1.trans_block.msa.linear1.weight
 |  0.000 | -0.143 |  0.149 |  0.055 | torch.Size([128]) || m_down3.1.trans_block.msa.linear1.bias
 |  0.896 |  0.414 |  1.270 |  0.193 | torch.Size([128]) || m_down3.1.trans_block.ln2.weight
 | -0.006 | -0.372 |  0.441 |  0.167 | torch.Size([128]) || m_down3.1.trans_block.ln2.bias
 | -0.000 | -0.451 |  0.369 |  0.058 | torch.Size([512, 128]) || m_down3.1.trans_block.mlp.0.weight
 | -0.044 | -0.239 |  0.033 |  0.052 | torch.Size([512]) || m_down3.1.trans_block.mlp.0.bias
 | -0.000 | -0.363 |  0.362 |  0.044 | torch.Size([128, 512]) || m_down3.1.trans_block.mlp.2.weight
 |  0.004 | -0.131 |  0.154 |  0.052 | torch.Size([128]) || m_down3.1.trans_block.mlp.2.bias
 | -0.004 | -1.805 |  0.669 |  0.088 | torch.Size([384, 384, 1, 1]) || m_down3.1.conv1_1.weight
 |  0.009 | -0.556 |  0.405 |  0.089 | torch.Size([384]) || m_down3.1.conv1_1.bias
 |  0.080 | -0.008 |  0.252 |  0.149 | torch.Size([1, 1, 1, 1, 3]) || m_down3.1.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_down3.1.conv3d.bias
 | -0.005 | -0.365 |  0.422 |  0.047 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.0.weight
 | -0.001 | -0.255 |  0.296 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.2.weight
 |  1.917 | -0.001 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.0.mixer.A_log
 |  1.011 |  0.991 |  1.142 |  0.025 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.305 |  0.307 |  0.026 | torch.Size([512, 128]) || m_down3.1.mamba_layers.0.mixer.in_proj.weight
 | -0.000 | -0.375 |  0.286 |  0.053 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.126 |  0.105 |  0.034 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.084 |  0.087 |  0.014 | torch.Size([40, 256]) || m_down3.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.039 |  0.057 |  0.012 | torch.Size([256, 8]) || m_down3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.022 |  0.011 |  0.002 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.215 |  0.222 |  0.028 | torch.Size([128, 256]) || m_down3.1.mamba_layers.0.mixer.out_proj.weight
 |  0.987 |  0.870 |  1.207 |  0.057 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.weight
 |  0.004 | -0.125 |  0.144 |  0.076 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.bias
 |  1.917 | -0.044 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.1.mixer.A_log
 |  1.021 |  0.949 |  1.312 |  0.049 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.D
 |  0.000 | -0.308 |  0.342 |  0.033 | torch.Size([512, 128]) || m_down3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.003 | -0.375 |  0.359 |  0.064 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.244 |  0.231 |  0.044 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.182 |  0.210 |  0.024 | torch.Size([40, 256]) || m_down3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.078 |  0.084 |  0.016 | torch.Size([256, 8]) || m_down3.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.010 | -0.109 |  0.195 |  0.031 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.287 |  0.302 |  0.034 | torch.Size([128, 256]) || m_down3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.010 |  0.830 |  1.240 |  0.081 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.weight
 | -0.003 | -0.173 |  0.191 |  0.105 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.090 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.2.mixer.A_log
 |  0.979 |  0.933 |  1.076 |  0.019 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.167 |  0.161 |  0.052 | torch.Size([512, 128]) || m_down3.1.mamba_layers.2.mixer.in_proj.weight
 | -0.012 | -0.553 |  0.578 |  0.277 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.2.mixer.conv1d.weight
 |  0.015 | -0.523 |  0.510 |  0.290 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.125 |  0.110 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.205 | torch.Size([256, 8]) || m_down3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.526 | -6.818 | -2.284 |  1.305 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.215 |  0.140 |  0.039 | torch.Size([128, 256]) || m_down3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.955 |  0.855 |  1.027 |  0.027 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.weight
 | -0.000 | -0.096 |  0.061 |  0.023 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.003 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.3.mixer.A_log
 |  0.979 |  0.931 |  1.017 |  0.015 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.D
 |  0.000 | -0.146 |  0.154 |  0.051 | torch.Size([512, 128]) || m_down3.1.mamba_layers.3.mixer.in_proj.weight
 |  0.010 | -0.548 |  0.544 |  0.276 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.3.mixer.conv1d.weight
 |  0.001 | -0.512 |  0.481 |  0.287 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.109 |  0.119 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.204 | torch.Size([256, 8]) || m_down3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.747 | -6.882 | -2.256 |  1.391 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.125 |  0.139 |  0.037 | torch.Size([128, 256]) || m_down3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.945 |  0.887 |  1.000 |  0.025 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.weight
 | -0.001 | -0.089 |  0.079 |  0.023 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.bias
 |  0.682 |  0.554 |  0.810 |  0.181 | torch.Size([2]) || m_down3.1.pcbam_module.h_cw.weight
 | -0.009 | -0.224 |  0.287 |  0.265 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.h_cw.conv.weight
 |  0.428 |  0.112 |  0.744 |  0.447 | torch.Size([2]) || m_down3.1.pcbam_module.w_hc.weight
 | -0.023 | -0.256 |  0.344 |  0.321 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.w_hc.conv.weight
 |  0.600 |  0.593 |  0.607 |  0.010 | torch.Size([2]) || m_down3.1.pcbam_module.c_hw.weight
 |  0.095 | -0.207 |  0.358 |  0.274 | torch.Size([1, 1, 1, 5]) || m_down3.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.488 |  0.302 |  0.032 | torch.Size([768, 384, 2, 2]) || m_down3.2.weight
 |  0.803 |  0.355 |  1.188 |  0.146 | torch.Size([256]) || m_body.0.trans_block.ln1.weight
 | -0.011 | -0.693 |  0.510 |  0.139 | torch.Size([256]) || m_body.0.trans_block.ln1.bias
 |  0.054 | -4.646 |  0.713 |  0.330 | torch.Size([8, 15, 15]) || m_body.0.trans_block.msa.relative_position_params
 | -0.000 | -0.399 |  0.391 |  0.037 | torch.Size([768, 256, 1, 1]) || m_body.0.trans_block.msa.embedding_layer1.weight
 |  0.002 | -0.216 |  0.230 |  0.054 | torch.Size([768]) || m_body.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.238 |  0.236 |  0.042 | torch.Size([256, 256, 1, 1]) || m_body.0.trans_block.msa.linear1.weight
 |  0.001 | -0.268 |  0.150 |  0.058 | torch.Size([256]) || m_body.0.trans_block.msa.linear1.bias
 |  0.852 |  0.383 |  1.179 |  0.124 | torch.Size([256]) || m_body.0.trans_block.ln2.weight
 |  0.002 | -0.198 |  0.275 |  0.080 | torch.Size([256]) || m_body.0.trans_block.ln2.bias
 |  0.000 | -0.255 |  0.282 |  0.034 | torch.Size([1024, 256]) || m_body.0.trans_block.mlp.0.weight
 | -0.011 | -0.233 |  0.104 |  0.042 | torch.Size([1024]) || m_body.0.trans_block.mlp.0.bias
 | -0.000 | -0.293 |  0.322 |  0.031 | torch.Size([256, 1024]) || m_body.0.trans_block.mlp.2.weight
 |  0.004 | -0.190 |  0.159 |  0.054 | torch.Size([256]) || m_body.0.trans_block.mlp.2.bias
 | -0.001 | -1.114 |  0.876 |  0.051 | torch.Size([768, 768, 1, 1]) || m_body.0.conv1_1.weight
 |  0.001 | -1.467 |  1.031 |  0.093 | torch.Size([768]) || m_body.0.conv1_1.bias
 |  0.064 | -0.005 |  0.198 |  0.116 | torch.Size([1, 1, 1, 1, 3]) || m_body.0.conv3d.weight
 |  0.025 |  0.025 |  0.025 |    nan | torch.Size([1]) || m_body.0.conv3d.bias
 |  0.000 | -0.238 |  0.256 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.0.weight
 | -0.000 | -0.239 |  0.211 |  0.036 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.D
 |  0.000 | -0.028 |  0.027 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.025 |  0.027 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.004 |  0.003 |  0.001 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.035 |  0.036 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.033 |  0.038 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.042 |  0.037 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.0.mixer.out_proj.weight
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.bias
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.001 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.D
 |  0.000 | -0.029 |  0.030 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.1.mixer.in_proj.weight
 |  0.000 | -0.035 |  0.059 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.1.mixer.conv1d.weight
 | -0.000 | -0.018 |  0.022 |  0.006 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.034 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.034 |  0.030 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.045 |  0.041 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.999 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.weight
 | -0.000 | -0.001 |  0.001 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.bias
 |  1.917 | -0.026 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.A_log
 |  0.999 |  0.973 |  1.015 |  0.004 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.D
 | -0.000 | -0.086 |  0.084 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.2.mixer.in_proj.weight
 | -0.007 | -0.504 |  0.519 |  0.289 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.2.mixer.conv1d.weight
 | -0.005 | -0.500 |  0.495 |  0.307 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.067 |  0.067 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.579 | -6.906 | -2.283 |  1.361 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.093 |  0.082 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.2.mixer.out_proj.weight
 |  0.995 |  0.984 |  1.008 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.weight
 |  0.000 | -0.013 |  0.007 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.bias
 |  1.917 | -0.017 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.A_log
 |  0.998 |  0.981 |  1.010 |  0.003 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.D
 |  0.000 | -0.081 |  0.080 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.3.mixer.in_proj.weight
 | -0.013 | -0.511 |  0.502 |  0.287 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.3.mixer.conv1d.weight
 |  0.003 | -0.500 |  0.496 |  0.280 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.070 |  0.068 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.3.mixer.x_proj.weight
 |  0.002 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.612 | -6.907 | -2.259 |  1.325 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.064 |  0.066 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.3.mixer.out_proj.weight
 |  0.995 |  0.986 |  1.006 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.weight
 | -0.000 | -0.010 |  0.009 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.bias
 |  1.128 |  0.894 |  1.363 |  0.331 | torch.Size([2]) || m_body.0.pcbam_module.h_cw.weight
 | -0.693 | -0.987 | -0.529 |  0.255 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.h_cw.conv.weight
 |  0.389 |  0.163 |  0.616 |  0.320 | torch.Size([2]) || m_body.0.pcbam_module.w_hc.weight
 | -0.547 | -0.641 | -0.366 |  0.156 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.w_hc.conv.weight
 |  1.020 |  0.132 |  1.907 |  1.256 | torch.Size([2]) || m_body.0.pcbam_module.c_hw.weight
 | -0.087 | -1.011 |  1.945 |  1.190 | torch.Size([1, 1, 1, 5]) || m_body.0.pcbam_module.c_hw.conv.weight
 |  0.746 |  0.302 |  1.004 |  0.127 | torch.Size([256]) || m_body.1.trans_block.ln1.weight
 |  0.029 | -0.826 |  0.544 |  0.167 | torch.Size([256]) || m_body.1.trans_block.ln1.bias
 |  0.052 | -3.778 |  0.814 |  0.348 | torch.Size([8, 15, 15]) || m_body.1.trans_block.msa.relative_position_params
 | -0.000 | -0.316 |  0.315 |  0.036 | torch.Size([768, 256, 1, 1]) || m_body.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.223 |  0.254 |  0.069 | torch.Size([768]) || m_body.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.277 |  0.271 |  0.037 | torch.Size([256, 256, 1, 1]) || m_body.1.trans_block.msa.linear1.weight
 | -0.004 | -0.220 |  0.267 |  0.059 | torch.Size([256]) || m_body.1.trans_block.msa.linear1.bias
 |  0.854 |  0.493 |  1.089 |  0.103 | torch.Size([256]) || m_body.1.trans_block.ln2.weight
 |  0.008 | -0.251 |  0.328 |  0.102 | torch.Size([256]) || m_body.1.trans_block.ln2.bias
 |  0.001 | -0.362 |  0.359 |  0.054 | torch.Size([1024, 256]) || m_body.1.trans_block.mlp.0.weight
 | -0.051 | -0.198 |  0.050 |  0.038 | torch.Size([1024]) || m_body.1.trans_block.mlp.0.bias
 | -0.001 | -0.437 |  0.433 |  0.052 | torch.Size([256, 1024]) || m_body.1.trans_block.mlp.2.weight
 | -0.001 | -0.241 |  0.143 |  0.053 | torch.Size([256]) || m_body.1.trans_block.mlp.2.bias
 | -0.001 | -1.068 |  0.773 |  0.056 | torch.Size([768, 768, 1, 1]) || m_body.1.conv1_1.weight
 | -0.000 | -0.313 |  0.949 |  0.085 | torch.Size([768]) || m_body.1.conv1_1.bias
 |  0.147 |  0.004 |  0.431 |  0.246 | torch.Size([1, 1, 1, 1, 3]) || m_body.1.conv3d.weight
 |  0.043 |  0.043 |  0.043 |    nan | torch.Size([1]) || m_body.1.conv3d.bias
 | -0.001 | -0.278 |  0.267 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.0.weight
 | -0.001 | -0.269 |  0.270 |  0.035 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.2.weight
 |  1.917 | -0.001 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.092 |  0.006 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.D
 | -0.000 | -0.123 |  0.107 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.108 |  0.289 |  0.013 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.024 |  0.071 |  0.004 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.036 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.035 |  0.029 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.008 |  0.004 |  0.000 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.166 |  0.121 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.0.mixer.out_proj.weight
 |  1.001 |  0.994 |  1.014 |  0.003 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.weight
 |  0.000 | -0.005 |  0.006 |  0.002 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.bias
 |  1.917 | -0.218 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.053 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.D
 |  0.000 | -0.159 |  0.145 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.1.mixer.in_proj.weight
 | -0.000 | -0.049 |  0.174 |  0.010 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.097 |  0.073 |  0.022 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.096 |  0.319 |  0.010 | torch.Size([48, 512]) || m_body.1.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.032 |  0.035 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.038 |  0.000 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.171 |  0.177 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.986 |  1.042 |  0.010 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.weight
 | -0.001 | -0.017 |  0.021 |  0.008 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.bias
 |  1.917 | -0.066 |  2.774 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.A_log
 |  0.998 |  0.963 |  1.031 |  0.005 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.D
 | -0.000 | -0.107 |  0.131 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.2.mixer.in_proj.weight
 |  0.004 | -0.530 |  0.504 |  0.283 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.2.mixer.conv1d.weight
 |  0.010 | -0.506 |  0.492 |  0.282 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.094 |  0.089 |  0.026 | torch.Size([48, 512]) || m_body.1.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.257 |  0.260 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.634 | -6.903 | -2.259 |  1.288 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.126 |  0.105 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.2.mixer.out_proj.weight
 |  0.996 |  0.961 |  1.012 |  0.008 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.weight
 |  0.000 | -0.023 |  0.021 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.bias
 |  1.917 | -0.069 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.A_log
 |  0.999 |  0.920 |  1.118 |  0.009 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.D
 |  0.000 | -0.122 |  0.123 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.531 |  0.505 |  0.293 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.3.mixer.conv1d.weight
 | -0.009 | -0.500 |  0.498 |  0.294 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.099 |  0.105 |  0.027 | torch.Size([48, 512]) || m_body.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.272 |  0.274 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.631 | -6.903 | -2.252 |  1.302 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.118 |  0.102 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.3.mixer.out_proj.weight
 |  1.000 |  0.969 |  1.029 |  0.009 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.weight
 |  0.000 | -0.017 |  0.019 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.bias
 |  1.226 |  0.884 |  1.568 |  0.484 | torch.Size([2]) || m_body.1.pcbam_module.h_cw.weight
 | -1.051 | -1.169 | -0.864 |  0.164 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.h_cw.conv.weight
 |  1.165 |  0.908 |  1.422 |  0.363 | torch.Size([2]) || m_body.1.pcbam_module.w_hc.weight
 | -0.980 | -1.093 | -0.820 |  0.142 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.w_hc.conv.weight
 |  1.519 |  0.158 |  2.880 |  1.925 | torch.Size([2]) || m_body.1.pcbam_module.c_hw.weight
 | -0.167 | -1.486 |  1.768 |  1.300 | torch.Size([1, 1, 1, 5]) || m_body.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.324 |  0.332 |  0.030 | torch.Size([768, 384, 2, 2]) || m_up3.0.weight
 |  0.959 |  0.556 |  1.369 |  0.157 | torch.Size([128]) || m_up3.1.trans_block.ln1.weight
 |  0.026 | -0.612 |  0.449 |  0.134 | torch.Size([128]) || m_up3.1.trans_block.ln1.bias
 |  0.050 | -3.715 |  0.652 |  0.304 | torch.Size([4, 15, 15]) || m_up3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.523 |  0.546 |  0.061 | torch.Size([384, 128, 1, 1]) || m_up3.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.259 |  0.245 |  0.071 | torch.Size([384]) || m_up3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.176 |  0.177 |  0.042 | torch.Size([128, 128, 1, 1]) || m_up3.1.trans_block.msa.linear1.weight
 | -0.001 | -0.109 |  0.283 |  0.047 | torch.Size([128]) || m_up3.1.trans_block.msa.linear1.bias
 |  0.857 |  0.602 |  1.006 |  0.072 | torch.Size([128]) || m_up3.1.trans_block.ln2.weight
 |  0.009 | -0.321 |  0.182 |  0.089 | torch.Size([128]) || m_up3.1.trans_block.ln2.bias
 |  0.000 | -0.333 |  0.322 |  0.059 | torch.Size([512, 128]) || m_up3.1.trans_block.mlp.0.weight
 | -0.038 | -0.189 |  0.068 |  0.044 | torch.Size([512]) || m_up3.1.trans_block.mlp.0.bias
 | -0.000 | -0.340 |  0.310 |  0.052 | torch.Size([128, 512]) || m_up3.1.trans_block.mlp.2.weight
 | -0.001 | -0.345 |  0.163 |  0.046 | torch.Size([128]) || m_up3.1.trans_block.mlp.2.bias
 | -0.001 | -2.380 |  0.668 |  0.087 | torch.Size([384, 384, 1, 1]) || m_up3.1.conv1_1.weight
 | -0.000 | -0.512 |  1.315 |  0.141 | torch.Size([384]) || m_up3.1.conv1_1.bias
 |  0.185 | -0.003 |  0.561 |  0.326 | torch.Size([1, 1, 1, 1, 3]) || m_up3.1.conv3d.weight
 | -0.006 | -0.006 | -0.006 |    nan | torch.Size([1]) || m_up3.1.conv3d.bias
 |  0.000 | -0.349 |  0.318 |  0.036 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.0.weight
 |  0.000 | -0.272 |  0.385 |  0.038 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.2.weight
 |  1.916 | -0.349 |  2.773 |  0.766 | torch.Size([256, 16]) || m_up3.1.mamba_layers.0.mixer.A_log
 |  1.053 |  0.998 |  1.430 |  0.078 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.401 |  0.370 |  0.043 | torch.Size([512, 128]) || m_up3.1.mamba_layers.0.mixer.in_proj.weight
 |  0.006 | -0.495 |  0.462 |  0.097 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.0.mixer.conv1d.weight
 |  0.013 | -0.181 |  0.483 |  0.073 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.163 |  0.213 |  0.025 | torch.Size([40, 256]) || m_up3.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.054 |  0.067 |  0.013 | torch.Size([256, 8]) || m_up3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.003 | -0.178 |  0.172 |  0.030 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.567 |  0.495 |  0.050 | torch.Size([128, 256]) || m_up3.1.mamba_layers.0.mixer.out_proj.weight
 |  1.034 |  0.905 |  1.175 |  0.064 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.weight
 | -0.003 | -0.306 |  0.302 |  0.126 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.bias
 |  1.916 | -0.847 |  3.034 |  0.769 | torch.Size([256, 16]) || m_up3.1.mamba_layers.1.mixer.A_log
 |  1.000 | -0.050 |  1.309 |  0.161 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.D
 | -0.000 | -0.419 |  0.417 |  0.055 | torch.Size([512, 128]) || m_up3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.003 | -0.604 |  0.389 |  0.113 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.022 | -0.299 |  0.315 |  0.177 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.conv1d.bias
 |  0.001 | -0.584 |  0.555 |  0.074 | torch.Size([40, 256]) || m_up3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.002 | -0.608 |  0.703 |  0.095 | torch.Size([256, 8]) || m_up3.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.011 | -1.014 |  0.284 |  0.107 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.277 |  0.279 |  0.056 | torch.Size([128, 256]) || m_up3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.030 |  0.658 |  1.217 |  0.117 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.weight
 | -0.002 | -0.255 |  0.264 |  0.109 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.295 |  2.787 |  0.764 | torch.Size([256, 16]) || m_up3.1.mamba_layers.2.mixer.A_log
 |  0.981 |  0.645 |  1.037 |  0.041 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.200 |  0.195 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.2.mixer.in_proj.weight
 |  0.014 | -0.558 |  0.536 |  0.273 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.2.mixer.conv1d.weight
 | -0.030 | -0.527 |  0.495 |  0.292 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.168 |  0.144 |  0.042 | torch.Size([40, 256]) || m_up3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.000 | -0.415 |  0.372 |  0.205 | torch.Size([256, 8]) || m_up3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.530 | -6.922 | -2.275 |  1.363 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.000 | -0.158 |  0.161 |  0.041 | torch.Size([128, 256]) || m_up3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.957 |  0.843 |  1.037 |  0.031 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.weight
 |  0.002 | -0.066 |  0.085 |  0.024 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.033 |  2.773 |  0.765 | torch.Size([256, 16]) || m_up3.1.mamba_layers.3.mixer.A_log
 |  0.990 |  0.944 |  1.076 |  0.018 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.D
 | -0.000 | -0.229 |  0.214 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.3.mixer.in_proj.weight
 | -0.010 | -0.532 |  0.605 |  0.267 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.3.mixer.conv1d.weight
 | -0.004 | -0.554 |  0.581 |  0.312 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.121 |  0.122 |  0.038 | torch.Size([40, 256]) || m_up3.1.mamba_layers.3.mixer.x_proj.weight
 | -0.001 | -0.357 |  0.357 |  0.203 | torch.Size([256, 8]) || m_up3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.644 | -6.923 | -2.262 |  1.394 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.178 |  0.170 |  0.041 | torch.Size([128, 256]) || m_up3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.960 |  0.893 |  1.028 |  0.028 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.weight
 | -0.000 | -0.077 |  0.059 |  0.022 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.bias
 |  0.530 |  0.193 |  0.867 |  0.477 | torch.Size([2]) || m_up3.1.pcbam_module.h_cw.weight
 |  0.057 |  0.005 |  0.144 |  0.076 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.h_cw.conv.weight
 |  0.878 |  0.846 |  0.909 |  0.045 | torch.Size([2]) || m_up3.1.pcbam_module.w_hc.weight
 |  0.093 |  0.036 |  0.147 |  0.056 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.w_hc.conv.weight
 |  0.497 |  0.240 |  0.755 |  0.365 | torch.Size([2]) || m_up3.1.pcbam_module.c_hw.weight
 | -0.018 | -0.190 |  0.144 |  0.150 | torch.Size([1, 1, 1, 5]) || m_up3.1.pcbam_module.c_hw.conv.weight
 |  1.121 |  0.585 |  1.350 |  0.144 | torch.Size([128]) || m_up3.2.trans_block.ln1.weight
 | -0.004 | -0.520 |  0.515 |  0.126 | torch.Size([128]) || m_up3.2.trans_block.ln1.bias
 |  0.061 | -3.059 |  0.727 |  0.353 | torch.Size([4, 15, 15]) || m_up3.2.trans_block.msa.relative_position_params
 | -0.000 | -0.476 |  0.327 |  0.057 | torch.Size([384, 128, 1, 1]) || m_up3.2.trans_block.msa.embedding_layer1.weight
 | -0.001 | -0.186 |  0.195 |  0.058 | torch.Size([384]) || m_up3.2.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.184 |  0.198 |  0.046 | torch.Size([128, 128, 1, 1]) || m_up3.2.trans_block.msa.linear1.weight
 | -0.002 | -0.134 |  0.232 |  0.056 | torch.Size([128]) || m_up3.2.trans_block.msa.linear1.bias
 |  1.183 |  0.883 |  1.489 |  0.095 | torch.Size([128]) || m_up3.2.trans_block.ln2.weight
 | -0.000 | -0.259 |  0.287 |  0.110 | torch.Size([128]) || m_up3.2.trans_block.ln2.bias
 |  0.000 | -0.349 |  0.331 |  0.073 | torch.Size([512, 128]) || m_up3.2.trans_block.mlp.0.weight
 | -0.048 | -0.182 |  0.055 |  0.038 | torch.Size([512]) || m_up3.2.trans_block.mlp.0.bias
 |  0.000 | -0.343 |  0.388 |  0.070 | torch.Size([128, 512]) || m_up3.2.trans_block.mlp.2.weight
 | -0.001 | -0.144 |  0.217 |  0.052 | torch.Size([128]) || m_up3.2.trans_block.mlp.2.bias
 | -0.000 | -0.870 |  0.462 |  0.076 | torch.Size([384, 384, 1, 1]) || m_up3.2.conv1_1.weight
 |  0.002 | -0.543 |  1.071 |  0.103 | torch.Size([384]) || m_up3.2.conv1_1.bias
 | -0.058 | -0.185 |  0.007 |  0.110 | torch.Size([1, 1, 1, 1, 3]) || m_up3.2.conv3d.weight
 | -0.003 | -0.003 | -0.003 |    nan | torch.Size([1]) || m_up3.2.conv3d.bias
 | -0.001 | -0.313 |  0.351 |  0.052 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.0.weight
 |  0.000 | -0.435 |  0.396 |  0.052 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.2.weight
 |  1.916 | -1.147 |  2.794 |  0.767 | torch.Size([256, 16]) || m_up3.2.mamba_layers.0.mixer.A_log
 |  1.074 |  0.396 |  1.577 |  0.161 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.D
 | -0.000 | -0.323 |  0.327 |  0.071 | torch.Size([512, 128]) || m_up3.2.mamba_layers.0.mixer.in_proj.weight
 | -0.001 | -0.379 |  0.421 |  0.143 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.0.mixer.conv1d.weight
 | -0.009 | -0.305 |  0.263 |  0.103 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.668 |  0.473 |  0.076 | torch.Size([40, 256]) || m_up3.2.mamba_layers.0.mixer.x_proj.weight
 |  0.002 | -0.695 |  0.724 |  0.100 | torch.Size([256, 8]) || m_up3.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.019 | -1.184 |  0.292 |  0.121 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.584 |  0.441 |  0.076 | torch.Size([128, 256]) || m_up3.2.mamba_layers.0.mixer.out_proj.weight
 |  1.014 |  0.617 |  1.157 |  0.085 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.weight
 |  0.006 | -0.442 |  0.410 |  0.136 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.bias
 |  1.911 | -0.990 |  2.866 |  0.776 | torch.Size([256, 16]) || m_up3.2.mamba_layers.1.mixer.A_log
 |  1.069 | -0.097 |  1.515 |  0.138 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.D
 |  0.000 | -0.344 |  0.424 |  0.072 | torch.Size([512, 128]) || m_up3.2.mamba_layers.1.mixer.in_proj.weight
 |  0.005 | -0.553 |  0.459 |  0.147 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.1.mixer.conv1d.weight
 |  0.011 | -0.313 |  0.346 |  0.150 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.conv1d.bias
 |  0.002 | -0.723 |  1.154 |  0.092 | torch.Size([40, 256]) || m_up3.2.mamba_layers.1.mixer.x_proj.weight
 | -0.005 | -0.663 |  0.594 |  0.125 | torch.Size([256, 8]) || m_up3.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.014 | -0.457 |  0.174 |  0.107 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.459 |  0.406 |  0.075 | torch.Size([128, 256]) || m_up3.2.mamba_layers.1.mixer.out_proj.weight
 |  1.071 |  0.637 |  1.215 |  0.084 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.weight
 |  0.004 | -0.262 |  0.246 |  0.108 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.bias
 |  1.917 | -0.049 |  2.834 |  0.765 | torch.Size([256, 16]) || m_up3.2.mamba_layers.2.mixer.A_log
 |  1.027 |  0.971 |  1.344 |  0.036 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.D
 | -0.000 | -0.226 |  0.215 |  0.057 | torch.Size([512, 128]) || m_up3.2.mamba_layers.2.mixer.in_proj.weight
 |  0.002 | -0.661 |  0.648 |  0.294 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.2.mixer.conv1d.weight
 |  0.036 | -0.541 |  0.542 |  0.318 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.159 |  0.175 |  0.045 | torch.Size([40, 256]) || m_up3.2.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.442 |  0.471 |  0.206 | torch.Size([256, 8]) || m_up3.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.531 | -6.898 | -2.237 |  1.383 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.229 |  0.203 |  0.046 | torch.Size([128, 256]) || m_up3.2.mamba_layers.2.mixer.out_proj.weight
 |  1.021 |  0.939 |  1.088 |  0.026 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.weight
 |  0.000 | -0.092 |  0.103 |  0.038 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.bias
 |  1.917 | -0.027 |  2.774 |  0.764 | torch.Size([256, 16]) || m_up3.2.mamba_layers.3.mixer.A_log
 |  1.008 |  0.975 |  1.068 |  0.013 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.D
 | -0.000 | -0.196 |  0.171 |  0.054 | torch.Size([512, 128]) || m_up3.2.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.564 |  0.554 |  0.286 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.3.mixer.conv1d.weight
 | -0.022 | -0.537 |  0.533 |  0.300 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.175 |  0.175 |  0.041 | torch.Size([40, 256]) || m_up3.2.mamba_layers.3.mixer.x_proj.weight
 | -0.005 | -0.366 |  0.370 |  0.206 | torch.Size([256, 8]) || m_up3.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.526 | -6.891 | -2.231 |  1.228 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.186 |  0.179 |  0.043 | torch.Size([128, 256]) || m_up3.2.mamba_layers.3.mixer.out_proj.weight
 |  0.999 |  0.794 |  1.051 |  0.032 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.weight
 | -0.001 | -0.151 |  0.078 |  0.028 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.bias
 |  0.755 |  0.557 |  0.954 |  0.280 | torch.Size([2]) || m_up3.2.pcbam_module.h_cw.weight
 | -0.103 | -0.244 |  0.133 |  0.206 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.h_cw.conv.weight
 |  0.793 |  0.740 |  0.845 |  0.074 | torch.Size([2]) || m_up3.2.pcbam_module.w_hc.weight
 |  0.021 | -0.140 |  0.160 |  0.151 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.w_hc.conv.weight
 |  0.554 |  0.117 |  0.991 |  0.618 | torch.Size([2]) || m_up3.2.pcbam_module.c_hw.weight
 |  0.297 | -0.086 |  1.451 |  0.649 | torch.Size([1, 1, 1, 5]) || m_up3.2.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.401 |  0.318 |  0.034 | torch.Size([384, 192, 2, 2]) || m_up2.0.weight
 |  1.336 |  0.968 |  1.555 |  0.140 | torch.Size([64]) || m_up2.1.trans_block.ln1.weight
 | -0.001 | -0.528 |  0.532 |  0.165 | torch.Size([64]) || m_up2.1.trans_block.ln1.bias
 |  0.173 | -2.384 |  0.910 |  0.340 | torch.Size([2, 15, 15]) || m_up2.1.trans_block.msa.relative_position_params
 |  0.000 | -0.515 |  0.537 |  0.109 | torch.Size([192, 64, 1, 1]) || m_up2.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.185 |  0.185 |  0.047 | torch.Size([192]) || m_up2.1.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.200 |  0.217 |  0.046 | torch.Size([64, 64, 1, 1]) || m_up2.1.trans_block.msa.linear1.weight
 | -0.002 | -0.184 |  0.236 |  0.055 | torch.Size([64]) || m_up2.1.trans_block.msa.linear1.bias
 |  1.032 |  0.743 |  1.174 |  0.082 | torch.Size([64]) || m_up2.1.trans_block.ln2.weight
 |  0.006 | -0.283 |  0.254 |  0.139 | torch.Size([64]) || m_up2.1.trans_block.ln2.bias
 | -0.000 | -0.360 |  0.341 |  0.090 | torch.Size([256, 64]) || m_up2.1.trans_block.mlp.0.weight
 | -0.046 | -0.344 |  0.224 |  0.073 | torch.Size([256]) || m_up2.1.trans_block.mlp.0.bias
 |  0.001 | -0.423 |  0.396 |  0.078 | torch.Size([64, 256]) || m_up2.1.trans_block.mlp.2.weight
 | -0.002 | -0.218 |  0.196 |  0.062 | torch.Size([64]) || m_up2.1.trans_block.mlp.2.bias
 |  0.002 | -0.456 |  2.131 |  0.102 | torch.Size([192, 192, 1, 1]) || m_up2.1.conv1_1.weight
 | -0.000 | -0.590 |  0.723 |  0.129 | torch.Size([192]) || m_up2.1.conv1_1.bias
 | -0.179 | -0.620 |  0.044 |  0.382 | torch.Size([1, 1, 1, 1, 3]) || m_up2.1.conv3d.weight
 |  0.002 |  0.002 |  0.002 |    nan | torch.Size([1]) || m_up2.1.conv3d.bias
 |  0.000 | -0.293 |  0.234 |  0.046 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.0.weight
 |  0.000 | -0.279 |  0.316 |  0.046 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.2.weight
 |  1.917 | -0.448 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.0.mixer.A_log
 |  1.111 |  0.999 |  1.287 |  0.058 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.D
 | -0.000 | -0.361 |  0.352 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.423 |  0.481 |  0.171 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.004 | -0.223 |  0.215 |  0.068 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.001 | -0.144 |  0.209 |  0.039 | torch.Size([36, 128]) || m_up2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.056 |  0.058 |  0.020 | torch.Size([128, 4]) || m_up2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.003 | -0.158 |  0.288 |  0.058 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.523 |  0.386 |  0.076 | torch.Size([64, 128]) || m_up2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.188 |  0.952 |  1.337 |  0.091 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.weight
 |  0.001 | -0.154 |  0.235 |  0.078 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.bias
 |  1.916 | -0.561 |  2.773 |  0.767 | torch.Size([128, 16]) || m_up2.1.mamba_layers.1.mixer.A_log
 |  1.147 |  0.999 |  1.412 |  0.066 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.D
 |  0.000 | -0.399 |  0.390 |  0.091 | torch.Size([256, 64]) || m_up2.1.mamba_layers.1.mixer.in_proj.weight
 | -0.007 | -0.499 |  0.658 |  0.187 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.011 | -0.308 |  0.287 |  0.122 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.237 |  0.303 |  0.063 | torch.Size([36, 128]) || m_up2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.113 |  0.285 |  0.042 | torch.Size([128, 4]) || m_up2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.032 | -0.123 |  0.240 |  0.062 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.001 | -0.393 |  0.461 |  0.090 | torch.Size([64, 128]) || m_up2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.205 |  0.843 |  1.340 |  0.108 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.weight
 |  0.000 | -0.220 |  0.248 |  0.087 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.041 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.2.mixer.A_log
 |  1.007 |  0.938 |  1.087 |  0.029 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.D
 |  0.001 | -0.248 |  0.276 |  0.076 | torch.Size([256, 64]) || m_up2.1.mamba_layers.2.mixer.in_proj.weight
 |  0.001 | -0.550 |  0.677 |  0.287 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.2.mixer.conv1d.weight
 | -0.028 | -0.537 |  0.492 |  0.307 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.174 |  0.171 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.016 | -0.497 |  0.500 |  0.287 | torch.Size([128, 4]) || m_up2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.802 | -6.895 | -2.292 |  1.396 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.223 |  0.205 |  0.060 | torch.Size([64, 128]) || m_up2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.998 |  0.904 |  1.178 |  0.043 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.weight
 |  0.000 | -0.070 |  0.061 |  0.021 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.015 |  2.775 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.3.mixer.A_log
 |  1.002 |  0.944 |  1.086 |  0.030 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.219 |  0.258 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.013 | -0.594 |  0.630 |  0.292 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.3.mixer.conv1d.weight
 | -0.016 | -0.568 |  0.565 |  0.318 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.197 |  0.172 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.3.mixer.x_proj.weight
 | -0.017 | -0.491 |  0.498 |  0.291 | torch.Size([128, 4]) || m_up2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.756 | -6.892 | -2.289 |  1.356 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.232 |  0.201 |  0.060 | torch.Size([64, 128]) || m_up2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.988 |  0.868 |  1.105 |  0.038 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.weight
 | -0.001 | -0.089 |  0.083 |  0.025 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.bias
 |  0.167 |  0.121 |  0.214 |  0.065 | torch.Size([2]) || m_up2.1.pcbam_module.h_cw.weight
 | -0.035 | -0.133 |  0.092 |  0.115 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.h_cw.conv.weight
 |  0.693 |  0.692 |  0.694 |  0.001 | torch.Size([2]) || m_up2.1.pcbam_module.w_hc.weight
 | -0.108 | -0.319 |  0.039 |  0.187 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.w_hc.conv.weight
 |  0.890 |  0.840 |  0.940 |  0.071 | torch.Size([2]) || m_up2.1.pcbam_module.c_hw.weight
 | -0.061 | -0.261 |  0.057 |  0.174 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.c_hw.conv.weight
 |  1.352 |  1.014 |  1.553 |  0.127 | torch.Size([64]) || m_up2.2.trans_block.ln1.weight
 |  0.039 | -0.470 |  0.554 |  0.145 | torch.Size([64]) || m_up2.2.trans_block.ln1.bias
 |  0.131 | -2.475 |  0.722 |  0.329 | torch.Size([2, 15, 15]) || m_up2.2.trans_block.msa.relative_position_params
 |  0.000 | -0.501 |  0.560 |  0.104 | torch.Size([192, 64, 1, 1]) || m_up2.2.trans_block.msa.embedding_layer1.weight
 |  0.000 | -0.263 |  0.296 |  0.070 | torch.Size([192]) || m_up2.2.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.288 |  0.269 |  0.048 | torch.Size([64, 64, 1, 1]) || m_up2.2.trans_block.msa.linear1.weight
 |  0.003 | -0.282 |  0.441 |  0.071 | torch.Size([64]) || m_up2.2.trans_block.msa.linear1.bias
 |  1.042 |  0.586 |  1.252 |  0.125 | torch.Size([64]) || m_up2.2.trans_block.ln2.weight
 |  0.015 | -0.435 |  0.425 |  0.130 | torch.Size([64]) || m_up2.2.trans_block.ln2.bias
 |  0.002 | -0.391 |  0.424 |  0.088 | torch.Size([256, 64]) || m_up2.2.trans_block.mlp.0.weight
 | -0.044 | -0.175 |  0.085 |  0.042 | torch.Size([256]) || m_up2.2.trans_block.mlp.0.bias
 | -0.000 | -0.318 |  0.371 |  0.077 | torch.Size([64, 256]) || m_up2.2.trans_block.mlp.2.weight
 |  0.001 | -0.262 |  0.260 |  0.062 | torch.Size([64]) || m_up2.2.trans_block.mlp.2.bias
 |  0.002 | -0.489 |  2.100 |  0.102 | torch.Size([192, 192, 1, 1]) || m_up2.2.conv1_1.weight
 | -0.002 | -0.456 |  0.860 |  0.130 | torch.Size([192]) || m_up2.2.conv1_1.bias
 | -0.186 | -0.607 |  0.029 |  0.364 | torch.Size([1, 1, 1, 1, 3]) || m_up2.2.conv3d.weight
 | -0.009 | -0.009 | -0.009 |    nan | torch.Size([1]) || m_up2.2.conv3d.bias
 |  0.001 | -0.419 |  0.460 |  0.054 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.0.weight
 | -0.000 | -0.310 |  0.432 |  0.056 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.2.weight
 |  1.915 | -0.405 |  2.782 |  0.770 | torch.Size([128, 16]) || m_up2.2.mamba_layers.0.mixer.A_log
 |  1.154 |  0.722 |  1.495 |  0.109 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.D
 |  0.000 | -0.508 |  0.405 |  0.097 | torch.Size([256, 64]) || m_up2.2.mamba_layers.0.mixer.in_proj.weight
 |  0.034 | -0.552 |  0.764 |  0.196 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.0.mixer.conv1d.weight
 |  0.041 | -0.246 |  0.296 |  0.105 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.conv1d.bias
 | -0.003 | -0.527 |  0.775 |  0.078 | torch.Size([36, 128]) || m_up2.2.mamba_layers.0.mixer.x_proj.weight
 | -0.006 | -0.483 |  0.341 |  0.106 | torch.Size([128, 4]) || m_up2.2.mamba_layers.0.mixer.dt_proj.weight
 | -0.014 | -0.615 |  0.344 |  0.121 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.382 |  0.577 |  0.099 | torch.Size([64, 128]) || m_up2.2.mamba_layers.0.mixer.out_proj.weight
 |  1.253 |  0.944 |  1.403 |  0.098 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.weight
 |  0.008 | -0.526 |  0.462 |  0.166 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.bias
 |  1.919 | -0.475 |  2.882 |  0.766 | torch.Size([128, 16]) || m_up2.2.mamba_layers.1.mixer.A_log
 |  1.150 |  0.793 |  1.463 |  0.098 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.D
 |  0.000 | -0.548 |  0.600 |  0.104 | torch.Size([256, 64]) || m_up2.2.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.693 |  1.017 |  0.213 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.1.mixer.conv1d.weight
 |  0.031 | -0.351 |  0.325 |  0.127 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.509 |  0.593 |  0.101 | torch.Size([36, 128]) || m_up2.2.mamba_layers.1.mixer.x_proj.weight
 |  0.002 | -0.444 |  0.364 |  0.105 | torch.Size([128, 4]) || m_up2.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.056 | -0.214 |  0.569 |  0.109 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.453 |  0.455 |  0.098 | torch.Size([64, 128]) || m_up2.2.mamba_layers.1.mixer.out_proj.weight
 |  1.316 |  0.842 |  1.519 |  0.140 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.weight
 |  0.003 | -0.149 |  0.354 |  0.088 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.bias
 |  1.917 | -0.029 |  2.774 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.2.mixer.A_log
 |  1.018 |  0.954 |  1.143 |  0.032 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.D
 | -0.000 | -0.346 |  0.310 |  0.078 | torch.Size([256, 64]) || m_up2.2.mamba_layers.2.mixer.in_proj.weight
 | -0.004 | -0.567 |  0.540 |  0.289 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.2.mixer.conv1d.weight
 |  0.065 | -0.560 |  0.576 |  0.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.217 |  0.193 |  0.054 | torch.Size([36, 128]) || m_up2.2.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.497 |  0.499 |  0.286 | torch.Size([128, 4]) || m_up2.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.495 | -6.884 | -2.259 |  1.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.279 |  0.279 |  0.065 | torch.Size([64, 128]) || m_up2.2.mamba_layers.2.mixer.out_proj.weight
 |  1.018 |  0.882 |  1.149 |  0.050 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.weight
 |  0.004 | -0.087 |  0.117 |  0.039 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.bias
 |  1.917 | -0.073 |  2.777 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.3.mixer.A_log
 |  1.024 |  0.953 |  1.196 |  0.042 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.D
 |  0.000 | -0.317 |  0.263 |  0.078 | torch.Size([256, 64]) || m_up2.2.mamba_layers.3.mixer.in_proj.weight
 |  0.009 | -0.636 |  0.615 |  0.288 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.3.mixer.conv1d.weight
 |  0.031 | -0.525 |  0.560 |  0.302 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.240 |  0.173 |  0.057 | torch.Size([36, 128]) || m_up2.2.mamba_layers.3.mixer.x_proj.weight
 |  0.004 | -0.595 |  0.600 |  0.291 | torch.Size([128, 4]) || m_up2.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.642 | -6.849 | -2.288 |  1.277 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.dt_proj.bias
 |  0.000 | -0.243 |  0.296 |  0.066 | torch.Size([64, 128]) || m_up2.2.mamba_layers.3.mixer.out_proj.weight
 |  1.014 |  0.878 |  1.138 |  0.048 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.weight
 |  0.004 | -0.075 |  0.074 |  0.032 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.bias
 |  0.305 |  0.187 |  0.423 |  0.167 | torch.Size([2]) || m_up2.2.pcbam_module.h_cw.weight
 |  0.051 | -0.090 |  0.150 |  0.125 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.h_cw.conv.weight
 |  0.820 |  0.756 |  0.884 |  0.091 | torch.Size([2]) || m_up2.2.pcbam_module.w_hc.weight
 | -0.005 | -0.137 |  0.061 |  0.114 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.w_hc.conv.weight
 |  0.734 |  0.714 |  0.754 |  0.028 | torch.Size([2]) || m_up2.2.pcbam_module.c_hw.weight
 |  0.097 |  0.080 |  0.111 |  0.015 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.168 |  0.185 |  0.027 | torch.Size([192, 96, 2, 2]) || m_up1.0.weight
 |  1.175 |  0.732 |  1.409 |  0.205 | torch.Size([32]) || m_up1.1.trans_block.ln1.weight
 | -0.009 | -0.395 |  0.521 |  0.227 | torch.Size([32]) || m_up1.1.trans_block.ln1.bias
 |  0.132 | -0.736 |  0.856 |  0.412 | torch.Size([1, 15, 15]) || m_up1.1.trans_block.msa.relative_position_params
 | -0.000 | -0.391 |  0.382 |  0.111 | torch.Size([96, 32, 1, 1]) || m_up1.1.trans_block.msa.embedding_layer1.weight
 | -0.013 | -0.380 |  0.400 |  0.176 | torch.Size([96]) || m_up1.1.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.250 |  0.258 |  0.074 | torch.Size([32, 32, 1, 1]) || m_up1.1.trans_block.msa.linear1.weight
 |  0.003 | -0.120 |  0.146 |  0.064 | torch.Size([32]) || m_up1.1.trans_block.msa.linear1.bias
 |  1.862 |  1.415 |  2.286 |  0.225 | torch.Size([32]) || m_up1.1.trans_block.ln2.weight
 | -0.001 | -0.345 |  0.338 |  0.197 | torch.Size([32]) || m_up1.1.trans_block.ln2.bias
 |  0.001 | -0.854 |  0.775 |  0.172 | torch.Size([128, 32]) || m_up1.1.trans_block.mlp.0.weight
 | -0.014 | -0.409 |  0.344 |  0.133 | torch.Size([128]) || m_up1.1.trans_block.mlp.0.bias
 |  0.001 | -0.663 |  0.840 |  0.128 | torch.Size([32, 128]) || m_up1.1.trans_block.mlp.2.weight
 | -0.030 | -0.413 |  0.253 |  0.164 | torch.Size([32]) || m_up1.1.trans_block.mlp.2.bias
 | -0.005 | -1.324 |  0.491 |  0.125 | torch.Size([96, 96, 1, 1]) || m_up1.1.conv1_1.weight
 | -0.001 | -0.286 |  0.262 |  0.084 | torch.Size([96]) || m_up1.1.conv1_1.bias
 |  0.018 | -0.243 |  0.394 |  0.333 | torch.Size([1, 1, 1, 1, 3]) || m_up1.1.conv3d.weight
 |  0.002 |  0.002 |  0.002 |    nan | torch.Size([1]) || m_up1.1.conv3d.bias
 | -0.001 | -0.580 |  0.715 |  0.087 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.0.weight
 |  0.000 | -0.607 |  0.797 |  0.095 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.2.weight
 |  1.912 | -0.265 |  2.774 |  0.773 | torch.Size([64, 16]) || m_up1.1.mamba_layers.0.mixer.A_log
 |  1.110 |  0.941 |  1.414 |  0.099 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.D
 | -0.001 | -0.476 |  0.654 |  0.125 | torch.Size([128, 32]) || m_up1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.013 | -0.524 |  0.392 |  0.168 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.0.mixer.conv1d.weight
 | -0.001 | -0.193 |  0.268 |  0.090 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.004 | -0.403 |  0.422 |  0.092 | torch.Size([34, 64]) || m_up1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.011 | -0.521 |  0.297 |  0.129 | torch.Size([64, 2]) || m_up1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.029 | -0.778 |  0.464 |  0.212 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.001 | -0.354 |  0.422 |  0.115 | torch.Size([32, 64]) || m_up1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.201 |  0.960 |  1.391 |  0.125 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.weight
 |  0.001 | -0.231 |  0.138 |  0.074 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.bias
 |  1.906 | -0.993 |  2.773 |  0.783 | torch.Size([64, 16]) || m_up1.1.mamba_layers.1.mixer.A_log
 |  1.175 |  1.060 |  1.328 |  0.056 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.D
 |  0.001 | -0.404 |  0.531 |  0.122 | torch.Size([128, 32]) || m_up1.1.mamba_layers.1.mixer.in_proj.weight
 | -0.008 | -0.502 |  0.368 |  0.156 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.1.mixer.conv1d.weight
 | -0.030 | -0.319 |  0.239 |  0.168 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.382 |  0.281 |  0.069 | torch.Size([34, 64]) || m_up1.1.mamba_layers.1.mixer.x_proj.weight
 | -0.012 | -0.374 |  0.251 |  0.086 | torch.Size([64, 2]) || m_up1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.090 | -0.090 |  0.504 |  0.090 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.004 | -0.606 |  0.501 |  0.128 | torch.Size([32, 64]) || m_up1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.169 |  0.921 |  1.361 |  0.089 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.weight
 |  0.005 | -0.159 |  0.209 |  0.097 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.bias
 |  1.916 | -0.071 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.2.mixer.A_log
 |  1.035 |  0.954 |  1.172 |  0.042 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.D
 | -0.002 | -0.357 |  0.359 |  0.112 | torch.Size([128, 32]) || m_up1.1.mamba_layers.2.mixer.in_proj.weight
 |  0.010 | -0.619 |  0.691 |  0.294 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.2.mixer.conv1d.weight
 |  0.007 | -0.520 |  0.481 |  0.302 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.214 |  0.255 |  0.082 | torch.Size([34, 64]) || m_up1.1.mamba_layers.2.mixer.x_proj.weight
 | -0.082 | -0.707 |  0.700 |  0.396 | torch.Size([64, 2]) || m_up1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.429 | -6.865 | -2.310 |  1.242 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.325 |  0.261 |  0.087 | torch.Size([32, 64]) || m_up1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.026 |  0.956 |  1.097 |  0.031 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.weight
 | -0.003 | -0.040 |  0.038 |  0.021 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.bias
 |  1.913 | -0.037 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.3.mixer.A_log
 |  1.027 |  0.962 |  1.130 |  0.035 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.278 |  0.312 |  0.108 | torch.Size([128, 32]) || m_up1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.012 | -0.519 |  0.571 |  0.296 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.3.mixer.conv1d.weight
 | -0.007 | -0.541 |  0.535 |  0.325 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.210 |  0.232 |  0.082 | torch.Size([34, 64]) || m_up1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.751 |  0.694 |  0.410 | torch.Size([64, 2]) || m_up1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.497 | -6.875 | -2.319 |  1.352 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.003 | -0.253 |  0.254 |  0.085 | torch.Size([32, 64]) || m_up1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.016 |  0.957 |  1.069 |  0.032 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.weight
 | -0.002 | -0.053 |  0.062 |  0.024 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.bias
 |  0.533 |  0.169 |  0.897 |  0.515 | torch.Size([2]) || m_up1.1.pcbam_module.h_cw.weight
 | -0.059 | -0.137 |  0.063 |  0.107 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.h_cw.conv.weight
 |  0.070 |  0.005 |  0.134 |  0.091 | torch.Size([2]) || m_up1.1.pcbam_module.w_hc.weight
 | -0.128 | -0.260 |  0.045 |  0.156 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.w_hc.conv.weight
 |  0.449 |  0.106 |  0.791 |  0.484 | torch.Size([2]) || m_up1.1.pcbam_module.c_hw.weight
 | -0.003 | -0.253 |  0.327 |  0.298 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.c_hw.conv.weight
 |  1.250 |  0.909 |  1.602 |  0.174 | torch.Size([32]) || m_up1.2.trans_block.ln1.weight
 |  0.010 | -0.445 |  0.521 |  0.190 | torch.Size([32]) || m_up1.2.trans_block.ln1.bias
 | -0.145 | -0.774 |  0.660 |  0.356 | torch.Size([1, 15, 15]) || m_up1.2.trans_block.msa.relative_position_params
 | -0.001 | -0.613 |  0.676 |  0.146 | torch.Size([96, 32, 1, 1]) || m_up1.2.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.230 |  0.149 |  0.044 | torch.Size([96]) || m_up1.2.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.153 |  0.176 |  0.044 | torch.Size([32, 32, 1, 1]) || m_up1.2.trans_block.msa.linear1.weight
 |  0.001 | -0.147 |  0.140 |  0.049 | torch.Size([32]) || m_up1.2.trans_block.msa.linear1.bias
 |  0.995 |  0.801 |  1.186 |  0.094 | torch.Size([32]) || m_up1.2.trans_block.ln2.weight
 | -0.006 | -0.183 |  0.216 |  0.080 | torch.Size([32]) || m_up1.2.trans_block.ln2.bias
 |  0.001 | -0.555 |  0.426 |  0.079 | torch.Size([128, 32]) || m_up1.2.trans_block.mlp.0.weight
 | -0.005 | -0.214 |  0.099 |  0.051 | torch.Size([128]) || m_up1.2.trans_block.mlp.0.bias
 | -0.002 | -0.341 |  0.369 |  0.082 | torch.Size([32, 128]) || m_up1.2.trans_block.mlp.2.weight
 |  0.001 | -0.104 |  0.243 |  0.063 | torch.Size([32]) || m_up1.2.trans_block.mlp.2.bias
 | -0.002 | -0.810 |  0.495 |  0.110 | torch.Size([96, 96, 1, 1]) || m_up1.2.conv1_1.weight
 | -0.002 | -0.224 |  0.384 |  0.061 | torch.Size([96]) || m_up1.2.conv1_1.bias
 |  0.087 | -0.065 |  0.340 |  0.220 | torch.Size([1, 1, 1, 1, 3]) || m_up1.2.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_up1.2.conv3d.bias
 |  0.002 | -0.369 |  0.581 |  0.081 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.0.weight
 | -0.000 | -0.593 |  0.785 |  0.098 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.2.weight
 |  1.913 | -0.760 |  2.773 |  0.775 | torch.Size([64, 16]) || m_up1.2.mamba_layers.0.mixer.A_log
 |  1.119 |  0.979 |  1.404 |  0.076 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.D
 |  0.001 | -0.536 |  0.540 |  0.125 | torch.Size([128, 32]) || m_up1.2.mamba_layers.0.mixer.in_proj.weight
 | -0.003 | -0.375 |  0.450 |  0.166 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.0.mixer.conv1d.weight
 |  0.006 | -0.089 |  0.134 |  0.050 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.530 |  0.349 |  0.102 | torch.Size([34, 64]) || m_up1.2.mamba_layers.0.mixer.x_proj.weight
 | -0.001 | -0.097 |  0.143 |  0.040 | torch.Size([64, 2]) || m_up1.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.028 | -0.382 |  0.654 |  0.188 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.361 |  0.396 |  0.112 | torch.Size([32, 64]) || m_up1.2.mamba_layers.0.mixer.out_proj.weight
 |  1.258 |  0.859 |  1.450 |  0.124 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.weight
 |  0.016 | -0.245 |  0.314 |  0.114 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.bias
 |  1.913 | -0.550 |  2.784 |  0.778 | torch.Size([64, 16]) || m_up1.2.mamba_layers.1.mixer.A_log
 |  1.193 |  0.973 |  1.463 |  0.105 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.D
 |  0.001 | -0.625 |  0.624 |  0.141 | torch.Size([128, 32]) || m_up1.2.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.604 |  0.675 |  0.188 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.1.mixer.conv1d.weight
 |  0.017 | -0.247 |  0.221 |  0.104 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.conv1d.bias
 |  0.001 | -0.534 |  0.588 |  0.122 | torch.Size([34, 64]) || m_up1.2.mamba_layers.1.mixer.x_proj.weight
 | -0.047 | -0.481 |  0.253 |  0.157 | torch.Size([64, 2]) || m_up1.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.042 | -0.450 |  0.552 |  0.160 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.dt_proj.bias
 | -0.002 | -0.741 |  0.564 |  0.147 | torch.Size([32, 64]) || m_up1.2.mamba_layers.1.mixer.out_proj.weight
 |  1.230 |  0.924 |  1.407 |  0.114 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.weight
 |  0.007 | -0.129 |  0.113 |  0.053 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.bias
 |  1.917 | -0.073 |  2.777 |  0.765 | torch.Size([64, 16]) || m_up1.2.mamba_layers.2.mixer.A_log
 |  1.014 |  0.942 |  1.177 |  0.046 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.D
 |  0.000 | -0.354 |  0.313 |  0.109 | torch.Size([128, 32]) || m_up1.2.mamba_layers.2.mixer.in_proj.weight
 | -0.022 | -0.644 |  0.593 |  0.282 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.2.mixer.conv1d.weight
 |  0.009 | -0.532 |  0.528 |  0.322 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.259 |  0.238 |  0.077 | torch.Size([34, 64]) || m_up1.2.mamba_layers.2.mixer.x_proj.weight
 |  0.070 | -0.709 |  0.670 |  0.392 | torch.Size([64, 2]) || m_up1.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.716 | -6.819 | -2.342 |  1.385 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.330 |  0.288 |  0.089 | torch.Size([32, 64]) || m_up1.2.mamba_layers.2.mixer.out_proj.weight
 |  1.014 |  0.901 |  1.119 |  0.055 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.weight
 |  0.001 | -0.064 |  0.048 |  0.027 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.bias
 |  1.916 | -0.067 |  2.776 |  0.766 | torch.Size([64, 16]) || m_up1.2.mamba_layers.3.mixer.A_log
 |  1.007 |  0.930 |  1.134 |  0.040 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.D
 | -0.001 | -0.371 |  0.439 |  0.110 | torch.Size([128, 32]) || m_up1.2.mamba_layers.3.mixer.in_proj.weight
 |  0.013 | -0.700 |  0.568 |  0.296 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.3.mixer.conv1d.weight
 |  0.083 | -0.446 |  0.560 |  0.281 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.conv1d.bias
 | -0.004 | -0.239 |  0.259 |  0.078 | torch.Size([34, 64]) || m_up1.2.mamba_layers.3.mixer.x_proj.weight
 | -0.115 | -0.707 |  0.686 |  0.390 | torch.Size([64, 2]) || m_up1.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.758 | -6.876 | -2.275 |  1.309 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.002 | -0.407 |  0.269 |  0.089 | torch.Size([32, 64]) || m_up1.2.mamba_layers.3.mixer.out_proj.weight
 |  1.019 |  0.958 |  1.209 |  0.053 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.weight
 | -0.001 | -0.052 |  0.062 |  0.022 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.bias
 |  0.665 |  0.456 |  0.874 |  0.296 | torch.Size([2]) || m_up1.2.pcbam_module.h_cw.weight
 |  0.135 |  0.075 |  0.176 |  0.053 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.h_cw.conv.weight
 |  0.182 |  0.079 |  0.285 |  0.145 | torch.Size([2]) || m_up1.2.pcbam_module.w_hc.weight
 | -0.024 | -0.155 |  0.201 |  0.196 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.w_hc.conv.weight
 |  0.235 |  0.094 |  0.376 |  0.200 | torch.Size([2]) || m_up1.2.pcbam_module.c_hw.weight
 |  0.073 | -0.039 |  0.152 |  0.100 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.c_hw.conv.weight
 |  0.000 | -0.071 |  0.069 |  0.014 | torch.Size([3, 96, 3, 3]) || m_tail.0.weight
 | -0.027 | -0.131 |  0.147 |  0.084 | torch.Size([3, 3, 1, 1]) || fft.mag.weight
 |  0.178 | -0.197 |  0.457 |  0.338 | torch.Size([3]) || fft.mag.bias
 |  0.163 |  0.030 |  0.320 |  0.147 | torch.Size([3]) || fft.mag_bn.weight
 | -0.814 | -2.189 | -0.114 |  1.191 | torch.Size([3]) || fft.mag_bn.bias
 | -1.441 | -5.003 |  2.895 |  4.005 | torch.Size([3]) || fft.mag_bn.running_mean
 | 283.145 | 158.846 | 518.032 | 203.534 | torch.Size([3]) || fft.mag_bn.running_var
 |  0.010 | -0.301 |  0.165 |  0.157 | torch.Size([3, 3, 1, 1]) || fft.pha.0.weight
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.0.bias
 |  1.179 |  0.836 |  1.435 |  0.309 | torch.Size([3]) || fft.pha.1.weight
 |  0.326 |  0.206 |  0.398 |  0.105 | torch.Size([3]) || fft.pha.1.bias
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.1.running_mean
 |  0.026 |  0.017 |  0.039 |  0.012 | torch.Size([3]) || fft.pha.1.running_var
 | -0.087 | -0.664 |  0.872 |  0.497 | torch.Size([3, 3, 1, 1]) || fft.pha.3.weight
 |  0.010 | -0.147 |  0.141 |  0.145 | torch.Size([3]) || fft.pha.3.bias
 |  0.323 | -0.158 |  2.090 |  0.868 | torch.Size([1, 6, 1, 1]) || fft.conv1.weight
 |  0.030 |  0.030 |  0.030 |    nan | torch.Size([1]) || fft.conv1.bias
 | -0.001 | -0.085 |  0.073 |  0.023 | torch.Size([96, 96, 1, 1]) || conv1.weight
 | -0.000 | -0.016 |  0.021 |  0.005 | torch.Size([96]) || conv1.bias
 |  0.398 |  0.002 |  0.888 |  0.227 | torch.Size([96]) || bn1.weight
 | -0.095 | -0.205 | -0.011 |  0.044 | torch.Size([96]) || bn1.bias
 | -0.004 | -0.044 |  0.059 |  0.028 | torch.Size([96]) || bn1.running_mean
 |  0.002 |  0.000 |  0.007 |  0.001 | torch.Size([96]) || bn1.running_var
 | -0.002 | -0.065 |  0.059 |  0.014 | torch.Size([192, 96, 2, 2]) || conv2.weight
 | -0.000 | -0.011 |  0.012 |  0.004 | torch.Size([192]) || conv2.bias
 |  0.407 |  0.016 |  0.895 |  0.228 | torch.Size([192]) || bn2.weight
 | -0.081 | -0.209 | -0.010 |  0.039 | torch.Size([192]) || bn2.bias
 | -0.026 | -0.123 |  0.096 |  0.050 | torch.Size([192]) || bn2.running_mean
 |  0.025 |  0.000 |  0.079 |  0.015 | torch.Size([192]) || bn2.running_var
 | -0.001 | -0.044 |  0.041 |  0.007 | torch.Size([384, 96, 4, 4]) || conv3.weight
 | -0.000 | -0.022 |  0.014 |  0.005 | torch.Size([384]) || conv3.bias
 |  0.435 |  0.045 |  0.918 |  0.222 | torch.Size([384]) || bn3.weight
 | -0.069 | -0.200 |  0.024 |  0.035 | torch.Size([384]) || bn3.bias
 | -0.066 | -0.197 |  0.165 |  0.045 | torch.Size([384]) || bn3.running_mean
 |  0.065 |  0.003 |  0.240 |  0.033 | torch.Size([384]) || bn3.running_var

25-05-15 09:21:34.430 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/13_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/RICE1
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 15
      sigma_test: 15
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/RICE100
      dataroot_L: None
      sigma: 15
      sigma_test: 15
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 1
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-15 09:21:34.431 : Random seed: 8943
25-05-15 09:21:34.453 : Number of train images: 385, iters: 385
25-05-15 09:21:36.329 : 
Networks name: DRNet
Params number: 18333721
Net structure:
DRNet(
  (m_head): Sequential(
    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (m_down1): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down2): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down3): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_body): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up3): Sequential(
    (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up2): Sequential(
    (0): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up1): Sequential(
    (0): ConvTranspose2d(192, 96, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_tail): Sequential(
    (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (fft): ResBlock_fft_bench(
    (mag): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
    (mag_bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (mag_relu): ReLU(inplace=True)
    (pha): Sequential(
      (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (4): Sigmoid()
    )
    (conv1): Conv2d(6, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
  (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (conv2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
  (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu2): ReLU()
  (conv3): Conv2d(96, 384, kernel_size=(4, 4), stride=(4, 4))
  (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu3): ReLU()
)

25-05-15 09:21:37.023 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.001 | -0.175 |  0.200 |  0.043 | torch.Size([96, 3, 3, 3]) || m_head.0.weight
 |  0.987 |  0.660 |  1.331 |  0.161 | torch.Size([32]) || m_down1.0.trans_block.ln1.weight
 | -0.029 | -0.287 |  0.309 |  0.141 | torch.Size([32]) || m_down1.0.trans_block.ln1.bias
 | -0.078 | -0.697 |  0.996 |  0.367 | torch.Size([1, 15, 15]) || m_down1.0.trans_block.msa.relative_position_params
 |  0.000 | -0.306 |  0.340 |  0.061 | torch.Size([96, 32, 1, 1]) || m_down1.0.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.126 |  0.122 |  0.055 | torch.Size([96]) || m_down1.0.trans_block.msa.embedding_layer1.bias
 |  0.003 | -0.181 |  0.211 |  0.052 | torch.Size([32, 32, 1, 1]) || m_down1.0.trans_block.msa.linear1.weight
 |  0.008 | -0.087 |  0.126 |  0.059 | torch.Size([32]) || m_down1.0.trans_block.msa.linear1.bias
 |  1.183 |  0.995 |  1.457 |  0.126 | torch.Size([32]) || m_down1.0.trans_block.ln2.weight
 | -0.012 | -0.173 |  0.141 |  0.061 | torch.Size([32]) || m_down1.0.trans_block.ln2.bias
 |  0.005 | -0.539 |  1.337 |  0.115 | torch.Size([128, 32]) || m_down1.0.trans_block.mlp.0.weight
 | -0.023 | -0.193 |  0.157 |  0.072 | torch.Size([128]) || m_down1.0.trans_block.mlp.0.bias
 | -0.001 | -0.498 |  0.763 |  0.088 | torch.Size([32, 128]) || m_down1.0.trans_block.mlp.2.weight
 |  0.000 | -0.123 |  0.322 |  0.096 | torch.Size([32]) || m_down1.0.trans_block.mlp.2.bias
 |  0.007 | -0.513 |  0.480 |  0.098 | torch.Size([96, 96, 1, 1]) || m_down1.0.conv1_1.weight
 | -0.000 | -0.450 |  0.422 |  0.109 | torch.Size([96]) || m_down1.0.conv1_1.bias
 | -0.083 | -0.171 |  0.001 |  0.086 | torch.Size([1, 1, 1, 1, 3]) || m_down1.0.conv3d.weight
 | -0.019 | -0.019 | -0.019 |    nan | torch.Size([1]) || m_down1.0.conv3d.bias
 |  0.006 | -0.351 |  0.450 |  0.073 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.0.weight
 | -0.003 | -0.462 |  0.370 |  0.072 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.2.weight
 |  1.906 | -2.375 |  2.825 |  0.814 | torch.Size([64, 16]) || m_down1.0.mamba_layers.0.mixer.A_log
 |  1.080 |  0.335 |  1.366 |  0.177 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.D
 | -0.000 | -0.472 |  0.518 |  0.121 | torch.Size([128, 32]) || m_down1.0.mamba_layers.0.mixer.in_proj.weight
 |  0.001 | -0.451 |  0.468 |  0.166 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.0.mixer.conv1d.weight
 | -0.010 | -0.240 |  0.194 |  0.097 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.921 |  0.734 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.0.mixer.x_proj.weight
 |  0.004 | -0.791 |  1.048 |  0.250 | torch.Size([64, 2]) || m_down1.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.078 | -1.700 |  0.446 |  0.386 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.663 |  0.579 |  0.116 | torch.Size([32, 64]) || m_down1.0.mamba_layers.0.mixer.out_proj.weight
 |  1.126 |  0.901 |  1.630 |  0.129 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.weight
 |  0.014 | -0.392 |  0.312 |  0.163 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.bias
 |  1.905 | -0.803 |  2.773 |  0.795 | torch.Size([64, 16]) || m_down1.0.mamba_layers.1.mixer.A_log
 |  1.161 |  0.902 |  1.358 |  0.086 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.D
 |  0.001 | -0.592 |  0.466 |  0.128 | torch.Size([128, 32]) || m_down1.0.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.375 |  0.488 |  0.159 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.1.mixer.conv1d.weight
 | -0.003 | -0.307 |  0.272 |  0.168 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.565 |  0.739 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.1.mixer.x_proj.weight
 |  0.014 | -0.295 |  0.482 |  0.148 | torch.Size([64, 2]) || m_down1.0.mamba_layers.1.mixer.dt_proj.weight
 |  0.051 | -0.349 |  0.267 |  0.126 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.002 | -0.370 |  0.431 |  0.119 | torch.Size([32, 64]) || m_down1.0.mamba_layers.1.mixer.out_proj.weight
 |  1.169 |  0.987 |  1.348 |  0.100 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.weight
 | -0.005 | -0.265 |  0.353 |  0.141 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.bias
 |  1.917 | -0.076 |  2.775 |  0.765 | torch.Size([64, 16]) || m_down1.0.mamba_layers.2.mixer.A_log
 |  1.015 |  0.929 |  1.117 |  0.039 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.D
 |  0.000 | -0.336 |  0.347 |  0.107 | torch.Size([128, 32]) || m_down1.0.mamba_layers.2.mixer.in_proj.weight
 | -0.011 | -0.588 |  0.582 |  0.292 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.2.mixer.conv1d.weight
 | -0.032 | -0.507 |  0.490 |  0.285 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.221 |  0.197 |  0.076 | torch.Size([34, 64]) || m_down1.0.mamba_layers.2.mixer.x_proj.weight
 | -0.055 | -0.706 |  0.714 |  0.417 | torch.Size([64, 2]) || m_down1.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.715 | -6.856 | -2.310 |  1.285 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.dt_proj.bias
 | -0.003 | -0.250 |  0.275 |  0.085 | torch.Size([32, 64]) || m_down1.0.mamba_layers.2.mixer.out_proj.weight
 |  0.997 |  0.908 |  1.102 |  0.039 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.weight
 |  0.006 | -0.042 |  0.062 |  0.024 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.bias
 |  1.916 | -0.288 |  2.776 |  0.766 | torch.Size([64, 16]) || m_down1.0.mamba_layers.3.mixer.A_log
 |  1.008 |  0.930 |  1.107 |  0.037 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.D
 |  0.003 | -0.277 |  0.272 |  0.106 | torch.Size([128, 32]) || m_down1.0.mamba_layers.3.mixer.in_proj.weight
 |  0.003 | -0.595 |  0.551 |  0.295 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.3.mixer.conv1d.weight
 | -0.073 | -0.633 |  0.543 |  0.307 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.209 |  0.225 |  0.077 | torch.Size([34, 64]) || m_down1.0.mamba_layers.3.mixer.x_proj.weight
 |  0.039 | -0.688 |  0.780 |  0.425 | torch.Size([64, 2]) || m_down1.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.400 | -7.109 | -2.270 |  1.483 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.242 |  0.301 |  0.084 | torch.Size([32, 64]) || m_down1.0.mamba_layers.3.mixer.out_proj.weight
 |  0.992 |  0.929 |  1.040 |  0.027 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.weight
 | -0.004 | -0.050 |  0.035 |  0.021 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.bias
 |  0.172 |  0.082 |  0.262 |  0.127 | torch.Size([2]) || m_down1.0.pcbam_module.h_cw.weight
 |  0.077 | -0.087 |  0.186 |  0.145 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.h_cw.conv.weight
 |  0.561 |  0.266 |  0.856 |  0.418 | torch.Size([2]) || m_down1.0.pcbam_module.w_hc.weight
 |  0.077 | -0.128 |  0.187 |  0.178 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.w_hc.conv.weight
 |  0.613 |  0.589 |  0.638 |  0.034 | torch.Size([2]) || m_down1.0.pcbam_module.c_hw.weight
 |  0.046 | -0.255 |  0.385 |  0.322 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.c_hw.conv.weight
 |  1.047 |  0.723 |  1.284 |  0.157 | torch.Size([32]) || m_down1.1.trans_block.ln1.weight
 |  0.022 | -0.321 |  0.299 |  0.146 | torch.Size([32]) || m_down1.1.trans_block.ln1.bias
 | -0.224 | -0.785 |  0.840 |  0.324 | torch.Size([1, 15, 15]) || m_down1.1.trans_block.msa.relative_position_params
 |  0.001 | -0.389 |  0.378 |  0.091 | torch.Size([96, 32, 1, 1]) || m_down1.1.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.192 |  0.185 |  0.052 | torch.Size([96]) || m_down1.1.trans_block.msa.embedding_layer1.bias
 | -0.002 | -0.207 |  0.203 |  0.054 | torch.Size([32, 32, 1, 1]) || m_down1.1.trans_block.msa.linear1.weight
 |  0.001 | -0.174 |  0.116 |  0.058 | torch.Size([32]) || m_down1.1.trans_block.msa.linear1.bias
 |  1.159 |  0.962 |  1.324 |  0.078 | torch.Size([32]) || m_down1.1.trans_block.ln2.weight
 |  0.000 | -0.130 |  0.189 |  0.072 | torch.Size([32]) || m_down1.1.trans_block.ln2.bias
 | -0.001 | -0.971 |  0.583 |  0.116 | torch.Size([128, 32]) || m_down1.1.trans_block.mlp.0.weight
 | -0.012 | -0.254 |  0.114 |  0.055 | torch.Size([128]) || m_down1.1.trans_block.mlp.0.bias
 | -0.000 | -0.671 |  0.674 |  0.099 | torch.Size([32, 128]) || m_down1.1.trans_block.mlp.2.weight
 | -0.005 | -0.128 |  0.227 |  0.083 | torch.Size([32]) || m_down1.1.trans_block.mlp.2.bias
 |  0.008 | -0.460 |  0.572 |  0.100 | torch.Size([96, 96, 1, 1]) || m_down1.1.conv1_1.weight
 | -0.007 | -0.190 |  0.290 |  0.062 | torch.Size([96]) || m_down1.1.conv1_1.bias
 | -0.075 | -0.281 |  0.031 |  0.178 | torch.Size([1, 1, 1, 1, 3]) || m_down1.1.conv3d.weight
 | -0.007 | -0.007 | -0.007 |    nan | torch.Size([1]) || m_down1.1.conv3d.bias
 | -0.002 | -0.396 |  0.350 |  0.065 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.0.weight
 | -0.006 | -0.313 |  0.296 |  0.065 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.2.weight
 |  1.917 | -0.011 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.0.mixer.A_log
 |  1.048 |  0.985 |  1.173 |  0.047 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.D
 | -0.000 | -0.452 |  0.447 |  0.086 | torch.Size([128, 32]) || m_down1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.014 | -0.310 |  0.347 |  0.115 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.0.mixer.conv1d.weight
 |  0.015 | -0.205 |  0.218 |  0.064 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.143 |  0.135 |  0.031 | torch.Size([34, 64]) || m_down1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.002 | -0.062 |  0.053 |  0.025 | torch.Size([64, 2]) || m_down1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.001 | -0.024 |  0.032 |  0.009 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.371 |  0.361 |  0.083 | torch.Size([32, 64]) || m_down1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.116 |  0.916 |  1.300 |  0.106 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.weight
 |  0.012 | -0.169 |  0.191 |  0.080 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.bias
 |  1.918 | -0.212 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.1.mixer.A_log
 |  1.091 |  0.987 |  1.483 |  0.090 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.D
 |  0.000 | -0.628 |  0.637 |  0.095 | torch.Size([128, 32]) || m_down1.1.mamba_layers.1.mixer.in_proj.weight
 |  0.001 | -0.337 |  0.387 |  0.127 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.1.mixer.conv1d.weight
 |  0.002 | -0.197 |  0.192 |  0.089 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.001 | -0.185 |  0.297 |  0.049 | torch.Size([34, 64]) || m_down1.1.mamba_layers.1.mixer.x_proj.weight
 |  0.006 | -0.152 |  0.156 |  0.037 | torch.Size([64, 2]) || m_down1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.008 | -0.161 |  0.452 |  0.077 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.004 | -0.546 |  0.368 |  0.087 | torch.Size([32, 64]) || m_down1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.136 |  1.025 |  1.302 |  0.076 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.weight
 | -0.002 | -0.095 |  0.090 |  0.052 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.bias
 |  1.917 | -0.018 |  2.774 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.2.mixer.A_log
 |  1.001 |  0.959 |  1.048 |  0.022 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.D
 | -0.001 | -0.233 |  0.264 |  0.106 | torch.Size([128, 32]) || m_down1.1.mamba_layers.2.mixer.in_proj.weight
 | -0.022 | -0.509 |  0.513 |  0.285 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.2.mixer.conv1d.weight
 | -0.017 | -0.508 |  0.444 |  0.282 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.150 |  0.153 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.2.mixer.x_proj.weight
 |  0.092 | -0.700 |  0.704 |  0.396 | torch.Size([64, 2]) || m_down1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.418 | -6.864 | -2.343 |  1.239 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.259 |  0.279 |  0.077 | torch.Size([32, 64]) || m_down1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.000 |  0.960 |  1.041 |  0.024 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.weight
 |  0.002 | -0.040 |  0.032 |  0.017 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.bias
 |  1.917 | -0.045 |  2.777 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.3.mixer.A_log
 |  1.008 |  0.964 |  1.080 |  0.028 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.298 |  0.349 |  0.110 | torch.Size([128, 32]) || m_down1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.024 | -0.512 |  0.552 |  0.300 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.3.mixer.conv1d.weight
 |  0.050 | -0.424 |  0.517 |  0.242 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.166 |  0.183 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.694 |  0.699 |  0.380 | torch.Size([64, 2]) || m_down1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.585 | -6.892 | -2.263 |  1.350 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.002 | -0.232 |  0.284 |  0.080 | torch.Size([32, 64]) || m_down1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.029 |  0.951 |  1.119 |  0.040 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.weight
 | -0.001 | -0.048 |  0.061 |  0.031 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.bias
 |  0.147 |  0.115 |  0.180 |  0.046 | torch.Size([2]) || m_down1.1.pcbam_module.h_cw.weight
 |  0.199 |  0.033 |  0.468 |  0.235 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.h_cw.conv.weight
 |  0.368 |  0.181 |  0.554 |  0.264 | torch.Size([2]) || m_down1.1.pcbam_module.w_hc.weight
 |  0.247 |  0.094 |  0.417 |  0.162 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.w_hc.conv.weight
 |  0.722 |  0.569 |  0.875 |  0.216 | torch.Size([2]) || m_down1.1.pcbam_module.c_hw.weight
 | -0.100 | -0.294 |  0.117 |  0.206 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.324 |  0.289 |  0.052 | torch.Size([192, 96, 2, 2]) || m_down1.2.weight
 |  1.092 |  0.706 |  1.746 |  0.253 | torch.Size([64]) || m_down2.0.trans_block.ln1.weight
 | -0.006 | -0.504 |  0.511 |  0.232 | torch.Size([64]) || m_down2.0.trans_block.ln1.bias
 | -0.206 | -1.978 |  1.851 |  0.710 | torch.Size([2, 15, 15]) || m_down2.0.trans_block.msa.relative_position_params
 |  0.000 | -0.453 |  0.444 |  0.078 | torch.Size([192, 64, 1, 1]) || m_down2.0.trans_block.msa.embedding_layer1.weight
 | -0.006 | -0.213 |  0.192 |  0.048 | torch.Size([192]) || m_down2.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.275 |  0.255 |  0.051 | torch.Size([64, 64, 1, 1]) || m_down2.0.trans_block.msa.linear1.weight
 |  0.002 | -0.125 |  0.215 |  0.048 | torch.Size([64]) || m_down2.0.trans_block.msa.linear1.bias
 |  1.127 |  0.791 |  1.483 |  0.141 | torch.Size([64]) || m_down2.0.trans_block.ln2.weight
 |  0.008 | -0.139 |  0.265 |  0.075 | torch.Size([64]) || m_down2.0.trans_block.ln2.bias
 |  0.002 | -0.509 |  0.472 |  0.095 | torch.Size([256, 64]) || m_down2.0.trans_block.mlp.0.weight
 | -0.047 | -0.284 |  0.068 |  0.048 | torch.Size([256]) || m_down2.0.trans_block.mlp.0.bias
 |  0.001 | -0.385 |  0.374 |  0.073 | torch.Size([64, 256]) || m_down2.0.trans_block.mlp.2.weight
 |  0.022 | -0.110 |  0.110 |  0.048 | torch.Size([64]) || m_down2.0.trans_block.mlp.2.bias
 |  0.008 | -0.716 |  0.853 |  0.099 | torch.Size([192, 192, 1, 1]) || m_down2.0.conv1_1.weight
 |  0.004 | -0.578 |  0.629 |  0.112 | torch.Size([192]) || m_down2.0.conv1_1.bias
 | -0.065 | -0.203 |  0.011 |  0.120 | torch.Size([1, 1, 1, 1, 3]) || m_down2.0.conv3d.weight
 | -0.005 | -0.005 | -0.005 |    nan | torch.Size([1]) || m_down2.0.conv3d.bias
 |  0.001 | -0.399 |  0.406 |  0.060 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.0.weight
 | -0.000 | -0.276 |  0.394 |  0.061 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.0.mamba_layers.0.mixer.A_log
 |  1.008 |  0.984 |  1.121 |  0.021 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.D
 | -0.000 | -0.277 |  0.253 |  0.032 | torch.Size([256, 64]) || m_down2.0.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.294 |  0.306 |  0.062 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.138 |  0.072 |  0.025 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.062 |  0.058 |  0.018 | torch.Size([36, 128]) || m_down2.0.mamba_layers.0.mixer.x_proj.weight
 |  0.001 | -0.049 |  0.055 |  0.018 | torch.Size([128, 4]) || m_down2.0.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.001 |  0.002 |  0.000 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.221 |  0.279 |  0.033 | torch.Size([64, 128]) || m_down2.0.mamba_layers.0.mixer.out_proj.weight
 |  1.035 |  0.889 |  1.218 |  0.082 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.weight
 |  0.004 | -0.148 |  0.151 |  0.074 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.bias
 |  1.916 | -0.324 |  2.773 |  0.767 | torch.Size([128, 16]) || m_down2.0.mamba_layers.1.mixer.A_log
 |  1.032 |  0.993 |  1.248 |  0.052 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.D
 | -0.000 | -0.335 |  0.353 |  0.050 | torch.Size([256, 64]) || m_down2.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.328 |  0.432 |  0.092 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.1.mixer.conv1d.weight
 |  0.016 | -0.175 |  0.314 |  0.070 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.245 |  0.185 |  0.034 | torch.Size([36, 128]) || m_down2.0.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.093 |  0.087 |  0.021 | torch.Size([128, 4]) || m_down2.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.010 | -0.303 |  0.160 |  0.052 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.349 |  0.356 |  0.051 | torch.Size([64, 128]) || m_down2.0.mamba_layers.1.mixer.out_proj.weight
 |  1.051 |  0.926 |  1.211 |  0.073 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.weight
 |  0.002 | -0.255 |  0.246 |  0.132 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.bias
 |  1.917 | -0.027 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.2.mixer.A_log
 |  0.984 |  0.944 |  1.035 |  0.019 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.D
 |  0.000 | -0.209 |  0.202 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.2.mixer.in_proj.weight
 | -0.004 | -0.517 |  0.513 |  0.273 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.2.mixer.conv1d.weight
 | -0.026 | -0.510 |  0.485 |  0.296 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.133 |  0.215 |  0.052 | torch.Size([36, 128]) || m_down2.0.mamba_layers.2.mixer.x_proj.weight
 |  0.014 | -0.500 |  0.501 |  0.292 | torch.Size([128, 4]) || m_down2.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.641 | -6.908 | -2.258 |  1.372 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.206 |  0.195 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.2.mixer.out_proj.weight
 |  0.966 |  0.883 |  1.026 |  0.032 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.weight
 |  0.002 | -0.090 |  0.064 |  0.029 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.bias
 |  1.917 | -0.021 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.3.mixer.A_log
 |  0.988 |  0.931 |  1.049 |  0.017 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.D
 |  0.001 | -0.194 |  0.185 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.3.mixer.in_proj.weight
 | -0.001 | -0.549 |  0.519 |  0.273 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.487 |  0.483 |  0.290 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.199 |  0.253 |  0.053 | torch.Size([36, 128]) || m_down2.0.mamba_layers.3.mixer.x_proj.weight
 |  0.011 | -0.496 |  0.500 |  0.303 | torch.Size([128, 4]) || m_down2.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.465 | -6.853 | -2.277 |  1.292 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.dt_proj.bias
 |  0.000 | -0.191 |  0.236 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.3.mixer.out_proj.weight
 |  0.972 |  0.915 |  1.037 |  0.025 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.weight
 | -0.002 | -0.045 |  0.065 |  0.023 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.bias
 |  0.632 |  0.128 |  1.136 |  0.712 | torch.Size([2]) || m_down2.0.pcbam_module.h_cw.weight
 |  0.111 | -0.107 |  0.483 |  0.323 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.h_cw.conv.weight
 |  0.678 |  0.609 |  0.746 |  0.097 | torch.Size([2]) || m_down2.0.pcbam_module.w_hc.weight
 |  0.057 | -0.143 |  0.401 |  0.299 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.w_hc.conv.weight
 |  0.594 |  0.347 |  0.841 |  0.349 | torch.Size([2]) || m_down2.0.pcbam_module.c_hw.weight
 | -0.032 | -0.100 |  0.043 |  0.072 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.c_hw.conv.weight
 |  1.159 |  0.847 |  1.736 |  0.232 | torch.Size([64]) || m_down2.1.trans_block.ln1.weight
 |  0.012 | -0.395 |  0.490 |  0.174 | torch.Size([64]) || m_down2.1.trans_block.ln1.bias
 | -0.006 | -1.105 |  0.653 |  0.241 | torch.Size([2, 15, 15]) || m_down2.1.trans_block.msa.relative_position_params
 | -0.000 | -0.388 |  0.443 |  0.084 | torch.Size([192, 64, 1, 1]) || m_down2.1.trans_block.msa.embedding_layer1.weight
 | -0.003 | -0.295 |  0.236 |  0.064 | torch.Size([192]) || m_down2.1.trans_block.msa.embedding_layer1.bias
 |  0.001 | -0.195 |  0.176 |  0.044 | torch.Size([64, 64, 1, 1]) || m_down2.1.trans_block.msa.linear1.weight
 | -0.001 | -0.134 |  0.209 |  0.050 | torch.Size([64]) || m_down2.1.trans_block.msa.linear1.bias
 |  1.041 |  0.711 |  1.338 |  0.147 | torch.Size([64]) || m_down2.1.trans_block.ln2.weight
 |  0.004 | -0.197 |  0.255 |  0.103 | torch.Size([64]) || m_down2.1.trans_block.ln2.bias
 | -0.000 | -0.483 |  0.470 |  0.076 | torch.Size([256, 64]) || m_down2.1.trans_block.mlp.0.weight
 | -0.042 | -0.321 |  0.066 |  0.057 | torch.Size([256]) || m_down2.1.trans_block.mlp.0.bias
 | -0.000 | -0.417 |  0.463 |  0.053 | torch.Size([64, 256]) || m_down2.1.trans_block.mlp.2.weight
 | -0.001 | -0.077 |  0.068 |  0.034 | torch.Size([64]) || m_down2.1.trans_block.mlp.2.bias
 | -0.009 | -1.115 |  0.517 |  0.104 | torch.Size([192, 192, 1, 1]) || m_down2.1.conv1_1.weight
 |  0.001 | -0.333 |  0.324 |  0.084 | torch.Size([192]) || m_down2.1.conv1_1.bias
 |  0.075 | -0.017 |  0.245 |  0.148 | torch.Size([1, 1, 1, 1, 3]) || m_down2.1.conv3d.weight
 | -0.004 | -0.004 | -0.004 |    nan | torch.Size([1]) || m_down2.1.conv3d.bias
 | -0.003 | -0.377 |  0.308 |  0.059 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.0.weight
 |  0.000 | -0.309 |  0.315 |  0.058 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.2.weight
 |  1.917 | -0.006 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.0.mixer.A_log
 |  1.023 |  0.995 |  1.258 |  0.040 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.D
 |  0.000 | -0.275 |  0.252 |  0.039 | torch.Size([256, 64]) || m_down2.1.mamba_layers.0.mixer.in_proj.weight
 | -0.003 | -0.434 |  0.293 |  0.074 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.001 | -0.083 |  0.113 |  0.029 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.167 |  0.165 |  0.024 | torch.Size([36, 128]) || m_down2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.049 |  0.052 |  0.018 | torch.Size([128, 4]) || m_down2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.061 |  0.079 |  0.016 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.274 |  0.283 |  0.043 | torch.Size([64, 128]) || m_down2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.023 |  0.836 |  1.225 |  0.076 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.weight
 |  0.001 | -0.171 |  0.207 |  0.101 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.bias
 |  1.917 | -0.245 |  2.773 |  0.765 | torch.Size([128, 16]) || m_down2.1.mamba_layers.1.mixer.A_log
 |  1.038 |  0.996 |  1.244 |  0.064 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.D
 | -0.000 | -0.439 |  0.420 |  0.051 | torch.Size([256, 64]) || m_down2.1.mamba_layers.1.mixer.in_proj.weight
 |  0.004 | -0.311 |  0.379 |  0.094 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.009 | -0.127 |  0.231 |  0.045 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.260 |  0.271 |  0.038 | torch.Size([36, 128]) || m_down2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.256 |  0.251 |  0.029 | torch.Size([128, 4]) || m_down2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.002 | -0.300 |  0.165 |  0.044 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.394 |  0.374 |  0.052 | torch.Size([64, 128]) || m_down2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.054 |  0.948 |  1.401 |  0.092 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.weight
 | -0.007 | -0.220 |  0.195 |  0.127 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.027 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.2.mixer.A_log
 |  0.988 |  0.942 |  1.085 |  0.023 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.D
 | -0.001 | -0.241 |  0.207 |  0.076 | torch.Size([256, 64]) || m_down2.1.mamba_layers.2.mixer.in_proj.weight
 | -0.007 | -0.567 |  0.538 |  0.283 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.2.mixer.conv1d.weight
 |  0.014 | -0.490 |  0.506 |  0.266 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.169 |  0.171 |  0.053 | torch.Size([36, 128]) || m_down2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.021 | -0.500 |  0.499 |  0.284 | torch.Size([128, 4]) || m_down2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.836 | -6.905 | -2.270 |  1.399 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.185 |  0.208 |  0.055 | torch.Size([64, 128]) || m_down2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.980 |  0.905 |  1.059 |  0.032 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.weight
 |  0.003 | -0.070 |  0.080 |  0.028 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.043 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.3.mixer.A_log
 |  0.986 |  0.950 |  1.054 |  0.019 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.211 |  0.283 |  0.074 | torch.Size([256, 64]) || m_down2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.001 | -0.512 |  0.515 |  0.279 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.3.mixer.conv1d.weight
 |  0.054 | -0.523 |  0.489 |  0.264 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.163 |  0.134 |  0.052 | torch.Size([36, 128]) || m_down2.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.500 |  0.499 |  0.290 | torch.Size([128, 4]) || m_down2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.409 | -6.903 | -2.271 |  1.291 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.179 |  0.191 |  0.054 | torch.Size([64, 128]) || m_down2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.972 |  0.919 |  1.032 |  0.029 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.weight
 |  0.001 | -0.059 |  0.056 |  0.024 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.bias
 |  0.860 |  0.685 |  1.036 |  0.249 | torch.Size([2]) || m_down2.1.pcbam_module.h_cw.weight
 |  0.141 | -0.074 |  0.413 |  0.249 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.h_cw.conv.weight
 |  0.696 |  0.603 |  0.790 |  0.132 | torch.Size([2]) || m_down2.1.pcbam_module.w_hc.weight
 |  0.077 | -0.277 |  0.457 |  0.367 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.w_hc.conv.weight
 |  0.886 |  0.744 |  1.029 |  0.201 | torch.Size([2]) || m_down2.1.pcbam_module.c_hw.weight
 | -0.068 | -0.261 |  0.250 |  0.277 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.c_hw.conv.weight
 | -0.001 | -0.275 |  0.410 |  0.043 | torch.Size([384, 192, 2, 2]) || m_down2.2.weight
 |  0.980 |  0.604 |  1.641 |  0.232 | torch.Size([128]) || m_down3.0.trans_block.ln1.weight
 |  0.005 | -0.613 |  0.623 |  0.256 | torch.Size([128]) || m_down3.0.trans_block.ln1.bias
 |  0.053 | -2.558 |  0.994 |  0.348 | torch.Size([4, 15, 15]) || m_down3.0.trans_block.msa.relative_position_params
 | -0.000 | -0.407 |  0.396 |  0.052 | torch.Size([384, 128, 1, 1]) || m_down3.0.trans_block.msa.embedding_layer1.weight
 |  0.006 | -0.197 |  0.272 |  0.057 | torch.Size([384]) || m_down3.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.164 |  0.167 |  0.040 | torch.Size([128, 128, 1, 1]) || m_down3.0.trans_block.msa.linear1.weight
 |  0.002 | -0.116 |  0.103 |  0.043 | torch.Size([128]) || m_down3.0.trans_block.msa.linear1.bias
 |  0.891 |  0.453 |  1.359 |  0.169 | torch.Size([128]) || m_down3.0.trans_block.ln2.weight
 |  0.001 | -0.337 |  0.362 |  0.115 | torch.Size([128]) || m_down3.0.trans_block.ln2.bias
 | -0.000 | -0.412 |  0.380 |  0.046 | torch.Size([512, 128]) || m_down3.0.trans_block.mlp.0.weight
 | -0.027 | -0.353 |  0.068 |  0.044 | torch.Size([512]) || m_down3.0.trans_block.mlp.0.bias
 | -0.000 | -0.401 |  0.451 |  0.037 | torch.Size([128, 512]) || m_down3.0.trans_block.mlp.2.weight
 |  0.002 | -0.125 |  0.210 |  0.054 | torch.Size([128]) || m_down3.0.trans_block.mlp.2.bias
 |  0.004 | -0.550 |  1.751 |  0.081 | torch.Size([384, 384, 1, 1]) || m_down3.0.conv1_1.weight
 | -0.003 | -0.796 |  0.608 |  0.128 | torch.Size([384]) || m_down3.0.conv1_1.bias
 | -0.078 | -0.238 |  0.004 |  0.139 | torch.Size([1, 1, 1, 1, 3]) || m_down3.0.conv3d.weight
 | -0.003 | -0.003 | -0.003 |    nan | torch.Size([1]) || m_down3.0.conv3d.bias
 |  0.001 | -0.377 |  0.292 |  0.045 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.0.weight
 | -0.000 | -0.230 |  0.277 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.0.mixer.A_log
 |  1.001 |  0.991 |  1.093 |  0.009 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.D
 | -0.000 | -0.091 |  0.110 |  0.011 | torch.Size([512, 128]) || m_down3.0.mamba_layers.0.mixer.in_proj.weight
 | -0.002 | -0.147 |  0.111 |  0.023 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.0.mixer.conv1d.weight
 | -0.002 | -0.116 |  0.149 |  0.035 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.051 |  0.051 |  0.012 | torch.Size([40, 256]) || m_down3.0.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.041 |  0.047 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.001 |  0.000 |  0.000 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.187 |  0.140 |  0.016 | torch.Size([128, 256]) || m_down3.0.mamba_layers.0.mixer.out_proj.weight
 |  0.999 |  0.985 |  1.026 |  0.008 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.weight
 |  0.001 | -0.024 |  0.023 |  0.012 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.bias
 |  1.917 | -0.005 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.1.mixer.A_log
 |  1.013 |  0.998 |  1.310 |  0.045 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.D
 |  0.000 | -0.321 |  0.273 |  0.019 | torch.Size([512, 128]) || m_down3.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.290 |  0.285 |  0.041 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.1.mixer.conv1d.weight
 | -0.003 | -0.245 |  0.224 |  0.054 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.119 |  0.125 |  0.013 | torch.Size([40, 256]) || m_down3.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.039 |  0.058 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.101 |  0.024 |  0.007 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.407 |  0.294 |  0.024 | torch.Size([128, 256]) || m_down3.0.mamba_layers.1.mixer.out_proj.weight
 |  0.949 |  0.855 |  1.174 |  0.052 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.weight
 |  0.013 | -0.150 |  0.158 |  0.098 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.bias
 |  1.917 | -0.002 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.2.mixer.A_log
 |  0.979 |  0.950 |  1.016 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.D
 |  0.000 | -0.142 |  0.149 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.2.mixer.in_proj.weight
 | -0.015 | -0.545 |  0.511 |  0.279 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.2.mixer.conv1d.weight
 |  0.031 | -0.514 |  0.483 |  0.274 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.105 |  0.098 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.2.mixer.x_proj.weight
 | -0.000 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.489 | -6.888 | -2.309 |  1.322 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.138 |  0.151 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.2.mixer.out_proj.weight
 |  0.954 |  0.898 |  1.032 |  0.022 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.weight
 |  0.001 | -0.071 |  0.061 |  0.032 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.bias
 |  1.917 | -0.001 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.3.mixer.A_log
 |  0.980 |  0.942 |  1.026 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.D
 | -0.000 | -0.136 |  0.142 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.3.mixer.in_proj.weight
 |  0.006 | -0.506 |  0.531 |  0.279 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.489 |  0.499 |  0.256 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.089 |  0.091 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.3.mixer.x_proj.weight
 | -0.002 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.511 | -6.890 | -2.277 |  1.395 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.128 |  0.130 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.3.mixer.out_proj.weight
 |  0.953 |  0.892 |  0.999 |  0.021 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.weight
 | -0.000 | -0.065 |  0.066 |  0.029 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.bias
 |  0.711 |  0.548 |  0.874 |  0.231 | torch.Size([2]) || m_down3.0.pcbam_module.h_cw.weight
 |  0.063 | -0.051 |  0.247 |  0.161 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.h_cw.conv.weight
 |  0.298 |  0.253 |  0.343 |  0.064 | torch.Size([2]) || m_down3.0.pcbam_module.w_hc.weight
 |  0.032 | -0.136 |  0.278 |  0.217 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.w_hc.conv.weight
 |  0.573 |  0.260 |  0.886 |  0.443 | torch.Size([2]) || m_down3.0.pcbam_module.c_hw.weight
 | -0.105 | -0.399 |  0.106 |  0.186 | torch.Size([1, 1, 1, 5]) || m_down3.0.pcbam_module.c_hw.conv.weight
 |  1.079 |  0.600 |  1.607 |  0.247 | torch.Size([128]) || m_down3.1.trans_block.ln1.weight
 | -0.017 | -0.824 |  0.674 |  0.224 | torch.Size([128]) || m_down3.1.trans_block.ln1.bias
 |  0.002 | -2.704 |  1.290 |  0.321 | torch.Size([4, 15, 15]) || m_down3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.456 |  0.467 |  0.057 | torch.Size([384, 128, 1, 1]) || m_down3.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.241 |  0.247 |  0.049 | torch.Size([384]) || m_down3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.168 |  0.168 |  0.039 | torch.Size([128, 128, 1, 1]) || m_down3.1.trans_block.msa.linear1.weight
 |  0.000 | -0.143 |  0.149 |  0.055 | torch.Size([128]) || m_down3.1.trans_block.msa.linear1.bias
 |  0.896 |  0.414 |  1.270 |  0.193 | torch.Size([128]) || m_down3.1.trans_block.ln2.weight
 | -0.006 | -0.372 |  0.441 |  0.167 | torch.Size([128]) || m_down3.1.trans_block.ln2.bias
 | -0.000 | -0.451 |  0.369 |  0.058 | torch.Size([512, 128]) || m_down3.1.trans_block.mlp.0.weight
 | -0.044 | -0.239 |  0.033 |  0.052 | torch.Size([512]) || m_down3.1.trans_block.mlp.0.bias
 | -0.000 | -0.363 |  0.362 |  0.044 | torch.Size([128, 512]) || m_down3.1.trans_block.mlp.2.weight
 |  0.004 | -0.131 |  0.154 |  0.052 | torch.Size([128]) || m_down3.1.trans_block.mlp.2.bias
 | -0.004 | -1.805 |  0.669 |  0.088 | torch.Size([384, 384, 1, 1]) || m_down3.1.conv1_1.weight
 |  0.009 | -0.556 |  0.405 |  0.089 | torch.Size([384]) || m_down3.1.conv1_1.bias
 |  0.080 | -0.008 |  0.252 |  0.149 | torch.Size([1, 1, 1, 1, 3]) || m_down3.1.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_down3.1.conv3d.bias
 | -0.005 | -0.365 |  0.422 |  0.047 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.0.weight
 | -0.001 | -0.255 |  0.296 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.2.weight
 |  1.917 | -0.001 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.0.mixer.A_log
 |  1.011 |  0.991 |  1.142 |  0.025 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.305 |  0.307 |  0.026 | torch.Size([512, 128]) || m_down3.1.mamba_layers.0.mixer.in_proj.weight
 | -0.000 | -0.375 |  0.286 |  0.053 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.126 |  0.105 |  0.034 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.084 |  0.087 |  0.014 | torch.Size([40, 256]) || m_down3.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.039 |  0.057 |  0.012 | torch.Size([256, 8]) || m_down3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.022 |  0.011 |  0.002 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.215 |  0.222 |  0.028 | torch.Size([128, 256]) || m_down3.1.mamba_layers.0.mixer.out_proj.weight
 |  0.987 |  0.870 |  1.207 |  0.057 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.weight
 |  0.004 | -0.125 |  0.144 |  0.076 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.bias
 |  1.917 | -0.044 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.1.mixer.A_log
 |  1.021 |  0.949 |  1.312 |  0.049 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.D
 |  0.000 | -0.308 |  0.342 |  0.033 | torch.Size([512, 128]) || m_down3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.003 | -0.375 |  0.359 |  0.064 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.244 |  0.231 |  0.044 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.182 |  0.210 |  0.024 | torch.Size([40, 256]) || m_down3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.078 |  0.084 |  0.016 | torch.Size([256, 8]) || m_down3.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.010 | -0.109 |  0.195 |  0.031 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.287 |  0.302 |  0.034 | torch.Size([128, 256]) || m_down3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.010 |  0.830 |  1.240 |  0.081 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.weight
 | -0.003 | -0.173 |  0.191 |  0.105 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.090 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.2.mixer.A_log
 |  0.979 |  0.933 |  1.076 |  0.019 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.167 |  0.161 |  0.052 | torch.Size([512, 128]) || m_down3.1.mamba_layers.2.mixer.in_proj.weight
 | -0.012 | -0.553 |  0.578 |  0.277 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.2.mixer.conv1d.weight
 |  0.015 | -0.523 |  0.510 |  0.290 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.125 |  0.110 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.205 | torch.Size([256, 8]) || m_down3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.526 | -6.818 | -2.284 |  1.305 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.215 |  0.140 |  0.039 | torch.Size([128, 256]) || m_down3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.955 |  0.855 |  1.027 |  0.027 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.weight
 | -0.000 | -0.096 |  0.061 |  0.023 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.003 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.3.mixer.A_log
 |  0.979 |  0.931 |  1.017 |  0.015 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.D
 |  0.000 | -0.146 |  0.154 |  0.051 | torch.Size([512, 128]) || m_down3.1.mamba_layers.3.mixer.in_proj.weight
 |  0.010 | -0.548 |  0.544 |  0.276 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.3.mixer.conv1d.weight
 |  0.001 | -0.512 |  0.481 |  0.287 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.109 |  0.119 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.204 | torch.Size([256, 8]) || m_down3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.747 | -6.882 | -2.256 |  1.391 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.125 |  0.139 |  0.037 | torch.Size([128, 256]) || m_down3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.945 |  0.887 |  1.000 |  0.025 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.weight
 | -0.001 | -0.089 |  0.079 |  0.023 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.bias
 |  0.682 |  0.554 |  0.810 |  0.181 | torch.Size([2]) || m_down3.1.pcbam_module.h_cw.weight
 | -0.009 | -0.224 |  0.287 |  0.265 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.h_cw.conv.weight
 |  0.428 |  0.112 |  0.744 |  0.447 | torch.Size([2]) || m_down3.1.pcbam_module.w_hc.weight
 | -0.023 | -0.256 |  0.344 |  0.321 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.w_hc.conv.weight
 |  0.600 |  0.593 |  0.607 |  0.010 | torch.Size([2]) || m_down3.1.pcbam_module.c_hw.weight
 |  0.095 | -0.207 |  0.358 |  0.274 | torch.Size([1, 1, 1, 5]) || m_down3.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.488 |  0.302 |  0.032 | torch.Size([768, 384, 2, 2]) || m_down3.2.weight
 |  0.803 |  0.355 |  1.188 |  0.146 | torch.Size([256]) || m_body.0.trans_block.ln1.weight
 | -0.011 | -0.693 |  0.510 |  0.139 | torch.Size([256]) || m_body.0.trans_block.ln1.bias
 |  0.054 | -4.646 |  0.713 |  0.330 | torch.Size([8, 15, 15]) || m_body.0.trans_block.msa.relative_position_params
 | -0.000 | -0.399 |  0.391 |  0.037 | torch.Size([768, 256, 1, 1]) || m_body.0.trans_block.msa.embedding_layer1.weight
 |  0.002 | -0.216 |  0.230 |  0.054 | torch.Size([768]) || m_body.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.238 |  0.236 |  0.042 | torch.Size([256, 256, 1, 1]) || m_body.0.trans_block.msa.linear1.weight
 |  0.001 | -0.268 |  0.150 |  0.058 | torch.Size([256]) || m_body.0.trans_block.msa.linear1.bias
 |  0.852 |  0.383 |  1.179 |  0.124 | torch.Size([256]) || m_body.0.trans_block.ln2.weight
 |  0.002 | -0.198 |  0.275 |  0.080 | torch.Size([256]) || m_body.0.trans_block.ln2.bias
 |  0.000 | -0.255 |  0.282 |  0.034 | torch.Size([1024, 256]) || m_body.0.trans_block.mlp.0.weight
 | -0.011 | -0.233 |  0.104 |  0.042 | torch.Size([1024]) || m_body.0.trans_block.mlp.0.bias
 | -0.000 | -0.293 |  0.322 |  0.031 | torch.Size([256, 1024]) || m_body.0.trans_block.mlp.2.weight
 |  0.004 | -0.190 |  0.159 |  0.054 | torch.Size([256]) || m_body.0.trans_block.mlp.2.bias
 | -0.001 | -1.114 |  0.876 |  0.051 | torch.Size([768, 768, 1, 1]) || m_body.0.conv1_1.weight
 |  0.001 | -1.467 |  1.031 |  0.093 | torch.Size([768]) || m_body.0.conv1_1.bias
 |  0.064 | -0.005 |  0.198 |  0.116 | torch.Size([1, 1, 1, 1, 3]) || m_body.0.conv3d.weight
 |  0.025 |  0.025 |  0.025 |    nan | torch.Size([1]) || m_body.0.conv3d.bias
 |  0.000 | -0.238 |  0.256 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.0.weight
 | -0.000 | -0.239 |  0.211 |  0.036 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.D
 |  0.000 | -0.028 |  0.027 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.025 |  0.027 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.004 |  0.003 |  0.001 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.035 |  0.036 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.033 |  0.038 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.042 |  0.037 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.0.mixer.out_proj.weight
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.bias
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.001 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.D
 |  0.000 | -0.029 |  0.030 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.1.mixer.in_proj.weight
 |  0.000 | -0.035 |  0.059 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.1.mixer.conv1d.weight
 | -0.000 | -0.018 |  0.022 |  0.006 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.034 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.034 |  0.030 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.045 |  0.041 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.999 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.weight
 | -0.000 | -0.001 |  0.001 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.bias
 |  1.917 | -0.026 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.A_log
 |  0.999 |  0.973 |  1.015 |  0.004 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.D
 | -0.000 | -0.086 |  0.084 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.2.mixer.in_proj.weight
 | -0.007 | -0.504 |  0.519 |  0.289 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.2.mixer.conv1d.weight
 | -0.005 | -0.500 |  0.495 |  0.307 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.067 |  0.067 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.579 | -6.906 | -2.283 |  1.361 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.093 |  0.082 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.2.mixer.out_proj.weight
 |  0.995 |  0.984 |  1.008 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.weight
 |  0.000 | -0.013 |  0.007 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.bias
 |  1.917 | -0.017 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.A_log
 |  0.998 |  0.981 |  1.010 |  0.003 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.D
 |  0.000 | -0.081 |  0.080 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.3.mixer.in_proj.weight
 | -0.013 | -0.511 |  0.502 |  0.287 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.3.mixer.conv1d.weight
 |  0.003 | -0.500 |  0.496 |  0.280 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.070 |  0.068 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.3.mixer.x_proj.weight
 |  0.002 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.612 | -6.907 | -2.259 |  1.325 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.064 |  0.066 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.3.mixer.out_proj.weight
 |  0.995 |  0.986 |  1.006 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.weight
 | -0.000 | -0.010 |  0.009 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.bias
 |  1.128 |  0.894 |  1.363 |  0.331 | torch.Size([2]) || m_body.0.pcbam_module.h_cw.weight
 | -0.693 | -0.987 | -0.529 |  0.255 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.h_cw.conv.weight
 |  0.389 |  0.163 |  0.616 |  0.320 | torch.Size([2]) || m_body.0.pcbam_module.w_hc.weight
 | -0.547 | -0.641 | -0.366 |  0.156 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.w_hc.conv.weight
 |  1.020 |  0.132 |  1.907 |  1.256 | torch.Size([2]) || m_body.0.pcbam_module.c_hw.weight
 | -0.087 | -1.011 |  1.945 |  1.190 | torch.Size([1, 1, 1, 5]) || m_body.0.pcbam_module.c_hw.conv.weight
 |  0.746 |  0.302 |  1.004 |  0.127 | torch.Size([256]) || m_body.1.trans_block.ln1.weight
 |  0.029 | -0.826 |  0.544 |  0.167 | torch.Size([256]) || m_body.1.trans_block.ln1.bias
 |  0.052 | -3.778 |  0.814 |  0.348 | torch.Size([8, 15, 15]) || m_body.1.trans_block.msa.relative_position_params
 | -0.000 | -0.316 |  0.315 |  0.036 | torch.Size([768, 256, 1, 1]) || m_body.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.223 |  0.254 |  0.069 | torch.Size([768]) || m_body.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.277 |  0.271 |  0.037 | torch.Size([256, 256, 1, 1]) || m_body.1.trans_block.msa.linear1.weight
 | -0.004 | -0.220 |  0.267 |  0.059 | torch.Size([256]) || m_body.1.trans_block.msa.linear1.bias
 |  0.854 |  0.493 |  1.089 |  0.103 | torch.Size([256]) || m_body.1.trans_block.ln2.weight
 |  0.008 | -0.251 |  0.328 |  0.102 | torch.Size([256]) || m_body.1.trans_block.ln2.bias
 |  0.001 | -0.362 |  0.359 |  0.054 | torch.Size([1024, 256]) || m_body.1.trans_block.mlp.0.weight
 | -0.051 | -0.198 |  0.050 |  0.038 | torch.Size([1024]) || m_body.1.trans_block.mlp.0.bias
 | -0.001 | -0.437 |  0.433 |  0.052 | torch.Size([256, 1024]) || m_body.1.trans_block.mlp.2.weight
 | -0.001 | -0.241 |  0.143 |  0.053 | torch.Size([256]) || m_body.1.trans_block.mlp.2.bias
 | -0.001 | -1.068 |  0.773 |  0.056 | torch.Size([768, 768, 1, 1]) || m_body.1.conv1_1.weight
 | -0.000 | -0.313 |  0.949 |  0.085 | torch.Size([768]) || m_body.1.conv1_1.bias
 |  0.147 |  0.004 |  0.431 |  0.246 | torch.Size([1, 1, 1, 1, 3]) || m_body.1.conv3d.weight
 |  0.043 |  0.043 |  0.043 |    nan | torch.Size([1]) || m_body.1.conv3d.bias
 | -0.001 | -0.278 |  0.267 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.0.weight
 | -0.001 | -0.269 |  0.270 |  0.035 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.2.weight
 |  1.917 | -0.001 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.092 |  0.006 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.D
 | -0.000 | -0.123 |  0.107 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.108 |  0.289 |  0.013 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.024 |  0.071 |  0.004 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.036 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.035 |  0.029 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.008 |  0.004 |  0.000 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.166 |  0.121 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.0.mixer.out_proj.weight
 |  1.001 |  0.994 |  1.014 |  0.003 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.weight
 |  0.000 | -0.005 |  0.006 |  0.002 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.bias
 |  1.917 | -0.218 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.053 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.D
 |  0.000 | -0.159 |  0.145 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.1.mixer.in_proj.weight
 | -0.000 | -0.049 |  0.174 |  0.010 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.097 |  0.073 |  0.022 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.096 |  0.319 |  0.010 | torch.Size([48, 512]) || m_body.1.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.032 |  0.035 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.038 |  0.000 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.171 |  0.177 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.986 |  1.042 |  0.010 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.weight
 | -0.001 | -0.017 |  0.021 |  0.008 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.bias
 |  1.917 | -0.066 |  2.774 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.A_log
 |  0.998 |  0.963 |  1.031 |  0.005 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.D
 | -0.000 | -0.107 |  0.131 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.2.mixer.in_proj.weight
 |  0.004 | -0.530 |  0.504 |  0.283 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.2.mixer.conv1d.weight
 |  0.010 | -0.506 |  0.492 |  0.282 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.094 |  0.089 |  0.026 | torch.Size([48, 512]) || m_body.1.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.257 |  0.260 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.634 | -6.903 | -2.259 |  1.288 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.126 |  0.105 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.2.mixer.out_proj.weight
 |  0.996 |  0.961 |  1.012 |  0.008 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.weight
 |  0.000 | -0.023 |  0.021 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.bias
 |  1.917 | -0.069 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.A_log
 |  0.999 |  0.920 |  1.118 |  0.009 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.D
 |  0.000 | -0.122 |  0.123 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.531 |  0.505 |  0.293 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.3.mixer.conv1d.weight
 | -0.009 | -0.500 |  0.498 |  0.294 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.099 |  0.105 |  0.027 | torch.Size([48, 512]) || m_body.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.272 |  0.274 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.631 | -6.903 | -2.252 |  1.302 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.118 |  0.102 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.3.mixer.out_proj.weight
 |  1.000 |  0.969 |  1.029 |  0.009 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.weight
 |  0.000 | -0.017 |  0.019 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.bias
 |  1.226 |  0.884 |  1.568 |  0.484 | torch.Size([2]) || m_body.1.pcbam_module.h_cw.weight
 | -1.051 | -1.169 | -0.864 |  0.164 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.h_cw.conv.weight
 |  1.165 |  0.908 |  1.422 |  0.363 | torch.Size([2]) || m_body.1.pcbam_module.w_hc.weight
 | -0.980 | -1.093 | -0.820 |  0.142 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.w_hc.conv.weight
 |  1.519 |  0.158 |  2.880 |  1.925 | torch.Size([2]) || m_body.1.pcbam_module.c_hw.weight
 | -0.167 | -1.486 |  1.768 |  1.300 | torch.Size([1, 1, 1, 5]) || m_body.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.324 |  0.332 |  0.030 | torch.Size([768, 384, 2, 2]) || m_up3.0.weight
 |  0.959 |  0.556 |  1.369 |  0.157 | torch.Size([128]) || m_up3.1.trans_block.ln1.weight
 |  0.026 | -0.612 |  0.449 |  0.134 | torch.Size([128]) || m_up3.1.trans_block.ln1.bias
 |  0.050 | -3.715 |  0.652 |  0.304 | torch.Size([4, 15, 15]) || m_up3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.523 |  0.546 |  0.061 | torch.Size([384, 128, 1, 1]) || m_up3.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.259 |  0.245 |  0.071 | torch.Size([384]) || m_up3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.176 |  0.177 |  0.042 | torch.Size([128, 128, 1, 1]) || m_up3.1.trans_block.msa.linear1.weight
 | -0.001 | -0.109 |  0.283 |  0.047 | torch.Size([128]) || m_up3.1.trans_block.msa.linear1.bias
 |  0.857 |  0.602 |  1.006 |  0.072 | torch.Size([128]) || m_up3.1.trans_block.ln2.weight
 |  0.009 | -0.321 |  0.182 |  0.089 | torch.Size([128]) || m_up3.1.trans_block.ln2.bias
 |  0.000 | -0.333 |  0.322 |  0.059 | torch.Size([512, 128]) || m_up3.1.trans_block.mlp.0.weight
 | -0.038 | -0.189 |  0.068 |  0.044 | torch.Size([512]) || m_up3.1.trans_block.mlp.0.bias
 | -0.000 | -0.340 |  0.310 |  0.052 | torch.Size([128, 512]) || m_up3.1.trans_block.mlp.2.weight
 | -0.001 | -0.345 |  0.163 |  0.046 | torch.Size([128]) || m_up3.1.trans_block.mlp.2.bias
 | -0.001 | -2.380 |  0.668 |  0.087 | torch.Size([384, 384, 1, 1]) || m_up3.1.conv1_1.weight
 | -0.000 | -0.512 |  1.315 |  0.141 | torch.Size([384]) || m_up3.1.conv1_1.bias
 |  0.185 | -0.003 |  0.561 |  0.326 | torch.Size([1, 1, 1, 1, 3]) || m_up3.1.conv3d.weight
 | -0.006 | -0.006 | -0.006 |    nan | torch.Size([1]) || m_up3.1.conv3d.bias
 |  0.000 | -0.349 |  0.318 |  0.036 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.0.weight
 |  0.000 | -0.272 |  0.385 |  0.038 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.2.weight
 |  1.916 | -0.349 |  2.773 |  0.766 | torch.Size([256, 16]) || m_up3.1.mamba_layers.0.mixer.A_log
 |  1.053 |  0.998 |  1.430 |  0.078 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.401 |  0.370 |  0.043 | torch.Size([512, 128]) || m_up3.1.mamba_layers.0.mixer.in_proj.weight
 |  0.006 | -0.495 |  0.462 |  0.097 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.0.mixer.conv1d.weight
 |  0.013 | -0.181 |  0.483 |  0.073 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.163 |  0.213 |  0.025 | torch.Size([40, 256]) || m_up3.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.054 |  0.067 |  0.013 | torch.Size([256, 8]) || m_up3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.003 | -0.178 |  0.172 |  0.030 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.567 |  0.495 |  0.050 | torch.Size([128, 256]) || m_up3.1.mamba_layers.0.mixer.out_proj.weight
 |  1.034 |  0.905 |  1.175 |  0.064 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.weight
 | -0.003 | -0.306 |  0.302 |  0.126 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.bias
 |  1.916 | -0.847 |  3.034 |  0.769 | torch.Size([256, 16]) || m_up3.1.mamba_layers.1.mixer.A_log
 |  1.000 | -0.050 |  1.309 |  0.161 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.D
 | -0.000 | -0.419 |  0.417 |  0.055 | torch.Size([512, 128]) || m_up3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.003 | -0.604 |  0.389 |  0.113 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.022 | -0.299 |  0.315 |  0.177 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.conv1d.bias
 |  0.001 | -0.584 |  0.555 |  0.074 | torch.Size([40, 256]) || m_up3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.002 | -0.608 |  0.703 |  0.095 | torch.Size([256, 8]) || m_up3.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.011 | -1.014 |  0.284 |  0.107 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.277 |  0.279 |  0.056 | torch.Size([128, 256]) || m_up3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.030 |  0.658 |  1.217 |  0.117 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.weight
 | -0.002 | -0.255 |  0.264 |  0.109 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.295 |  2.787 |  0.764 | torch.Size([256, 16]) || m_up3.1.mamba_layers.2.mixer.A_log
 |  0.981 |  0.645 |  1.037 |  0.041 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.200 |  0.195 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.2.mixer.in_proj.weight
 |  0.014 | -0.558 |  0.536 |  0.273 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.2.mixer.conv1d.weight
 | -0.030 | -0.527 |  0.495 |  0.292 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.168 |  0.144 |  0.042 | torch.Size([40, 256]) || m_up3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.000 | -0.415 |  0.372 |  0.205 | torch.Size([256, 8]) || m_up3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.530 | -6.922 | -2.275 |  1.363 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.000 | -0.158 |  0.161 |  0.041 | torch.Size([128, 256]) || m_up3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.957 |  0.843 |  1.037 |  0.031 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.weight
 |  0.002 | -0.066 |  0.085 |  0.024 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.033 |  2.773 |  0.765 | torch.Size([256, 16]) || m_up3.1.mamba_layers.3.mixer.A_log
 |  0.990 |  0.944 |  1.076 |  0.018 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.D
 | -0.000 | -0.229 |  0.214 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.3.mixer.in_proj.weight
 | -0.010 | -0.532 |  0.605 |  0.267 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.3.mixer.conv1d.weight
 | -0.004 | -0.554 |  0.581 |  0.312 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.121 |  0.122 |  0.038 | torch.Size([40, 256]) || m_up3.1.mamba_layers.3.mixer.x_proj.weight
 | -0.001 | -0.357 |  0.357 |  0.203 | torch.Size([256, 8]) || m_up3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.644 | -6.923 | -2.262 |  1.394 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.178 |  0.170 |  0.041 | torch.Size([128, 256]) || m_up3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.960 |  0.893 |  1.028 |  0.028 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.weight
 | -0.000 | -0.077 |  0.059 |  0.022 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.bias
 |  0.530 |  0.193 |  0.867 |  0.477 | torch.Size([2]) || m_up3.1.pcbam_module.h_cw.weight
 |  0.057 |  0.005 |  0.144 |  0.076 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.h_cw.conv.weight
 |  0.878 |  0.846 |  0.909 |  0.045 | torch.Size([2]) || m_up3.1.pcbam_module.w_hc.weight
 |  0.093 |  0.036 |  0.147 |  0.056 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.w_hc.conv.weight
 |  0.497 |  0.240 |  0.755 |  0.365 | torch.Size([2]) || m_up3.1.pcbam_module.c_hw.weight
 | -0.018 | -0.190 |  0.144 |  0.150 | torch.Size([1, 1, 1, 5]) || m_up3.1.pcbam_module.c_hw.conv.weight
 |  1.121 |  0.585 |  1.350 |  0.144 | torch.Size([128]) || m_up3.2.trans_block.ln1.weight
 | -0.004 | -0.520 |  0.515 |  0.126 | torch.Size([128]) || m_up3.2.trans_block.ln1.bias
 |  0.061 | -3.059 |  0.727 |  0.353 | torch.Size([4, 15, 15]) || m_up3.2.trans_block.msa.relative_position_params
 | -0.000 | -0.476 |  0.327 |  0.057 | torch.Size([384, 128, 1, 1]) || m_up3.2.trans_block.msa.embedding_layer1.weight
 | -0.001 | -0.186 |  0.195 |  0.058 | torch.Size([384]) || m_up3.2.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.184 |  0.198 |  0.046 | torch.Size([128, 128, 1, 1]) || m_up3.2.trans_block.msa.linear1.weight
 | -0.002 | -0.134 |  0.232 |  0.056 | torch.Size([128]) || m_up3.2.trans_block.msa.linear1.bias
 |  1.183 |  0.883 |  1.489 |  0.095 | torch.Size([128]) || m_up3.2.trans_block.ln2.weight
 | -0.000 | -0.259 |  0.287 |  0.110 | torch.Size([128]) || m_up3.2.trans_block.ln2.bias
 |  0.000 | -0.349 |  0.331 |  0.073 | torch.Size([512, 128]) || m_up3.2.trans_block.mlp.0.weight
 | -0.048 | -0.182 |  0.055 |  0.038 | torch.Size([512]) || m_up3.2.trans_block.mlp.0.bias
 |  0.000 | -0.343 |  0.388 |  0.070 | torch.Size([128, 512]) || m_up3.2.trans_block.mlp.2.weight
 | -0.001 | -0.144 |  0.217 |  0.052 | torch.Size([128]) || m_up3.2.trans_block.mlp.2.bias
 | -0.000 | -0.870 |  0.462 |  0.076 | torch.Size([384, 384, 1, 1]) || m_up3.2.conv1_1.weight
 |  0.002 | -0.543 |  1.071 |  0.103 | torch.Size([384]) || m_up3.2.conv1_1.bias
 | -0.058 | -0.185 |  0.007 |  0.110 | torch.Size([1, 1, 1, 1, 3]) || m_up3.2.conv3d.weight
 | -0.003 | -0.003 | -0.003 |    nan | torch.Size([1]) || m_up3.2.conv3d.bias
 | -0.001 | -0.313 |  0.351 |  0.052 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.0.weight
 |  0.000 | -0.435 |  0.396 |  0.052 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.2.weight
 |  1.916 | -1.147 |  2.794 |  0.767 | torch.Size([256, 16]) || m_up3.2.mamba_layers.0.mixer.A_log
 |  1.074 |  0.396 |  1.577 |  0.161 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.D
 | -0.000 | -0.323 |  0.327 |  0.071 | torch.Size([512, 128]) || m_up3.2.mamba_layers.0.mixer.in_proj.weight
 | -0.001 | -0.379 |  0.421 |  0.143 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.0.mixer.conv1d.weight
 | -0.009 | -0.305 |  0.263 |  0.103 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.668 |  0.473 |  0.076 | torch.Size([40, 256]) || m_up3.2.mamba_layers.0.mixer.x_proj.weight
 |  0.002 | -0.695 |  0.724 |  0.100 | torch.Size([256, 8]) || m_up3.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.019 | -1.184 |  0.292 |  0.121 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.584 |  0.441 |  0.076 | torch.Size([128, 256]) || m_up3.2.mamba_layers.0.mixer.out_proj.weight
 |  1.014 |  0.617 |  1.157 |  0.085 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.weight
 |  0.006 | -0.442 |  0.410 |  0.136 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.bias
 |  1.911 | -0.990 |  2.866 |  0.776 | torch.Size([256, 16]) || m_up3.2.mamba_layers.1.mixer.A_log
 |  1.069 | -0.097 |  1.515 |  0.138 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.D
 |  0.000 | -0.344 |  0.424 |  0.072 | torch.Size([512, 128]) || m_up3.2.mamba_layers.1.mixer.in_proj.weight
 |  0.005 | -0.553 |  0.459 |  0.147 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.1.mixer.conv1d.weight
 |  0.011 | -0.313 |  0.346 |  0.150 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.conv1d.bias
 |  0.002 | -0.723 |  1.154 |  0.092 | torch.Size([40, 256]) || m_up3.2.mamba_layers.1.mixer.x_proj.weight
 | -0.005 | -0.663 |  0.594 |  0.125 | torch.Size([256, 8]) || m_up3.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.014 | -0.457 |  0.174 |  0.107 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.459 |  0.406 |  0.075 | torch.Size([128, 256]) || m_up3.2.mamba_layers.1.mixer.out_proj.weight
 |  1.071 |  0.637 |  1.215 |  0.084 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.weight
 |  0.004 | -0.262 |  0.246 |  0.108 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.bias
 |  1.917 | -0.049 |  2.834 |  0.765 | torch.Size([256, 16]) || m_up3.2.mamba_layers.2.mixer.A_log
 |  1.027 |  0.971 |  1.344 |  0.036 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.D
 | -0.000 | -0.226 |  0.215 |  0.057 | torch.Size([512, 128]) || m_up3.2.mamba_layers.2.mixer.in_proj.weight
 |  0.002 | -0.661 |  0.648 |  0.294 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.2.mixer.conv1d.weight
 |  0.036 | -0.541 |  0.542 |  0.318 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.159 |  0.175 |  0.045 | torch.Size([40, 256]) || m_up3.2.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.442 |  0.471 |  0.206 | torch.Size([256, 8]) || m_up3.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.531 | -6.898 | -2.237 |  1.383 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.229 |  0.203 |  0.046 | torch.Size([128, 256]) || m_up3.2.mamba_layers.2.mixer.out_proj.weight
 |  1.021 |  0.939 |  1.088 |  0.026 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.weight
 |  0.000 | -0.092 |  0.103 |  0.038 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.bias
 |  1.917 | -0.027 |  2.774 |  0.764 | torch.Size([256, 16]) || m_up3.2.mamba_layers.3.mixer.A_log
 |  1.008 |  0.975 |  1.068 |  0.013 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.D
 | -0.000 | -0.196 |  0.171 |  0.054 | torch.Size([512, 128]) || m_up3.2.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.564 |  0.554 |  0.286 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.3.mixer.conv1d.weight
 | -0.022 | -0.537 |  0.533 |  0.300 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.175 |  0.175 |  0.041 | torch.Size([40, 256]) || m_up3.2.mamba_layers.3.mixer.x_proj.weight
 | -0.005 | -0.366 |  0.370 |  0.206 | torch.Size([256, 8]) || m_up3.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.526 | -6.891 | -2.231 |  1.228 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.186 |  0.179 |  0.043 | torch.Size([128, 256]) || m_up3.2.mamba_layers.3.mixer.out_proj.weight
 |  0.999 |  0.794 |  1.051 |  0.032 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.weight
 | -0.001 | -0.151 |  0.078 |  0.028 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.bias
 |  0.755 |  0.557 |  0.954 |  0.280 | torch.Size([2]) || m_up3.2.pcbam_module.h_cw.weight
 | -0.103 | -0.244 |  0.133 |  0.206 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.h_cw.conv.weight
 |  0.793 |  0.740 |  0.845 |  0.074 | torch.Size([2]) || m_up3.2.pcbam_module.w_hc.weight
 |  0.021 | -0.140 |  0.160 |  0.151 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.w_hc.conv.weight
 |  0.554 |  0.117 |  0.991 |  0.618 | torch.Size([2]) || m_up3.2.pcbam_module.c_hw.weight
 |  0.297 | -0.086 |  1.451 |  0.649 | torch.Size([1, 1, 1, 5]) || m_up3.2.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.401 |  0.318 |  0.034 | torch.Size([384, 192, 2, 2]) || m_up2.0.weight
 |  1.336 |  0.968 |  1.555 |  0.140 | torch.Size([64]) || m_up2.1.trans_block.ln1.weight
 | -0.001 | -0.528 |  0.532 |  0.165 | torch.Size([64]) || m_up2.1.trans_block.ln1.bias
 |  0.173 | -2.384 |  0.910 |  0.340 | torch.Size([2, 15, 15]) || m_up2.1.trans_block.msa.relative_position_params
 |  0.000 | -0.515 |  0.537 |  0.109 | torch.Size([192, 64, 1, 1]) || m_up2.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.185 |  0.185 |  0.047 | torch.Size([192]) || m_up2.1.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.200 |  0.217 |  0.046 | torch.Size([64, 64, 1, 1]) || m_up2.1.trans_block.msa.linear1.weight
 | -0.002 | -0.184 |  0.236 |  0.055 | torch.Size([64]) || m_up2.1.trans_block.msa.linear1.bias
 |  1.032 |  0.743 |  1.174 |  0.082 | torch.Size([64]) || m_up2.1.trans_block.ln2.weight
 |  0.006 | -0.283 |  0.254 |  0.139 | torch.Size([64]) || m_up2.1.trans_block.ln2.bias
 | -0.000 | -0.360 |  0.341 |  0.090 | torch.Size([256, 64]) || m_up2.1.trans_block.mlp.0.weight
 | -0.046 | -0.344 |  0.224 |  0.073 | torch.Size([256]) || m_up2.1.trans_block.mlp.0.bias
 |  0.001 | -0.423 |  0.396 |  0.078 | torch.Size([64, 256]) || m_up2.1.trans_block.mlp.2.weight
 | -0.002 | -0.218 |  0.196 |  0.062 | torch.Size([64]) || m_up2.1.trans_block.mlp.2.bias
 |  0.002 | -0.456 |  2.131 |  0.102 | torch.Size([192, 192, 1, 1]) || m_up2.1.conv1_1.weight
 | -0.000 | -0.590 |  0.723 |  0.129 | torch.Size([192]) || m_up2.1.conv1_1.bias
 | -0.179 | -0.620 |  0.044 |  0.382 | torch.Size([1, 1, 1, 1, 3]) || m_up2.1.conv3d.weight
 |  0.002 |  0.002 |  0.002 |    nan | torch.Size([1]) || m_up2.1.conv3d.bias
 |  0.000 | -0.293 |  0.234 |  0.046 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.0.weight
 |  0.000 | -0.279 |  0.316 |  0.046 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.2.weight
 |  1.917 | -0.448 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.0.mixer.A_log
 |  1.111 |  0.999 |  1.287 |  0.058 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.D
 | -0.000 | -0.361 |  0.352 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.423 |  0.481 |  0.171 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.004 | -0.223 |  0.215 |  0.068 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.001 | -0.144 |  0.209 |  0.039 | torch.Size([36, 128]) || m_up2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.056 |  0.058 |  0.020 | torch.Size([128, 4]) || m_up2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.003 | -0.158 |  0.288 |  0.058 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.523 |  0.386 |  0.076 | torch.Size([64, 128]) || m_up2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.188 |  0.952 |  1.337 |  0.091 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.weight
 |  0.001 | -0.154 |  0.235 |  0.078 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.bias
 |  1.916 | -0.561 |  2.773 |  0.767 | torch.Size([128, 16]) || m_up2.1.mamba_layers.1.mixer.A_log
 |  1.147 |  0.999 |  1.412 |  0.066 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.D
 |  0.000 | -0.399 |  0.390 |  0.091 | torch.Size([256, 64]) || m_up2.1.mamba_layers.1.mixer.in_proj.weight
 | -0.007 | -0.499 |  0.658 |  0.187 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.011 | -0.308 |  0.287 |  0.122 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.237 |  0.303 |  0.063 | torch.Size([36, 128]) || m_up2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.113 |  0.285 |  0.042 | torch.Size([128, 4]) || m_up2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.032 | -0.123 |  0.240 |  0.062 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.001 | -0.393 |  0.461 |  0.090 | torch.Size([64, 128]) || m_up2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.205 |  0.843 |  1.340 |  0.108 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.weight
 |  0.000 | -0.220 |  0.248 |  0.087 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.041 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.2.mixer.A_log
 |  1.007 |  0.938 |  1.087 |  0.029 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.D
 |  0.001 | -0.248 |  0.276 |  0.076 | torch.Size([256, 64]) || m_up2.1.mamba_layers.2.mixer.in_proj.weight
 |  0.001 | -0.550 |  0.677 |  0.287 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.2.mixer.conv1d.weight
 | -0.028 | -0.537 |  0.492 |  0.307 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.174 |  0.171 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.016 | -0.497 |  0.500 |  0.287 | torch.Size([128, 4]) || m_up2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.802 | -6.895 | -2.292 |  1.396 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.223 |  0.205 |  0.060 | torch.Size([64, 128]) || m_up2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.998 |  0.904 |  1.178 |  0.043 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.weight
 |  0.000 | -0.070 |  0.061 |  0.021 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.015 |  2.775 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.3.mixer.A_log
 |  1.002 |  0.944 |  1.086 |  0.030 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.219 |  0.258 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.013 | -0.594 |  0.630 |  0.292 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.3.mixer.conv1d.weight
 | -0.016 | -0.568 |  0.565 |  0.318 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.197 |  0.172 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.3.mixer.x_proj.weight
 | -0.017 | -0.491 |  0.498 |  0.291 | torch.Size([128, 4]) || m_up2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.756 | -6.892 | -2.289 |  1.356 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.232 |  0.201 |  0.060 | torch.Size([64, 128]) || m_up2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.988 |  0.868 |  1.105 |  0.038 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.weight
 | -0.001 | -0.089 |  0.083 |  0.025 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.bias
 |  0.167 |  0.121 |  0.214 |  0.065 | torch.Size([2]) || m_up2.1.pcbam_module.h_cw.weight
 | -0.035 | -0.133 |  0.092 |  0.115 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.h_cw.conv.weight
 |  0.693 |  0.692 |  0.694 |  0.001 | torch.Size([2]) || m_up2.1.pcbam_module.w_hc.weight
 | -0.108 | -0.319 |  0.039 |  0.187 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.w_hc.conv.weight
 |  0.890 |  0.840 |  0.940 |  0.071 | torch.Size([2]) || m_up2.1.pcbam_module.c_hw.weight
 | -0.061 | -0.261 |  0.057 |  0.174 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.c_hw.conv.weight
 |  1.352 |  1.014 |  1.553 |  0.127 | torch.Size([64]) || m_up2.2.trans_block.ln1.weight
 |  0.039 | -0.470 |  0.554 |  0.145 | torch.Size([64]) || m_up2.2.trans_block.ln1.bias
 |  0.131 | -2.475 |  0.722 |  0.329 | torch.Size([2, 15, 15]) || m_up2.2.trans_block.msa.relative_position_params
 |  0.000 | -0.501 |  0.560 |  0.104 | torch.Size([192, 64, 1, 1]) || m_up2.2.trans_block.msa.embedding_layer1.weight
 |  0.000 | -0.263 |  0.296 |  0.070 | torch.Size([192]) || m_up2.2.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.288 |  0.269 |  0.048 | torch.Size([64, 64, 1, 1]) || m_up2.2.trans_block.msa.linear1.weight
 |  0.003 | -0.282 |  0.441 |  0.071 | torch.Size([64]) || m_up2.2.trans_block.msa.linear1.bias
 |  1.042 |  0.586 |  1.252 |  0.125 | torch.Size([64]) || m_up2.2.trans_block.ln2.weight
 |  0.015 | -0.435 |  0.425 |  0.130 | torch.Size([64]) || m_up2.2.trans_block.ln2.bias
 |  0.002 | -0.391 |  0.424 |  0.088 | torch.Size([256, 64]) || m_up2.2.trans_block.mlp.0.weight
 | -0.044 | -0.175 |  0.085 |  0.042 | torch.Size([256]) || m_up2.2.trans_block.mlp.0.bias
 | -0.000 | -0.318 |  0.371 |  0.077 | torch.Size([64, 256]) || m_up2.2.trans_block.mlp.2.weight
 |  0.001 | -0.262 |  0.260 |  0.062 | torch.Size([64]) || m_up2.2.trans_block.mlp.2.bias
 |  0.002 | -0.489 |  2.100 |  0.102 | torch.Size([192, 192, 1, 1]) || m_up2.2.conv1_1.weight
 | -0.002 | -0.456 |  0.860 |  0.130 | torch.Size([192]) || m_up2.2.conv1_1.bias
 | -0.186 | -0.607 |  0.029 |  0.364 | torch.Size([1, 1, 1, 1, 3]) || m_up2.2.conv3d.weight
 | -0.009 | -0.009 | -0.009 |    nan | torch.Size([1]) || m_up2.2.conv3d.bias
 |  0.001 | -0.419 |  0.460 |  0.054 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.0.weight
 | -0.000 | -0.310 |  0.432 |  0.056 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.2.weight
 |  1.915 | -0.405 |  2.782 |  0.770 | torch.Size([128, 16]) || m_up2.2.mamba_layers.0.mixer.A_log
 |  1.154 |  0.722 |  1.495 |  0.109 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.D
 |  0.000 | -0.508 |  0.405 |  0.097 | torch.Size([256, 64]) || m_up2.2.mamba_layers.0.mixer.in_proj.weight
 |  0.034 | -0.552 |  0.764 |  0.196 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.0.mixer.conv1d.weight
 |  0.041 | -0.246 |  0.296 |  0.105 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.conv1d.bias
 | -0.003 | -0.527 |  0.775 |  0.078 | torch.Size([36, 128]) || m_up2.2.mamba_layers.0.mixer.x_proj.weight
 | -0.006 | -0.483 |  0.341 |  0.106 | torch.Size([128, 4]) || m_up2.2.mamba_layers.0.mixer.dt_proj.weight
 | -0.014 | -0.615 |  0.344 |  0.121 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.382 |  0.577 |  0.099 | torch.Size([64, 128]) || m_up2.2.mamba_layers.0.mixer.out_proj.weight
 |  1.253 |  0.944 |  1.403 |  0.098 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.weight
 |  0.008 | -0.526 |  0.462 |  0.166 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.bias
 |  1.919 | -0.475 |  2.882 |  0.766 | torch.Size([128, 16]) || m_up2.2.mamba_layers.1.mixer.A_log
 |  1.150 |  0.793 |  1.463 |  0.098 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.D
 |  0.000 | -0.548 |  0.600 |  0.104 | torch.Size([256, 64]) || m_up2.2.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.693 |  1.017 |  0.213 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.1.mixer.conv1d.weight
 |  0.031 | -0.351 |  0.325 |  0.127 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.509 |  0.593 |  0.101 | torch.Size([36, 128]) || m_up2.2.mamba_layers.1.mixer.x_proj.weight
 |  0.002 | -0.444 |  0.364 |  0.105 | torch.Size([128, 4]) || m_up2.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.056 | -0.214 |  0.569 |  0.109 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.453 |  0.455 |  0.098 | torch.Size([64, 128]) || m_up2.2.mamba_layers.1.mixer.out_proj.weight
 |  1.316 |  0.842 |  1.519 |  0.140 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.weight
 |  0.003 | -0.149 |  0.354 |  0.088 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.bias
 |  1.917 | -0.029 |  2.774 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.2.mixer.A_log
 |  1.018 |  0.954 |  1.143 |  0.032 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.D
 | -0.000 | -0.346 |  0.310 |  0.078 | torch.Size([256, 64]) || m_up2.2.mamba_layers.2.mixer.in_proj.weight
 | -0.004 | -0.567 |  0.540 |  0.289 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.2.mixer.conv1d.weight
 |  0.065 | -0.560 |  0.576 |  0.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.217 |  0.193 |  0.054 | torch.Size([36, 128]) || m_up2.2.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.497 |  0.499 |  0.286 | torch.Size([128, 4]) || m_up2.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.495 | -6.884 | -2.259 |  1.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.279 |  0.279 |  0.065 | torch.Size([64, 128]) || m_up2.2.mamba_layers.2.mixer.out_proj.weight
 |  1.018 |  0.882 |  1.149 |  0.050 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.weight
 |  0.004 | -0.087 |  0.117 |  0.039 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.bias
 |  1.917 | -0.073 |  2.777 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.3.mixer.A_log
 |  1.024 |  0.953 |  1.196 |  0.042 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.D
 |  0.000 | -0.317 |  0.263 |  0.078 | torch.Size([256, 64]) || m_up2.2.mamba_layers.3.mixer.in_proj.weight
 |  0.009 | -0.636 |  0.615 |  0.288 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.3.mixer.conv1d.weight
 |  0.031 | -0.525 |  0.560 |  0.302 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.240 |  0.173 |  0.057 | torch.Size([36, 128]) || m_up2.2.mamba_layers.3.mixer.x_proj.weight
 |  0.004 | -0.595 |  0.600 |  0.291 | torch.Size([128, 4]) || m_up2.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.642 | -6.849 | -2.288 |  1.277 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.dt_proj.bias
 |  0.000 | -0.243 |  0.296 |  0.066 | torch.Size([64, 128]) || m_up2.2.mamba_layers.3.mixer.out_proj.weight
 |  1.014 |  0.878 |  1.138 |  0.048 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.weight
 |  0.004 | -0.075 |  0.074 |  0.032 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.bias
 |  0.305 |  0.187 |  0.423 |  0.167 | torch.Size([2]) || m_up2.2.pcbam_module.h_cw.weight
 |  0.051 | -0.090 |  0.150 |  0.125 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.h_cw.conv.weight
 |  0.820 |  0.756 |  0.884 |  0.091 | torch.Size([2]) || m_up2.2.pcbam_module.w_hc.weight
 | -0.005 | -0.137 |  0.061 |  0.114 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.w_hc.conv.weight
 |  0.734 |  0.714 |  0.754 |  0.028 | torch.Size([2]) || m_up2.2.pcbam_module.c_hw.weight
 |  0.097 |  0.080 |  0.111 |  0.015 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.168 |  0.185 |  0.027 | torch.Size([192, 96, 2, 2]) || m_up1.0.weight
 |  1.175 |  0.732 |  1.409 |  0.205 | torch.Size([32]) || m_up1.1.trans_block.ln1.weight
 | -0.009 | -0.395 |  0.521 |  0.227 | torch.Size([32]) || m_up1.1.trans_block.ln1.bias
 |  0.132 | -0.736 |  0.856 |  0.412 | torch.Size([1, 15, 15]) || m_up1.1.trans_block.msa.relative_position_params
 | -0.000 | -0.391 |  0.382 |  0.111 | torch.Size([96, 32, 1, 1]) || m_up1.1.trans_block.msa.embedding_layer1.weight
 | -0.013 | -0.380 |  0.400 |  0.176 | torch.Size([96]) || m_up1.1.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.250 |  0.258 |  0.074 | torch.Size([32, 32, 1, 1]) || m_up1.1.trans_block.msa.linear1.weight
 |  0.003 | -0.120 |  0.146 |  0.064 | torch.Size([32]) || m_up1.1.trans_block.msa.linear1.bias
 |  1.862 |  1.415 |  2.286 |  0.225 | torch.Size([32]) || m_up1.1.trans_block.ln2.weight
 | -0.001 | -0.345 |  0.338 |  0.197 | torch.Size([32]) || m_up1.1.trans_block.ln2.bias
 |  0.001 | -0.854 |  0.775 |  0.172 | torch.Size([128, 32]) || m_up1.1.trans_block.mlp.0.weight
 | -0.014 | -0.409 |  0.344 |  0.133 | torch.Size([128]) || m_up1.1.trans_block.mlp.0.bias
 |  0.001 | -0.663 |  0.840 |  0.128 | torch.Size([32, 128]) || m_up1.1.trans_block.mlp.2.weight
 | -0.030 | -0.413 |  0.253 |  0.164 | torch.Size([32]) || m_up1.1.trans_block.mlp.2.bias
 | -0.005 | -1.324 |  0.491 |  0.125 | torch.Size([96, 96, 1, 1]) || m_up1.1.conv1_1.weight
 | -0.001 | -0.286 |  0.262 |  0.084 | torch.Size([96]) || m_up1.1.conv1_1.bias
 |  0.018 | -0.243 |  0.394 |  0.333 | torch.Size([1, 1, 1, 1, 3]) || m_up1.1.conv3d.weight
 |  0.002 |  0.002 |  0.002 |    nan | torch.Size([1]) || m_up1.1.conv3d.bias
 | -0.001 | -0.580 |  0.715 |  0.087 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.0.weight
 |  0.000 | -0.607 |  0.797 |  0.095 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.2.weight
 |  1.912 | -0.265 |  2.774 |  0.773 | torch.Size([64, 16]) || m_up1.1.mamba_layers.0.mixer.A_log
 |  1.110 |  0.941 |  1.414 |  0.099 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.D
 | -0.001 | -0.476 |  0.654 |  0.125 | torch.Size([128, 32]) || m_up1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.013 | -0.524 |  0.392 |  0.168 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.0.mixer.conv1d.weight
 | -0.001 | -0.193 |  0.268 |  0.090 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.004 | -0.403 |  0.422 |  0.092 | torch.Size([34, 64]) || m_up1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.011 | -0.521 |  0.297 |  0.129 | torch.Size([64, 2]) || m_up1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.029 | -0.778 |  0.464 |  0.212 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.001 | -0.354 |  0.422 |  0.115 | torch.Size([32, 64]) || m_up1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.201 |  0.960 |  1.391 |  0.125 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.weight
 |  0.001 | -0.231 |  0.138 |  0.074 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.bias
 |  1.906 | -0.993 |  2.773 |  0.783 | torch.Size([64, 16]) || m_up1.1.mamba_layers.1.mixer.A_log
 |  1.175 |  1.060 |  1.328 |  0.056 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.D
 |  0.001 | -0.404 |  0.531 |  0.122 | torch.Size([128, 32]) || m_up1.1.mamba_layers.1.mixer.in_proj.weight
 | -0.008 | -0.502 |  0.368 |  0.156 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.1.mixer.conv1d.weight
 | -0.030 | -0.319 |  0.239 |  0.168 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.382 |  0.281 |  0.069 | torch.Size([34, 64]) || m_up1.1.mamba_layers.1.mixer.x_proj.weight
 | -0.012 | -0.374 |  0.251 |  0.086 | torch.Size([64, 2]) || m_up1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.090 | -0.090 |  0.504 |  0.090 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.004 | -0.606 |  0.501 |  0.128 | torch.Size([32, 64]) || m_up1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.169 |  0.921 |  1.361 |  0.089 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.weight
 |  0.005 | -0.159 |  0.209 |  0.097 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.bias
 |  1.916 | -0.071 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.2.mixer.A_log
 |  1.035 |  0.954 |  1.172 |  0.042 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.D
 | -0.002 | -0.357 |  0.359 |  0.112 | torch.Size([128, 32]) || m_up1.1.mamba_layers.2.mixer.in_proj.weight
 |  0.010 | -0.619 |  0.691 |  0.294 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.2.mixer.conv1d.weight
 |  0.007 | -0.520 |  0.481 |  0.302 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.214 |  0.255 |  0.082 | torch.Size([34, 64]) || m_up1.1.mamba_layers.2.mixer.x_proj.weight
 | -0.082 | -0.707 |  0.700 |  0.396 | torch.Size([64, 2]) || m_up1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.429 | -6.865 | -2.310 |  1.242 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.325 |  0.261 |  0.087 | torch.Size([32, 64]) || m_up1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.026 |  0.956 |  1.097 |  0.031 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.weight
 | -0.003 | -0.040 |  0.038 |  0.021 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.bias
 |  1.913 | -0.037 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.3.mixer.A_log
 |  1.027 |  0.962 |  1.130 |  0.035 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.278 |  0.312 |  0.108 | torch.Size([128, 32]) || m_up1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.012 | -0.519 |  0.571 |  0.296 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.3.mixer.conv1d.weight
 | -0.007 | -0.541 |  0.535 |  0.325 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.210 |  0.232 |  0.082 | torch.Size([34, 64]) || m_up1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.751 |  0.694 |  0.410 | torch.Size([64, 2]) || m_up1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.497 | -6.875 | -2.319 |  1.352 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.003 | -0.253 |  0.254 |  0.085 | torch.Size([32, 64]) || m_up1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.016 |  0.957 |  1.069 |  0.032 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.weight
 | -0.002 | -0.053 |  0.062 |  0.024 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.bias
 |  0.533 |  0.169 |  0.897 |  0.515 | torch.Size([2]) || m_up1.1.pcbam_module.h_cw.weight
 | -0.059 | -0.137 |  0.063 |  0.107 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.h_cw.conv.weight
 |  0.070 |  0.005 |  0.134 |  0.091 | torch.Size([2]) || m_up1.1.pcbam_module.w_hc.weight
 | -0.128 | -0.260 |  0.045 |  0.156 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.w_hc.conv.weight
 |  0.449 |  0.106 |  0.791 |  0.484 | torch.Size([2]) || m_up1.1.pcbam_module.c_hw.weight
 | -0.003 | -0.253 |  0.327 |  0.298 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.c_hw.conv.weight
 |  1.250 |  0.909 |  1.602 |  0.174 | torch.Size([32]) || m_up1.2.trans_block.ln1.weight
 |  0.010 | -0.445 |  0.521 |  0.190 | torch.Size([32]) || m_up1.2.trans_block.ln1.bias
 | -0.145 | -0.774 |  0.660 |  0.356 | torch.Size([1, 15, 15]) || m_up1.2.trans_block.msa.relative_position_params
 | -0.001 | -0.613 |  0.676 |  0.146 | torch.Size([96, 32, 1, 1]) || m_up1.2.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.230 |  0.149 |  0.044 | torch.Size([96]) || m_up1.2.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.153 |  0.176 |  0.044 | torch.Size([32, 32, 1, 1]) || m_up1.2.trans_block.msa.linear1.weight
 |  0.001 | -0.147 |  0.140 |  0.049 | torch.Size([32]) || m_up1.2.trans_block.msa.linear1.bias
 |  0.995 |  0.801 |  1.186 |  0.094 | torch.Size([32]) || m_up1.2.trans_block.ln2.weight
 | -0.006 | -0.183 |  0.216 |  0.080 | torch.Size([32]) || m_up1.2.trans_block.ln2.bias
 |  0.001 | -0.555 |  0.426 |  0.079 | torch.Size([128, 32]) || m_up1.2.trans_block.mlp.0.weight
 | -0.005 | -0.214 |  0.099 |  0.051 | torch.Size([128]) || m_up1.2.trans_block.mlp.0.bias
 | -0.002 | -0.341 |  0.369 |  0.082 | torch.Size([32, 128]) || m_up1.2.trans_block.mlp.2.weight
 |  0.001 | -0.104 |  0.243 |  0.063 | torch.Size([32]) || m_up1.2.trans_block.mlp.2.bias
 | -0.002 | -0.810 |  0.495 |  0.110 | torch.Size([96, 96, 1, 1]) || m_up1.2.conv1_1.weight
 | -0.002 | -0.224 |  0.384 |  0.061 | torch.Size([96]) || m_up1.2.conv1_1.bias
 |  0.087 | -0.065 |  0.340 |  0.220 | torch.Size([1, 1, 1, 1, 3]) || m_up1.2.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_up1.2.conv3d.bias
 |  0.002 | -0.369 |  0.581 |  0.081 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.0.weight
 | -0.000 | -0.593 |  0.785 |  0.098 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.2.weight
 |  1.913 | -0.760 |  2.773 |  0.775 | torch.Size([64, 16]) || m_up1.2.mamba_layers.0.mixer.A_log
 |  1.119 |  0.979 |  1.404 |  0.076 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.D
 |  0.001 | -0.536 |  0.540 |  0.125 | torch.Size([128, 32]) || m_up1.2.mamba_layers.0.mixer.in_proj.weight
 | -0.003 | -0.375 |  0.450 |  0.166 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.0.mixer.conv1d.weight
 |  0.006 | -0.089 |  0.134 |  0.050 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.530 |  0.349 |  0.102 | torch.Size([34, 64]) || m_up1.2.mamba_layers.0.mixer.x_proj.weight
 | -0.001 | -0.097 |  0.143 |  0.040 | torch.Size([64, 2]) || m_up1.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.028 | -0.382 |  0.654 |  0.188 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.361 |  0.396 |  0.112 | torch.Size([32, 64]) || m_up1.2.mamba_layers.0.mixer.out_proj.weight
 |  1.258 |  0.859 |  1.450 |  0.124 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.weight
 |  0.016 | -0.245 |  0.314 |  0.114 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.bias
 |  1.913 | -0.550 |  2.784 |  0.778 | torch.Size([64, 16]) || m_up1.2.mamba_layers.1.mixer.A_log
 |  1.193 |  0.973 |  1.463 |  0.105 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.D
 |  0.001 | -0.625 |  0.624 |  0.141 | torch.Size([128, 32]) || m_up1.2.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.604 |  0.675 |  0.188 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.1.mixer.conv1d.weight
 |  0.017 | -0.247 |  0.221 |  0.104 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.conv1d.bias
 |  0.001 | -0.534 |  0.588 |  0.122 | torch.Size([34, 64]) || m_up1.2.mamba_layers.1.mixer.x_proj.weight
 | -0.047 | -0.481 |  0.253 |  0.157 | torch.Size([64, 2]) || m_up1.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.042 | -0.450 |  0.552 |  0.160 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.dt_proj.bias
 | -0.002 | -0.741 |  0.564 |  0.147 | torch.Size([32, 64]) || m_up1.2.mamba_layers.1.mixer.out_proj.weight
 |  1.230 |  0.924 |  1.407 |  0.114 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.weight
 |  0.007 | -0.129 |  0.113 |  0.053 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.bias
 |  1.917 | -0.073 |  2.777 |  0.765 | torch.Size([64, 16]) || m_up1.2.mamba_layers.2.mixer.A_log
 |  1.014 |  0.942 |  1.177 |  0.046 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.D
 |  0.000 | -0.354 |  0.313 |  0.109 | torch.Size([128, 32]) || m_up1.2.mamba_layers.2.mixer.in_proj.weight
 | -0.022 | -0.644 |  0.593 |  0.282 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.2.mixer.conv1d.weight
 |  0.009 | -0.532 |  0.528 |  0.322 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.259 |  0.238 |  0.077 | torch.Size([34, 64]) || m_up1.2.mamba_layers.2.mixer.x_proj.weight
 |  0.070 | -0.709 |  0.670 |  0.392 | torch.Size([64, 2]) || m_up1.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.716 | -6.819 | -2.342 |  1.385 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.330 |  0.288 |  0.089 | torch.Size([32, 64]) || m_up1.2.mamba_layers.2.mixer.out_proj.weight
 |  1.014 |  0.901 |  1.119 |  0.055 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.weight
 |  0.001 | -0.064 |  0.048 |  0.027 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.bias
 |  1.916 | -0.067 |  2.776 |  0.766 | torch.Size([64, 16]) || m_up1.2.mamba_layers.3.mixer.A_log
 |  1.007 |  0.930 |  1.134 |  0.040 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.D
 | -0.001 | -0.371 |  0.439 |  0.110 | torch.Size([128, 32]) || m_up1.2.mamba_layers.3.mixer.in_proj.weight
 |  0.013 | -0.700 |  0.568 |  0.296 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.3.mixer.conv1d.weight
 |  0.083 | -0.446 |  0.560 |  0.281 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.conv1d.bias
 | -0.004 | -0.239 |  0.259 |  0.078 | torch.Size([34, 64]) || m_up1.2.mamba_layers.3.mixer.x_proj.weight
 | -0.115 | -0.707 |  0.686 |  0.390 | torch.Size([64, 2]) || m_up1.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.758 | -6.876 | -2.275 |  1.309 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.002 | -0.407 |  0.269 |  0.089 | torch.Size([32, 64]) || m_up1.2.mamba_layers.3.mixer.out_proj.weight
 |  1.019 |  0.958 |  1.209 |  0.053 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.weight
 | -0.001 | -0.052 |  0.062 |  0.022 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.bias
 |  0.665 |  0.456 |  0.874 |  0.296 | torch.Size([2]) || m_up1.2.pcbam_module.h_cw.weight
 |  0.135 |  0.075 |  0.176 |  0.053 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.h_cw.conv.weight
 |  0.182 |  0.079 |  0.285 |  0.145 | torch.Size([2]) || m_up1.2.pcbam_module.w_hc.weight
 | -0.024 | -0.155 |  0.201 |  0.196 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.w_hc.conv.weight
 |  0.235 |  0.094 |  0.376 |  0.200 | torch.Size([2]) || m_up1.2.pcbam_module.c_hw.weight
 |  0.073 | -0.039 |  0.152 |  0.100 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.c_hw.conv.weight
 |  0.000 | -0.071 |  0.069 |  0.014 | torch.Size([3, 96, 3, 3]) || m_tail.0.weight
 | -0.027 | -0.131 |  0.147 |  0.084 | torch.Size([3, 3, 1, 1]) || fft.mag.weight
 |  0.178 | -0.197 |  0.457 |  0.338 | torch.Size([3]) || fft.mag.bias
 |  0.163 |  0.030 |  0.320 |  0.147 | torch.Size([3]) || fft.mag_bn.weight
 | -0.814 | -2.189 | -0.114 |  1.191 | torch.Size([3]) || fft.mag_bn.bias
 | -1.441 | -5.003 |  2.895 |  4.005 | torch.Size([3]) || fft.mag_bn.running_mean
 | 283.145 | 158.846 | 518.032 | 203.534 | torch.Size([3]) || fft.mag_bn.running_var
 |  0.010 | -0.301 |  0.165 |  0.157 | torch.Size([3, 3, 1, 1]) || fft.pha.0.weight
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.0.bias
 |  1.179 |  0.836 |  1.435 |  0.309 | torch.Size([3]) || fft.pha.1.weight
 |  0.326 |  0.206 |  0.398 |  0.105 | torch.Size([3]) || fft.pha.1.bias
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.1.running_mean
 |  0.026 |  0.017 |  0.039 |  0.012 | torch.Size([3]) || fft.pha.1.running_var
 | -0.087 | -0.664 |  0.872 |  0.497 | torch.Size([3, 3, 1, 1]) || fft.pha.3.weight
 |  0.010 | -0.147 |  0.141 |  0.145 | torch.Size([3]) || fft.pha.3.bias
 |  0.323 | -0.158 |  2.090 |  0.868 | torch.Size([1, 6, 1, 1]) || fft.conv1.weight
 |  0.030 |  0.030 |  0.030 |    nan | torch.Size([1]) || fft.conv1.bias
 | -0.001 | -0.085 |  0.073 |  0.023 | torch.Size([96, 96, 1, 1]) || conv1.weight
 | -0.000 | -0.016 |  0.021 |  0.005 | torch.Size([96]) || conv1.bias
 |  0.398 |  0.002 |  0.888 |  0.227 | torch.Size([96]) || bn1.weight
 | -0.095 | -0.205 | -0.011 |  0.044 | torch.Size([96]) || bn1.bias
 | -0.004 | -0.044 |  0.059 |  0.028 | torch.Size([96]) || bn1.running_mean
 |  0.002 |  0.000 |  0.007 |  0.001 | torch.Size([96]) || bn1.running_var
 | -0.002 | -0.065 |  0.059 |  0.014 | torch.Size([192, 96, 2, 2]) || conv2.weight
 | -0.000 | -0.011 |  0.012 |  0.004 | torch.Size([192]) || conv2.bias
 |  0.407 |  0.016 |  0.895 |  0.228 | torch.Size([192]) || bn2.weight
 | -0.081 | -0.209 | -0.010 |  0.039 | torch.Size([192]) || bn2.bias
 | -0.026 | -0.123 |  0.096 |  0.050 | torch.Size([192]) || bn2.running_mean
 |  0.025 |  0.000 |  0.079 |  0.015 | torch.Size([192]) || bn2.running_var
 | -0.001 | -0.044 |  0.041 |  0.007 | torch.Size([384, 96, 4, 4]) || conv3.weight
 | -0.000 | -0.022 |  0.014 |  0.005 | torch.Size([384]) || conv3.bias
 |  0.435 |  0.045 |  0.918 |  0.222 | torch.Size([384]) || bn3.weight
 | -0.069 | -0.200 |  0.024 |  0.035 | torch.Size([384]) || bn3.bias
 | -0.066 | -0.197 |  0.165 |  0.045 | torch.Size([384]) || bn3.running_mean
 |  0.065 |  0.003 |  0.240 |  0.033 | torch.Size([384]) || bn3.running_var

25-05-15 09:21:39.466 : ---1-->      0.png | 32.79dB
25-05-15 09:21:40.225 : ---2-->      1.png | 34.63dB
25-05-15 09:21:40.979 : ---3-->     10.png | 32.48dB
25-05-15 09:21:56.152 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/13_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/RICE1
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 15
      sigma_test: 15
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/RICE100
      dataroot_L: None
      sigma: 15
      sigma_test: 15
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-15 09:21:56.152 : Random seed: 5060
25-05-15 09:21:56.166 : Number of train images: 385, iters: 385
25-05-15 09:21:58.047 : 
Networks name: DRNet
Params number: 18333721
Net structure:
DRNet(
  (m_head): Sequential(
    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (m_down1): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down2): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down3): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_body): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up3): Sequential(
    (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up2): Sequential(
    (0): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up1): Sequential(
    (0): ConvTranspose2d(192, 96, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_tail): Sequential(
    (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (fft): ResBlock_fft_bench(
    (mag): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
    (mag_bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (mag_relu): ReLU(inplace=True)
    (pha): Sequential(
      (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (4): Sigmoid()
    )
    (conv1): Conv2d(6, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
  (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (conv2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
  (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu2): ReLU()
  (conv3): Conv2d(96, 384, kernel_size=(4, 4), stride=(4, 4))
  (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu3): ReLU()
)

25-05-15 09:21:58.780 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.001 | -0.175 |  0.200 |  0.043 | torch.Size([96, 3, 3, 3]) || m_head.0.weight
 |  0.987 |  0.660 |  1.331 |  0.161 | torch.Size([32]) || m_down1.0.trans_block.ln1.weight
 | -0.029 | -0.287 |  0.309 |  0.141 | torch.Size([32]) || m_down1.0.trans_block.ln1.bias
 | -0.078 | -0.697 |  0.996 |  0.367 | torch.Size([1, 15, 15]) || m_down1.0.trans_block.msa.relative_position_params
 |  0.000 | -0.306 |  0.340 |  0.061 | torch.Size([96, 32, 1, 1]) || m_down1.0.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.126 |  0.122 |  0.055 | torch.Size([96]) || m_down1.0.trans_block.msa.embedding_layer1.bias
 |  0.003 | -0.181 |  0.211 |  0.052 | torch.Size([32, 32, 1, 1]) || m_down1.0.trans_block.msa.linear1.weight
 |  0.008 | -0.087 |  0.126 |  0.059 | torch.Size([32]) || m_down1.0.trans_block.msa.linear1.bias
 |  1.183 |  0.995 |  1.457 |  0.126 | torch.Size([32]) || m_down1.0.trans_block.ln2.weight
 | -0.012 | -0.173 |  0.141 |  0.061 | torch.Size([32]) || m_down1.0.trans_block.ln2.bias
 |  0.005 | -0.539 |  1.337 |  0.115 | torch.Size([128, 32]) || m_down1.0.trans_block.mlp.0.weight
 | -0.023 | -0.193 |  0.157 |  0.072 | torch.Size([128]) || m_down1.0.trans_block.mlp.0.bias
 | -0.001 | -0.498 |  0.763 |  0.088 | torch.Size([32, 128]) || m_down1.0.trans_block.mlp.2.weight
 |  0.000 | -0.123 |  0.322 |  0.096 | torch.Size([32]) || m_down1.0.trans_block.mlp.2.bias
 |  0.007 | -0.513 |  0.480 |  0.098 | torch.Size([96, 96, 1, 1]) || m_down1.0.conv1_1.weight
 | -0.000 | -0.450 |  0.422 |  0.109 | torch.Size([96]) || m_down1.0.conv1_1.bias
 | -0.083 | -0.171 |  0.001 |  0.086 | torch.Size([1, 1, 1, 1, 3]) || m_down1.0.conv3d.weight
 | -0.019 | -0.019 | -0.019 |    nan | torch.Size([1]) || m_down1.0.conv3d.bias
 |  0.006 | -0.351 |  0.450 |  0.073 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.0.weight
 | -0.003 | -0.462 |  0.370 |  0.072 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.2.weight
 |  1.906 | -2.375 |  2.825 |  0.814 | torch.Size([64, 16]) || m_down1.0.mamba_layers.0.mixer.A_log
 |  1.080 |  0.335 |  1.366 |  0.177 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.D
 | -0.000 | -0.472 |  0.518 |  0.121 | torch.Size([128, 32]) || m_down1.0.mamba_layers.0.mixer.in_proj.weight
 |  0.001 | -0.451 |  0.468 |  0.166 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.0.mixer.conv1d.weight
 | -0.010 | -0.240 |  0.194 |  0.097 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.921 |  0.734 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.0.mixer.x_proj.weight
 |  0.004 | -0.791 |  1.048 |  0.250 | torch.Size([64, 2]) || m_down1.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.078 | -1.700 |  0.446 |  0.386 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.663 |  0.579 |  0.116 | torch.Size([32, 64]) || m_down1.0.mamba_layers.0.mixer.out_proj.weight
 |  1.126 |  0.901 |  1.630 |  0.129 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.weight
 |  0.014 | -0.392 |  0.312 |  0.163 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.bias
 |  1.905 | -0.803 |  2.773 |  0.795 | torch.Size([64, 16]) || m_down1.0.mamba_layers.1.mixer.A_log
 |  1.161 |  0.902 |  1.358 |  0.086 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.D
 |  0.001 | -0.592 |  0.466 |  0.128 | torch.Size([128, 32]) || m_down1.0.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.375 |  0.488 |  0.159 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.1.mixer.conv1d.weight
 | -0.003 | -0.307 |  0.272 |  0.168 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.565 |  0.739 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.1.mixer.x_proj.weight
 |  0.014 | -0.295 |  0.482 |  0.148 | torch.Size([64, 2]) || m_down1.0.mamba_layers.1.mixer.dt_proj.weight
 |  0.051 | -0.349 |  0.267 |  0.126 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.002 | -0.370 |  0.431 |  0.119 | torch.Size([32, 64]) || m_down1.0.mamba_layers.1.mixer.out_proj.weight
 |  1.169 |  0.987 |  1.348 |  0.100 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.weight
 | -0.005 | -0.265 |  0.353 |  0.141 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.bias
 |  1.917 | -0.076 |  2.775 |  0.765 | torch.Size([64, 16]) || m_down1.0.mamba_layers.2.mixer.A_log
 |  1.015 |  0.929 |  1.117 |  0.039 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.D
 |  0.000 | -0.336 |  0.347 |  0.107 | torch.Size([128, 32]) || m_down1.0.mamba_layers.2.mixer.in_proj.weight
 | -0.011 | -0.588 |  0.582 |  0.292 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.2.mixer.conv1d.weight
 | -0.032 | -0.507 |  0.490 |  0.285 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.221 |  0.197 |  0.076 | torch.Size([34, 64]) || m_down1.0.mamba_layers.2.mixer.x_proj.weight
 | -0.055 | -0.706 |  0.714 |  0.417 | torch.Size([64, 2]) || m_down1.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.715 | -6.856 | -2.310 |  1.285 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.dt_proj.bias
 | -0.003 | -0.250 |  0.275 |  0.085 | torch.Size([32, 64]) || m_down1.0.mamba_layers.2.mixer.out_proj.weight
 |  0.997 |  0.908 |  1.102 |  0.039 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.weight
 |  0.006 | -0.042 |  0.062 |  0.024 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.bias
 |  1.916 | -0.288 |  2.776 |  0.766 | torch.Size([64, 16]) || m_down1.0.mamba_layers.3.mixer.A_log
 |  1.008 |  0.930 |  1.107 |  0.037 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.D
 |  0.003 | -0.277 |  0.272 |  0.106 | torch.Size([128, 32]) || m_down1.0.mamba_layers.3.mixer.in_proj.weight
 |  0.003 | -0.595 |  0.551 |  0.295 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.3.mixer.conv1d.weight
 | -0.073 | -0.633 |  0.543 |  0.307 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.209 |  0.225 |  0.077 | torch.Size([34, 64]) || m_down1.0.mamba_layers.3.mixer.x_proj.weight
 |  0.039 | -0.688 |  0.780 |  0.425 | torch.Size([64, 2]) || m_down1.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.400 | -7.109 | -2.270 |  1.483 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.242 |  0.301 |  0.084 | torch.Size([32, 64]) || m_down1.0.mamba_layers.3.mixer.out_proj.weight
 |  0.992 |  0.929 |  1.040 |  0.027 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.weight
 | -0.004 | -0.050 |  0.035 |  0.021 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.bias
 |  0.172 |  0.082 |  0.262 |  0.127 | torch.Size([2]) || m_down1.0.pcbam_module.h_cw.weight
 |  0.077 | -0.087 |  0.186 |  0.145 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.h_cw.conv.weight
 |  0.561 |  0.266 |  0.856 |  0.418 | torch.Size([2]) || m_down1.0.pcbam_module.w_hc.weight
 |  0.077 | -0.128 |  0.187 |  0.178 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.w_hc.conv.weight
 |  0.613 |  0.589 |  0.638 |  0.034 | torch.Size([2]) || m_down1.0.pcbam_module.c_hw.weight
 |  0.046 | -0.255 |  0.385 |  0.322 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.c_hw.conv.weight
 |  1.047 |  0.723 |  1.284 |  0.157 | torch.Size([32]) || m_down1.1.trans_block.ln1.weight
 |  0.022 | -0.321 |  0.299 |  0.146 | torch.Size([32]) || m_down1.1.trans_block.ln1.bias
 | -0.224 | -0.785 |  0.840 |  0.324 | torch.Size([1, 15, 15]) || m_down1.1.trans_block.msa.relative_position_params
 |  0.001 | -0.389 |  0.378 |  0.091 | torch.Size([96, 32, 1, 1]) || m_down1.1.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.192 |  0.185 |  0.052 | torch.Size([96]) || m_down1.1.trans_block.msa.embedding_layer1.bias
 | -0.002 | -0.207 |  0.203 |  0.054 | torch.Size([32, 32, 1, 1]) || m_down1.1.trans_block.msa.linear1.weight
 |  0.001 | -0.174 |  0.116 |  0.058 | torch.Size([32]) || m_down1.1.trans_block.msa.linear1.bias
 |  1.159 |  0.962 |  1.324 |  0.078 | torch.Size([32]) || m_down1.1.trans_block.ln2.weight
 |  0.000 | -0.130 |  0.189 |  0.072 | torch.Size([32]) || m_down1.1.trans_block.ln2.bias
 | -0.001 | -0.971 |  0.583 |  0.116 | torch.Size([128, 32]) || m_down1.1.trans_block.mlp.0.weight
 | -0.012 | -0.254 |  0.114 |  0.055 | torch.Size([128]) || m_down1.1.trans_block.mlp.0.bias
 | -0.000 | -0.671 |  0.674 |  0.099 | torch.Size([32, 128]) || m_down1.1.trans_block.mlp.2.weight
 | -0.005 | -0.128 |  0.227 |  0.083 | torch.Size([32]) || m_down1.1.trans_block.mlp.2.bias
 |  0.008 | -0.460 |  0.572 |  0.100 | torch.Size([96, 96, 1, 1]) || m_down1.1.conv1_1.weight
 | -0.007 | -0.190 |  0.290 |  0.062 | torch.Size([96]) || m_down1.1.conv1_1.bias
 | -0.075 | -0.281 |  0.031 |  0.178 | torch.Size([1, 1, 1, 1, 3]) || m_down1.1.conv3d.weight
 | -0.007 | -0.007 | -0.007 |    nan | torch.Size([1]) || m_down1.1.conv3d.bias
 | -0.002 | -0.396 |  0.350 |  0.065 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.0.weight
 | -0.006 | -0.313 |  0.296 |  0.065 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.2.weight
 |  1.917 | -0.011 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.0.mixer.A_log
 |  1.048 |  0.985 |  1.173 |  0.047 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.D
 | -0.000 | -0.452 |  0.447 |  0.086 | torch.Size([128, 32]) || m_down1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.014 | -0.310 |  0.347 |  0.115 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.0.mixer.conv1d.weight
 |  0.015 | -0.205 |  0.218 |  0.064 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.143 |  0.135 |  0.031 | torch.Size([34, 64]) || m_down1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.002 | -0.062 |  0.053 |  0.025 | torch.Size([64, 2]) || m_down1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.001 | -0.024 |  0.032 |  0.009 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.371 |  0.361 |  0.083 | torch.Size([32, 64]) || m_down1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.116 |  0.916 |  1.300 |  0.106 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.weight
 |  0.012 | -0.169 |  0.191 |  0.080 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.bias
 |  1.918 | -0.212 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.1.mixer.A_log
 |  1.091 |  0.987 |  1.483 |  0.090 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.D
 |  0.000 | -0.628 |  0.637 |  0.095 | torch.Size([128, 32]) || m_down1.1.mamba_layers.1.mixer.in_proj.weight
 |  0.001 | -0.337 |  0.387 |  0.127 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.1.mixer.conv1d.weight
 |  0.002 | -0.197 |  0.192 |  0.089 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.001 | -0.185 |  0.297 |  0.049 | torch.Size([34, 64]) || m_down1.1.mamba_layers.1.mixer.x_proj.weight
 |  0.006 | -0.152 |  0.156 |  0.037 | torch.Size([64, 2]) || m_down1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.008 | -0.161 |  0.452 |  0.077 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.004 | -0.546 |  0.368 |  0.087 | torch.Size([32, 64]) || m_down1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.136 |  1.025 |  1.302 |  0.076 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.weight
 | -0.002 | -0.095 |  0.090 |  0.052 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.bias
 |  1.917 | -0.018 |  2.774 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.2.mixer.A_log
 |  1.001 |  0.959 |  1.048 |  0.022 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.D
 | -0.001 | -0.233 |  0.264 |  0.106 | torch.Size([128, 32]) || m_down1.1.mamba_layers.2.mixer.in_proj.weight
 | -0.022 | -0.509 |  0.513 |  0.285 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.2.mixer.conv1d.weight
 | -0.017 | -0.508 |  0.444 |  0.282 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.150 |  0.153 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.2.mixer.x_proj.weight
 |  0.092 | -0.700 |  0.704 |  0.396 | torch.Size([64, 2]) || m_down1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.418 | -6.864 | -2.343 |  1.239 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.259 |  0.279 |  0.077 | torch.Size([32, 64]) || m_down1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.000 |  0.960 |  1.041 |  0.024 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.weight
 |  0.002 | -0.040 |  0.032 |  0.017 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.bias
 |  1.917 | -0.045 |  2.777 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.3.mixer.A_log
 |  1.008 |  0.964 |  1.080 |  0.028 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.298 |  0.349 |  0.110 | torch.Size([128, 32]) || m_down1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.024 | -0.512 |  0.552 |  0.300 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.3.mixer.conv1d.weight
 |  0.050 | -0.424 |  0.517 |  0.242 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.166 |  0.183 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.694 |  0.699 |  0.380 | torch.Size([64, 2]) || m_down1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.585 | -6.892 | -2.263 |  1.350 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.002 | -0.232 |  0.284 |  0.080 | torch.Size([32, 64]) || m_down1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.029 |  0.951 |  1.119 |  0.040 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.weight
 | -0.001 | -0.048 |  0.061 |  0.031 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.bias
 |  0.147 |  0.115 |  0.180 |  0.046 | torch.Size([2]) || m_down1.1.pcbam_module.h_cw.weight
 |  0.199 |  0.033 |  0.468 |  0.235 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.h_cw.conv.weight
 |  0.368 |  0.181 |  0.554 |  0.264 | torch.Size([2]) || m_down1.1.pcbam_module.w_hc.weight
 |  0.247 |  0.094 |  0.417 |  0.162 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.w_hc.conv.weight
 |  0.722 |  0.569 |  0.875 |  0.216 | torch.Size([2]) || m_down1.1.pcbam_module.c_hw.weight
 | -0.100 | -0.294 |  0.117 |  0.206 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.324 |  0.289 |  0.052 | torch.Size([192, 96, 2, 2]) || m_down1.2.weight
 |  1.092 |  0.706 |  1.746 |  0.253 | torch.Size([64]) || m_down2.0.trans_block.ln1.weight
 | -0.006 | -0.504 |  0.511 |  0.232 | torch.Size([64]) || m_down2.0.trans_block.ln1.bias
 | -0.206 | -1.978 |  1.851 |  0.710 | torch.Size([2, 15, 15]) || m_down2.0.trans_block.msa.relative_position_params
 |  0.000 | -0.453 |  0.444 |  0.078 | torch.Size([192, 64, 1, 1]) || m_down2.0.trans_block.msa.embedding_layer1.weight
 | -0.006 | -0.213 |  0.192 |  0.048 | torch.Size([192]) || m_down2.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.275 |  0.255 |  0.051 | torch.Size([64, 64, 1, 1]) || m_down2.0.trans_block.msa.linear1.weight
 |  0.002 | -0.125 |  0.215 |  0.048 | torch.Size([64]) || m_down2.0.trans_block.msa.linear1.bias
 |  1.127 |  0.791 |  1.483 |  0.141 | torch.Size([64]) || m_down2.0.trans_block.ln2.weight
 |  0.008 | -0.139 |  0.265 |  0.075 | torch.Size([64]) || m_down2.0.trans_block.ln2.bias
 |  0.002 | -0.509 |  0.472 |  0.095 | torch.Size([256, 64]) || m_down2.0.trans_block.mlp.0.weight
 | -0.047 | -0.284 |  0.068 |  0.048 | torch.Size([256]) || m_down2.0.trans_block.mlp.0.bias
 |  0.001 | -0.385 |  0.374 |  0.073 | torch.Size([64, 256]) || m_down2.0.trans_block.mlp.2.weight
 |  0.022 | -0.110 |  0.110 |  0.048 | torch.Size([64]) || m_down2.0.trans_block.mlp.2.bias
 |  0.008 | -0.716 |  0.853 |  0.099 | torch.Size([192, 192, 1, 1]) || m_down2.0.conv1_1.weight
 |  0.004 | -0.578 |  0.629 |  0.112 | torch.Size([192]) || m_down2.0.conv1_1.bias
 | -0.065 | -0.203 |  0.011 |  0.120 | torch.Size([1, 1, 1, 1, 3]) || m_down2.0.conv3d.weight
 | -0.005 | -0.005 | -0.005 |    nan | torch.Size([1]) || m_down2.0.conv3d.bias
 |  0.001 | -0.399 |  0.406 |  0.060 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.0.weight
 | -0.000 | -0.276 |  0.394 |  0.061 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.0.mamba_layers.0.mixer.A_log
 |  1.008 |  0.984 |  1.121 |  0.021 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.D
 | -0.000 | -0.277 |  0.253 |  0.032 | torch.Size([256, 64]) || m_down2.0.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.294 |  0.306 |  0.062 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.138 |  0.072 |  0.025 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.062 |  0.058 |  0.018 | torch.Size([36, 128]) || m_down2.0.mamba_layers.0.mixer.x_proj.weight
 |  0.001 | -0.049 |  0.055 |  0.018 | torch.Size([128, 4]) || m_down2.0.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.001 |  0.002 |  0.000 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.221 |  0.279 |  0.033 | torch.Size([64, 128]) || m_down2.0.mamba_layers.0.mixer.out_proj.weight
 |  1.035 |  0.889 |  1.218 |  0.082 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.weight
 |  0.004 | -0.148 |  0.151 |  0.074 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.bias
 |  1.916 | -0.324 |  2.773 |  0.767 | torch.Size([128, 16]) || m_down2.0.mamba_layers.1.mixer.A_log
 |  1.032 |  0.993 |  1.248 |  0.052 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.D
 | -0.000 | -0.335 |  0.353 |  0.050 | torch.Size([256, 64]) || m_down2.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.328 |  0.432 |  0.092 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.1.mixer.conv1d.weight
 |  0.016 | -0.175 |  0.314 |  0.070 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.245 |  0.185 |  0.034 | torch.Size([36, 128]) || m_down2.0.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.093 |  0.087 |  0.021 | torch.Size([128, 4]) || m_down2.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.010 | -0.303 |  0.160 |  0.052 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.349 |  0.356 |  0.051 | torch.Size([64, 128]) || m_down2.0.mamba_layers.1.mixer.out_proj.weight
 |  1.051 |  0.926 |  1.211 |  0.073 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.weight
 |  0.002 | -0.255 |  0.246 |  0.132 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.bias
 |  1.917 | -0.027 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.2.mixer.A_log
 |  0.984 |  0.944 |  1.035 |  0.019 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.D
 |  0.000 | -0.209 |  0.202 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.2.mixer.in_proj.weight
 | -0.004 | -0.517 |  0.513 |  0.273 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.2.mixer.conv1d.weight
 | -0.026 | -0.510 |  0.485 |  0.296 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.133 |  0.215 |  0.052 | torch.Size([36, 128]) || m_down2.0.mamba_layers.2.mixer.x_proj.weight
 |  0.014 | -0.500 |  0.501 |  0.292 | torch.Size([128, 4]) || m_down2.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.641 | -6.908 | -2.258 |  1.372 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.206 |  0.195 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.2.mixer.out_proj.weight
 |  0.966 |  0.883 |  1.026 |  0.032 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.weight
 |  0.002 | -0.090 |  0.064 |  0.029 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.bias
 |  1.917 | -0.021 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.3.mixer.A_log
 |  0.988 |  0.931 |  1.049 |  0.017 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.D
 |  0.001 | -0.194 |  0.185 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.3.mixer.in_proj.weight
 | -0.001 | -0.549 |  0.519 |  0.273 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.487 |  0.483 |  0.290 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.199 |  0.253 |  0.053 | torch.Size([36, 128]) || m_down2.0.mamba_layers.3.mixer.x_proj.weight
 |  0.011 | -0.496 |  0.500 |  0.303 | torch.Size([128, 4]) || m_down2.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.465 | -6.853 | -2.277 |  1.292 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.dt_proj.bias
 |  0.000 | -0.191 |  0.236 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.3.mixer.out_proj.weight
 |  0.972 |  0.915 |  1.037 |  0.025 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.weight
 | -0.002 | -0.045 |  0.065 |  0.023 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.bias
 |  0.632 |  0.128 |  1.136 |  0.712 | torch.Size([2]) || m_down2.0.pcbam_module.h_cw.weight
 |  0.111 | -0.107 |  0.483 |  0.323 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.h_cw.conv.weight
 |  0.678 |  0.609 |  0.746 |  0.097 | torch.Size([2]) || m_down2.0.pcbam_module.w_hc.weight
 |  0.057 | -0.143 |  0.401 |  0.299 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.w_hc.conv.weight
 |  0.594 |  0.347 |  0.841 |  0.349 | torch.Size([2]) || m_down2.0.pcbam_module.c_hw.weight
 | -0.032 | -0.100 |  0.043 |  0.072 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.c_hw.conv.weight
 |  1.159 |  0.847 |  1.736 |  0.232 | torch.Size([64]) || m_down2.1.trans_block.ln1.weight
 |  0.012 | -0.395 |  0.490 |  0.174 | torch.Size([64]) || m_down2.1.trans_block.ln1.bias
 | -0.006 | -1.105 |  0.653 |  0.241 | torch.Size([2, 15, 15]) || m_down2.1.trans_block.msa.relative_position_params
 | -0.000 | -0.388 |  0.443 |  0.084 | torch.Size([192, 64, 1, 1]) || m_down2.1.trans_block.msa.embedding_layer1.weight
 | -0.003 | -0.295 |  0.236 |  0.064 | torch.Size([192]) || m_down2.1.trans_block.msa.embedding_layer1.bias
 |  0.001 | -0.195 |  0.176 |  0.044 | torch.Size([64, 64, 1, 1]) || m_down2.1.trans_block.msa.linear1.weight
 | -0.001 | -0.134 |  0.209 |  0.050 | torch.Size([64]) || m_down2.1.trans_block.msa.linear1.bias
 |  1.041 |  0.711 |  1.338 |  0.147 | torch.Size([64]) || m_down2.1.trans_block.ln2.weight
 |  0.004 | -0.197 |  0.255 |  0.103 | torch.Size([64]) || m_down2.1.trans_block.ln2.bias
 | -0.000 | -0.483 |  0.470 |  0.076 | torch.Size([256, 64]) || m_down2.1.trans_block.mlp.0.weight
 | -0.042 | -0.321 |  0.066 |  0.057 | torch.Size([256]) || m_down2.1.trans_block.mlp.0.bias
 | -0.000 | -0.417 |  0.463 |  0.053 | torch.Size([64, 256]) || m_down2.1.trans_block.mlp.2.weight
 | -0.001 | -0.077 |  0.068 |  0.034 | torch.Size([64]) || m_down2.1.trans_block.mlp.2.bias
 | -0.009 | -1.115 |  0.517 |  0.104 | torch.Size([192, 192, 1, 1]) || m_down2.1.conv1_1.weight
 |  0.001 | -0.333 |  0.324 |  0.084 | torch.Size([192]) || m_down2.1.conv1_1.bias
 |  0.075 | -0.017 |  0.245 |  0.148 | torch.Size([1, 1, 1, 1, 3]) || m_down2.1.conv3d.weight
 | -0.004 | -0.004 | -0.004 |    nan | torch.Size([1]) || m_down2.1.conv3d.bias
 | -0.003 | -0.377 |  0.308 |  0.059 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.0.weight
 |  0.000 | -0.309 |  0.315 |  0.058 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.2.weight
 |  1.917 | -0.006 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.0.mixer.A_log
 |  1.023 |  0.995 |  1.258 |  0.040 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.D
 |  0.000 | -0.275 |  0.252 |  0.039 | torch.Size([256, 64]) || m_down2.1.mamba_layers.0.mixer.in_proj.weight
 | -0.003 | -0.434 |  0.293 |  0.074 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.001 | -0.083 |  0.113 |  0.029 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.167 |  0.165 |  0.024 | torch.Size([36, 128]) || m_down2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.049 |  0.052 |  0.018 | torch.Size([128, 4]) || m_down2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.061 |  0.079 |  0.016 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.274 |  0.283 |  0.043 | torch.Size([64, 128]) || m_down2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.023 |  0.836 |  1.225 |  0.076 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.weight
 |  0.001 | -0.171 |  0.207 |  0.101 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.bias
 |  1.917 | -0.245 |  2.773 |  0.765 | torch.Size([128, 16]) || m_down2.1.mamba_layers.1.mixer.A_log
 |  1.038 |  0.996 |  1.244 |  0.064 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.D
 | -0.000 | -0.439 |  0.420 |  0.051 | torch.Size([256, 64]) || m_down2.1.mamba_layers.1.mixer.in_proj.weight
 |  0.004 | -0.311 |  0.379 |  0.094 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.009 | -0.127 |  0.231 |  0.045 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.260 |  0.271 |  0.038 | torch.Size([36, 128]) || m_down2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.256 |  0.251 |  0.029 | torch.Size([128, 4]) || m_down2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.002 | -0.300 |  0.165 |  0.044 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.394 |  0.374 |  0.052 | torch.Size([64, 128]) || m_down2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.054 |  0.948 |  1.401 |  0.092 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.weight
 | -0.007 | -0.220 |  0.195 |  0.127 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.027 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.2.mixer.A_log
 |  0.988 |  0.942 |  1.085 |  0.023 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.D
 | -0.001 | -0.241 |  0.207 |  0.076 | torch.Size([256, 64]) || m_down2.1.mamba_layers.2.mixer.in_proj.weight
 | -0.007 | -0.567 |  0.538 |  0.283 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.2.mixer.conv1d.weight
 |  0.014 | -0.490 |  0.506 |  0.266 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.169 |  0.171 |  0.053 | torch.Size([36, 128]) || m_down2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.021 | -0.500 |  0.499 |  0.284 | torch.Size([128, 4]) || m_down2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.836 | -6.905 | -2.270 |  1.399 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.185 |  0.208 |  0.055 | torch.Size([64, 128]) || m_down2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.980 |  0.905 |  1.059 |  0.032 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.weight
 |  0.003 | -0.070 |  0.080 |  0.028 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.043 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.3.mixer.A_log
 |  0.986 |  0.950 |  1.054 |  0.019 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.211 |  0.283 |  0.074 | torch.Size([256, 64]) || m_down2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.001 | -0.512 |  0.515 |  0.279 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.3.mixer.conv1d.weight
 |  0.054 | -0.523 |  0.489 |  0.264 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.163 |  0.134 |  0.052 | torch.Size([36, 128]) || m_down2.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.500 |  0.499 |  0.290 | torch.Size([128, 4]) || m_down2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.409 | -6.903 | -2.271 |  1.291 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.179 |  0.191 |  0.054 | torch.Size([64, 128]) || m_down2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.972 |  0.919 |  1.032 |  0.029 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.weight
 |  0.001 | -0.059 |  0.056 |  0.024 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.bias
 |  0.860 |  0.685 |  1.036 |  0.249 | torch.Size([2]) || m_down2.1.pcbam_module.h_cw.weight
 |  0.141 | -0.074 |  0.413 |  0.249 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.h_cw.conv.weight
 |  0.696 |  0.603 |  0.790 |  0.132 | torch.Size([2]) || m_down2.1.pcbam_module.w_hc.weight
 |  0.077 | -0.277 |  0.457 |  0.367 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.w_hc.conv.weight
 |  0.886 |  0.744 |  1.029 |  0.201 | torch.Size([2]) || m_down2.1.pcbam_module.c_hw.weight
 | -0.068 | -0.261 |  0.250 |  0.277 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.c_hw.conv.weight
 | -0.001 | -0.275 |  0.410 |  0.043 | torch.Size([384, 192, 2, 2]) || m_down2.2.weight
 |  0.980 |  0.604 |  1.641 |  0.232 | torch.Size([128]) || m_down3.0.trans_block.ln1.weight
 |  0.005 | -0.613 |  0.623 |  0.256 | torch.Size([128]) || m_down3.0.trans_block.ln1.bias
 |  0.053 | -2.558 |  0.994 |  0.348 | torch.Size([4, 15, 15]) || m_down3.0.trans_block.msa.relative_position_params
 | -0.000 | -0.407 |  0.396 |  0.052 | torch.Size([384, 128, 1, 1]) || m_down3.0.trans_block.msa.embedding_layer1.weight
 |  0.006 | -0.197 |  0.272 |  0.057 | torch.Size([384]) || m_down3.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.164 |  0.167 |  0.040 | torch.Size([128, 128, 1, 1]) || m_down3.0.trans_block.msa.linear1.weight
 |  0.002 | -0.116 |  0.103 |  0.043 | torch.Size([128]) || m_down3.0.trans_block.msa.linear1.bias
 |  0.891 |  0.453 |  1.359 |  0.169 | torch.Size([128]) || m_down3.0.trans_block.ln2.weight
 |  0.001 | -0.337 |  0.362 |  0.115 | torch.Size([128]) || m_down3.0.trans_block.ln2.bias
 | -0.000 | -0.412 |  0.380 |  0.046 | torch.Size([512, 128]) || m_down3.0.trans_block.mlp.0.weight
 | -0.027 | -0.353 |  0.068 |  0.044 | torch.Size([512]) || m_down3.0.trans_block.mlp.0.bias
 | -0.000 | -0.401 |  0.451 |  0.037 | torch.Size([128, 512]) || m_down3.0.trans_block.mlp.2.weight
 |  0.002 | -0.125 |  0.210 |  0.054 | torch.Size([128]) || m_down3.0.trans_block.mlp.2.bias
 |  0.004 | -0.550 |  1.751 |  0.081 | torch.Size([384, 384, 1, 1]) || m_down3.0.conv1_1.weight
 | -0.003 | -0.796 |  0.608 |  0.128 | torch.Size([384]) || m_down3.0.conv1_1.bias
 | -0.078 | -0.238 |  0.004 |  0.139 | torch.Size([1, 1, 1, 1, 3]) || m_down3.0.conv3d.weight
 | -0.003 | -0.003 | -0.003 |    nan | torch.Size([1]) || m_down3.0.conv3d.bias
 |  0.001 | -0.377 |  0.292 |  0.045 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.0.weight
 | -0.000 | -0.230 |  0.277 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.0.mixer.A_log
 |  1.001 |  0.991 |  1.093 |  0.009 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.D
 | -0.000 | -0.091 |  0.110 |  0.011 | torch.Size([512, 128]) || m_down3.0.mamba_layers.0.mixer.in_proj.weight
 | -0.002 | -0.147 |  0.111 |  0.023 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.0.mixer.conv1d.weight
 | -0.002 | -0.116 |  0.149 |  0.035 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.051 |  0.051 |  0.012 | torch.Size([40, 256]) || m_down3.0.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.041 |  0.047 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.001 |  0.000 |  0.000 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.187 |  0.140 |  0.016 | torch.Size([128, 256]) || m_down3.0.mamba_layers.0.mixer.out_proj.weight
 |  0.999 |  0.985 |  1.026 |  0.008 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.weight
 |  0.001 | -0.024 |  0.023 |  0.012 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.bias
 |  1.917 | -0.005 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.1.mixer.A_log
 |  1.013 |  0.998 |  1.310 |  0.045 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.D
 |  0.000 | -0.321 |  0.273 |  0.019 | torch.Size([512, 128]) || m_down3.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.290 |  0.285 |  0.041 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.1.mixer.conv1d.weight
 | -0.003 | -0.245 |  0.224 |  0.054 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.119 |  0.125 |  0.013 | torch.Size([40, 256]) || m_down3.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.039 |  0.058 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.101 |  0.024 |  0.007 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.407 |  0.294 |  0.024 | torch.Size([128, 256]) || m_down3.0.mamba_layers.1.mixer.out_proj.weight
 |  0.949 |  0.855 |  1.174 |  0.052 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.weight
 |  0.013 | -0.150 |  0.158 |  0.098 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.bias
 |  1.917 | -0.002 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.2.mixer.A_log
 |  0.979 |  0.950 |  1.016 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.D
 |  0.000 | -0.142 |  0.149 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.2.mixer.in_proj.weight
 | -0.015 | -0.545 |  0.511 |  0.279 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.2.mixer.conv1d.weight
 |  0.031 | -0.514 |  0.483 |  0.274 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.105 |  0.098 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.2.mixer.x_proj.weight
 | -0.000 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.489 | -6.888 | -2.309 |  1.322 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.138 |  0.151 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.2.mixer.out_proj.weight
 |  0.954 |  0.898 |  1.032 |  0.022 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.weight
 |  0.001 | -0.071 |  0.061 |  0.032 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.bias
 |  1.917 | -0.001 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.3.mixer.A_log
 |  0.980 |  0.942 |  1.026 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.D
 | -0.000 | -0.136 |  0.142 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.3.mixer.in_proj.weight
 |  0.006 | -0.506 |  0.531 |  0.279 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.489 |  0.499 |  0.256 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.089 |  0.091 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.3.mixer.x_proj.weight
 | -0.002 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.511 | -6.890 | -2.277 |  1.395 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.128 |  0.130 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.3.mixer.out_proj.weight
 |  0.953 |  0.892 |  0.999 |  0.021 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.weight
 | -0.000 | -0.065 |  0.066 |  0.029 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.bias
 |  0.711 |  0.548 |  0.874 |  0.231 | torch.Size([2]) || m_down3.0.pcbam_module.h_cw.weight
 |  0.063 | -0.051 |  0.247 |  0.161 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.h_cw.conv.weight
 |  0.298 |  0.253 |  0.343 |  0.064 | torch.Size([2]) || m_down3.0.pcbam_module.w_hc.weight
 |  0.032 | -0.136 |  0.278 |  0.217 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.w_hc.conv.weight
 |  0.573 |  0.260 |  0.886 |  0.443 | torch.Size([2]) || m_down3.0.pcbam_module.c_hw.weight
 | -0.105 | -0.399 |  0.106 |  0.186 | torch.Size([1, 1, 1, 5]) || m_down3.0.pcbam_module.c_hw.conv.weight
 |  1.079 |  0.600 |  1.607 |  0.247 | torch.Size([128]) || m_down3.1.trans_block.ln1.weight
 | -0.017 | -0.824 |  0.674 |  0.224 | torch.Size([128]) || m_down3.1.trans_block.ln1.bias
 |  0.002 | -2.704 |  1.290 |  0.321 | torch.Size([4, 15, 15]) || m_down3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.456 |  0.467 |  0.057 | torch.Size([384, 128, 1, 1]) || m_down3.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.241 |  0.247 |  0.049 | torch.Size([384]) || m_down3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.168 |  0.168 |  0.039 | torch.Size([128, 128, 1, 1]) || m_down3.1.trans_block.msa.linear1.weight
 |  0.000 | -0.143 |  0.149 |  0.055 | torch.Size([128]) || m_down3.1.trans_block.msa.linear1.bias
 |  0.896 |  0.414 |  1.270 |  0.193 | torch.Size([128]) || m_down3.1.trans_block.ln2.weight
 | -0.006 | -0.372 |  0.441 |  0.167 | torch.Size([128]) || m_down3.1.trans_block.ln2.bias
 | -0.000 | -0.451 |  0.369 |  0.058 | torch.Size([512, 128]) || m_down3.1.trans_block.mlp.0.weight
 | -0.044 | -0.239 |  0.033 |  0.052 | torch.Size([512]) || m_down3.1.trans_block.mlp.0.bias
 | -0.000 | -0.363 |  0.362 |  0.044 | torch.Size([128, 512]) || m_down3.1.trans_block.mlp.2.weight
 |  0.004 | -0.131 |  0.154 |  0.052 | torch.Size([128]) || m_down3.1.trans_block.mlp.2.bias
 | -0.004 | -1.805 |  0.669 |  0.088 | torch.Size([384, 384, 1, 1]) || m_down3.1.conv1_1.weight
 |  0.009 | -0.556 |  0.405 |  0.089 | torch.Size([384]) || m_down3.1.conv1_1.bias
 |  0.080 | -0.008 |  0.252 |  0.149 | torch.Size([1, 1, 1, 1, 3]) || m_down3.1.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_down3.1.conv3d.bias
 | -0.005 | -0.365 |  0.422 |  0.047 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.0.weight
 | -0.001 | -0.255 |  0.296 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.2.weight
 |  1.917 | -0.001 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.0.mixer.A_log
 |  1.011 |  0.991 |  1.142 |  0.025 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.305 |  0.307 |  0.026 | torch.Size([512, 128]) || m_down3.1.mamba_layers.0.mixer.in_proj.weight
 | -0.000 | -0.375 |  0.286 |  0.053 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.126 |  0.105 |  0.034 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.084 |  0.087 |  0.014 | torch.Size([40, 256]) || m_down3.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.039 |  0.057 |  0.012 | torch.Size([256, 8]) || m_down3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.022 |  0.011 |  0.002 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.215 |  0.222 |  0.028 | torch.Size([128, 256]) || m_down3.1.mamba_layers.0.mixer.out_proj.weight
 |  0.987 |  0.870 |  1.207 |  0.057 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.weight
 |  0.004 | -0.125 |  0.144 |  0.076 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.bias
 |  1.917 | -0.044 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.1.mixer.A_log
 |  1.021 |  0.949 |  1.312 |  0.049 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.D
 |  0.000 | -0.308 |  0.342 |  0.033 | torch.Size([512, 128]) || m_down3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.003 | -0.375 |  0.359 |  0.064 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.244 |  0.231 |  0.044 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.182 |  0.210 |  0.024 | torch.Size([40, 256]) || m_down3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.078 |  0.084 |  0.016 | torch.Size([256, 8]) || m_down3.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.010 | -0.109 |  0.195 |  0.031 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.287 |  0.302 |  0.034 | torch.Size([128, 256]) || m_down3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.010 |  0.830 |  1.240 |  0.081 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.weight
 | -0.003 | -0.173 |  0.191 |  0.105 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.090 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.2.mixer.A_log
 |  0.979 |  0.933 |  1.076 |  0.019 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.167 |  0.161 |  0.052 | torch.Size([512, 128]) || m_down3.1.mamba_layers.2.mixer.in_proj.weight
 | -0.012 | -0.553 |  0.578 |  0.277 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.2.mixer.conv1d.weight
 |  0.015 | -0.523 |  0.510 |  0.290 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.125 |  0.110 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.205 | torch.Size([256, 8]) || m_down3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.526 | -6.818 | -2.284 |  1.305 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.215 |  0.140 |  0.039 | torch.Size([128, 256]) || m_down3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.955 |  0.855 |  1.027 |  0.027 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.weight
 | -0.000 | -0.096 |  0.061 |  0.023 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.003 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.3.mixer.A_log
 |  0.979 |  0.931 |  1.017 |  0.015 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.D
 |  0.000 | -0.146 |  0.154 |  0.051 | torch.Size([512, 128]) || m_down3.1.mamba_layers.3.mixer.in_proj.weight
 |  0.010 | -0.548 |  0.544 |  0.276 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.3.mixer.conv1d.weight
 |  0.001 | -0.512 |  0.481 |  0.287 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.109 |  0.119 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.204 | torch.Size([256, 8]) || m_down3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.747 | -6.882 | -2.256 |  1.391 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.125 |  0.139 |  0.037 | torch.Size([128, 256]) || m_down3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.945 |  0.887 |  1.000 |  0.025 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.weight
 | -0.001 | -0.089 |  0.079 |  0.023 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.bias
 |  0.682 |  0.554 |  0.810 |  0.181 | torch.Size([2]) || m_down3.1.pcbam_module.h_cw.weight
 | -0.009 | -0.224 |  0.287 |  0.265 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.h_cw.conv.weight
 |  0.428 |  0.112 |  0.744 |  0.447 | torch.Size([2]) || m_down3.1.pcbam_module.w_hc.weight
 | -0.023 | -0.256 |  0.344 |  0.321 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.w_hc.conv.weight
 |  0.600 |  0.593 |  0.607 |  0.010 | torch.Size([2]) || m_down3.1.pcbam_module.c_hw.weight
 |  0.095 | -0.207 |  0.358 |  0.274 | torch.Size([1, 1, 1, 5]) || m_down3.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.488 |  0.302 |  0.032 | torch.Size([768, 384, 2, 2]) || m_down3.2.weight
 |  0.803 |  0.355 |  1.188 |  0.146 | torch.Size([256]) || m_body.0.trans_block.ln1.weight
 | -0.011 | -0.693 |  0.510 |  0.139 | torch.Size([256]) || m_body.0.trans_block.ln1.bias
 |  0.054 | -4.646 |  0.713 |  0.330 | torch.Size([8, 15, 15]) || m_body.0.trans_block.msa.relative_position_params
 | -0.000 | -0.399 |  0.391 |  0.037 | torch.Size([768, 256, 1, 1]) || m_body.0.trans_block.msa.embedding_layer1.weight
 |  0.002 | -0.216 |  0.230 |  0.054 | torch.Size([768]) || m_body.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.238 |  0.236 |  0.042 | torch.Size([256, 256, 1, 1]) || m_body.0.trans_block.msa.linear1.weight
 |  0.001 | -0.268 |  0.150 |  0.058 | torch.Size([256]) || m_body.0.trans_block.msa.linear1.bias
 |  0.852 |  0.383 |  1.179 |  0.124 | torch.Size([256]) || m_body.0.trans_block.ln2.weight
 |  0.002 | -0.198 |  0.275 |  0.080 | torch.Size([256]) || m_body.0.trans_block.ln2.bias
 |  0.000 | -0.255 |  0.282 |  0.034 | torch.Size([1024, 256]) || m_body.0.trans_block.mlp.0.weight
 | -0.011 | -0.233 |  0.104 |  0.042 | torch.Size([1024]) || m_body.0.trans_block.mlp.0.bias
 | -0.000 | -0.293 |  0.322 |  0.031 | torch.Size([256, 1024]) || m_body.0.trans_block.mlp.2.weight
 |  0.004 | -0.190 |  0.159 |  0.054 | torch.Size([256]) || m_body.0.trans_block.mlp.2.bias
 | -0.001 | -1.114 |  0.876 |  0.051 | torch.Size([768, 768, 1, 1]) || m_body.0.conv1_1.weight
 |  0.001 | -1.467 |  1.031 |  0.093 | torch.Size([768]) || m_body.0.conv1_1.bias
 |  0.064 | -0.005 |  0.198 |  0.116 | torch.Size([1, 1, 1, 1, 3]) || m_body.0.conv3d.weight
 |  0.025 |  0.025 |  0.025 |    nan | torch.Size([1]) || m_body.0.conv3d.bias
 |  0.000 | -0.238 |  0.256 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.0.weight
 | -0.000 | -0.239 |  0.211 |  0.036 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.D
 |  0.000 | -0.028 |  0.027 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.025 |  0.027 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.004 |  0.003 |  0.001 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.035 |  0.036 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.033 |  0.038 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.042 |  0.037 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.0.mixer.out_proj.weight
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.bias
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.001 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.D
 |  0.000 | -0.029 |  0.030 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.1.mixer.in_proj.weight
 |  0.000 | -0.035 |  0.059 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.1.mixer.conv1d.weight
 | -0.000 | -0.018 |  0.022 |  0.006 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.034 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.034 |  0.030 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.045 |  0.041 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.999 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.weight
 | -0.000 | -0.001 |  0.001 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.bias
 |  1.917 | -0.026 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.A_log
 |  0.999 |  0.973 |  1.015 |  0.004 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.D
 | -0.000 | -0.086 |  0.084 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.2.mixer.in_proj.weight
 | -0.007 | -0.504 |  0.519 |  0.289 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.2.mixer.conv1d.weight
 | -0.005 | -0.500 |  0.495 |  0.307 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.067 |  0.067 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.579 | -6.906 | -2.283 |  1.361 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.093 |  0.082 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.2.mixer.out_proj.weight
 |  0.995 |  0.984 |  1.008 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.weight
 |  0.000 | -0.013 |  0.007 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.bias
 |  1.917 | -0.017 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.A_log
 |  0.998 |  0.981 |  1.010 |  0.003 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.D
 |  0.000 | -0.081 |  0.080 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.3.mixer.in_proj.weight
 | -0.013 | -0.511 |  0.502 |  0.287 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.3.mixer.conv1d.weight
 |  0.003 | -0.500 |  0.496 |  0.280 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.070 |  0.068 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.3.mixer.x_proj.weight
 |  0.002 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.612 | -6.907 | -2.259 |  1.325 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.064 |  0.066 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.3.mixer.out_proj.weight
 |  0.995 |  0.986 |  1.006 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.weight
 | -0.000 | -0.010 |  0.009 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.bias
 |  1.128 |  0.894 |  1.363 |  0.331 | torch.Size([2]) || m_body.0.pcbam_module.h_cw.weight
 | -0.693 | -0.987 | -0.529 |  0.255 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.h_cw.conv.weight
 |  0.389 |  0.163 |  0.616 |  0.320 | torch.Size([2]) || m_body.0.pcbam_module.w_hc.weight
 | -0.547 | -0.641 | -0.366 |  0.156 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.w_hc.conv.weight
 |  1.020 |  0.132 |  1.907 |  1.256 | torch.Size([2]) || m_body.0.pcbam_module.c_hw.weight
 | -0.087 | -1.011 |  1.945 |  1.190 | torch.Size([1, 1, 1, 5]) || m_body.0.pcbam_module.c_hw.conv.weight
 |  0.746 |  0.302 |  1.004 |  0.127 | torch.Size([256]) || m_body.1.trans_block.ln1.weight
 |  0.029 | -0.826 |  0.544 |  0.167 | torch.Size([256]) || m_body.1.trans_block.ln1.bias
 |  0.052 | -3.778 |  0.814 |  0.348 | torch.Size([8, 15, 15]) || m_body.1.trans_block.msa.relative_position_params
 | -0.000 | -0.316 |  0.315 |  0.036 | torch.Size([768, 256, 1, 1]) || m_body.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.223 |  0.254 |  0.069 | torch.Size([768]) || m_body.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.277 |  0.271 |  0.037 | torch.Size([256, 256, 1, 1]) || m_body.1.trans_block.msa.linear1.weight
 | -0.004 | -0.220 |  0.267 |  0.059 | torch.Size([256]) || m_body.1.trans_block.msa.linear1.bias
 |  0.854 |  0.493 |  1.089 |  0.103 | torch.Size([256]) || m_body.1.trans_block.ln2.weight
 |  0.008 | -0.251 |  0.328 |  0.102 | torch.Size([256]) || m_body.1.trans_block.ln2.bias
 |  0.001 | -0.362 |  0.359 |  0.054 | torch.Size([1024, 256]) || m_body.1.trans_block.mlp.0.weight
 | -0.051 | -0.198 |  0.050 |  0.038 | torch.Size([1024]) || m_body.1.trans_block.mlp.0.bias
 | -0.001 | -0.437 |  0.433 |  0.052 | torch.Size([256, 1024]) || m_body.1.trans_block.mlp.2.weight
 | -0.001 | -0.241 |  0.143 |  0.053 | torch.Size([256]) || m_body.1.trans_block.mlp.2.bias
 | -0.001 | -1.068 |  0.773 |  0.056 | torch.Size([768, 768, 1, 1]) || m_body.1.conv1_1.weight
 | -0.000 | -0.313 |  0.949 |  0.085 | torch.Size([768]) || m_body.1.conv1_1.bias
 |  0.147 |  0.004 |  0.431 |  0.246 | torch.Size([1, 1, 1, 1, 3]) || m_body.1.conv3d.weight
 |  0.043 |  0.043 |  0.043 |    nan | torch.Size([1]) || m_body.1.conv3d.bias
 | -0.001 | -0.278 |  0.267 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.0.weight
 | -0.001 | -0.269 |  0.270 |  0.035 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.2.weight
 |  1.917 | -0.001 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.092 |  0.006 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.D
 | -0.000 | -0.123 |  0.107 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.108 |  0.289 |  0.013 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.024 |  0.071 |  0.004 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.036 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.035 |  0.029 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.008 |  0.004 |  0.000 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.166 |  0.121 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.0.mixer.out_proj.weight
 |  1.001 |  0.994 |  1.014 |  0.003 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.weight
 |  0.000 | -0.005 |  0.006 |  0.002 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.bias
 |  1.917 | -0.218 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.053 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.D
 |  0.000 | -0.159 |  0.145 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.1.mixer.in_proj.weight
 | -0.000 | -0.049 |  0.174 |  0.010 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.097 |  0.073 |  0.022 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.096 |  0.319 |  0.010 | torch.Size([48, 512]) || m_body.1.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.032 |  0.035 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.038 |  0.000 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.171 |  0.177 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.986 |  1.042 |  0.010 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.weight
 | -0.001 | -0.017 |  0.021 |  0.008 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.bias
 |  1.917 | -0.066 |  2.774 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.A_log
 |  0.998 |  0.963 |  1.031 |  0.005 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.D
 | -0.000 | -0.107 |  0.131 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.2.mixer.in_proj.weight
 |  0.004 | -0.530 |  0.504 |  0.283 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.2.mixer.conv1d.weight
 |  0.010 | -0.506 |  0.492 |  0.282 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.094 |  0.089 |  0.026 | torch.Size([48, 512]) || m_body.1.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.257 |  0.260 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.634 | -6.903 | -2.259 |  1.288 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.126 |  0.105 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.2.mixer.out_proj.weight
 |  0.996 |  0.961 |  1.012 |  0.008 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.weight
 |  0.000 | -0.023 |  0.021 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.bias
 |  1.917 | -0.069 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.A_log
 |  0.999 |  0.920 |  1.118 |  0.009 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.D
 |  0.000 | -0.122 |  0.123 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.531 |  0.505 |  0.293 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.3.mixer.conv1d.weight
 | -0.009 | -0.500 |  0.498 |  0.294 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.099 |  0.105 |  0.027 | torch.Size([48, 512]) || m_body.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.272 |  0.274 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.631 | -6.903 | -2.252 |  1.302 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.118 |  0.102 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.3.mixer.out_proj.weight
 |  1.000 |  0.969 |  1.029 |  0.009 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.weight
 |  0.000 | -0.017 |  0.019 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.bias
 |  1.226 |  0.884 |  1.568 |  0.484 | torch.Size([2]) || m_body.1.pcbam_module.h_cw.weight
 | -1.051 | -1.169 | -0.864 |  0.164 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.h_cw.conv.weight
 |  1.165 |  0.908 |  1.422 |  0.363 | torch.Size([2]) || m_body.1.pcbam_module.w_hc.weight
 | -0.980 | -1.093 | -0.820 |  0.142 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.w_hc.conv.weight
 |  1.519 |  0.158 |  2.880 |  1.925 | torch.Size([2]) || m_body.1.pcbam_module.c_hw.weight
 | -0.167 | -1.486 |  1.768 |  1.300 | torch.Size([1, 1, 1, 5]) || m_body.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.324 |  0.332 |  0.030 | torch.Size([768, 384, 2, 2]) || m_up3.0.weight
 |  0.959 |  0.556 |  1.369 |  0.157 | torch.Size([128]) || m_up3.1.trans_block.ln1.weight
 |  0.026 | -0.612 |  0.449 |  0.134 | torch.Size([128]) || m_up3.1.trans_block.ln1.bias
 |  0.050 | -3.715 |  0.652 |  0.304 | torch.Size([4, 15, 15]) || m_up3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.523 |  0.546 |  0.061 | torch.Size([384, 128, 1, 1]) || m_up3.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.259 |  0.245 |  0.071 | torch.Size([384]) || m_up3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.176 |  0.177 |  0.042 | torch.Size([128, 128, 1, 1]) || m_up3.1.trans_block.msa.linear1.weight
 | -0.001 | -0.109 |  0.283 |  0.047 | torch.Size([128]) || m_up3.1.trans_block.msa.linear1.bias
 |  0.857 |  0.602 |  1.006 |  0.072 | torch.Size([128]) || m_up3.1.trans_block.ln2.weight
 |  0.009 | -0.321 |  0.182 |  0.089 | torch.Size([128]) || m_up3.1.trans_block.ln2.bias
 |  0.000 | -0.333 |  0.322 |  0.059 | torch.Size([512, 128]) || m_up3.1.trans_block.mlp.0.weight
 | -0.038 | -0.189 |  0.068 |  0.044 | torch.Size([512]) || m_up3.1.trans_block.mlp.0.bias
 | -0.000 | -0.340 |  0.310 |  0.052 | torch.Size([128, 512]) || m_up3.1.trans_block.mlp.2.weight
 | -0.001 | -0.345 |  0.163 |  0.046 | torch.Size([128]) || m_up3.1.trans_block.mlp.2.bias
 | -0.001 | -2.380 |  0.668 |  0.087 | torch.Size([384, 384, 1, 1]) || m_up3.1.conv1_1.weight
 | -0.000 | -0.512 |  1.315 |  0.141 | torch.Size([384]) || m_up3.1.conv1_1.bias
 |  0.185 | -0.003 |  0.561 |  0.326 | torch.Size([1, 1, 1, 1, 3]) || m_up3.1.conv3d.weight
 | -0.006 | -0.006 | -0.006 |    nan | torch.Size([1]) || m_up3.1.conv3d.bias
 |  0.000 | -0.349 |  0.318 |  0.036 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.0.weight
 |  0.000 | -0.272 |  0.385 |  0.038 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.2.weight
 |  1.916 | -0.349 |  2.773 |  0.766 | torch.Size([256, 16]) || m_up3.1.mamba_layers.0.mixer.A_log
 |  1.053 |  0.998 |  1.430 |  0.078 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.401 |  0.370 |  0.043 | torch.Size([512, 128]) || m_up3.1.mamba_layers.0.mixer.in_proj.weight
 |  0.006 | -0.495 |  0.462 |  0.097 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.0.mixer.conv1d.weight
 |  0.013 | -0.181 |  0.483 |  0.073 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.163 |  0.213 |  0.025 | torch.Size([40, 256]) || m_up3.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.054 |  0.067 |  0.013 | torch.Size([256, 8]) || m_up3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.003 | -0.178 |  0.172 |  0.030 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.567 |  0.495 |  0.050 | torch.Size([128, 256]) || m_up3.1.mamba_layers.0.mixer.out_proj.weight
 |  1.034 |  0.905 |  1.175 |  0.064 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.weight
 | -0.003 | -0.306 |  0.302 |  0.126 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.bias
 |  1.916 | -0.847 |  3.034 |  0.769 | torch.Size([256, 16]) || m_up3.1.mamba_layers.1.mixer.A_log
 |  1.000 | -0.050 |  1.309 |  0.161 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.D
 | -0.000 | -0.419 |  0.417 |  0.055 | torch.Size([512, 128]) || m_up3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.003 | -0.604 |  0.389 |  0.113 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.022 | -0.299 |  0.315 |  0.177 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.conv1d.bias
 |  0.001 | -0.584 |  0.555 |  0.074 | torch.Size([40, 256]) || m_up3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.002 | -0.608 |  0.703 |  0.095 | torch.Size([256, 8]) || m_up3.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.011 | -1.014 |  0.284 |  0.107 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.277 |  0.279 |  0.056 | torch.Size([128, 256]) || m_up3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.030 |  0.658 |  1.217 |  0.117 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.weight
 | -0.002 | -0.255 |  0.264 |  0.109 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.295 |  2.787 |  0.764 | torch.Size([256, 16]) || m_up3.1.mamba_layers.2.mixer.A_log
 |  0.981 |  0.645 |  1.037 |  0.041 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.200 |  0.195 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.2.mixer.in_proj.weight
 |  0.014 | -0.558 |  0.536 |  0.273 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.2.mixer.conv1d.weight
 | -0.030 | -0.527 |  0.495 |  0.292 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.168 |  0.144 |  0.042 | torch.Size([40, 256]) || m_up3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.000 | -0.415 |  0.372 |  0.205 | torch.Size([256, 8]) || m_up3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.530 | -6.922 | -2.275 |  1.363 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.000 | -0.158 |  0.161 |  0.041 | torch.Size([128, 256]) || m_up3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.957 |  0.843 |  1.037 |  0.031 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.weight
 |  0.002 | -0.066 |  0.085 |  0.024 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.033 |  2.773 |  0.765 | torch.Size([256, 16]) || m_up3.1.mamba_layers.3.mixer.A_log
 |  0.990 |  0.944 |  1.076 |  0.018 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.D
 | -0.000 | -0.229 |  0.214 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.3.mixer.in_proj.weight
 | -0.010 | -0.532 |  0.605 |  0.267 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.3.mixer.conv1d.weight
 | -0.004 | -0.554 |  0.581 |  0.312 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.121 |  0.122 |  0.038 | torch.Size([40, 256]) || m_up3.1.mamba_layers.3.mixer.x_proj.weight
 | -0.001 | -0.357 |  0.357 |  0.203 | torch.Size([256, 8]) || m_up3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.644 | -6.923 | -2.262 |  1.394 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.178 |  0.170 |  0.041 | torch.Size([128, 256]) || m_up3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.960 |  0.893 |  1.028 |  0.028 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.weight
 | -0.000 | -0.077 |  0.059 |  0.022 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.bias
 |  0.530 |  0.193 |  0.867 |  0.477 | torch.Size([2]) || m_up3.1.pcbam_module.h_cw.weight
 |  0.057 |  0.005 |  0.144 |  0.076 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.h_cw.conv.weight
 |  0.878 |  0.846 |  0.909 |  0.045 | torch.Size([2]) || m_up3.1.pcbam_module.w_hc.weight
 |  0.093 |  0.036 |  0.147 |  0.056 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.w_hc.conv.weight
 |  0.497 |  0.240 |  0.755 |  0.365 | torch.Size([2]) || m_up3.1.pcbam_module.c_hw.weight
 | -0.018 | -0.190 |  0.144 |  0.150 | torch.Size([1, 1, 1, 5]) || m_up3.1.pcbam_module.c_hw.conv.weight
 |  1.121 |  0.585 |  1.350 |  0.144 | torch.Size([128]) || m_up3.2.trans_block.ln1.weight
 | -0.004 | -0.520 |  0.515 |  0.126 | torch.Size([128]) || m_up3.2.trans_block.ln1.bias
 |  0.061 | -3.059 |  0.727 |  0.353 | torch.Size([4, 15, 15]) || m_up3.2.trans_block.msa.relative_position_params
 | -0.000 | -0.476 |  0.327 |  0.057 | torch.Size([384, 128, 1, 1]) || m_up3.2.trans_block.msa.embedding_layer1.weight
 | -0.001 | -0.186 |  0.195 |  0.058 | torch.Size([384]) || m_up3.2.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.184 |  0.198 |  0.046 | torch.Size([128, 128, 1, 1]) || m_up3.2.trans_block.msa.linear1.weight
 | -0.002 | -0.134 |  0.232 |  0.056 | torch.Size([128]) || m_up3.2.trans_block.msa.linear1.bias
 |  1.183 |  0.883 |  1.489 |  0.095 | torch.Size([128]) || m_up3.2.trans_block.ln2.weight
 | -0.000 | -0.259 |  0.287 |  0.110 | torch.Size([128]) || m_up3.2.trans_block.ln2.bias
 |  0.000 | -0.349 |  0.331 |  0.073 | torch.Size([512, 128]) || m_up3.2.trans_block.mlp.0.weight
 | -0.048 | -0.182 |  0.055 |  0.038 | torch.Size([512]) || m_up3.2.trans_block.mlp.0.bias
 |  0.000 | -0.343 |  0.388 |  0.070 | torch.Size([128, 512]) || m_up3.2.trans_block.mlp.2.weight
 | -0.001 | -0.144 |  0.217 |  0.052 | torch.Size([128]) || m_up3.2.trans_block.mlp.2.bias
 | -0.000 | -0.870 |  0.462 |  0.076 | torch.Size([384, 384, 1, 1]) || m_up3.2.conv1_1.weight
 |  0.002 | -0.543 |  1.071 |  0.103 | torch.Size([384]) || m_up3.2.conv1_1.bias
 | -0.058 | -0.185 |  0.007 |  0.110 | torch.Size([1, 1, 1, 1, 3]) || m_up3.2.conv3d.weight
 | -0.003 | -0.003 | -0.003 |    nan | torch.Size([1]) || m_up3.2.conv3d.bias
 | -0.001 | -0.313 |  0.351 |  0.052 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.0.weight
 |  0.000 | -0.435 |  0.396 |  0.052 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.2.weight
 |  1.916 | -1.147 |  2.794 |  0.767 | torch.Size([256, 16]) || m_up3.2.mamba_layers.0.mixer.A_log
 |  1.074 |  0.396 |  1.577 |  0.161 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.D
 | -0.000 | -0.323 |  0.327 |  0.071 | torch.Size([512, 128]) || m_up3.2.mamba_layers.0.mixer.in_proj.weight
 | -0.001 | -0.379 |  0.421 |  0.143 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.0.mixer.conv1d.weight
 | -0.009 | -0.305 |  0.263 |  0.103 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.668 |  0.473 |  0.076 | torch.Size([40, 256]) || m_up3.2.mamba_layers.0.mixer.x_proj.weight
 |  0.002 | -0.695 |  0.724 |  0.100 | torch.Size([256, 8]) || m_up3.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.019 | -1.184 |  0.292 |  0.121 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.584 |  0.441 |  0.076 | torch.Size([128, 256]) || m_up3.2.mamba_layers.0.mixer.out_proj.weight
 |  1.014 |  0.617 |  1.157 |  0.085 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.weight
 |  0.006 | -0.442 |  0.410 |  0.136 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.bias
 |  1.911 | -0.990 |  2.866 |  0.776 | torch.Size([256, 16]) || m_up3.2.mamba_layers.1.mixer.A_log
 |  1.069 | -0.097 |  1.515 |  0.138 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.D
 |  0.000 | -0.344 |  0.424 |  0.072 | torch.Size([512, 128]) || m_up3.2.mamba_layers.1.mixer.in_proj.weight
 |  0.005 | -0.553 |  0.459 |  0.147 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.1.mixer.conv1d.weight
 |  0.011 | -0.313 |  0.346 |  0.150 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.conv1d.bias
 |  0.002 | -0.723 |  1.154 |  0.092 | torch.Size([40, 256]) || m_up3.2.mamba_layers.1.mixer.x_proj.weight
 | -0.005 | -0.663 |  0.594 |  0.125 | torch.Size([256, 8]) || m_up3.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.014 | -0.457 |  0.174 |  0.107 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.459 |  0.406 |  0.075 | torch.Size([128, 256]) || m_up3.2.mamba_layers.1.mixer.out_proj.weight
 |  1.071 |  0.637 |  1.215 |  0.084 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.weight
 |  0.004 | -0.262 |  0.246 |  0.108 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.bias
 |  1.917 | -0.049 |  2.834 |  0.765 | torch.Size([256, 16]) || m_up3.2.mamba_layers.2.mixer.A_log
 |  1.027 |  0.971 |  1.344 |  0.036 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.D
 | -0.000 | -0.226 |  0.215 |  0.057 | torch.Size([512, 128]) || m_up3.2.mamba_layers.2.mixer.in_proj.weight
 |  0.002 | -0.661 |  0.648 |  0.294 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.2.mixer.conv1d.weight
 |  0.036 | -0.541 |  0.542 |  0.318 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.159 |  0.175 |  0.045 | torch.Size([40, 256]) || m_up3.2.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.442 |  0.471 |  0.206 | torch.Size([256, 8]) || m_up3.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.531 | -6.898 | -2.237 |  1.383 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.229 |  0.203 |  0.046 | torch.Size([128, 256]) || m_up3.2.mamba_layers.2.mixer.out_proj.weight
 |  1.021 |  0.939 |  1.088 |  0.026 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.weight
 |  0.000 | -0.092 |  0.103 |  0.038 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.bias
 |  1.917 | -0.027 |  2.774 |  0.764 | torch.Size([256, 16]) || m_up3.2.mamba_layers.3.mixer.A_log
 |  1.008 |  0.975 |  1.068 |  0.013 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.D
 | -0.000 | -0.196 |  0.171 |  0.054 | torch.Size([512, 128]) || m_up3.2.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.564 |  0.554 |  0.286 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.3.mixer.conv1d.weight
 | -0.022 | -0.537 |  0.533 |  0.300 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.175 |  0.175 |  0.041 | torch.Size([40, 256]) || m_up3.2.mamba_layers.3.mixer.x_proj.weight
 | -0.005 | -0.366 |  0.370 |  0.206 | torch.Size([256, 8]) || m_up3.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.526 | -6.891 | -2.231 |  1.228 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.186 |  0.179 |  0.043 | torch.Size([128, 256]) || m_up3.2.mamba_layers.3.mixer.out_proj.weight
 |  0.999 |  0.794 |  1.051 |  0.032 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.weight
 | -0.001 | -0.151 |  0.078 |  0.028 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.bias
 |  0.755 |  0.557 |  0.954 |  0.280 | torch.Size([2]) || m_up3.2.pcbam_module.h_cw.weight
 | -0.103 | -0.244 |  0.133 |  0.206 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.h_cw.conv.weight
 |  0.793 |  0.740 |  0.845 |  0.074 | torch.Size([2]) || m_up3.2.pcbam_module.w_hc.weight
 |  0.021 | -0.140 |  0.160 |  0.151 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.w_hc.conv.weight
 |  0.554 |  0.117 |  0.991 |  0.618 | torch.Size([2]) || m_up3.2.pcbam_module.c_hw.weight
 |  0.297 | -0.086 |  1.451 |  0.649 | torch.Size([1, 1, 1, 5]) || m_up3.2.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.401 |  0.318 |  0.034 | torch.Size([384, 192, 2, 2]) || m_up2.0.weight
 |  1.336 |  0.968 |  1.555 |  0.140 | torch.Size([64]) || m_up2.1.trans_block.ln1.weight
 | -0.001 | -0.528 |  0.532 |  0.165 | torch.Size([64]) || m_up2.1.trans_block.ln1.bias
 |  0.173 | -2.384 |  0.910 |  0.340 | torch.Size([2, 15, 15]) || m_up2.1.trans_block.msa.relative_position_params
 |  0.000 | -0.515 |  0.537 |  0.109 | torch.Size([192, 64, 1, 1]) || m_up2.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.185 |  0.185 |  0.047 | torch.Size([192]) || m_up2.1.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.200 |  0.217 |  0.046 | torch.Size([64, 64, 1, 1]) || m_up2.1.trans_block.msa.linear1.weight
 | -0.002 | -0.184 |  0.236 |  0.055 | torch.Size([64]) || m_up2.1.trans_block.msa.linear1.bias
 |  1.032 |  0.743 |  1.174 |  0.082 | torch.Size([64]) || m_up2.1.trans_block.ln2.weight
 |  0.006 | -0.283 |  0.254 |  0.139 | torch.Size([64]) || m_up2.1.trans_block.ln2.bias
 | -0.000 | -0.360 |  0.341 |  0.090 | torch.Size([256, 64]) || m_up2.1.trans_block.mlp.0.weight
 | -0.046 | -0.344 |  0.224 |  0.073 | torch.Size([256]) || m_up2.1.trans_block.mlp.0.bias
 |  0.001 | -0.423 |  0.396 |  0.078 | torch.Size([64, 256]) || m_up2.1.trans_block.mlp.2.weight
 | -0.002 | -0.218 |  0.196 |  0.062 | torch.Size([64]) || m_up2.1.trans_block.mlp.2.bias
 |  0.002 | -0.456 |  2.131 |  0.102 | torch.Size([192, 192, 1, 1]) || m_up2.1.conv1_1.weight
 | -0.000 | -0.590 |  0.723 |  0.129 | torch.Size([192]) || m_up2.1.conv1_1.bias
 | -0.179 | -0.620 |  0.044 |  0.382 | torch.Size([1, 1, 1, 1, 3]) || m_up2.1.conv3d.weight
 |  0.002 |  0.002 |  0.002 |    nan | torch.Size([1]) || m_up2.1.conv3d.bias
 |  0.000 | -0.293 |  0.234 |  0.046 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.0.weight
 |  0.000 | -0.279 |  0.316 |  0.046 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.2.weight
 |  1.917 | -0.448 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.0.mixer.A_log
 |  1.111 |  0.999 |  1.287 |  0.058 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.D
 | -0.000 | -0.361 |  0.352 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.423 |  0.481 |  0.171 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.004 | -0.223 |  0.215 |  0.068 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.001 | -0.144 |  0.209 |  0.039 | torch.Size([36, 128]) || m_up2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.056 |  0.058 |  0.020 | torch.Size([128, 4]) || m_up2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.003 | -0.158 |  0.288 |  0.058 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.523 |  0.386 |  0.076 | torch.Size([64, 128]) || m_up2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.188 |  0.952 |  1.337 |  0.091 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.weight
 |  0.001 | -0.154 |  0.235 |  0.078 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.bias
 |  1.916 | -0.561 |  2.773 |  0.767 | torch.Size([128, 16]) || m_up2.1.mamba_layers.1.mixer.A_log
 |  1.147 |  0.999 |  1.412 |  0.066 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.D
 |  0.000 | -0.399 |  0.390 |  0.091 | torch.Size([256, 64]) || m_up2.1.mamba_layers.1.mixer.in_proj.weight
 | -0.007 | -0.499 |  0.658 |  0.187 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.011 | -0.308 |  0.287 |  0.122 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.237 |  0.303 |  0.063 | torch.Size([36, 128]) || m_up2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.113 |  0.285 |  0.042 | torch.Size([128, 4]) || m_up2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.032 | -0.123 |  0.240 |  0.062 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.001 | -0.393 |  0.461 |  0.090 | torch.Size([64, 128]) || m_up2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.205 |  0.843 |  1.340 |  0.108 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.weight
 |  0.000 | -0.220 |  0.248 |  0.087 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.041 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.2.mixer.A_log
 |  1.007 |  0.938 |  1.087 |  0.029 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.D
 |  0.001 | -0.248 |  0.276 |  0.076 | torch.Size([256, 64]) || m_up2.1.mamba_layers.2.mixer.in_proj.weight
 |  0.001 | -0.550 |  0.677 |  0.287 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.2.mixer.conv1d.weight
 | -0.028 | -0.537 |  0.492 |  0.307 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.174 |  0.171 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.016 | -0.497 |  0.500 |  0.287 | torch.Size([128, 4]) || m_up2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.802 | -6.895 | -2.292 |  1.396 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.223 |  0.205 |  0.060 | torch.Size([64, 128]) || m_up2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.998 |  0.904 |  1.178 |  0.043 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.weight
 |  0.000 | -0.070 |  0.061 |  0.021 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.015 |  2.775 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.3.mixer.A_log
 |  1.002 |  0.944 |  1.086 |  0.030 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.219 |  0.258 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.013 | -0.594 |  0.630 |  0.292 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.3.mixer.conv1d.weight
 | -0.016 | -0.568 |  0.565 |  0.318 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.197 |  0.172 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.3.mixer.x_proj.weight
 | -0.017 | -0.491 |  0.498 |  0.291 | torch.Size([128, 4]) || m_up2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.756 | -6.892 | -2.289 |  1.356 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.232 |  0.201 |  0.060 | torch.Size([64, 128]) || m_up2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.988 |  0.868 |  1.105 |  0.038 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.weight
 | -0.001 | -0.089 |  0.083 |  0.025 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.bias
 |  0.167 |  0.121 |  0.214 |  0.065 | torch.Size([2]) || m_up2.1.pcbam_module.h_cw.weight
 | -0.035 | -0.133 |  0.092 |  0.115 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.h_cw.conv.weight
 |  0.693 |  0.692 |  0.694 |  0.001 | torch.Size([2]) || m_up2.1.pcbam_module.w_hc.weight
 | -0.108 | -0.319 |  0.039 |  0.187 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.w_hc.conv.weight
 |  0.890 |  0.840 |  0.940 |  0.071 | torch.Size([2]) || m_up2.1.pcbam_module.c_hw.weight
 | -0.061 | -0.261 |  0.057 |  0.174 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.c_hw.conv.weight
 |  1.352 |  1.014 |  1.553 |  0.127 | torch.Size([64]) || m_up2.2.trans_block.ln1.weight
 |  0.039 | -0.470 |  0.554 |  0.145 | torch.Size([64]) || m_up2.2.trans_block.ln1.bias
 |  0.131 | -2.475 |  0.722 |  0.329 | torch.Size([2, 15, 15]) || m_up2.2.trans_block.msa.relative_position_params
 |  0.000 | -0.501 |  0.560 |  0.104 | torch.Size([192, 64, 1, 1]) || m_up2.2.trans_block.msa.embedding_layer1.weight
 |  0.000 | -0.263 |  0.296 |  0.070 | torch.Size([192]) || m_up2.2.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.288 |  0.269 |  0.048 | torch.Size([64, 64, 1, 1]) || m_up2.2.trans_block.msa.linear1.weight
 |  0.003 | -0.282 |  0.441 |  0.071 | torch.Size([64]) || m_up2.2.trans_block.msa.linear1.bias
 |  1.042 |  0.586 |  1.252 |  0.125 | torch.Size([64]) || m_up2.2.trans_block.ln2.weight
 |  0.015 | -0.435 |  0.425 |  0.130 | torch.Size([64]) || m_up2.2.trans_block.ln2.bias
 |  0.002 | -0.391 |  0.424 |  0.088 | torch.Size([256, 64]) || m_up2.2.trans_block.mlp.0.weight
 | -0.044 | -0.175 |  0.085 |  0.042 | torch.Size([256]) || m_up2.2.trans_block.mlp.0.bias
 | -0.000 | -0.318 |  0.371 |  0.077 | torch.Size([64, 256]) || m_up2.2.trans_block.mlp.2.weight
 |  0.001 | -0.262 |  0.260 |  0.062 | torch.Size([64]) || m_up2.2.trans_block.mlp.2.bias
 |  0.002 | -0.489 |  2.100 |  0.102 | torch.Size([192, 192, 1, 1]) || m_up2.2.conv1_1.weight
 | -0.002 | -0.456 |  0.860 |  0.130 | torch.Size([192]) || m_up2.2.conv1_1.bias
 | -0.186 | -0.607 |  0.029 |  0.364 | torch.Size([1, 1, 1, 1, 3]) || m_up2.2.conv3d.weight
 | -0.009 | -0.009 | -0.009 |    nan | torch.Size([1]) || m_up2.2.conv3d.bias
 |  0.001 | -0.419 |  0.460 |  0.054 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.0.weight
 | -0.000 | -0.310 |  0.432 |  0.056 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.2.weight
 |  1.915 | -0.405 |  2.782 |  0.770 | torch.Size([128, 16]) || m_up2.2.mamba_layers.0.mixer.A_log
 |  1.154 |  0.722 |  1.495 |  0.109 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.D
 |  0.000 | -0.508 |  0.405 |  0.097 | torch.Size([256, 64]) || m_up2.2.mamba_layers.0.mixer.in_proj.weight
 |  0.034 | -0.552 |  0.764 |  0.196 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.0.mixer.conv1d.weight
 |  0.041 | -0.246 |  0.296 |  0.105 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.conv1d.bias
 | -0.003 | -0.527 |  0.775 |  0.078 | torch.Size([36, 128]) || m_up2.2.mamba_layers.0.mixer.x_proj.weight
 | -0.006 | -0.483 |  0.341 |  0.106 | torch.Size([128, 4]) || m_up2.2.mamba_layers.0.mixer.dt_proj.weight
 | -0.014 | -0.615 |  0.344 |  0.121 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.382 |  0.577 |  0.099 | torch.Size([64, 128]) || m_up2.2.mamba_layers.0.mixer.out_proj.weight
 |  1.253 |  0.944 |  1.403 |  0.098 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.weight
 |  0.008 | -0.526 |  0.462 |  0.166 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.bias
 |  1.919 | -0.475 |  2.882 |  0.766 | torch.Size([128, 16]) || m_up2.2.mamba_layers.1.mixer.A_log
 |  1.150 |  0.793 |  1.463 |  0.098 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.D
 |  0.000 | -0.548 |  0.600 |  0.104 | torch.Size([256, 64]) || m_up2.2.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.693 |  1.017 |  0.213 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.1.mixer.conv1d.weight
 |  0.031 | -0.351 |  0.325 |  0.127 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.509 |  0.593 |  0.101 | torch.Size([36, 128]) || m_up2.2.mamba_layers.1.mixer.x_proj.weight
 |  0.002 | -0.444 |  0.364 |  0.105 | torch.Size([128, 4]) || m_up2.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.056 | -0.214 |  0.569 |  0.109 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.453 |  0.455 |  0.098 | torch.Size([64, 128]) || m_up2.2.mamba_layers.1.mixer.out_proj.weight
 |  1.316 |  0.842 |  1.519 |  0.140 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.weight
 |  0.003 | -0.149 |  0.354 |  0.088 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.bias
 |  1.917 | -0.029 |  2.774 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.2.mixer.A_log
 |  1.018 |  0.954 |  1.143 |  0.032 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.D
 | -0.000 | -0.346 |  0.310 |  0.078 | torch.Size([256, 64]) || m_up2.2.mamba_layers.2.mixer.in_proj.weight
 | -0.004 | -0.567 |  0.540 |  0.289 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.2.mixer.conv1d.weight
 |  0.065 | -0.560 |  0.576 |  0.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.217 |  0.193 |  0.054 | torch.Size([36, 128]) || m_up2.2.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.497 |  0.499 |  0.286 | torch.Size([128, 4]) || m_up2.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.495 | -6.884 | -2.259 |  1.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.279 |  0.279 |  0.065 | torch.Size([64, 128]) || m_up2.2.mamba_layers.2.mixer.out_proj.weight
 |  1.018 |  0.882 |  1.149 |  0.050 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.weight
 |  0.004 | -0.087 |  0.117 |  0.039 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.bias
 |  1.917 | -0.073 |  2.777 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.3.mixer.A_log
 |  1.024 |  0.953 |  1.196 |  0.042 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.D
 |  0.000 | -0.317 |  0.263 |  0.078 | torch.Size([256, 64]) || m_up2.2.mamba_layers.3.mixer.in_proj.weight
 |  0.009 | -0.636 |  0.615 |  0.288 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.3.mixer.conv1d.weight
 |  0.031 | -0.525 |  0.560 |  0.302 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.240 |  0.173 |  0.057 | torch.Size([36, 128]) || m_up2.2.mamba_layers.3.mixer.x_proj.weight
 |  0.004 | -0.595 |  0.600 |  0.291 | torch.Size([128, 4]) || m_up2.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.642 | -6.849 | -2.288 |  1.277 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.dt_proj.bias
 |  0.000 | -0.243 |  0.296 |  0.066 | torch.Size([64, 128]) || m_up2.2.mamba_layers.3.mixer.out_proj.weight
 |  1.014 |  0.878 |  1.138 |  0.048 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.weight
 |  0.004 | -0.075 |  0.074 |  0.032 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.bias
 |  0.305 |  0.187 |  0.423 |  0.167 | torch.Size([2]) || m_up2.2.pcbam_module.h_cw.weight
 |  0.051 | -0.090 |  0.150 |  0.125 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.h_cw.conv.weight
 |  0.820 |  0.756 |  0.884 |  0.091 | torch.Size([2]) || m_up2.2.pcbam_module.w_hc.weight
 | -0.005 | -0.137 |  0.061 |  0.114 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.w_hc.conv.weight
 |  0.734 |  0.714 |  0.754 |  0.028 | torch.Size([2]) || m_up2.2.pcbam_module.c_hw.weight
 |  0.097 |  0.080 |  0.111 |  0.015 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.168 |  0.185 |  0.027 | torch.Size([192, 96, 2, 2]) || m_up1.0.weight
 |  1.175 |  0.732 |  1.409 |  0.205 | torch.Size([32]) || m_up1.1.trans_block.ln1.weight
 | -0.009 | -0.395 |  0.521 |  0.227 | torch.Size([32]) || m_up1.1.trans_block.ln1.bias
 |  0.132 | -0.736 |  0.856 |  0.412 | torch.Size([1, 15, 15]) || m_up1.1.trans_block.msa.relative_position_params
 | -0.000 | -0.391 |  0.382 |  0.111 | torch.Size([96, 32, 1, 1]) || m_up1.1.trans_block.msa.embedding_layer1.weight
 | -0.013 | -0.380 |  0.400 |  0.176 | torch.Size([96]) || m_up1.1.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.250 |  0.258 |  0.074 | torch.Size([32, 32, 1, 1]) || m_up1.1.trans_block.msa.linear1.weight
 |  0.003 | -0.120 |  0.146 |  0.064 | torch.Size([32]) || m_up1.1.trans_block.msa.linear1.bias
 |  1.862 |  1.415 |  2.286 |  0.225 | torch.Size([32]) || m_up1.1.trans_block.ln2.weight
 | -0.001 | -0.345 |  0.338 |  0.197 | torch.Size([32]) || m_up1.1.trans_block.ln2.bias
 |  0.001 | -0.854 |  0.775 |  0.172 | torch.Size([128, 32]) || m_up1.1.trans_block.mlp.0.weight
 | -0.014 | -0.409 |  0.344 |  0.133 | torch.Size([128]) || m_up1.1.trans_block.mlp.0.bias
 |  0.001 | -0.663 |  0.840 |  0.128 | torch.Size([32, 128]) || m_up1.1.trans_block.mlp.2.weight
 | -0.030 | -0.413 |  0.253 |  0.164 | torch.Size([32]) || m_up1.1.trans_block.mlp.2.bias
 | -0.005 | -1.324 |  0.491 |  0.125 | torch.Size([96, 96, 1, 1]) || m_up1.1.conv1_1.weight
 | -0.001 | -0.286 |  0.262 |  0.084 | torch.Size([96]) || m_up1.1.conv1_1.bias
 |  0.018 | -0.243 |  0.394 |  0.333 | torch.Size([1, 1, 1, 1, 3]) || m_up1.1.conv3d.weight
 |  0.002 |  0.002 |  0.002 |    nan | torch.Size([1]) || m_up1.1.conv3d.bias
 | -0.001 | -0.580 |  0.715 |  0.087 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.0.weight
 |  0.000 | -0.607 |  0.797 |  0.095 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.2.weight
 |  1.912 | -0.265 |  2.774 |  0.773 | torch.Size([64, 16]) || m_up1.1.mamba_layers.0.mixer.A_log
 |  1.110 |  0.941 |  1.414 |  0.099 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.D
 | -0.001 | -0.476 |  0.654 |  0.125 | torch.Size([128, 32]) || m_up1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.013 | -0.524 |  0.392 |  0.168 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.0.mixer.conv1d.weight
 | -0.001 | -0.193 |  0.268 |  0.090 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.004 | -0.403 |  0.422 |  0.092 | torch.Size([34, 64]) || m_up1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.011 | -0.521 |  0.297 |  0.129 | torch.Size([64, 2]) || m_up1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.029 | -0.778 |  0.464 |  0.212 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.001 | -0.354 |  0.422 |  0.115 | torch.Size([32, 64]) || m_up1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.201 |  0.960 |  1.391 |  0.125 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.weight
 |  0.001 | -0.231 |  0.138 |  0.074 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.bias
 |  1.906 | -0.993 |  2.773 |  0.783 | torch.Size([64, 16]) || m_up1.1.mamba_layers.1.mixer.A_log
 |  1.175 |  1.060 |  1.328 |  0.056 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.D
 |  0.001 | -0.404 |  0.531 |  0.122 | torch.Size([128, 32]) || m_up1.1.mamba_layers.1.mixer.in_proj.weight
 | -0.008 | -0.502 |  0.368 |  0.156 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.1.mixer.conv1d.weight
 | -0.030 | -0.319 |  0.239 |  0.168 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.382 |  0.281 |  0.069 | torch.Size([34, 64]) || m_up1.1.mamba_layers.1.mixer.x_proj.weight
 | -0.012 | -0.374 |  0.251 |  0.086 | torch.Size([64, 2]) || m_up1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.090 | -0.090 |  0.504 |  0.090 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.004 | -0.606 |  0.501 |  0.128 | torch.Size([32, 64]) || m_up1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.169 |  0.921 |  1.361 |  0.089 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.weight
 |  0.005 | -0.159 |  0.209 |  0.097 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.bias
 |  1.916 | -0.071 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.2.mixer.A_log
 |  1.035 |  0.954 |  1.172 |  0.042 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.D
 | -0.002 | -0.357 |  0.359 |  0.112 | torch.Size([128, 32]) || m_up1.1.mamba_layers.2.mixer.in_proj.weight
 |  0.010 | -0.619 |  0.691 |  0.294 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.2.mixer.conv1d.weight
 |  0.007 | -0.520 |  0.481 |  0.302 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.214 |  0.255 |  0.082 | torch.Size([34, 64]) || m_up1.1.mamba_layers.2.mixer.x_proj.weight
 | -0.082 | -0.707 |  0.700 |  0.396 | torch.Size([64, 2]) || m_up1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.429 | -6.865 | -2.310 |  1.242 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.325 |  0.261 |  0.087 | torch.Size([32, 64]) || m_up1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.026 |  0.956 |  1.097 |  0.031 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.weight
 | -0.003 | -0.040 |  0.038 |  0.021 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.bias
 |  1.913 | -0.037 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.3.mixer.A_log
 |  1.027 |  0.962 |  1.130 |  0.035 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.278 |  0.312 |  0.108 | torch.Size([128, 32]) || m_up1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.012 | -0.519 |  0.571 |  0.296 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.3.mixer.conv1d.weight
 | -0.007 | -0.541 |  0.535 |  0.325 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.210 |  0.232 |  0.082 | torch.Size([34, 64]) || m_up1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.751 |  0.694 |  0.410 | torch.Size([64, 2]) || m_up1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.497 | -6.875 | -2.319 |  1.352 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.003 | -0.253 |  0.254 |  0.085 | torch.Size([32, 64]) || m_up1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.016 |  0.957 |  1.069 |  0.032 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.weight
 | -0.002 | -0.053 |  0.062 |  0.024 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.bias
 |  0.533 |  0.169 |  0.897 |  0.515 | torch.Size([2]) || m_up1.1.pcbam_module.h_cw.weight
 | -0.059 | -0.137 |  0.063 |  0.107 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.h_cw.conv.weight
 |  0.070 |  0.005 |  0.134 |  0.091 | torch.Size([2]) || m_up1.1.pcbam_module.w_hc.weight
 | -0.128 | -0.260 |  0.045 |  0.156 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.w_hc.conv.weight
 |  0.449 |  0.106 |  0.791 |  0.484 | torch.Size([2]) || m_up1.1.pcbam_module.c_hw.weight
 | -0.003 | -0.253 |  0.327 |  0.298 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.c_hw.conv.weight
 |  1.250 |  0.909 |  1.602 |  0.174 | torch.Size([32]) || m_up1.2.trans_block.ln1.weight
 |  0.010 | -0.445 |  0.521 |  0.190 | torch.Size([32]) || m_up1.2.trans_block.ln1.bias
 | -0.145 | -0.774 |  0.660 |  0.356 | torch.Size([1, 15, 15]) || m_up1.2.trans_block.msa.relative_position_params
 | -0.001 | -0.613 |  0.676 |  0.146 | torch.Size([96, 32, 1, 1]) || m_up1.2.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.230 |  0.149 |  0.044 | torch.Size([96]) || m_up1.2.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.153 |  0.176 |  0.044 | torch.Size([32, 32, 1, 1]) || m_up1.2.trans_block.msa.linear1.weight
 |  0.001 | -0.147 |  0.140 |  0.049 | torch.Size([32]) || m_up1.2.trans_block.msa.linear1.bias
 |  0.995 |  0.801 |  1.186 |  0.094 | torch.Size([32]) || m_up1.2.trans_block.ln2.weight
 | -0.006 | -0.183 |  0.216 |  0.080 | torch.Size([32]) || m_up1.2.trans_block.ln2.bias
 |  0.001 | -0.555 |  0.426 |  0.079 | torch.Size([128, 32]) || m_up1.2.trans_block.mlp.0.weight
 | -0.005 | -0.214 |  0.099 |  0.051 | torch.Size([128]) || m_up1.2.trans_block.mlp.0.bias
 | -0.002 | -0.341 |  0.369 |  0.082 | torch.Size([32, 128]) || m_up1.2.trans_block.mlp.2.weight
 |  0.001 | -0.104 |  0.243 |  0.063 | torch.Size([32]) || m_up1.2.trans_block.mlp.2.bias
 | -0.002 | -0.810 |  0.495 |  0.110 | torch.Size([96, 96, 1, 1]) || m_up1.2.conv1_1.weight
 | -0.002 | -0.224 |  0.384 |  0.061 | torch.Size([96]) || m_up1.2.conv1_1.bias
 |  0.087 | -0.065 |  0.340 |  0.220 | torch.Size([1, 1, 1, 1, 3]) || m_up1.2.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_up1.2.conv3d.bias
 |  0.002 | -0.369 |  0.581 |  0.081 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.0.weight
 | -0.000 | -0.593 |  0.785 |  0.098 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.2.weight
 |  1.913 | -0.760 |  2.773 |  0.775 | torch.Size([64, 16]) || m_up1.2.mamba_layers.0.mixer.A_log
 |  1.119 |  0.979 |  1.404 |  0.076 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.D
 |  0.001 | -0.536 |  0.540 |  0.125 | torch.Size([128, 32]) || m_up1.2.mamba_layers.0.mixer.in_proj.weight
 | -0.003 | -0.375 |  0.450 |  0.166 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.0.mixer.conv1d.weight
 |  0.006 | -0.089 |  0.134 |  0.050 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.530 |  0.349 |  0.102 | torch.Size([34, 64]) || m_up1.2.mamba_layers.0.mixer.x_proj.weight
 | -0.001 | -0.097 |  0.143 |  0.040 | torch.Size([64, 2]) || m_up1.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.028 | -0.382 |  0.654 |  0.188 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.361 |  0.396 |  0.112 | torch.Size([32, 64]) || m_up1.2.mamba_layers.0.mixer.out_proj.weight
 |  1.258 |  0.859 |  1.450 |  0.124 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.weight
 |  0.016 | -0.245 |  0.314 |  0.114 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.bias
 |  1.913 | -0.550 |  2.784 |  0.778 | torch.Size([64, 16]) || m_up1.2.mamba_layers.1.mixer.A_log
 |  1.193 |  0.973 |  1.463 |  0.105 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.D
 |  0.001 | -0.625 |  0.624 |  0.141 | torch.Size([128, 32]) || m_up1.2.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.604 |  0.675 |  0.188 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.1.mixer.conv1d.weight
 |  0.017 | -0.247 |  0.221 |  0.104 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.conv1d.bias
 |  0.001 | -0.534 |  0.588 |  0.122 | torch.Size([34, 64]) || m_up1.2.mamba_layers.1.mixer.x_proj.weight
 | -0.047 | -0.481 |  0.253 |  0.157 | torch.Size([64, 2]) || m_up1.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.042 | -0.450 |  0.552 |  0.160 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.dt_proj.bias
 | -0.002 | -0.741 |  0.564 |  0.147 | torch.Size([32, 64]) || m_up1.2.mamba_layers.1.mixer.out_proj.weight
 |  1.230 |  0.924 |  1.407 |  0.114 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.weight
 |  0.007 | -0.129 |  0.113 |  0.053 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.bias
 |  1.917 | -0.073 |  2.777 |  0.765 | torch.Size([64, 16]) || m_up1.2.mamba_layers.2.mixer.A_log
 |  1.014 |  0.942 |  1.177 |  0.046 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.D
 |  0.000 | -0.354 |  0.313 |  0.109 | torch.Size([128, 32]) || m_up1.2.mamba_layers.2.mixer.in_proj.weight
 | -0.022 | -0.644 |  0.593 |  0.282 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.2.mixer.conv1d.weight
 |  0.009 | -0.532 |  0.528 |  0.322 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.259 |  0.238 |  0.077 | torch.Size([34, 64]) || m_up1.2.mamba_layers.2.mixer.x_proj.weight
 |  0.070 | -0.709 |  0.670 |  0.392 | torch.Size([64, 2]) || m_up1.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.716 | -6.819 | -2.342 |  1.385 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.330 |  0.288 |  0.089 | torch.Size([32, 64]) || m_up1.2.mamba_layers.2.mixer.out_proj.weight
 |  1.014 |  0.901 |  1.119 |  0.055 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.weight
 |  0.001 | -0.064 |  0.048 |  0.027 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.bias
 |  1.916 | -0.067 |  2.776 |  0.766 | torch.Size([64, 16]) || m_up1.2.mamba_layers.3.mixer.A_log
 |  1.007 |  0.930 |  1.134 |  0.040 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.D
 | -0.001 | -0.371 |  0.439 |  0.110 | torch.Size([128, 32]) || m_up1.2.mamba_layers.3.mixer.in_proj.weight
 |  0.013 | -0.700 |  0.568 |  0.296 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.3.mixer.conv1d.weight
 |  0.083 | -0.446 |  0.560 |  0.281 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.conv1d.bias
 | -0.004 | -0.239 |  0.259 |  0.078 | torch.Size([34, 64]) || m_up1.2.mamba_layers.3.mixer.x_proj.weight
 | -0.115 | -0.707 |  0.686 |  0.390 | torch.Size([64, 2]) || m_up1.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.758 | -6.876 | -2.275 |  1.309 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.002 | -0.407 |  0.269 |  0.089 | torch.Size([32, 64]) || m_up1.2.mamba_layers.3.mixer.out_proj.weight
 |  1.019 |  0.958 |  1.209 |  0.053 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.weight
 | -0.001 | -0.052 |  0.062 |  0.022 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.bias
 |  0.665 |  0.456 |  0.874 |  0.296 | torch.Size([2]) || m_up1.2.pcbam_module.h_cw.weight
 |  0.135 |  0.075 |  0.176 |  0.053 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.h_cw.conv.weight
 |  0.182 |  0.079 |  0.285 |  0.145 | torch.Size([2]) || m_up1.2.pcbam_module.w_hc.weight
 | -0.024 | -0.155 |  0.201 |  0.196 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.w_hc.conv.weight
 |  0.235 |  0.094 |  0.376 |  0.200 | torch.Size([2]) || m_up1.2.pcbam_module.c_hw.weight
 |  0.073 | -0.039 |  0.152 |  0.100 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.c_hw.conv.weight
 |  0.000 | -0.071 |  0.069 |  0.014 | torch.Size([3, 96, 3, 3]) || m_tail.0.weight
 | -0.027 | -0.131 |  0.147 |  0.084 | torch.Size([3, 3, 1, 1]) || fft.mag.weight
 |  0.178 | -0.197 |  0.457 |  0.338 | torch.Size([3]) || fft.mag.bias
 |  0.163 |  0.030 |  0.320 |  0.147 | torch.Size([3]) || fft.mag_bn.weight
 | -0.814 | -2.189 | -0.114 |  1.191 | torch.Size([3]) || fft.mag_bn.bias
 | -1.441 | -5.003 |  2.895 |  4.005 | torch.Size([3]) || fft.mag_bn.running_mean
 | 283.145 | 158.846 | 518.032 | 203.534 | torch.Size([3]) || fft.mag_bn.running_var
 |  0.010 | -0.301 |  0.165 |  0.157 | torch.Size([3, 3, 1, 1]) || fft.pha.0.weight
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.0.bias
 |  1.179 |  0.836 |  1.435 |  0.309 | torch.Size([3]) || fft.pha.1.weight
 |  0.326 |  0.206 |  0.398 |  0.105 | torch.Size([3]) || fft.pha.1.bias
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.1.running_mean
 |  0.026 |  0.017 |  0.039 |  0.012 | torch.Size([3]) || fft.pha.1.running_var
 | -0.087 | -0.664 |  0.872 |  0.497 | torch.Size([3, 3, 1, 1]) || fft.pha.3.weight
 |  0.010 | -0.147 |  0.141 |  0.145 | torch.Size([3]) || fft.pha.3.bias
 |  0.323 | -0.158 |  2.090 |  0.868 | torch.Size([1, 6, 1, 1]) || fft.conv1.weight
 |  0.030 |  0.030 |  0.030 |    nan | torch.Size([1]) || fft.conv1.bias
 | -0.001 | -0.085 |  0.073 |  0.023 | torch.Size([96, 96, 1, 1]) || conv1.weight
 | -0.000 | -0.016 |  0.021 |  0.005 | torch.Size([96]) || conv1.bias
 |  0.398 |  0.002 |  0.888 |  0.227 | torch.Size([96]) || bn1.weight
 | -0.095 | -0.205 | -0.011 |  0.044 | torch.Size([96]) || bn1.bias
 | -0.004 | -0.044 |  0.059 |  0.028 | torch.Size([96]) || bn1.running_mean
 |  0.002 |  0.000 |  0.007 |  0.001 | torch.Size([96]) || bn1.running_var
 | -0.002 | -0.065 |  0.059 |  0.014 | torch.Size([192, 96, 2, 2]) || conv2.weight
 | -0.000 | -0.011 |  0.012 |  0.004 | torch.Size([192]) || conv2.bias
 |  0.407 |  0.016 |  0.895 |  0.228 | torch.Size([192]) || bn2.weight
 | -0.081 | -0.209 | -0.010 |  0.039 | torch.Size([192]) || bn2.bias
 | -0.026 | -0.123 |  0.096 |  0.050 | torch.Size([192]) || bn2.running_mean
 |  0.025 |  0.000 |  0.079 |  0.015 | torch.Size([192]) || bn2.running_var
 | -0.001 | -0.044 |  0.041 |  0.007 | torch.Size([384, 96, 4, 4]) || conv3.weight
 | -0.000 | -0.022 |  0.014 |  0.005 | torch.Size([384]) || conv3.bias
 |  0.435 |  0.045 |  0.918 |  0.222 | torch.Size([384]) || bn3.weight
 | -0.069 | -0.200 |  0.024 |  0.035 | torch.Size([384]) || bn3.bias
 | -0.066 | -0.197 |  0.165 |  0.045 | torch.Size([384]) || bn3.running_mean
 |  0.065 |  0.003 |  0.240 |  0.033 | torch.Size([384]) || bn3.running_var

25-05-15 10:06:19.043 : <epoch: 12, iter:   5,000, lr:1.000e-05> G_loss: 2.849e-06 
25-05-15 10:06:19.045 : Saving the model.
25-05-15 10:06:20.579 : ---1-->      0.png | 33.84dB
25-05-15 10:06:21.346 : ---2-->      1.png | 35.54dB
25-05-15 10:06:22.102 : ---3-->     10.png | 33.52dB
25-05-15 10:06:22.869 : ---4-->    100.png | 35.18dB
25-05-15 10:06:23.631 : ---5-->     11.png | 34.40dB
25-05-15 10:06:21.895 : ---6-->     12.png | 33.93dB
25-05-15 10:06:22.660 : ---7-->     13.png | 34.97dB
25-05-15 10:06:23.425 : ---8-->     14.png | 34.11dB
25-05-15 10:06:24.188 : ---9-->     15.png | 34.41dB
25-05-15 10:06:24.960 : --10-->     16.png | 34.66dB
25-05-15 10:06:25.744 : --11-->     17.png | 34.95dB
25-05-15 10:06:26.512 : --12-->     18.png | 34.09dB
25-05-15 10:06:27.297 : --13-->     19.png | 33.55dB
25-05-15 10:06:28.062 : --14-->      2.png | 34.70dB
25-05-15 10:06:28.822 : --15-->     20.png | 33.81dB
25-05-15 10:06:29.599 : --16-->     21.png | 34.44dB
25-05-15 10:06:30.364 : --17-->     22.png | 34.86dB
25-05-15 10:06:31.147 : --18-->     23.png | 35.03dB
25-05-15 10:06:31.914 : --19-->     24.png | 34.85dB
25-05-15 10:06:32.663 : --20-->     25.png | 33.61dB
25-05-15 10:06:33.435 : --21-->     26.png | 34.11dB
25-05-15 10:06:34.193 : --22-->     27.png | 33.93dB
25-05-15 10:06:34.963 : --23-->     28.png | 33.62dB
25-05-15 10:06:35.744 : --24-->     29.png | 34.36dB
25-05-15 10:06:36.519 : --25-->      3.png | 34.85dB
25-05-15 10:06:37.288 : --26-->     30.png | 34.90dB
25-05-15 10:06:38.059 : --27-->     31.png | 35.73dB
25-05-15 10:06:38.823 : --28-->     32.png | 34.26dB
25-05-15 10:06:39.591 : --29-->     33.png | 34.68dB
25-05-15 10:06:40.363 : --30-->     34.png | 34.31dB
25-05-15 10:06:41.139 : --31-->     35.png | 34.75dB
25-05-15 10:06:41.907 : --32-->     36.png | 34.05dB
25-05-15 10:06:42.671 : --33-->     37.png | 34.41dB
25-05-15 10:06:43.439 : --34-->     38.png | 34.17dB
25-05-15 10:06:44.207 : --35-->     39.png | 35.33dB
25-05-15 10:06:44.975 : --36-->      4.png | 34.72dB
25-05-15 10:06:45.743 : --37-->     40.png | 34.99dB
25-05-15 10:06:46.510 : --38-->     41.png | 34.75dB
25-05-15 10:06:47.279 : --39-->     42.png | 34.66dB
25-05-15 10:06:48.066 : --40-->     43.png | 35.36dB
25-05-15 10:06:48.837 : --41-->     44.png | 34.75dB
25-05-15 10:06:49.599 : --42-->     45.png | 34.39dB
25-05-15 10:06:50.373 : --43-->     46.png | 34.21dB
25-05-15 10:06:51.144 : --44-->     47.png | 33.94dB
25-05-15 10:06:51.903 : --45-->     48.png | 34.90dB
25-05-15 10:06:52.661 : --46-->     49.png | 35.33dB
25-05-15 10:06:53.430 : --47-->      5.png | 34.27dB
25-05-15 10:06:51.697 : --48-->     50.png | 35.18dB
25-05-15 10:06:52.460 : --49-->     51.png | 33.40dB
25-05-15 10:06:53.224 : --50-->     52.png | 34.76dB
25-05-15 10:06:53.982 : --51-->     53.png | 35.29dB
25-05-15 10:06:54.747 : --52-->     54.png | 37.59dB
25-05-15 10:06:55.516 : --53-->     55.png | 37.04dB
25-05-15 10:06:56.287 : --54-->     56.png | 37.84dB
25-05-15 10:06:57.054 : --55-->     57.png | 37.65dB
25-05-15 10:06:57.814 : --56-->     58.png | 37.72dB
25-05-15 10:06:58.582 : --57-->     59.png | 37.29dB
25-05-15 10:06:59.362 : --58-->      6.png | 35.50dB
25-05-15 10:07:00.132 : --59-->     60.png | 37.07dB
25-05-15 10:07:00.892 : --60-->     61.png | 37.58dB
25-05-15 10:07:01.658 : --61-->     62.png | 37.08dB
25-05-15 10:07:02.424 : --62-->     63.png | 36.62dB
25-05-15 10:07:03.182 : --63-->     64.png | 36.60dB
25-05-15 10:07:03.952 : --64-->     65.png | 36.84dB
25-05-15 10:07:04.730 : --65-->     66.png | 37.66dB
25-05-15 10:07:05.488 : --66-->     67.png | 37.47dB
25-05-15 10:07:06.244 : --67-->     68.png | 37.39dB
25-05-15 10:07:07.015 : --68-->     69.png | 37.79dB
25-05-15 10:07:07.771 : --69-->      7.png | 34.59dB
25-05-15 10:07:08.537 : --70-->     70.png | 36.96dB
25-05-15 10:07:09.302 : --71-->     71.png | 35.50dB
25-05-15 10:07:10.071 : --72-->     72.png | 36.74dB
25-05-15 10:07:10.844 : --73-->     73.png | 35.36dB
25-05-15 10:07:11.606 : --74-->     74.png | 35.82dB
25-05-15 10:07:12.367 : --75-->     75.png | 36.59dB
25-05-15 10:07:13.146 : --76-->     76.png | 37.18dB
25-05-15 10:07:13.909 : --77-->     77.png | 37.18dB
25-05-15 10:07:14.671 : --78-->     78.png | 36.85dB
25-05-15 10:07:15.431 : --79-->     79.png | 35.77dB
25-05-15 10:07:16.194 : --80-->      8.png | 34.56dB
25-05-15 10:07:16.946 : --81-->     80.png | 35.23dB
25-05-15 10:07:17.707 : --82-->     81.png | 36.42dB
25-05-15 10:07:18.463 : --83-->     82.png | 36.31dB
25-05-15 10:07:19.234 : --84-->     83.png | 35.94dB
25-05-15 10:07:20.005 : --85-->     84.png | 34.93dB
25-05-15 10:07:20.779 : --86-->     85.png | 36.14dB
25-05-15 10:07:21.557 : --87-->     86.png | 36.85dB
25-05-15 10:07:22.326 : --88-->     87.png | 37.27dB
25-05-15 10:07:23.103 : --89-->     88.png | 34.61dB
25-05-15 10:07:23.881 : --90-->     89.png | 36.03dB
25-05-15 10:07:22.156 : --91-->      9.png | 33.99dB
25-05-15 10:07:22.932 : --92-->     90.png | 37.26dB
25-05-15 10:07:23.709 : --93-->     91.png | 35.74dB
25-05-15 10:07:24.479 : --94-->     92.png | 35.72dB
25-05-15 10:07:25.249 : --95-->     93.png | 35.96dB
25-05-15 10:07:26.014 : --96-->     94.png | 36.83dB
25-05-15 10:07:26.772 : --97-->     95.png | 35.61dB
25-05-15 10:07:27.541 : --98-->     96.png | 36.51dB
25-05-15 10:07:28.296 : --99-->     97.png | 36.39dB
25-05-15 10:07:29.057 : -100-->     98.png | 35.98dB
25-05-15 10:07:29.832 : -101-->     99.png | 36.50dB
25-05-15 10:07:29.847 : <epoch: 12, iter:   5,000, Average PSNR : 35.47dB

25-05-15 10:52:31.009 : <epoch: 25, iter:  10,000, lr:1.000e-05> G_loss: 6.538e-06 
25-05-15 10:52:31.011 : Saving the model.
25-05-15 10:52:32.566 : ---1-->      0.png | 33.89dB
25-05-15 10:52:33.362 : ---2-->      1.png | 35.59dB
25-05-15 10:52:34.154 : ---3-->     10.png | 33.57dB
25-05-15 10:52:34.943 : ---4-->    100.png | 35.23dB
25-05-15 10:52:35.723 : ---5-->     11.png | 34.44dB
25-05-15 10:52:36.505 : ---6-->     12.png | 33.97dB
25-05-15 10:52:37.298 : ---7-->     13.png | 35.02dB
25-05-15 10:52:38.070 : ---8-->     14.png | 34.17dB
25-05-15 10:52:38.837 : ---9-->     15.png | 34.44dB
25-05-15 10:52:39.614 : --10-->     16.png | 34.70dB
25-05-15 10:52:40.382 : --11-->     17.png | 34.99dB
25-05-15 10:52:41.152 : --12-->     18.png | 34.14dB
25-05-15 10:52:41.931 : --13-->     19.png | 33.62dB
25-05-15 10:52:42.714 : --14-->      2.png | 34.74dB
25-05-15 10:52:43.491 : --15-->     20.png | 33.87dB
25-05-15 10:52:44.275 : --16-->     21.png | 34.47dB
25-05-15 10:52:45.069 : --17-->     22.png | 34.90dB
25-05-15 10:52:45.854 : --18-->     23.png | 35.07dB
25-05-15 10:52:46.640 : --19-->     24.png | 34.89dB
25-05-15 10:52:47.414 : --20-->     25.png | 33.65dB
25-05-15 10:52:48.186 : --21-->     26.png | 34.15dB
25-05-15 10:52:48.975 : --22-->     27.png | 33.98dB
25-05-15 10:52:49.768 : --23-->     28.png | 33.67dB
25-05-15 10:52:50.556 : --24-->     29.png | 34.40dB
25-05-15 10:52:51.335 : --25-->      3.png | 34.89dB
25-05-15 10:52:52.113 : --26-->     30.png | 34.94dB
25-05-15 10:52:52.913 : --27-->     31.png | 35.78dB
25-05-15 10:52:53.689 : --28-->     32.png | 34.30dB
25-05-15 10:52:51.966 : --29-->     33.png | 34.72dB
25-05-15 10:52:52.750 : --30-->     34.png | 34.35dB
25-05-15 10:52:53.523 : --31-->     35.png | 34.79dB
25-05-15 10:52:54.301 : --32-->     36.png | 34.08dB
25-05-15 10:52:55.081 : --33-->     37.png | 34.44dB
25-05-15 10:52:55.860 : --34-->     38.png | 34.22dB
25-05-15 10:52:56.649 : --35-->     39.png | 35.38dB
25-05-15 10:52:57.432 : --36-->      4.png | 34.77dB
25-05-15 10:52:58.207 : --37-->     40.png | 35.04dB
25-05-15 10:52:58.978 : --38-->     41.png | 34.78dB
25-05-15 10:52:59.777 : --39-->     42.png | 34.71dB
25-05-15 10:53:00.558 : --40-->     43.png | 35.43dB
25-05-15 10:53:01.334 : --41-->     44.png | 34.81dB
25-05-15 10:53:02.105 : --42-->     45.png | 34.42dB
25-05-15 10:53:02.873 : --43-->     46.png | 34.24dB
25-05-15 10:53:03.655 : --44-->     47.png | 34.00dB
25-05-15 10:53:04.429 : --45-->     48.png | 34.93dB
25-05-15 10:53:05.206 : --46-->     49.png | 35.38dB
25-05-15 10:53:05.979 : --47-->      5.png | 34.32dB
25-05-15 10:53:06.749 : --48-->     50.png | 35.21dB
25-05-15 10:53:07.513 : --49-->     51.png | 33.44dB
25-05-15 10:53:08.274 : --50-->     52.png | 34.80dB
25-05-15 10:53:09.040 : --51-->     53.png | 35.35dB
25-05-15 10:53:09.811 : --52-->     54.png | 37.66dB
25-05-15 10:53:10.588 : --53-->     55.png | 37.11dB
25-05-15 10:53:11.365 : --54-->     56.png | 37.90dB
25-05-15 10:53:12.136 : --55-->     57.png | 37.73dB
25-05-15 10:53:12.911 : --56-->     58.png | 37.79dB
25-05-15 10:53:13.685 : --57-->     59.png | 37.35dB
25-05-15 10:53:14.465 : --58-->      6.png | 35.54dB
25-05-15 10:53:15.255 : --59-->     60.png | 37.14dB
25-05-15 10:53:16.038 : --60-->     61.png | 37.64dB
25-05-15 10:53:16.816 : --61-->     62.png | 37.13dB
25-05-15 10:53:17.592 : --62-->     63.png | 36.66dB
25-05-15 10:53:18.355 : --63-->     64.png | 36.66dB
25-05-15 10:53:19.132 : --64-->     65.png | 36.90dB
25-05-15 10:53:19.896 : --65-->     66.png | 37.72dB
25-05-15 10:53:20.670 : --66-->     67.png | 37.53dB
25-05-15 10:53:21.448 : --67-->     68.png | 37.45dB
25-05-15 10:53:22.219 : --68-->     69.png | 37.85dB
25-05-15 10:53:22.987 : --69-->      7.png | 34.63dB
25-05-15 10:53:21.305 : --70-->     70.png | 37.02dB
25-05-15 10:53:22.077 : --71-->     71.png | 35.55dB
25-05-15 10:53:22.843 : --72-->     72.png | 36.80dB
25-05-15 10:53:23.611 : --73-->     73.png | 35.41dB
25-05-15 10:53:24.391 : --74-->     74.png | 35.87dB
25-05-15 10:53:25.168 : --75-->     75.png | 36.66dB
25-05-15 10:53:25.943 : --76-->     76.png | 37.25dB
25-05-15 10:53:26.713 : --77-->     77.png | 37.25dB
25-05-15 10:53:27.490 : --78-->     78.png | 36.91dB
25-05-15 10:53:28.254 : --79-->     79.png | 35.82dB
25-05-15 10:53:29.030 : --80-->      8.png | 34.60dB
25-05-15 10:53:29.809 : --81-->     80.png | 35.27dB
25-05-15 10:53:30.581 : --82-->     81.png | 36.47dB
25-05-15 10:53:31.352 : --83-->     82.png | 36.36dB
25-05-15 10:53:32.121 : --84-->     83.png | 35.99dB
25-05-15 10:53:32.880 : --85-->     84.png | 34.98dB
25-05-15 10:53:33.653 : --86-->     85.png | 36.20dB
25-05-15 10:53:34.429 : --87-->     86.png | 36.91dB
25-05-15 10:53:35.210 : --88-->     87.png | 37.33dB
25-05-15 10:53:35.981 : --89-->     88.png | 34.65dB
25-05-15 10:53:36.747 : --90-->     89.png | 36.08dB
25-05-15 10:53:37.519 : --91-->      9.png | 34.03dB
25-05-15 10:53:38.282 : --92-->     90.png | 37.32dB
25-05-15 10:53:39.061 : --93-->     91.png | 35.81dB
25-05-15 10:53:39.835 : --94-->     92.png | 35.78dB
25-05-15 10:53:40.616 : --95-->     93.png | 36.01dB
25-05-15 10:53:41.390 : --96-->     94.png | 36.90dB
25-05-15 10:53:42.154 : --97-->     95.png | 35.66dB
25-05-15 10:53:42.917 : --98-->     96.png | 36.58dB
25-05-15 10:53:43.678 : --99-->     97.png | 36.45dB
25-05-15 10:53:44.442 : -100-->     98.png | 36.03dB
25-05-15 10:53:45.209 : -101-->     99.png | 36.55dB
25-05-15 10:53:45.222 : <epoch: 25, iter:  10,000, Average PSNR : 35.52dB

25-05-15 11:06:45.858 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/2_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/RICE1
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/RICE100
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-15 11:06:45.858 : Random seed: 4078
25-05-15 11:06:45.877 : Number of train images: 385, iters: 385
25-05-15 11:06:48.286 : 
Networks name: DRNet
Params number: 18333721
Net structure:
DRNet(
  (m_head): Sequential(
    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (m_down1): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down2): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down3): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_body): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up3): Sequential(
    (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up2): Sequential(
    (0): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up1): Sequential(
    (0): ConvTranspose2d(192, 96, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_tail): Sequential(
    (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (fft): ResBlock_fft_bench(
    (mag): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
    (mag_bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (mag_relu): ReLU(inplace=True)
    (pha): Sequential(
      (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (4): Sigmoid()
    )
    (conv1): Conv2d(6, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
  (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (conv2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
  (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu2): ReLU()
  (conv3): Conv2d(96, 384, kernel_size=(4, 4), stride=(4, 4))
  (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu3): ReLU()
)

25-05-15 11:06:49.002 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.001 | -0.152 |  0.163 |  0.036 | torch.Size([96, 3, 3, 3]) || m_head.0.weight
 |  0.991 |  0.631 |  1.335 |  0.166 | torch.Size([32]) || m_down1.0.trans_block.ln1.weight
 | -0.031 | -0.324 |  0.326 |  0.146 | torch.Size([32]) || m_down1.0.trans_block.ln1.bias
 | -0.077 | -0.735 |  0.951 |  0.363 | torch.Size([1, 15, 15]) || m_down1.0.trans_block.msa.relative_position_params
 |  0.000 | -0.345 |  0.347 |  0.063 | torch.Size([96, 32, 1, 1]) || m_down1.0.trans_block.msa.embedding_layer1.weight
 |  0.000 | -0.121 |  0.118 |  0.051 | torch.Size([96]) || m_down1.0.trans_block.msa.embedding_layer1.bias
 |  0.003 | -0.194 |  0.251 |  0.057 | torch.Size([32, 32, 1, 1]) || m_down1.0.trans_block.msa.linear1.weight
 |  0.006 | -0.102 |  0.149 |  0.064 | torch.Size([32]) || m_down1.0.trans_block.msa.linear1.bias
 |  1.174 |  0.994 |  1.418 |  0.117 | torch.Size([32]) || m_down1.0.trans_block.ln2.weight
 | -0.011 | -0.187 |  0.173 |  0.068 | torch.Size([32]) || m_down1.0.trans_block.ln2.bias
 |  0.005 | -0.603 |  1.292 |  0.116 | torch.Size([128, 32]) || m_down1.0.trans_block.mlp.0.weight
 | -0.024 | -0.185 |  0.151 |  0.071 | torch.Size([128]) || m_down1.0.trans_block.mlp.0.bias
 |  0.000 | -0.439 |  0.677 |  0.089 | torch.Size([32, 128]) || m_down1.0.trans_block.mlp.2.weight
 | -0.004 | -0.129 |  0.323 |  0.101 | torch.Size([32]) || m_down1.0.trans_block.mlp.2.bias
 |  0.008 | -0.474 |  0.545 |  0.098 | torch.Size([96, 96, 1, 1]) || m_down1.0.conv1_1.weight
 | -0.003 | -0.481 |  0.437 |  0.122 | torch.Size([96]) || m_down1.0.conv1_1.bias
 | -0.086 | -0.171 |  0.002 |  0.087 | torch.Size([1, 1, 1, 1, 3]) || m_down1.0.conv3d.weight
 | -0.035 | -0.035 | -0.035 |    nan | torch.Size([1]) || m_down1.0.conv3d.bias
 |  0.007 | -0.331 |  0.514 |  0.077 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.0.weight
 | -0.005 | -0.501 |  0.372 |  0.078 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.2.weight
 |  1.905 | -2.585 |  2.825 |  0.818 | torch.Size([64, 16]) || m_down1.0.mamba_layers.0.mixer.A_log
 |  1.077 |  0.283 |  1.380 |  0.191 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.D
 | -0.000 | -0.484 |  0.556 |  0.124 | torch.Size([128, 32]) || m_down1.0.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.472 |  0.544 |  0.176 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.0.mixer.conv1d.weight
 | -0.012 | -0.212 |  0.199 |  0.096 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.993 |  0.729 |  0.128 | torch.Size([34, 64]) || m_down1.0.mamba_layers.0.mixer.x_proj.weight
 |  0.008 | -0.813 |  0.944 |  0.261 | torch.Size([64, 2]) || m_down1.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.094 | -1.924 |  0.445 |  0.419 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.686 |  0.576 |  0.120 | torch.Size([32, 64]) || m_down1.0.mamba_layers.0.mixer.out_proj.weight
 |  1.126 |  0.924 |  1.638 |  0.127 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.weight
 |  0.016 | -0.386 |  0.330 |  0.173 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.bias
 |  1.904 | -0.837 |  2.773 |  0.797 | torch.Size([64, 16]) || m_down1.0.mamba_layers.1.mixer.A_log
 |  1.159 |  0.864 |  1.356 |  0.090 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.D
 |  0.001 | -0.595 |  0.467 |  0.132 | torch.Size([128, 32]) || m_down1.0.mamba_layers.1.mixer.in_proj.weight
 |  0.018 | -0.393 |  0.510 |  0.169 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.1.mixer.conv1d.weight
 | -0.004 | -0.303 |  0.272 |  0.169 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.573 |  0.727 |  0.127 | torch.Size([34, 64]) || m_down1.0.mamba_layers.1.mixer.x_proj.weight
 |  0.027 | -0.270 |  0.631 |  0.161 | torch.Size([64, 2]) || m_down1.0.mamba_layers.1.mixer.dt_proj.weight
 |  0.043 | -0.459 |  0.278 |  0.148 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.003 | -0.368 |  0.444 |  0.123 | torch.Size([32, 64]) || m_down1.0.mamba_layers.1.mixer.out_proj.weight
 |  1.181 |  1.000 |  1.340 |  0.097 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.weight
 | -0.006 | -0.271 |  0.352 |  0.140 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.bias
 |  1.917 | -0.091 |  2.775 |  0.765 | torch.Size([64, 16]) || m_down1.0.mamba_layers.2.mixer.A_log
 |  1.027 |  0.921 |  1.150 |  0.050 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.D
 |  0.000 | -0.350 |  0.380 |  0.112 | torch.Size([128, 32]) || m_down1.0.mamba_layers.2.mixer.in_proj.weight
 | -0.010 | -0.584 |  0.581 |  0.299 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.2.mixer.conv1d.weight
 | -0.029 | -0.492 |  0.498 |  0.288 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.233 |  0.199 |  0.077 | torch.Size([34, 64]) || m_down1.0.mamba_layers.2.mixer.x_proj.weight
 | -0.054 | -0.706 |  0.718 |  0.417 | torch.Size([64, 2]) || m_down1.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.713 | -6.851 | -2.301 |  1.285 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.dt_proj.bias
 | -0.003 | -0.282 |  0.306 |  0.091 | torch.Size([32, 64]) || m_down1.0.mamba_layers.2.mixer.out_proj.weight
 |  1.014 |  0.897 |  1.120 |  0.047 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.weight
 |  0.009 | -0.075 |  0.095 |  0.035 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.bias
 |  1.916 | -0.620 |  2.776 |  0.767 | torch.Size([64, 16]) || m_down1.0.mamba_layers.3.mixer.A_log
 |  1.012 |  0.832 |  1.124 |  0.049 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.D
 |  0.003 | -0.329 |  0.318 |  0.110 | torch.Size([128, 32]) || m_down1.0.mamba_layers.3.mixer.in_proj.weight
 |  0.005 | -0.632 |  0.556 |  0.302 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.3.mixer.conv1d.weight
 | -0.072 | -0.636 |  0.560 |  0.312 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.conv1d.bias
 |  0.003 | -0.262 |  0.236 |  0.080 | torch.Size([34, 64]) || m_down1.0.mamba_layers.3.mixer.x_proj.weight
 |  0.046 | -0.689 |  0.818 |  0.430 | torch.Size([64, 2]) || m_down1.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.405 | -7.365 | -2.266 |  1.491 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.002 | -0.287 |  0.336 |  0.089 | torch.Size([32, 64]) || m_down1.0.mamba_layers.3.mixer.out_proj.weight
 |  1.008 |  0.941 |  1.068 |  0.030 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.weight
 | -0.004 | -0.067 |  0.041 |  0.029 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.bias
 |  0.165 |  0.068 |  0.262 |  0.137 | torch.Size([2]) || m_down1.0.pcbam_module.h_cw.weight
 |  0.006 | -0.135 |  0.158 |  0.147 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.h_cw.conv.weight
 |  0.566 |  0.283 |  0.848 |  0.399 | torch.Size([2]) || m_down1.0.pcbam_module.w_hc.weight
 |  0.078 | -0.112 |  0.281 |  0.197 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.w_hc.conv.weight
 |  0.654 |  0.642 |  0.666 |  0.017 | torch.Size([2]) || m_down1.0.pcbam_module.c_hw.weight
 |  0.088 | -0.283 |  0.573 |  0.439 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.c_hw.conv.weight
 |  1.035 |  0.678 |  1.291 |  0.161 | torch.Size([32]) || m_down1.1.trans_block.ln1.weight
 |  0.024 | -0.350 |  0.329 |  0.159 | torch.Size([32]) || m_down1.1.trans_block.ln1.bias
 | -0.211 | -0.771 |  0.660 |  0.304 | torch.Size([1, 15, 15]) || m_down1.1.trans_block.msa.relative_position_params
 |  0.001 | -0.393 |  0.357 |  0.089 | torch.Size([96, 32, 1, 1]) || m_down1.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.220 |  0.220 |  0.060 | torch.Size([96]) || m_down1.1.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.212 |  0.223 |  0.059 | torch.Size([32, 32, 1, 1]) || m_down1.1.trans_block.msa.linear1.weight
 | -0.000 | -0.193 |  0.107 |  0.060 | torch.Size([32]) || m_down1.1.trans_block.msa.linear1.bias
 |  1.155 |  0.950 |  1.292 |  0.082 | torch.Size([32]) || m_down1.1.trans_block.ln2.weight
 |  0.000 | -0.144 |  0.191 |  0.077 | torch.Size([32]) || m_down1.1.trans_block.ln2.bias
 | -0.001 | -0.877 |  0.579 |  0.118 | torch.Size([128, 32]) || m_down1.1.trans_block.mlp.0.weight
 | -0.012 | -0.228 |  0.121 |  0.056 | torch.Size([128]) || m_down1.1.trans_block.mlp.0.bias
 |  0.001 | -0.620 |  0.596 |  0.102 | torch.Size([32, 128]) || m_down1.1.trans_block.mlp.2.weight
 | -0.011 | -0.139 |  0.239 |  0.087 | torch.Size([32]) || m_down1.1.trans_block.mlp.2.bias
 |  0.008 | -0.462 |  0.604 |  0.102 | torch.Size([96, 96, 1, 1]) || m_down1.1.conv1_1.weight
 | -0.010 | -0.233 |  0.313 |  0.071 | torch.Size([96]) || m_down1.1.conv1_1.bias
 | -0.074 | -0.293 |  0.040 |  0.190 | torch.Size([1, 1, 1, 1, 3]) || m_down1.1.conv3d.weight
 | -0.013 | -0.013 | -0.013 |    nan | torch.Size([1]) || m_down1.1.conv3d.bias
 | -0.002 | -0.424 |  0.367 |  0.069 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.0.weight
 | -0.006 | -0.358 |  0.319 |  0.069 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.2.weight
 |  1.917 | -0.011 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.0.mixer.A_log
 |  1.048 |  0.985 |  1.153 |  0.046 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.D
 | -0.000 | -0.442 |  0.403 |  0.087 | torch.Size([128, 32]) || m_down1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.014 | -0.286 |  0.306 |  0.117 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.0.mixer.conv1d.weight
 |  0.016 | -0.214 |  0.208 |  0.066 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.147 |  0.137 |  0.031 | torch.Size([34, 64]) || m_down1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.002 | -0.062 |  0.053 |  0.025 | torch.Size([64, 2]) || m_down1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.001 | -0.024 |  0.032 |  0.009 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.384 |  0.374 |  0.085 | torch.Size([32, 64]) || m_down1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.112 |  0.919 |  1.273 |  0.111 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.weight
 |  0.011 | -0.159 |  0.186 |  0.078 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.bias
 |  1.918 | -0.213 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.1.mixer.A_log
 |  1.090 |  0.987 |  1.477 |  0.089 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.D
 |  0.000 | -0.615 |  0.611 |  0.095 | torch.Size([128, 32]) || m_down1.1.mamba_layers.1.mixer.in_proj.weight
 |  0.001 | -0.352 |  0.352 |  0.127 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.1.mixer.conv1d.weight
 |  0.002 | -0.198 |  0.188 |  0.087 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.001 | -0.185 |  0.294 |  0.048 | torch.Size([34, 64]) || m_down1.1.mamba_layers.1.mixer.x_proj.weight
 |  0.006 | -0.153 |  0.148 |  0.037 | torch.Size([64, 2]) || m_down1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.008 | -0.162 |  0.421 |  0.075 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.004 | -0.542 |  0.369 |  0.088 | torch.Size([32, 64]) || m_down1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.130 |  1.008 |  1.307 |  0.077 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.weight
 | -0.003 | -0.095 |  0.089 |  0.050 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.bias
 |  1.917 | -0.069 |  2.774 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.2.mixer.A_log
 |  1.003 |  0.957 |  1.065 |  0.025 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.D
 | -0.001 | -0.278 |  0.261 |  0.108 | torch.Size([128, 32]) || m_down1.1.mamba_layers.2.mixer.in_proj.weight
 | -0.022 | -0.528 |  0.519 |  0.287 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.2.mixer.conv1d.weight
 | -0.016 | -0.513 |  0.444 |  0.282 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.158 |  0.166 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.2.mixer.x_proj.weight
 |  0.093 | -0.700 |  0.704 |  0.395 | torch.Size([64, 2]) || m_down1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.419 | -6.864 | -2.343 |  1.240 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.002 | -0.260 |  0.283 |  0.079 | torch.Size([32, 64]) || m_down1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.004 |  0.954 |  1.061 |  0.029 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.weight
 |  0.002 | -0.051 |  0.039 |  0.020 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.bias
 |  1.917 | -0.107 |  2.777 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.3.mixer.A_log
 |  1.010 |  0.964 |  1.085 |  0.029 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.301 |  0.379 |  0.111 | torch.Size([128, 32]) || m_down1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.025 | -0.519 |  0.567 |  0.301 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.3.mixer.conv1d.weight
 |  0.051 | -0.419 |  0.532 |  0.244 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.187 |  0.199 |  0.074 | torch.Size([34, 64]) || m_down1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.019 | -0.694 |  0.700 |  0.380 | torch.Size([64, 2]) || m_down1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.587 | -6.932 | -2.266 |  1.352 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.002 | -0.244 |  0.288 |  0.082 | torch.Size([32, 64]) || m_down1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.032 |  0.962 |  1.135 |  0.046 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.weight
 | -0.001 | -0.050 |  0.070 |  0.034 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.bias
 |  0.136 |  0.116 |  0.156 |  0.028 | torch.Size([2]) || m_down1.1.pcbam_module.h_cw.weight
 |  0.145 |  0.040 |  0.346 |  0.173 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.h_cw.conv.weight
 |  0.354 |  0.183 |  0.526 |  0.242 | torch.Size([2]) || m_down1.1.pcbam_module.w_hc.weight
 |  0.172 |  0.029 |  0.255 |  0.124 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.w_hc.conv.weight
 |  0.727 |  0.587 |  0.868 |  0.198 | torch.Size([2]) || m_down1.1.pcbam_module.c_hw.weight
 | -0.064 | -0.314 |  0.199 |  0.257 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.347 |  0.294 |  0.051 | torch.Size([192, 96, 2, 2]) || m_down1.2.weight
 |  1.067 |  0.677 |  1.755 |  0.262 | torch.Size([64]) || m_down2.0.trans_block.ln1.weight
 | -0.006 | -0.523 |  0.543 |  0.241 | torch.Size([64]) || m_down2.0.trans_block.ln1.bias
 | -0.201 | -1.954 |  1.681 |  0.690 | torch.Size([2, 15, 15]) || m_down2.0.trans_block.msa.relative_position_params
 |  0.000 | -0.475 |  0.431 |  0.075 | torch.Size([192, 64, 1, 1]) || m_down2.0.trans_block.msa.embedding_layer1.weight
 | -0.006 | -0.228 |  0.207 |  0.053 | torch.Size([192]) || m_down2.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.305 |  0.277 |  0.056 | torch.Size([64, 64, 1, 1]) || m_down2.0.trans_block.msa.linear1.weight
 |  0.001 | -0.151 |  0.244 |  0.055 | torch.Size([64]) || m_down2.0.trans_block.msa.linear1.bias
 |  1.128 |  0.775 |  1.459 |  0.143 | torch.Size([64]) || m_down2.0.trans_block.ln2.weight
 |  0.008 | -0.157 |  0.296 |  0.078 | torch.Size([64]) || m_down2.0.trans_block.ln2.bias
 |  0.002 | -0.492 |  0.469 |  0.097 | torch.Size([256, 64]) || m_down2.0.trans_block.mlp.0.weight
 | -0.051 | -0.285 |  0.058 |  0.049 | torch.Size([256]) || m_down2.0.trans_block.mlp.0.bias
 |  0.001 | -0.390 |  0.375 |  0.075 | torch.Size([64, 256]) || m_down2.0.trans_block.mlp.2.weight
 |  0.021 | -0.114 |  0.116 |  0.050 | torch.Size([64]) || m_down2.0.trans_block.mlp.2.bias
 |  0.008 | -0.735 |  0.913 |  0.101 | torch.Size([192, 192, 1, 1]) || m_down2.0.conv1_1.weight
 |  0.003 | -0.664 |  0.743 |  0.132 | torch.Size([192]) || m_down2.0.conv1_1.bias
 | -0.077 | -0.236 |  0.011 |  0.138 | torch.Size([1, 1, 1, 1, 3]) || m_down2.0.conv3d.weight
 | -0.010 | -0.010 | -0.010 |    nan | torch.Size([1]) || m_down2.0.conv3d.bias
 |  0.001 | -0.398 |  0.436 |  0.062 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.0.weight
 | -0.000 | -0.294 |  0.391 |  0.064 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.0.mamba_layers.0.mixer.A_log
 |  1.009 |  0.981 |  1.140 |  0.023 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.D
 | -0.000 | -0.290 |  0.255 |  0.034 | torch.Size([256, 64]) || m_down2.0.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.274 |  0.328 |  0.066 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.141 |  0.097 |  0.028 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.062 |  0.058 |  0.018 | torch.Size([36, 128]) || m_down2.0.mamba_layers.0.mixer.x_proj.weight
 |  0.001 | -0.049 |  0.055 |  0.018 | torch.Size([128, 4]) || m_down2.0.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.001 |  0.002 |  0.000 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.259 |  0.250 |  0.035 | torch.Size([64, 128]) || m_down2.0.mamba_layers.0.mixer.out_proj.weight
 |  1.037 |  0.878 |  1.205 |  0.083 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.weight
 |  0.004 | -0.151 |  0.159 |  0.078 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.bias
 |  1.916 | -0.323 |  2.773 |  0.767 | torch.Size([128, 16]) || m_down2.0.mamba_layers.1.mixer.A_log
 |  1.033 |  0.993 |  1.274 |  0.054 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.D
 | -0.000 | -0.332 |  0.369 |  0.052 | torch.Size([256, 64]) || m_down2.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.346 |  0.481 |  0.097 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.1.mixer.conv1d.weight
 |  0.017 | -0.186 |  0.347 |  0.075 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.conv1d.bias
 | -0.001 | -0.252 |  0.175 |  0.035 | torch.Size([36, 128]) || m_down2.0.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.096 |  0.089 |  0.022 | torch.Size([128, 4]) || m_down2.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.011 | -0.311 |  0.165 |  0.055 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.363 |  0.353 |  0.053 | torch.Size([64, 128]) || m_down2.0.mamba_layers.1.mixer.out_proj.weight
 |  1.052 |  0.920 |  1.215 |  0.074 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.weight
 |  0.002 | -0.254 |  0.245 |  0.130 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.bias
 |  1.917 | -0.049 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.2.mixer.A_log
 |  0.988 |  0.939 |  1.094 |  0.024 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.D
 |  0.000 | -0.209 |  0.219 |  0.075 | torch.Size([256, 64]) || m_down2.0.mamba_layers.2.mixer.in_proj.weight
 | -0.003 | -0.523 |  0.520 |  0.277 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.2.mixer.conv1d.weight
 | -0.024 | -0.510 |  0.494 |  0.296 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.199 |  0.256 |  0.053 | torch.Size([36, 128]) || m_down2.0.mamba_layers.2.mixer.x_proj.weight
 |  0.014 | -0.499 |  0.506 |  0.292 | torch.Size([128, 4]) || m_down2.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.641 | -6.909 | -2.256 |  1.373 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.244 |  0.224 |  0.058 | torch.Size([64, 128]) || m_down2.0.mamba_layers.2.mixer.out_proj.weight
 |  0.979 |  0.879 |  1.054 |  0.038 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.weight
 |  0.002 | -0.111 |  0.080 |  0.039 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.bias
 |  1.917 | -0.032 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.3.mixer.A_log
 |  0.994 |  0.909 |  1.047 |  0.021 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.D
 |  0.001 | -0.213 |  0.209 |  0.075 | torch.Size([256, 64]) || m_down2.0.mamba_layers.3.mixer.in_proj.weight
 | -0.000 | -0.570 |  0.544 |  0.278 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.3.mixer.conv1d.weight
 |  0.010 | -0.486 |  0.493 |  0.292 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.248 |  0.267 |  0.054 | torch.Size([36, 128]) || m_down2.0.mamba_layers.3.mixer.x_proj.weight
 |  0.011 | -0.496 |  0.500 |  0.303 | torch.Size([128, 4]) || m_down2.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.466 | -6.855 | -2.278 |  1.292 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.dt_proj.bias
 |  0.000 | -0.220 |  0.277 |  0.059 | torch.Size([64, 128]) || m_down2.0.mamba_layers.3.mixer.out_proj.weight
 |  0.991 |  0.905 |  1.067 |  0.033 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.weight
 | -0.001 | -0.056 |  0.081 |  0.030 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.bias
 |  0.622 |  0.130 |  1.115 |  0.697 | torch.Size([2]) || m_down2.0.pcbam_module.h_cw.weight
 |  0.075 | -0.112 |  0.356 |  0.248 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.h_cw.conv.weight
 |  0.664 |  0.581 |  0.748 |  0.118 | torch.Size([2]) || m_down2.0.pcbam_module.w_hc.weight
 |  0.025 | -0.118 |  0.248 |  0.196 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.w_hc.conv.weight
 |  0.597 |  0.344 |  0.850 |  0.358 | torch.Size([2]) || m_down2.0.pcbam_module.c_hw.weight
 |  0.028 | -0.080 |  0.158 |  0.121 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.c_hw.conv.weight
 |  1.145 |  0.817 |  1.751 |  0.250 | torch.Size([64]) || m_down2.1.trans_block.ln1.weight
 |  0.012 | -0.438 |  0.519 |  0.187 | torch.Size([64]) || m_down2.1.trans_block.ln1.bias
 | -0.001 | -1.492 |  0.704 |  0.242 | torch.Size([2, 15, 15]) || m_down2.1.trans_block.msa.relative_position_params
 | -0.000 | -0.386 |  0.421 |  0.084 | torch.Size([192, 64, 1, 1]) || m_down2.1.trans_block.msa.embedding_layer1.weight
 | -0.003 | -0.313 |  0.255 |  0.070 | torch.Size([192]) || m_down2.1.trans_block.msa.embedding_layer1.bias
 |  0.001 | -0.206 |  0.203 |  0.051 | torch.Size([64, 64, 1, 1]) || m_down2.1.trans_block.msa.linear1.weight
 |  0.001 | -0.155 |  0.232 |  0.057 | torch.Size([64]) || m_down2.1.trans_block.msa.linear1.bias
 |  1.048 |  0.681 |  1.360 |  0.156 | torch.Size([64]) || m_down2.1.trans_block.ln2.weight
 |  0.005 | -0.210 |  0.274 |  0.108 | torch.Size([64]) || m_down2.1.trans_block.ln2.bias
 | -0.000 | -0.493 |  0.485 |  0.079 | torch.Size([256, 64]) || m_down2.1.trans_block.mlp.0.weight
 | -0.044 | -0.330 |  0.055 |  0.059 | torch.Size([256]) || m_down2.1.trans_block.mlp.0.bias
 | -0.000 | -0.429 |  0.468 |  0.056 | torch.Size([64, 256]) || m_down2.1.trans_block.mlp.2.weight
 |  0.001 | -0.075 |  0.068 |  0.034 | torch.Size([64]) || m_down2.1.trans_block.mlp.2.bias
 | -0.009 | -1.113 |  0.556 |  0.106 | torch.Size([192, 192, 1, 1]) || m_down2.1.conv1_1.weight
 |  0.001 | -0.424 |  0.388 |  0.096 | torch.Size([192]) || m_down2.1.conv1_1.bias
 |  0.087 | -0.018 |  0.282 |  0.169 | torch.Size([1, 1, 1, 1, 3]) || m_down2.1.conv3d.weight
 | -0.004 | -0.004 | -0.004 |    nan | torch.Size([1]) || m_down2.1.conv3d.bias
 | -0.003 | -0.378 |  0.307 |  0.062 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.0.weight
 |  0.001 | -0.303 |  0.321 |  0.061 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.2.weight
 |  1.917 | -0.007 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.0.mixer.A_log
 |  1.022 |  0.995 |  1.228 |  0.038 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.D
 |  0.000 | -0.267 |  0.259 |  0.039 | torch.Size([256, 64]) || m_down2.1.mamba_layers.0.mixer.in_proj.weight
 | -0.003 | -0.402 |  0.319 |  0.075 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.092 |  0.132 |  0.031 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.176 |  0.176 |  0.024 | torch.Size([36, 128]) || m_down2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.049 |  0.052 |  0.018 | torch.Size([128, 4]) || m_down2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.074 |  0.081 |  0.017 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.272 |  0.285 |  0.043 | torch.Size([64, 128]) || m_down2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.019 |  0.845 |  1.212 |  0.073 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.weight
 |  0.000 | -0.172 |  0.212 |  0.103 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.bias
 |  1.917 | -0.261 |  2.773 |  0.765 | torch.Size([128, 16]) || m_down2.1.mamba_layers.1.mixer.A_log
 |  1.038 |  0.996 |  1.252 |  0.065 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.D
 | -0.000 | -0.384 |  0.408 |  0.051 | torch.Size([256, 64]) || m_down2.1.mamba_layers.1.mixer.in_proj.weight
 |  0.005 | -0.298 |  0.373 |  0.094 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.009 | -0.172 |  0.274 |  0.049 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.271 |  0.272 |  0.037 | torch.Size([36, 128]) || m_down2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.263 |  0.259 |  0.030 | torch.Size([128, 4]) || m_down2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.001 | -0.311 |  0.161 |  0.045 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.390 |  0.367 |  0.052 | torch.Size([64, 128]) || m_down2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.050 |  0.941 |  1.370 |  0.090 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.weight
 | -0.007 | -0.230 |  0.210 |  0.132 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.026 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.2.mixer.A_log
 |  0.987 |  0.934 |  1.062 |  0.021 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.D
 | -0.001 | -0.220 |  0.208 |  0.076 | torch.Size([256, 64]) || m_down2.1.mamba_layers.2.mixer.in_proj.weight
 | -0.007 | -0.555 |  0.552 |  0.283 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.2.mixer.conv1d.weight
 |  0.015 | -0.492 |  0.499 |  0.268 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.185 |  0.194 |  0.054 | torch.Size([36, 128]) || m_down2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.021 | -0.500 |  0.499 |  0.284 | torch.Size([128, 4]) || m_down2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.836 | -6.905 | -2.271 |  1.398 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.180 |  0.182 |  0.056 | torch.Size([64, 128]) || m_down2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.980 |  0.882 |  1.066 |  0.037 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.weight
 |  0.002 | -0.085 |  0.088 |  0.036 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.037 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.3.mixer.A_log
 |  0.987 |  0.943 |  1.040 |  0.019 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.214 |  0.259 |  0.074 | torch.Size([256, 64]) || m_down2.1.mamba_layers.3.mixer.in_proj.weight
 |  0.001 | -0.528 |  0.524 |  0.280 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.3.mixer.conv1d.weight
 |  0.054 | -0.525 |  0.474 |  0.262 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.142 |  0.140 |  0.052 | torch.Size([36, 128]) || m_down2.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.500 |  0.499 |  0.290 | torch.Size([128, 4]) || m_down2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.409 | -6.903 | -2.272 |  1.291 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.202 |  0.190 |  0.055 | torch.Size([64, 128]) || m_down2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.975 |  0.903 |  1.040 |  0.031 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.weight
 |  0.001 | -0.073 |  0.075 |  0.031 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.bias
 |  0.846 |  0.687 |  1.004 |  0.225 | torch.Size([2]) || m_down2.1.pcbam_module.h_cw.weight
 |  0.083 | -0.063 |  0.209 |  0.137 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.h_cw.conv.weight
 |  0.675 |  0.557 |  0.793 |  0.167 | torch.Size([2]) || m_down2.1.pcbam_module.w_hc.weight
 |  0.020 | -0.250 |  0.249 |  0.252 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.w_hc.conv.weight
 |  0.884 |  0.730 |  1.038 |  0.218 | torch.Size([2]) || m_down2.1.pcbam_module.c_hw.weight
 | -0.039 | -0.237 |  0.271 |  0.272 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.c_hw.conv.weight
 | -0.001 | -0.289 |  0.460 |  0.043 | torch.Size([384, 192, 2, 2]) || m_down2.2.weight
 |  0.963 |  0.566 |  1.646 |  0.248 | torch.Size([128]) || m_down3.0.trans_block.ln1.weight
 |  0.004 | -0.647 |  0.636 |  0.258 | torch.Size([128]) || m_down3.0.trans_block.ln1.bias
 |  0.054 | -2.618 |  1.002 |  0.369 | torch.Size([4, 15, 15]) || m_down3.0.trans_block.msa.relative_position_params
 | -0.000 | -0.411 |  0.394 |  0.053 | torch.Size([384, 128, 1, 1]) || m_down3.0.trans_block.msa.embedding_layer1.weight
 |  0.007 | -0.224 |  0.307 |  0.064 | torch.Size([384]) || m_down3.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.200 |  0.194 |  0.046 | torch.Size([128, 128, 1, 1]) || m_down3.0.trans_block.msa.linear1.weight
 |  0.002 | -0.147 |  0.134 |  0.055 | torch.Size([128]) || m_down3.0.trans_block.msa.linear1.bias
 |  0.889 |  0.440 |  1.301 |  0.171 | torch.Size([128]) || m_down3.0.trans_block.ln2.weight
 |  0.000 | -0.354 |  0.391 |  0.123 | torch.Size([128]) || m_down3.0.trans_block.ln2.bias
 | -0.000 | -0.414 |  0.380 |  0.048 | torch.Size([512, 128]) || m_down3.0.trans_block.mlp.0.weight
 | -0.029 | -0.372 |  0.083 |  0.047 | torch.Size([512]) || m_down3.0.trans_block.mlp.0.bias
 | -0.000 | -0.397 |  0.452 |  0.040 | torch.Size([128, 512]) || m_down3.0.trans_block.mlp.2.weight
 |  0.002 | -0.138 |  0.227 |  0.063 | torch.Size([128]) || m_down3.0.trans_block.mlp.2.bias
 |  0.005 | -0.569 |  1.812 |  0.083 | torch.Size([384, 384, 1, 1]) || m_down3.0.conv1_1.weight
 | -0.004 | -0.916 |  0.692 |  0.148 | torch.Size([384]) || m_down3.0.conv1_1.bias
 | -0.093 | -0.284 |  0.006 |  0.166 | torch.Size([1, 1, 1, 1, 3]) || m_down3.0.conv3d.weight
 | -0.007 | -0.007 | -0.007 |    nan | torch.Size([1]) || m_down3.0.conv3d.bias
 |  0.001 | -0.413 |  0.320 |  0.047 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.0.weight
 | -0.000 | -0.223 |  0.286 |  0.042 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.0.mixer.A_log
 |  1.002 |  0.992 |  1.111 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.D
 | -0.000 | -0.106 |  0.119 |  0.012 | torch.Size([512, 128]) || m_down3.0.mamba_layers.0.mixer.in_proj.weight
 | -0.002 | -0.177 |  0.123 |  0.026 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.0.mixer.conv1d.weight
 | -0.002 | -0.124 |  0.164 |  0.041 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.051 |  0.050 |  0.012 | torch.Size([40, 256]) || m_down3.0.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.041 |  0.047 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.001 |  0.000 |  0.000 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.189 |  0.145 |  0.017 | torch.Size([128, 256]) || m_down3.0.mamba_layers.0.mixer.out_proj.weight
 |  0.999 |  0.983 |  1.031 |  0.009 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.weight
 |  0.001 | -0.025 |  0.024 |  0.012 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.bias
 |  1.917 | -0.005 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.1.mixer.A_log
 |  1.014 |  0.998 |  1.317 |  0.048 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.D
 |  0.000 | -0.333 |  0.289 |  0.020 | torch.Size([512, 128]) || m_down3.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.309 |  0.307 |  0.044 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.1.mixer.conv1d.weight
 | -0.003 | -0.253 |  0.239 |  0.056 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.115 |  0.119 |  0.013 | torch.Size([40, 256]) || m_down3.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.039 |  0.058 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.114 |  0.024 |  0.008 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.410 |  0.302 |  0.024 | torch.Size([128, 256]) || m_down3.0.mamba_layers.1.mixer.out_proj.weight
 |  0.946 |  0.846 |  1.183 |  0.055 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.weight
 |  0.012 | -0.154 |  0.161 |  0.099 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.bias
 |  1.917 | -0.002 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.2.mixer.A_log
 |  0.981 |  0.953 |  1.020 |  0.013 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.D
 |  0.000 | -0.154 |  0.168 |  0.052 | torch.Size([512, 128]) || m_down3.0.mamba_layers.2.mixer.in_proj.weight
 | -0.015 | -0.563 |  0.513 |  0.281 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.2.mixer.conv1d.weight
 |  0.032 | -0.517 |  0.489 |  0.275 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.137 |  0.119 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.2.mixer.x_proj.weight
 | -0.000 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.489 | -6.888 | -2.309 |  1.322 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.181 |  0.199 |  0.037 | torch.Size([128, 256]) || m_down3.0.mamba_layers.2.mixer.out_proj.weight
 |  0.960 |  0.897 |  1.054 |  0.025 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.weight
 |  0.001 | -0.095 |  0.079 |  0.041 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.bias
 |  1.917 | -0.001 |  2.775 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.3.mixer.A_log
 |  0.983 |  0.943 |  1.034 |  0.013 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.D
 | -0.000 | -0.158 |  0.163 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.3.mixer.in_proj.weight
 |  0.006 | -0.509 |  0.541 |  0.281 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.3.mixer.conv1d.weight
 |  0.009 | -0.497 |  0.503 |  0.257 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.087 |  0.088 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.3.mixer.x_proj.weight
 | -0.002 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.511 | -6.890 | -2.278 |  1.395 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.139 |  0.165 |  0.037 | torch.Size([128, 256]) || m_down3.0.mamba_layers.3.mixer.out_proj.weight
 |  0.961 |  0.906 |  1.014 |  0.023 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.weight
 | -0.001 | -0.084 |  0.079 |  0.035 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.bias
 |  0.700 |  0.550 |  0.849 |  0.212 | torch.Size([2]) || m_down3.0.pcbam_module.h_cw.weight
 |  0.027 | -0.036 |  0.111 |  0.076 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.h_cw.conv.weight
 |  0.282 |  0.257 |  0.308 |  0.036 | torch.Size([2]) || m_down3.0.pcbam_module.w_hc.weight
 | -0.002 | -0.122 |  0.144 |  0.135 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.w_hc.conv.weight
 |  0.557 |  0.223 |  0.891 |  0.472 | torch.Size([2]) || m_down3.0.pcbam_module.c_hw.weight
 | -0.077 | -0.284 |  0.078 |  0.131 | torch.Size([1, 1, 1, 5]) || m_down3.0.pcbam_module.c_hw.conv.weight
 |  1.058 |  0.560 |  1.594 |  0.259 | torch.Size([128]) || m_down3.1.trans_block.ln1.weight
 | -0.018 | -0.854 |  0.703 |  0.229 | torch.Size([128]) || m_down3.1.trans_block.ln1.bias
 |  0.004 | -3.063 |  1.227 |  0.337 | torch.Size([4, 15, 15]) || m_down3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.467 |  0.481 |  0.059 | torch.Size([384, 128, 1, 1]) || m_down3.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.278 |  0.277 |  0.058 | torch.Size([384]) || m_down3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.189 |  0.181 |  0.044 | torch.Size([128, 128, 1, 1]) || m_down3.1.trans_block.msa.linear1.weight
 |  0.001 | -0.168 |  0.175 |  0.068 | torch.Size([128]) || m_down3.1.trans_block.msa.linear1.bias
 |  0.900 |  0.381 |  1.273 |  0.195 | torch.Size([128]) || m_down3.1.trans_block.ln2.weight
 | -0.006 | -0.395 |  0.479 |  0.178 | torch.Size([128]) || m_down3.1.trans_block.ln2.bias
 | -0.000 | -0.482 |  0.379 |  0.061 | torch.Size([512, 128]) || m_down3.1.trans_block.mlp.0.weight
 | -0.047 | -0.254 |  0.036 |  0.054 | torch.Size([512]) || m_down3.1.trans_block.mlp.0.bias
 | -0.000 | -0.375 |  0.380 |  0.048 | torch.Size([128, 512]) || m_down3.1.trans_block.mlp.2.weight
 |  0.005 | -0.127 |  0.175 |  0.058 | torch.Size([128]) || m_down3.1.trans_block.mlp.2.bias
 | -0.003 | -1.860 |  0.713 |  0.090 | torch.Size([384, 384, 1, 1]) || m_down3.1.conv1_1.weight
 |  0.010 | -0.650 |  0.478 |  0.106 | torch.Size([384]) || m_down3.1.conv1_1.bias
 |  0.101 | -0.010 |  0.320 |  0.190 | torch.Size([1, 1, 1, 1, 3]) || m_down3.1.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_down3.1.conv3d.bias
 | -0.006 | -0.396 |  0.412 |  0.049 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.0.weight
 | -0.000 | -0.268 |  0.321 |  0.042 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.2.weight
 |  1.917 | -0.002 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.0.mixer.A_log
 |  1.012 |  0.984 |  1.162 |  0.028 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.291 |  0.299 |  0.027 | torch.Size([512, 128]) || m_down3.1.mamba_layers.0.mixer.in_proj.weight
 | -0.001 | -0.394 |  0.303 |  0.058 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.159 |  0.117 |  0.039 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.088 |  0.101 |  0.014 | torch.Size([40, 256]) || m_down3.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.039 |  0.057 |  0.012 | torch.Size([256, 8]) || m_down3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.030 |  0.015 |  0.002 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.231 |  0.223 |  0.030 | torch.Size([128, 256]) || m_down3.1.mamba_layers.0.mixer.out_proj.weight
 |  0.990 |  0.854 |  1.211 |  0.062 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.weight
 |  0.004 | -0.126 |  0.147 |  0.078 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.bias
 |  1.917 | -0.057 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.1.mixer.A_log
 |  1.023 |  0.945 |  1.324 |  0.053 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.D
 |  0.000 | -0.314 |  0.358 |  0.035 | torch.Size([512, 128]) || m_down3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.004 | -0.418 |  0.355 |  0.069 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.259 |  0.234 |  0.049 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.182 |  0.218 |  0.024 | torch.Size([40, 256]) || m_down3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.079 |  0.088 |  0.016 | torch.Size([256, 8]) || m_down3.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.010 | -0.114 |  0.190 |  0.031 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.281 |  0.306 |  0.036 | torch.Size([128, 256]) || m_down3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.014 |  0.835 |  1.239 |  0.082 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.weight
 | -0.003 | -0.185 |  0.188 |  0.105 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.131 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.2.mixer.A_log
 |  0.980 |  0.893 |  1.097 |  0.024 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.198 |  0.189 |  0.054 | torch.Size([512, 128]) || m_down3.1.mamba_layers.2.mixer.in_proj.weight
 | -0.013 | -0.596 |  0.580 |  0.282 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.2.mixer.conv1d.weight
 |  0.014 | -0.520 |  0.498 |  0.283 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.148 |  0.116 |  0.038 | torch.Size([40, 256]) || m_down3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.001 | -0.367 |  0.355 |  0.205 | torch.Size([256, 8]) || m_down3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.525 | -6.819 | -2.284 |  1.305 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.210 |  0.152 |  0.041 | torch.Size([128, 256]) || m_down3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.966 |  0.813 |  1.063 |  0.037 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.weight
 | -0.001 | -0.138 |  0.079 |  0.033 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.009 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.3.mixer.A_log
 |  0.983 |  0.934 |  1.030 |  0.017 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.D
 |  0.000 | -0.170 |  0.168 |  0.052 | torch.Size([512, 128]) || m_down3.1.mamba_layers.3.mixer.in_proj.weight
 |  0.011 | -0.585 |  0.559 |  0.280 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.3.mixer.conv1d.weight
 |  0.002 | -0.512 |  0.477 |  0.285 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.123 |  0.145 |  0.038 | torch.Size([40, 256]) || m_down3.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.204 | torch.Size([256, 8]) || m_down3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.747 | -6.882 | -2.255 |  1.391 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.145 |  0.143 |  0.039 | torch.Size([128, 256]) || m_down3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.961 |  0.874 |  1.045 |  0.032 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.weight
 | -0.001 | -0.117 |  0.090 |  0.031 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.bias
 |  0.678 |  0.554 |  0.802 |  0.175 | torch.Size([2]) || m_down3.1.pcbam_module.h_cw.weight
 |  0.002 | -0.192 |  0.251 |  0.226 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.h_cw.conv.weight
 |  0.420 |  0.112 |  0.727 |  0.435 | torch.Size([2]) || m_down3.1.pcbam_module.w_hc.weight
 | -0.002 | -0.211 |  0.291 |  0.261 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.w_hc.conv.weight
 |  0.632 |  0.611 |  0.653 |  0.029 | torch.Size([2]) || m_down3.1.pcbam_module.c_hw.weight
 |  0.154 | -0.205 |  0.506 |  0.331 | torch.Size([1, 1, 1, 5]) || m_down3.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.489 |  0.315 |  0.032 | torch.Size([768, 384, 2, 2]) || m_down3.2.weight
 |  0.811 |  0.333 |  1.124 |  0.153 | torch.Size([256]) || m_body.0.trans_block.ln1.weight
 | -0.011 | -0.705 |  0.525 |  0.142 | torch.Size([256]) || m_body.0.trans_block.ln1.bias
 |  0.055 | -4.783 |  0.812 |  0.345 | torch.Size([8, 15, 15]) || m_body.0.trans_block.msa.relative_position_params
 | -0.000 | -0.391 |  0.414 |  0.040 | torch.Size([768, 256, 1, 1]) || m_body.0.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.226 |  0.232 |  0.061 | torch.Size([768]) || m_body.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.255 |  0.246 |  0.047 | torch.Size([256, 256, 1, 1]) || m_body.0.trans_block.msa.linear1.weight
 |  0.005 | -0.259 |  0.166 |  0.064 | torch.Size([256]) || m_body.0.trans_block.msa.linear1.bias
 |  0.867 |  0.401 |  1.220 |  0.124 | torch.Size([256]) || m_body.0.trans_block.ln2.weight
 |  0.002 | -0.206 |  0.294 |  0.088 | torch.Size([256]) || m_body.0.trans_block.ln2.bias
 |  0.000 | -0.269 |  0.296 |  0.035 | torch.Size([1024, 256]) || m_body.0.trans_block.mlp.0.weight
 | -0.012 | -0.237 |  0.104 |  0.043 | torch.Size([1024]) || m_body.0.trans_block.mlp.0.bias
 | -0.000 | -0.293 |  0.321 |  0.033 | torch.Size([256, 1024]) || m_body.0.trans_block.mlp.2.weight
 |  0.008 | -0.257 |  0.163 |  0.058 | torch.Size([256]) || m_body.0.trans_block.mlp.2.bias
 | -0.001 | -1.132 |  0.854 |  0.052 | torch.Size([768, 768, 1, 1]) || m_body.0.conv1_1.weight
 |  0.000 | -1.553 |  1.044 |  0.103 | torch.Size([768]) || m_body.0.conv1_1.bias
 |  0.123 | -0.005 |  0.375 |  0.218 | torch.Size([1, 1, 1, 1, 3]) || m_body.0.conv3d.weight
 |  0.140 |  0.140 |  0.140 |    nan | torch.Size([1]) || m_body.0.conv3d.bias
 |  0.000 | -0.257 |  0.259 |  0.035 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.0.weight
 | -0.000 | -0.235 |  0.232 |  0.037 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.D
 |  0.000 | -0.028 |  0.027 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.025 |  0.027 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.004 |  0.003 |  0.001 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.035 |  0.036 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.033 |  0.038 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.042 |  0.037 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.0.mixer.out_proj.weight
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.bias
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.001 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.D
 |  0.000 | -0.029 |  0.030 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.1.mixer.in_proj.weight
 |  0.000 | -0.035 |  0.059 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.1.mixer.conv1d.weight
 | -0.000 | -0.018 |  0.022 |  0.006 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.034 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.034 |  0.030 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.045 |  0.041 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.999 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.weight
 | -0.000 | -0.001 |  0.001 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.bias
 |  1.917 | -0.097 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.A_log
 |  1.000 |  0.938 |  1.044 |  0.007 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.D
 | -0.000 | -0.098 |  0.094 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.2.mixer.in_proj.weight
 | -0.007 | -0.528 |  0.573 |  0.290 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.2.mixer.conv1d.weight
 | -0.004 | -0.501 |  0.501 |  0.307 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.104 |  0.078 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.253 |  0.276 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.580 | -6.906 | -2.284 |  1.360 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.110 |  0.112 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.2.mixer.out_proj.weight
 |  1.001 |  0.987 |  1.021 |  0.006 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.weight
 |  0.000 | -0.019 |  0.014 |  0.006 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.bias
 |  1.917 | -0.054 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.A_log
 |  1.000 |  0.986 |  1.028 |  0.004 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.D
 |  0.000 | -0.103 |  0.119 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.3.mixer.in_proj.weight
 | -0.013 | -0.514 |  0.518 |  0.288 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.3.mixer.conv1d.weight
 |  0.004 | -0.501 |  0.498 |  0.281 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.139 |  0.127 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.3.mixer.x_proj.weight
 |  0.002 | -0.266 |  0.286 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.613 | -6.907 | -2.260 |  1.325 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.110 |  0.102 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.3.mixer.out_proj.weight
 |  1.000 |  0.986 |  1.019 |  0.006 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.weight
 |  0.000 | -0.020 |  0.015 |  0.006 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.bias
 |  1.197 |  0.945 |  1.448 |  0.356 | torch.Size([2]) || m_body.0.pcbam_module.h_cw.weight
 | -0.840 | -1.100 | -0.698 |  0.225 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.h_cw.conv.weight
 |  0.471 |  0.223 |  0.719 |  0.351 | torch.Size([2]) || m_body.0.pcbam_module.w_hc.weight
 | -0.698 | -0.793 | -0.515 |  0.158 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.w_hc.conv.weight
 |  1.386 |  0.830 |  1.941 |  0.786 | torch.Size([2]) || m_body.0.pcbam_module.c_hw.weight
 | -0.302 | -1.301 |  2.073 |  1.369 | torch.Size([1, 1, 1, 5]) || m_body.0.pcbam_module.c_hw.conv.weight
 |  0.741 |  0.292 |  0.989 |  0.133 | torch.Size([256]) || m_body.1.trans_block.ln1.weight
 |  0.030 | -0.841 |  0.563 |  0.168 | torch.Size([256]) || m_body.1.trans_block.ln1.bias
 |  0.053 | -4.103 |  0.881 |  0.362 | torch.Size([8, 15, 15]) || m_body.1.trans_block.msa.relative_position_params
 | -0.000 | -0.332 |  0.329 |  0.038 | torch.Size([768, 256, 1, 1]) || m_body.1.trans_block.msa.embedding_layer1.weight
 |  0.000 | -0.248 |  0.278 |  0.077 | torch.Size([768]) || m_body.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.297 |  0.312 |  0.043 | torch.Size([256, 256, 1, 1]) || m_body.1.trans_block.msa.linear1.weight
 | -0.001 | -0.220 |  0.179 |  0.068 | torch.Size([256]) || m_body.1.trans_block.msa.linear1.bias
 |  0.872 |  0.538 |  1.119 |  0.101 | torch.Size([256]) || m_body.1.trans_block.ln2.weight
 |  0.007 | -0.311 |  0.352 |  0.118 | torch.Size([256]) || m_body.1.trans_block.ln2.bias
 |  0.001 | -0.410 |  0.377 |  0.056 | torch.Size([1024, 256]) || m_body.1.trans_block.mlp.0.weight
 | -0.053 | -0.221 |  0.056 |  0.041 | torch.Size([1024]) || m_body.1.trans_block.mlp.0.bias
 | -0.001 | -0.495 |  0.410 |  0.054 | torch.Size([256, 1024]) || m_body.1.trans_block.mlp.2.weight
 |  0.003 | -0.217 |  0.134 |  0.061 | torch.Size([256]) || m_body.1.trans_block.mlp.2.bias
 | -0.001 | -1.098 |  0.774 |  0.057 | torch.Size([768, 768, 1, 1]) || m_body.1.conv1_1.weight
 |  0.002 | -0.325 |  0.944 |  0.090 | torch.Size([768]) || m_body.1.conv1_1.bias
 |  0.230 |  0.013 |  0.661 |  0.373 | torch.Size([1, 1, 1, 1, 3]) || m_body.1.conv3d.weight
 |  0.121 |  0.121 |  0.121 |    nan | torch.Size([1]) || m_body.1.conv3d.bias
 | -0.001 | -0.290 |  0.287 |  0.035 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.0.weight
 | -0.001 | -0.293 |  0.281 |  0.037 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.2.weight
 |  1.917 | -0.001 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.087 |  0.005 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.D
 | -0.000 | -0.127 |  0.114 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.099 |  0.249 |  0.012 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.008 |  0.062 |  0.003 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.036 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.035 |  0.029 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.007 |  0.004 |  0.000 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.149 |  0.096 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.0.mixer.out_proj.weight
 |  1.001 |  0.994 |  1.019 |  0.003 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.weight
 |  0.000 | -0.005 |  0.006 |  0.002 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.bias
 |  1.917 | -0.218 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.043 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.D
 |  0.000 | -0.167 |  0.149 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.1.mixer.in_proj.weight
 | -0.000 | -0.070 |  0.165 |  0.010 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.097 |  0.073 |  0.022 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.096 |  0.323 |  0.010 | torch.Size([48, 512]) || m_body.1.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.032 |  0.035 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.037 |  0.000 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.157 |  0.182 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.986 |  1.044 |  0.010 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.weight
 | -0.001 | -0.017 |  0.021 |  0.008 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.bias
 |  1.917 | -0.073 |  2.774 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.A_log
 |  0.999 |  0.959 |  1.034 |  0.005 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.D
 | -0.000 | -0.107 |  0.116 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.2.mixer.in_proj.weight
 |  0.004 | -0.504 |  0.518 |  0.283 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.2.mixer.conv1d.weight
 |  0.011 | -0.507 |  0.492 |  0.282 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.080 |  0.095 |  0.026 | torch.Size([48, 512]) || m_body.1.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.257 |  0.260 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.634 | -6.903 | -2.259 |  1.288 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.109 |  0.125 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.2.mixer.out_proj.weight
 |  0.996 |  0.962 |  1.010 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.weight
 | -0.000 | -0.022 |  0.021 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.bias
 |  1.917 | -0.071 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.A_log
 |  1.000 |  0.915 |  1.123 |  0.010 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.D
 |  0.000 | -0.126 |  0.120 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.534 |  0.505 |  0.293 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.3.mixer.conv1d.weight
 | -0.009 | -0.501 |  0.499 |  0.294 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.102 |  0.104 |  0.027 | torch.Size([48, 512]) || m_body.1.mamba_layers.3.mixer.x_proj.weight
 |  0.000 | -0.269 |  0.279 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.632 | -6.905 | -2.251 |  1.302 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.114 |  0.115 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.3.mixer.out_proj.weight
 |  1.000 |  0.978 |  1.028 |  0.008 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.weight
 |  0.000 | -0.014 |  0.015 |  0.006 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.bias
 |  1.200 |  0.904 |  1.497 |  0.420 | torch.Size([2]) || m_body.1.pcbam_module.h_cw.weight
 | -0.965 | -1.022 | -0.857 |  0.093 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.h_cw.conv.weight
 |  1.128 |  0.926 |  1.331 |  0.287 | torch.Size([2]) || m_body.1.pcbam_module.w_hc.weight
 | -0.869 | -0.966 | -0.745 |  0.113 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.w_hc.conv.weight
 |  1.843 |  0.989 |  2.696 |  1.207 | torch.Size([2]) || m_body.1.pcbam_module.c_hw.weight
 | -0.283 | -1.636 |  1.696 |  1.326 | torch.Size([1, 1, 1, 5]) || m_body.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.307 |  0.372 |  0.031 | torch.Size([768, 384, 2, 2]) || m_up3.0.weight
 |  0.954 |  0.542 |  1.382 |  0.163 | torch.Size([128]) || m_up3.1.trans_block.ln1.weight
 |  0.027 | -0.628 |  0.455 |  0.135 | torch.Size([128]) || m_up3.1.trans_block.ln1.bias
 |  0.054 | -4.249 |  0.736 |  0.342 | torch.Size([4, 15, 15]) || m_up3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.531 |  0.577 |  0.065 | torch.Size([384, 128, 1, 1]) || m_up3.1.trans_block.msa.embedding_layer1.weight
 |  0.000 | -0.301 |  0.292 |  0.078 | torch.Size([384]) || m_up3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.214 |  0.214 |  0.051 | torch.Size([128, 128, 1, 1]) || m_up3.1.trans_block.msa.linear1.weight
 | -0.003 | -0.124 |  0.231 |  0.055 | torch.Size([128]) || m_up3.1.trans_block.msa.linear1.bias
 |  0.902 |  0.641 |  1.063 |  0.074 | torch.Size([128]) || m_up3.1.trans_block.ln2.weight
 |  0.009 | -0.313 |  0.197 |  0.090 | torch.Size([128]) || m_up3.1.trans_block.ln2.bias
 |  0.000 | -0.341 |  0.334 |  0.065 | torch.Size([512, 128]) || m_up3.1.trans_block.mlp.0.weight
 | -0.042 | -0.207 |  0.064 |  0.046 | torch.Size([512]) || m_up3.1.trans_block.mlp.0.bias
 | -0.000 | -0.388 |  0.362 |  0.058 | torch.Size([128, 512]) || m_up3.1.trans_block.mlp.2.weight
 | -0.003 | -0.398 |  0.190 |  0.053 | torch.Size([128]) || m_up3.1.trans_block.mlp.2.bias
 | -0.001 | -2.417 |  0.683 |  0.089 | torch.Size([384, 384, 1, 1]) || m_up3.1.conv1_1.weight
 | -0.002 | -0.483 |  1.570 |  0.151 | torch.Size([384]) || m_up3.1.conv1_1.bias
 |  0.184 | -0.010 |  0.570 |  0.334 | torch.Size([1, 1, 1, 1, 3]) || m_up3.1.conv3d.weight
 | -0.003 | -0.003 | -0.003 |    nan | torch.Size([1]) || m_up3.1.conv3d.bias
 |  0.000 | -0.415 |  0.297 |  0.036 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.0.weight
 |  0.000 | -0.288 |  0.428 |  0.038 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.2.weight
 |  1.916 | -0.378 |  2.773 |  0.766 | torch.Size([256, 16]) || m_up3.1.mamba_layers.0.mixer.A_log
 |  1.054 |  0.998 |  1.345 |  0.077 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.396 |  0.383 |  0.045 | torch.Size([512, 128]) || m_up3.1.mamba_layers.0.mixer.in_proj.weight
 |  0.007 | -0.428 |  0.490 |  0.101 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.0.mixer.conv1d.weight
 |  0.012 | -0.201 |  0.367 |  0.070 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.180 |  0.285 |  0.027 | torch.Size([40, 256]) || m_up3.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.063 |  0.069 |  0.013 | torch.Size([256, 8]) || m_up3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.003 | -0.183 |  0.129 |  0.031 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.512 |  0.471 |  0.052 | torch.Size([128, 256]) || m_up3.1.mamba_layers.0.mixer.out_proj.weight
 |  1.028 |  0.896 |  1.165 |  0.066 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.weight
 | -0.002 | -0.273 |  0.276 |  0.121 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.bias
 |  1.915 | -0.809 |  3.034 |  0.769 | torch.Size([256, 16]) || m_up3.1.mamba_layers.1.mixer.A_log
 |  0.997 | -0.093 |  1.305 |  0.170 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.D
 | -0.000 | -0.422 |  0.437 |  0.056 | torch.Size([512, 128]) || m_up3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.004 | -0.478 |  0.394 |  0.112 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.021 | -0.301 |  0.304 |  0.178 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.565 |  0.548 |  0.075 | torch.Size([40, 256]) || m_up3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.002 | -0.567 |  0.680 |  0.097 | torch.Size([256, 8]) || m_up3.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.014 | -1.005 |  0.231 |  0.108 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.287 |  0.280 |  0.058 | torch.Size([128, 256]) || m_up3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.006 |  0.645 |  1.189 |  0.109 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.weight
 | -0.002 | -0.240 |  0.274 |  0.103 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.313 |  2.788 |  0.765 | torch.Size([256, 16]) || m_up3.1.mamba_layers.2.mixer.A_log
 |  0.973 |  0.487 |  1.043 |  0.063 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.194 |  0.229 |  0.053 | torch.Size([512, 128]) || m_up3.1.mamba_layers.2.mixer.in_proj.weight
 |  0.014 | -0.579 |  0.573 |  0.277 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.2.mixer.conv1d.weight
 | -0.030 | -0.528 |  0.510 |  0.290 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.217 |  0.173 |  0.047 | torch.Size([40, 256]) || m_up3.1.mamba_layers.2.mixer.x_proj.weight
 | -0.004 | -0.719 |  0.371 |  0.207 | torch.Size([256, 8]) || m_up3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.532 | -6.924 | -2.275 |  1.358 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.000 | -0.166 |  0.158 |  0.042 | torch.Size([128, 256]) || m_up3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.947 |  0.812 |  1.035 |  0.034 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.weight
 |  0.001 | -0.083 |  0.091 |  0.029 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.037 |  2.773 |  0.765 | torch.Size([256, 16]) || m_up3.1.mamba_layers.3.mixer.A_log
 |  0.991 |  0.940 |  1.040 |  0.017 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.D
 | -0.000 | -0.169 |  0.171 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.3.mixer.in_proj.weight
 | -0.011 | -0.538 |  0.535 |  0.268 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.3.mixer.conv1d.weight
 | -0.005 | -0.558 |  0.535 |  0.311 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.125 |  0.134 |  0.038 | torch.Size([40, 256]) || m_up3.1.mamba_layers.3.mixer.x_proj.weight
 | -0.001 | -0.355 |  0.355 |  0.203 | torch.Size([256, 8]) || m_up3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.644 | -6.922 | -2.261 |  1.394 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.152 |  0.149 |  0.042 | torch.Size([128, 256]) || m_up3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.956 |  0.839 |  1.032 |  0.030 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.weight
 | -0.000 | -0.116 |  0.112 |  0.028 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.bias
 |  0.531 |  0.193 |  0.869 |  0.478 | torch.Size([2]) || m_up3.1.pcbam_module.h_cw.weight
 |  0.110 |  0.061 |  0.205 |  0.082 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.h_cw.conv.weight
 |  0.879 |  0.849 |  0.910 |  0.043 | torch.Size([2]) || m_up3.1.pcbam_module.w_hc.weight
 |  0.147 |  0.089 |  0.183 |  0.051 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.w_hc.conv.weight
 |  0.485 |  0.213 |  0.756 |  0.384 | torch.Size([2]) || m_up3.1.pcbam_module.c_hw.weight
 | -0.013 | -0.146 |  0.044 |  0.080 | torch.Size([1, 1, 1, 5]) || m_up3.1.pcbam_module.c_hw.conv.weight
 |  1.128 |  0.571 |  1.372 |  0.155 | torch.Size([128]) || m_up3.2.trans_block.ln1.weight
 | -0.005 | -0.558 |  0.553 |  0.134 | torch.Size([128]) || m_up3.2.trans_block.ln1.bias
 |  0.063 | -3.364 |  0.782 |  0.383 | torch.Size([4, 15, 15]) || m_up3.2.trans_block.msa.relative_position_params
 | -0.000 | -0.497 |  0.345 |  0.061 | torch.Size([384, 128, 1, 1]) || m_up3.2.trans_block.msa.embedding_layer1.weight
 | -0.001 | -0.207 |  0.219 |  0.064 | torch.Size([384]) || m_up3.2.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.219 |  0.241 |  0.054 | torch.Size([128, 128, 1, 1]) || m_up3.2.trans_block.msa.linear1.weight
 | -0.003 | -0.164 |  0.157 |  0.065 | torch.Size([128]) || m_up3.2.trans_block.msa.linear1.bias
 |  1.226 |  0.902 |  1.541 |  0.098 | torch.Size([128]) || m_up3.2.trans_block.ln2.weight
 | -0.000 | -0.280 |  0.308 |  0.120 | torch.Size([128]) || m_up3.2.trans_block.ln2.bias
 |  0.000 | -0.365 |  0.334 |  0.077 | torch.Size([512, 128]) || m_up3.2.trans_block.mlp.0.weight
 | -0.050 | -0.201 |  0.060 |  0.041 | torch.Size([512]) || m_up3.2.trans_block.mlp.0.bias
 |  0.000 | -0.344 |  0.384 |  0.075 | torch.Size([128, 512]) || m_up3.2.trans_block.mlp.2.weight
 | -0.002 | -0.161 |  0.245 |  0.059 | torch.Size([128]) || m_up3.2.trans_block.mlp.2.bias
 | -0.000 | -0.830 |  0.510 |  0.077 | torch.Size([384, 384, 1, 1]) || m_up3.2.conv1_1.weight
 |  0.001 | -0.644 |  1.226 |  0.122 | torch.Size([384]) || m_up3.2.conv1_1.bias
 | -0.075 | -0.232 |  0.004 |  0.136 | torch.Size([1, 1, 1, 1, 3]) || m_up3.2.conv3d.weight
 | -0.007 | -0.007 | -0.007 |    nan | torch.Size([1]) || m_up3.2.conv3d.bias
 | -0.001 | -0.323 |  0.375 |  0.052 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.0.weight
 |  0.000 | -0.396 |  0.413 |  0.052 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.2.weight
 |  1.916 | -1.176 |  2.794 |  0.767 | torch.Size([256, 16]) || m_up3.2.mamba_layers.0.mixer.A_log
 |  1.075 |  0.275 |  1.627 |  0.175 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.D
 | -0.000 | -0.335 |  0.352 |  0.073 | torch.Size([512, 128]) || m_up3.2.mamba_layers.0.mixer.in_proj.weight
 | -0.001 | -0.393 |  0.453 |  0.145 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.0.mixer.conv1d.weight
 | -0.010 | -0.328 |  0.299 |  0.112 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.751 |  0.489 |  0.077 | torch.Size([40, 256]) || m_up3.2.mamba_layers.0.mixer.x_proj.weight
 |  0.001 | -0.753 |  0.782 |  0.103 | torch.Size([256, 8]) || m_up3.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.022 | -1.207 |  0.285 |  0.122 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.623 |  0.454 |  0.079 | torch.Size([128, 256]) || m_up3.2.mamba_layers.0.mixer.out_proj.weight
 |  1.006 |  0.631 |  1.136 |  0.080 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.weight
 |  0.007 | -0.436 |  0.431 |  0.134 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.bias
 |  1.910 | -0.956 |  2.868 |  0.778 | torch.Size([256, 16]) || m_up3.2.mamba_layers.1.mixer.A_log
 |  1.067 | -0.167 |  1.528 |  0.146 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.D
 |  0.000 | -0.361 |  0.432 |  0.074 | torch.Size([512, 128]) || m_up3.2.mamba_layers.1.mixer.in_proj.weight
 |  0.005 | -0.572 |  0.494 |  0.152 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.1.mixer.conv1d.weight
 |  0.012 | -0.332 |  0.349 |  0.156 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.conv1d.bias
 |  0.002 | -0.712 |  1.188 |  0.095 | torch.Size([40, 256]) || m_up3.2.mamba_layers.1.mixer.x_proj.weight
 | -0.005 | -0.705 |  0.564 |  0.127 | torch.Size([256, 8]) || m_up3.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.014 | -0.480 |  0.184 |  0.109 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.501 |  0.453 |  0.078 | torch.Size([128, 256]) || m_up3.2.mamba_layers.1.mixer.out_proj.weight
 |  1.063 |  0.615 |  1.225 |  0.084 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.weight
 |  0.005 | -0.274 |  0.254 |  0.111 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.bias
 |  1.917 | -0.047 |  2.853 |  0.765 | torch.Size([256, 16]) || m_up3.2.mamba_layers.2.mixer.A_log
 |  1.035 |  0.964 |  1.425 |  0.045 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.D
 | -0.000 | -0.246 |  0.238 |  0.059 | torch.Size([512, 128]) || m_up3.2.mamba_layers.2.mixer.in_proj.weight
 |  0.002 | -0.680 |  0.657 |  0.298 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.2.mixer.conv1d.weight
 |  0.040 | -0.561 |  0.559 |  0.325 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.203 |  0.243 |  0.048 | torch.Size([40, 256]) || m_up3.2.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.459 |  0.521 |  0.206 | torch.Size([256, 8]) || m_up3.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.529 | -6.898 | -2.206 |  1.384 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.255 |  0.222 |  0.050 | torch.Size([128, 256]) || m_up3.2.mamba_layers.2.mixer.out_proj.weight
 |  1.039 |  0.945 |  1.122 |  0.032 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.weight
 |  0.001 | -0.131 |  0.137 |  0.051 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.bias
 |  1.917 | -0.028 |  2.774 |  0.764 | torch.Size([256, 16]) || m_up3.2.mamba_layers.3.mixer.A_log
 |  1.011 |  0.961 |  1.101 |  0.017 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.D
 | -0.000 | -0.201 |  0.196 |  0.056 | torch.Size([512, 128]) || m_up3.2.mamba_layers.3.mixer.in_proj.weight
 | -0.000 | -0.581 |  0.577 |  0.289 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.3.mixer.conv1d.weight
 | -0.019 | -0.548 |  0.557 |  0.311 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.190 |  0.188 |  0.044 | torch.Size([40, 256]) || m_up3.2.mamba_layers.3.mixer.x_proj.weight
 | -0.004 | -0.374 |  0.399 |  0.207 | torch.Size([256, 8]) || m_up3.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.522 | -6.886 | -2.228 |  1.228 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.202 |  0.204 |  0.046 | torch.Size([128, 256]) || m_up3.2.mamba_layers.3.mixer.out_proj.weight
 |  1.014 |  0.727 |  1.081 |  0.042 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.weight
 |  0.001 | -0.209 |  0.107 |  0.039 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.bias
 |  0.754 |  0.557 |  0.950 |  0.278 | torch.Size([2]) || m_up3.2.pcbam_module.h_cw.weight
 | -0.050 | -0.197 |  0.182 |  0.204 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.h_cw.conv.weight
 |  0.796 |  0.740 |  0.852 |  0.079 | torch.Size([2]) || m_up3.2.pcbam_module.w_hc.weight
 |  0.087 | -0.076 |  0.270 |  0.174 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.w_hc.conv.weight
 |  0.604 |  0.058 |  1.151 |  0.773 | torch.Size([2]) || m_up3.2.pcbam_module.c_hw.weight
 |  0.352 | -0.096 |  1.720 |  0.768 | torch.Size([1, 1, 1, 5]) || m_up3.2.pcbam_module.c_hw.conv.weight
 | -0.001 | -0.424 |  0.323 |  0.035 | torch.Size([384, 192, 2, 2]) || m_up2.0.weight
 |  1.328 |  0.979 |  1.553 |  0.144 | torch.Size([64]) || m_up2.1.trans_block.ln1.weight
 | -0.000 | -0.531 |  0.545 |  0.169 | torch.Size([64]) || m_up2.1.trans_block.ln1.bias
 |  0.183 | -2.789 |  0.975 |  0.379 | torch.Size([2, 15, 15]) || m_up2.1.trans_block.msa.relative_position_params
 |  0.000 | -0.504 |  0.533 |  0.110 | torch.Size([192, 64, 1, 1]) || m_up2.1.trans_block.msa.embedding_layer1.weight
 |  0.000 | -0.189 |  0.186 |  0.051 | torch.Size([192]) || m_up2.1.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.222 |  0.244 |  0.057 | torch.Size([64, 64, 1, 1]) || m_up2.1.trans_block.msa.linear1.weight
 | -0.003 | -0.236 |  0.255 |  0.065 | torch.Size([64]) || m_up2.1.trans_block.msa.linear1.bias
 |  1.067 |  0.768 |  1.202 |  0.083 | torch.Size([64]) || m_up2.1.trans_block.ln2.weight
 |  0.008 | -0.290 |  0.292 |  0.147 | torch.Size([64]) || m_up2.1.trans_block.ln2.bias
 | -0.000 | -0.385 |  0.377 |  0.097 | torch.Size([256, 64]) || m_up2.1.trans_block.mlp.0.weight
 | -0.048 | -0.369 |  0.232 |  0.080 | torch.Size([256]) || m_up2.1.trans_block.mlp.0.bias
 |  0.001 | -0.465 |  0.455 |  0.086 | torch.Size([64, 256]) || m_up2.1.trans_block.mlp.2.weight
 | -0.003 | -0.262 |  0.212 |  0.072 | torch.Size([64]) || m_up2.1.trans_block.mlp.2.bias
 |  0.002 | -0.430 |  2.109 |  0.104 | torch.Size([192, 192, 1, 1]) || m_up2.1.conv1_1.weight
 |  0.000 | -0.701 |  0.929 |  0.146 | torch.Size([192]) || m_up2.1.conv1_1.bias
 | -0.201 | -0.692 |  0.049 |  0.426 | torch.Size([1, 1, 1, 1, 3]) || m_up2.1.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_up2.1.conv3d.bias
 |  0.000 | -0.260 |  0.286 |  0.046 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.0.weight
 |  0.000 | -0.293 |  0.278 |  0.047 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.2.weight
 |  1.916 | -0.595 |  2.773 |  0.766 | torch.Size([128, 16]) || m_up2.1.mamba_layers.0.mixer.A_log
 |  1.117 |  0.999 |  1.310 |  0.060 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.D
 | -0.000 | -0.318 |  0.321 |  0.077 | torch.Size([256, 64]) || m_up2.1.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.450 |  0.485 |  0.176 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.005 | -0.216 |  0.238 |  0.072 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.001 | -0.162 |  0.223 |  0.041 | torch.Size([36, 128]) || m_up2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.054 |  0.058 |  0.020 | torch.Size([128, 4]) || m_up2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.002 | -0.179 |  0.279 |  0.057 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.556 |  0.406 |  0.080 | torch.Size([64, 128]) || m_up2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.181 |  0.951 |  1.328 |  0.087 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.weight
 |  0.001 | -0.151 |  0.236 |  0.078 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.bias
 |  1.916 | -0.583 |  2.773 |  0.768 | torch.Size([128, 16]) || m_up2.1.mamba_layers.1.mixer.A_log
 |  1.148 |  0.999 |  1.409 |  0.066 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.D
 |  0.000 | -0.399 |  0.423 |  0.092 | torch.Size([256, 64]) || m_up2.1.mamba_layers.1.mixer.in_proj.weight
 | -0.008 | -0.482 |  0.683 |  0.187 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.010 | -0.310 |  0.270 |  0.123 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.244 |  0.310 |  0.065 | torch.Size([36, 128]) || m_up2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.127 |  0.278 |  0.046 | torch.Size([128, 4]) || m_up2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.032 | -0.142 |  0.233 |  0.064 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.001 | -0.405 |  0.487 |  0.092 | torch.Size([64, 128]) || m_up2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.194 |  0.817 |  1.351 |  0.110 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.weight
 |  0.002 | -0.217 |  0.261 |  0.088 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.045 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.2.mixer.A_log
 |  1.005 |  0.923 |  1.107 |  0.032 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.D
 |  0.001 | -0.262 |  0.286 |  0.077 | torch.Size([256, 64]) || m_up2.1.mamba_layers.2.mixer.in_proj.weight
 | -0.001 | -0.538 |  0.699 |  0.288 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.2.mixer.conv1d.weight
 | -0.027 | -0.542 |  0.498 |  0.311 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.191 |  0.186 |  0.056 | torch.Size([36, 128]) || m_up2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.016 | -0.497 |  0.502 |  0.287 | torch.Size([128, 4]) || m_up2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.802 | -6.894 | -2.291 |  1.396 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.207 |  0.219 |  0.063 | torch.Size([64, 128]) || m_up2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.999 |  0.878 |  1.161 |  0.044 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.weight
 |  0.001 | -0.098 |  0.087 |  0.030 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.017 |  2.775 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.3.mixer.A_log
 |  1.007 |  0.932 |  1.091 |  0.032 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.223 |  0.237 |  0.076 | torch.Size([256, 64]) || m_up2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.011 | -0.583 |  0.589 |  0.295 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.3.mixer.conv1d.weight
 | -0.013 | -0.579 |  0.575 |  0.323 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.237 |  0.196 |  0.056 | torch.Size([36, 128]) || m_up2.1.mamba_layers.3.mixer.x_proj.weight
 | -0.017 | -0.491 |  0.499 |  0.291 | torch.Size([128, 4]) || m_up2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.755 | -6.888 | -2.287 |  1.356 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.255 |  0.205 |  0.062 | torch.Size([64, 128]) || m_up2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.993 |  0.829 |  1.104 |  0.042 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.weight
 |  0.001 | -0.125 |  0.113 |  0.033 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.bias
 |  0.170 |  0.121 |  0.218 |  0.069 | torch.Size([2]) || m_up2.1.pcbam_module.h_cw.weight
 |  0.042 | -0.070 |  0.185 |  0.130 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.h_cw.conv.weight
 |  0.690 |  0.686 |  0.693 |  0.005 | torch.Size([2]) || m_up2.1.pcbam_module.w_hc.weight
 | -0.073 | -0.294 |  0.102 |  0.202 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.w_hc.conv.weight
 |  0.884 |  0.826 |  0.943 |  0.083 | torch.Size([2]) || m_up2.1.pcbam_module.c_hw.weight
 | -0.026 | -0.145 |  0.077 |  0.112 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.c_hw.conv.weight
 |  1.364 |  1.021 |  1.593 |  0.134 | torch.Size([64]) || m_up2.2.trans_block.ln1.weight
 |  0.042 | -0.477 |  0.560 |  0.150 | torch.Size([64]) || m_up2.2.trans_block.ln1.bias
 |  0.143 | -2.807 |  0.783 |  0.367 | torch.Size([2, 15, 15]) || m_up2.2.trans_block.msa.relative_position_params
 |  0.000 | -0.490 |  0.549 |  0.108 | torch.Size([192, 64, 1, 1]) || m_up2.2.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.287 |  0.319 |  0.076 | torch.Size([192]) || m_up2.2.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.331 |  0.297 |  0.058 | torch.Size([64, 64, 1, 1]) || m_up2.2.trans_block.msa.linear1.weight
 |  0.004 | -0.280 |  0.481 |  0.077 | torch.Size([64]) || m_up2.2.trans_block.msa.linear1.bias
 |  1.077 |  0.594 |  1.289 |  0.131 | torch.Size([64]) || m_up2.2.trans_block.ln2.weight
 |  0.015 | -0.452 |  0.427 |  0.134 | torch.Size([64]) || m_up2.2.trans_block.ln2.bias
 |  0.002 | -0.407 |  0.461 |  0.095 | torch.Size([256, 64]) || m_up2.2.trans_block.mlp.0.weight
 | -0.047 | -0.191 |  0.085 |  0.047 | torch.Size([256]) || m_up2.2.trans_block.mlp.0.bias
 | -0.000 | -0.372 |  0.397 |  0.085 | torch.Size([64, 256]) || m_up2.2.trans_block.mlp.2.weight
 |  0.002 | -0.294 |  0.300 |  0.069 | torch.Size([64]) || m_up2.2.trans_block.mlp.2.bias
 |  0.002 | -0.517 |  2.022 |  0.104 | torch.Size([192, 192, 1, 1]) || m_up2.2.conv1_1.weight
 | -0.002 | -0.435 |  0.892 |  0.127 | torch.Size([192]) || m_up2.2.conv1_1.bias
 | -0.209 | -0.653 |  0.015 |  0.385 | torch.Size([1, 1, 1, 1, 3]) || m_up2.2.conv3d.weight
 | -0.005 | -0.005 | -0.005 |    nan | torch.Size([1]) || m_up2.2.conv3d.bias
 |  0.001 | -0.404 |  0.429 |  0.055 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.0.weight
 |  0.000 | -0.348 |  0.395 |  0.057 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.2.weight
 |  1.915 | -0.490 |  2.782 |  0.771 | torch.Size([128, 16]) || m_up2.2.mamba_layers.0.mixer.A_log
 |  1.149 |  0.700 |  1.492 |  0.107 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.D
 |  0.000 | -0.505 |  0.417 |  0.097 | torch.Size([256, 64]) || m_up2.2.mamba_layers.0.mixer.in_proj.weight
 |  0.031 | -0.541 |  0.701 |  0.191 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.0.mixer.conv1d.weight
 |  0.038 | -0.247 |  0.273 |  0.096 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.conv1d.bias
 | -0.002 | -0.533 |  0.738 |  0.077 | torch.Size([36, 128]) || m_up2.2.mamba_layers.0.mixer.x_proj.weight
 | -0.007 | -0.444 |  0.319 |  0.104 | torch.Size([128, 4]) || m_up2.2.mamba_layers.0.mixer.dt_proj.weight
 | -0.017 | -0.602 |  0.300 |  0.119 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.399 |  0.592 |  0.099 | torch.Size([64, 128]) || m_up2.2.mamba_layers.0.mixer.out_proj.weight
 |  1.227 |  0.890 |  1.388 |  0.101 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.weight
 |  0.008 | -0.570 |  0.498 |  0.179 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.bias
 |  1.919 | -0.513 |  2.883 |  0.767 | torch.Size([128, 16]) || m_up2.2.mamba_layers.1.mixer.A_log
 |  1.150 |  0.789 |  1.462 |  0.097 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.D
 |  0.000 | -0.495 |  0.517 |  0.102 | torch.Size([256, 64]) || m_up2.2.mamba_layers.1.mixer.in_proj.weight
 |  0.011 | -0.637 |  1.028 |  0.203 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.1.mixer.conv1d.weight
 |  0.027 | -0.322 |  0.290 |  0.119 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.491 |  0.591 |  0.101 | torch.Size([36, 128]) || m_up2.2.mamba_layers.1.mixer.x_proj.weight
 |  0.002 | -0.468 |  0.389 |  0.107 | torch.Size([128, 4]) || m_up2.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.052 | -0.192 |  0.576 |  0.111 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.486 |  0.467 |  0.099 | torch.Size([64, 128]) || m_up2.2.mamba_layers.1.mixer.out_proj.weight
 |  1.257 |  0.825 |  1.452 |  0.130 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.weight
 |  0.004 | -0.198 |  0.375 |  0.096 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.bias
 |  1.917 | -0.027 |  2.774 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.2.mixer.A_log
 |  1.017 |  0.952 |  1.133 |  0.032 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.D
 | -0.000 | -0.345 |  0.266 |  0.078 | torch.Size([256, 64]) || m_up2.2.mamba_layers.2.mixer.in_proj.weight
 | -0.003 | -0.555 |  0.577 |  0.289 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.2.mixer.conv1d.weight
 |  0.065 | -0.563 |  0.565 |  0.306 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.272 |  0.216 |  0.055 | torch.Size([36, 128]) || m_up2.2.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.497 |  0.499 |  0.286 | torch.Size([128, 4]) || m_up2.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.495 | -6.884 | -2.260 |  1.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.291 |  0.270 |  0.067 | torch.Size([64, 128]) || m_up2.2.mamba_layers.2.mixer.out_proj.weight
 |  1.008 |  0.853 |  1.130 |  0.049 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.weight
 |  0.004 | -0.120 |  0.111 |  0.035 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.bias
 |  1.917 | -0.072 |  2.777 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.3.mixer.A_log
 |  1.025 |  0.954 |  1.208 |  0.043 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.D
 |  0.000 | -0.334 |  0.298 |  0.078 | torch.Size([256, 64]) || m_up2.2.mamba_layers.3.mixer.in_proj.weight
 |  0.007 | -0.629 |  0.592 |  0.288 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.3.mixer.conv1d.weight
 |  0.033 | -0.540 |  0.575 |  0.306 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.287 |  0.189 |  0.058 | torch.Size([36, 128]) || m_up2.2.mamba_layers.3.mixer.x_proj.weight
 |  0.004 | -0.573 |  0.579 |  0.290 | torch.Size([128, 4]) || m_up2.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.642 | -6.848 | -2.284 |  1.277 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.dt_proj.bias
 |  0.000 | -0.265 |  0.287 |  0.068 | torch.Size([64, 128]) || m_up2.2.mamba_layers.3.mixer.out_proj.weight
 |  1.012 |  0.864 |  1.119 |  0.051 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.weight
 |  0.004 | -0.123 |  0.110 |  0.036 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.bias
 |  0.309 |  0.187 |  0.430 |  0.172 | torch.Size([2]) || m_up2.2.pcbam_module.h_cw.weight
 |  0.126 | -0.001 |  0.204 |  0.111 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.h_cw.conv.weight
 |  0.822 |  0.759 |  0.885 |  0.089 | torch.Size([2]) || m_up2.2.pcbam_module.w_hc.weight
 |  0.068 | -0.073 |  0.145 |  0.123 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.w_hc.conv.weight
 |  0.739 |  0.716 |  0.763 |  0.033 | torch.Size([2]) || m_up2.2.pcbam_module.c_hw.weight
 |  0.145 |  0.055 |  0.192 |  0.077 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.212 |  0.196 |  0.029 | torch.Size([192, 96, 2, 2]) || m_up1.0.weight
 |  1.165 |  0.744 |  1.393 |  0.206 | torch.Size([32]) || m_up1.1.trans_block.ln1.weight
 | -0.009 | -0.370 |  0.522 |  0.218 | torch.Size([32]) || m_up1.1.trans_block.ln1.bias
 |  0.140 | -1.138 |  0.818 |  0.424 | torch.Size([1, 15, 15]) || m_up1.1.trans_block.msa.relative_position_params
 | -0.000 | -0.438 |  0.383 |  0.107 | torch.Size([96, 32, 1, 1]) || m_up1.1.trans_block.msa.embedding_layer1.weight
 | -0.010 | -0.348 |  0.373 |  0.160 | torch.Size([96]) || m_up1.1.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.285 |  0.259 |  0.073 | torch.Size([32, 32, 1, 1]) || m_up1.1.trans_block.msa.linear1.weight
 |  0.004 | -0.131 |  0.162 |  0.069 | torch.Size([32]) || m_up1.1.trans_block.msa.linear1.bias
 |  1.614 |  1.238 |  2.023 |  0.185 | torch.Size([32]) || m_up1.1.trans_block.ln2.weight
 | -0.003 | -0.320 |  0.311 |  0.183 | torch.Size([32]) || m_up1.1.trans_block.ln2.bias
 |  0.001 | -0.754 |  0.696 |  0.159 | torch.Size([128, 32]) || m_up1.1.trans_block.mlp.0.weight
 | -0.017 | -0.363 |  0.329 |  0.115 | torch.Size([128]) || m_up1.1.trans_block.mlp.0.bias
 | -0.000 | -0.650 |  0.835 |  0.128 | torch.Size([32, 128]) || m_up1.1.trans_block.mlp.2.weight
 | -0.029 | -0.455 |  0.333 |  0.175 | torch.Size([32]) || m_up1.1.trans_block.mlp.2.bias
 | -0.005 | -1.268 |  0.504 |  0.127 | torch.Size([96, 96, 1, 1]) || m_up1.1.conv1_1.weight
 | -0.001 | -0.307 |  0.339 |  0.086 | torch.Size([96]) || m_up1.1.conv1_1.bias
 |  0.034 | -0.239 |  0.403 |  0.332 | torch.Size([1, 1, 1, 1, 3]) || m_up1.1.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_up1.1.conv3d.bias
 | -0.001 | -0.580 |  0.739 |  0.088 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.0.weight
 |  0.000 | -0.609 |  0.791 |  0.096 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.2.weight
 |  1.912 | -0.269 |  2.774 |  0.774 | torch.Size([64, 16]) || m_up1.1.mamba_layers.0.mixer.A_log
 |  1.119 |  0.895 |  1.456 |  0.107 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.D
 | -0.001 | -0.472 |  0.594 |  0.128 | torch.Size([128, 32]) || m_up1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.013 | -0.558 |  0.418 |  0.176 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.0.mixer.conv1d.weight
 | -0.001 | -0.191 |  0.286 |  0.096 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.004 | -0.392 |  0.428 |  0.094 | torch.Size([34, 64]) || m_up1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.014 | -0.501 |  0.308 |  0.132 | torch.Size([64, 2]) || m_up1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.026 | -0.763 |  0.464 |  0.216 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.367 |  0.448 |  0.120 | torch.Size([32, 64]) || m_up1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.205 |  0.958 |  1.405 |  0.118 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.weight
 | -0.000 | -0.254 |  0.159 |  0.085 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.bias
 |  1.906 | -1.076 |  2.773 |  0.784 | torch.Size([64, 16]) || m_up1.1.mamba_layers.1.mixer.A_log
 |  1.175 |  1.024 |  1.306 |  0.057 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.D
 |  0.001 | -0.397 |  0.538 |  0.125 | torch.Size([128, 32]) || m_up1.1.mamba_layers.1.mixer.in_proj.weight
 | -0.010 | -0.520 |  0.369 |  0.162 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.1.mixer.conv1d.weight
 | -0.031 | -0.323 |  0.257 |  0.172 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.405 |  0.300 |  0.071 | torch.Size([34, 64]) || m_up1.1.mamba_layers.1.mixer.x_proj.weight
 | -0.013 | -0.379 |  0.279 |  0.087 | torch.Size([64, 2]) || m_up1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.092 | -0.090 |  0.508 |  0.089 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.004 | -0.653 |  0.485 |  0.130 | torch.Size([32, 64]) || m_up1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.177 |  0.898 |  1.354 |  0.093 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.weight
 |  0.005 | -0.154 |  0.219 |  0.095 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.bias
 |  1.916 | -0.077 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.2.mixer.A_log
 |  1.042 |  0.951 |  1.196 |  0.051 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.D
 | -0.003 | -0.352 |  0.418 |  0.115 | torch.Size([128, 32]) || m_up1.1.mamba_layers.2.mixer.in_proj.weight
 |  0.009 | -0.675 |  0.738 |  0.299 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.2.mixer.conv1d.weight
 |  0.009 | -0.532 |  0.507 |  0.309 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.207 |  0.271 |  0.083 | torch.Size([34, 64]) || m_up1.1.mamba_layers.2.mixer.x_proj.weight
 | -0.083 | -0.709 |  0.699 |  0.396 | torch.Size([64, 2]) || m_up1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.427 | -6.863 | -2.299 |  1.243 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.378 |  0.338 |  0.092 | torch.Size([32, 64]) || m_up1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.039 |  0.960 |  1.124 |  0.037 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.weight
 | -0.004 | -0.045 |  0.054 |  0.026 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.bias
 |  1.913 | -0.037 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.3.mixer.A_log
 |  1.034 |  0.960 |  1.157 |  0.039 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.321 |  0.307 |  0.110 | torch.Size([128, 32]) || m_up1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.011 | -0.527 |  0.584 |  0.299 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.3.mixer.conv1d.weight
 | -0.004 | -0.568 |  0.555 |  0.334 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.002 | -0.228 |  0.241 |  0.084 | torch.Size([34, 64]) || m_up1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.750 |  0.694 |  0.410 | torch.Size([64, 2]) || m_up1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.496 | -6.871 | -2.320 |  1.353 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.002 | -0.268 |  0.276 |  0.090 | torch.Size([32, 64]) || m_up1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.027 |  0.945 |  1.105 |  0.043 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.weight
 | -0.002 | -0.078 |  0.086 |  0.032 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.bias
 |  0.534 |  0.169 |  0.899 |  0.516 | torch.Size([2]) || m_up1.1.pcbam_module.h_cw.weight
 | -0.062 | -0.153 |  0.071 |  0.118 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.h_cw.conv.weight
 |  0.071 |  0.007 |  0.135 |  0.090 | torch.Size([2]) || m_up1.1.pcbam_module.w_hc.weight
 | -0.094 | -0.247 |  0.109 |  0.183 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.w_hc.conv.weight
 |  0.448 |  0.106 |  0.790 |  0.484 | torch.Size([2]) || m_up1.1.pcbam_module.c_hw.weight
 |  0.005 | -0.238 |  0.343 |  0.302 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.c_hw.conv.weight
 |  1.263 |  0.911 |  1.601 |  0.171 | torch.Size([32]) || m_up1.2.trans_block.ln1.weight
 |  0.013 | -0.485 |  0.576 |  0.206 | torch.Size([32]) || m_up1.2.trans_block.ln1.bias
 | -0.118 | -1.198 |  0.586 |  0.346 | torch.Size([1, 15, 15]) || m_up1.2.trans_block.msa.relative_position_params
 | -0.001 | -0.616 |  0.734 |  0.149 | torch.Size([96, 32, 1, 1]) || m_up1.2.trans_block.msa.embedding_layer1.weight
 | -0.003 | -0.197 |  0.128 |  0.040 | torch.Size([96]) || m_up1.2.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.195 |  0.184 |  0.053 | torch.Size([32, 32, 1, 1]) || m_up1.2.trans_block.msa.linear1.weight
 |  0.001 | -0.112 |  0.151 |  0.047 | torch.Size([32]) || m_up1.2.trans_block.msa.linear1.bias
 |  1.024 |  0.791 |  1.249 |  0.102 | torch.Size([32]) || m_up1.2.trans_block.ln2.weight
 | -0.006 | -0.205 |  0.225 |  0.086 | torch.Size([32]) || m_up1.2.trans_block.ln2.bias
 |  0.001 | -0.580 |  0.437 |  0.086 | torch.Size([128, 32]) || m_up1.2.trans_block.mlp.0.weight
 | -0.004 | -0.232 |  0.101 |  0.051 | torch.Size([128]) || m_up1.2.trans_block.mlp.0.bias
 | -0.001 | -0.346 |  0.393 |  0.094 | torch.Size([32, 128]) || m_up1.2.trans_block.mlp.2.weight
 |  0.001 | -0.117 |  0.278 |  0.072 | torch.Size([32]) || m_up1.2.trans_block.mlp.2.bias
 | -0.002 | -0.750 |  0.498 |  0.110 | torch.Size([96, 96, 1, 1]) || m_up1.2.conv1_1.weight
 | -0.003 | -0.282 |  0.444 |  0.078 | torch.Size([96]) || m_up1.2.conv1_1.bias
 |  0.117 | -0.021 |  0.338 |  0.194 | torch.Size([1, 1, 1, 1, 3]) || m_up1.2.conv3d.weight
 |  0.004 |  0.004 |  0.004 |    nan | torch.Size([1]) || m_up1.2.conv3d.bias
 |  0.002 | -0.320 |  0.549 |  0.080 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.0.weight
 | -0.000 | -0.540 |  0.748 |  0.094 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.2.weight
 |  1.913 | -0.753 |  2.773 |  0.776 | torch.Size([64, 16]) || m_up1.2.mamba_layers.0.mixer.A_log
 |  1.120 |  0.955 |  1.387 |  0.078 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.D
 |  0.001 | -0.489 |  0.479 |  0.126 | torch.Size([128, 32]) || m_up1.2.mamba_layers.0.mixer.in_proj.weight
 | -0.004 | -0.395 |  0.424 |  0.167 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.0.mixer.conv1d.weight
 |  0.007 | -0.098 |  0.152 |  0.051 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.566 |  0.352 |  0.103 | torch.Size([34, 64]) || m_up1.2.mamba_layers.0.mixer.x_proj.weight
 | -0.001 | -0.106 |  0.167 |  0.042 | torch.Size([64, 2]) || m_up1.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.027 | -0.378 |  0.671 |  0.189 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.383 |  0.439 |  0.115 | torch.Size([32, 64]) || m_up1.2.mamba_layers.0.mixer.out_proj.weight
 |  1.246 |  0.882 |  1.462 |  0.114 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.weight
 |  0.016 | -0.256 |  0.314 |  0.111 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.bias
 |  1.913 | -0.577 |  2.783 |  0.779 | torch.Size([64, 16]) || m_up1.2.mamba_layers.1.mixer.A_log
 |  1.195 |  0.986 |  1.449 |  0.106 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.D
 |  0.001 | -0.636 |  0.663 |  0.143 | torch.Size([128, 32]) || m_up1.2.mamba_layers.1.mixer.in_proj.weight
 |  0.014 | -0.615 |  0.620 |  0.189 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.1.mixer.conv1d.weight
 |  0.018 | -0.242 |  0.224 |  0.107 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.conv1d.bias
 |  0.001 | -0.548 |  0.606 |  0.124 | torch.Size([34, 64]) || m_up1.2.mamba_layers.1.mixer.x_proj.weight
 | -0.061 | -0.503 |  0.230 |  0.159 | torch.Size([64, 2]) || m_up1.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.040 | -0.457 |  0.531 |  0.164 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.dt_proj.bias
 | -0.002 | -0.752 |  0.567 |  0.149 | torch.Size([32, 64]) || m_up1.2.mamba_layers.1.mixer.out_proj.weight
 |  1.223 |  0.911 |  1.374 |  0.109 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.weight
 |  0.007 | -0.147 |  0.120 |  0.056 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.bias
 |  1.917 | -0.060 |  2.777 |  0.765 | torch.Size([64, 16]) || m_up1.2.mamba_layers.2.mixer.A_log
 |  1.021 |  0.927 |  1.202 |  0.050 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.D
 |  0.000 | -0.343 |  0.361 |  0.112 | torch.Size([128, 32]) || m_up1.2.mamba_layers.2.mixer.in_proj.weight
 | -0.022 | -0.604 |  0.593 |  0.286 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.2.mixer.conv1d.weight
 |  0.012 | -0.542 |  0.514 |  0.328 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.conv1d.bias
 |  0.003 | -0.276 |  0.231 |  0.078 | torch.Size([34, 64]) || m_up1.2.mamba_layers.2.mixer.x_proj.weight
 |  0.070 | -0.709 |  0.676 |  0.392 | torch.Size([64, 2]) || m_up1.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.717 | -6.824 | -2.340 |  1.384 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.002 | -0.314 |  0.283 |  0.094 | torch.Size([32, 64]) || m_up1.2.mamba_layers.2.mixer.out_proj.weight
 |  1.025 |  0.904 |  1.121 |  0.057 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.weight
 |  0.001 | -0.062 |  0.060 |  0.034 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.bias
 |  1.916 | -0.118 |  2.776 |  0.767 | torch.Size([64, 16]) || m_up1.2.mamba_layers.3.mixer.A_log
 |  1.015 |  0.921 |  1.157 |  0.045 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.D
 | -0.002 | -0.435 |  0.506 |  0.114 | torch.Size([128, 32]) || m_up1.2.mamba_layers.3.mixer.in_proj.weight
 |  0.016 | -0.637 |  0.586 |  0.302 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.3.mixer.conv1d.weight
 |  0.091 | -0.433 |  0.564 |  0.285 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.conv1d.bias
 | -0.005 | -0.276 |  0.246 |  0.079 | torch.Size([34, 64]) || m_up1.2.mamba_layers.3.mixer.x_proj.weight
 | -0.116 | -0.708 |  0.685 |  0.390 | torch.Size([64, 2]) || m_up1.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.761 | -6.866 | -2.274 |  1.307 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.002 | -0.400 |  0.325 |  0.095 | torch.Size([32, 64]) || m_up1.2.mamba_layers.3.mixer.out_proj.weight
 |  1.032 |  0.963 |  1.197 |  0.051 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.weight
 | -0.002 | -0.062 |  0.089 |  0.031 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.bias
 |  0.664 |  0.454 |  0.873 |  0.296 | torch.Size([2]) || m_up1.2.pcbam_module.h_cw.weight
 |  0.129 |  0.068 |  0.176 |  0.055 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.h_cw.conv.weight
 |  0.184 |  0.084 |  0.285 |  0.142 | torch.Size([2]) || m_up1.2.pcbam_module.w_hc.weight
 | -0.027 | -0.168 |  0.221 |  0.215 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.w_hc.conv.weight
 |  0.235 |  0.091 |  0.378 |  0.203 | torch.Size([2]) || m_up1.2.pcbam_module.c_hw.weight
 |  0.045 | -0.094 |  0.166 |  0.130 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.c_hw.conv.weight
 |  0.000 | -0.074 |  0.062 |  0.012 | torch.Size([3, 96, 3, 3]) || m_tail.0.weight
 | -0.019 | -0.129 |  0.139 |  0.092 | torch.Size([3, 3, 1, 1]) || fft.mag.weight
 |  0.178 | -0.197 |  0.457 |  0.338 | torch.Size([3]) || fft.mag.bias
 |  0.158 |  0.030 |  0.316 |  0.146 | torch.Size([3]) || fft.mag_bn.weight
 | -0.841 | -2.256 | -0.120 |  1.225 | torch.Size([3]) || fft.mag_bn.bias
 | -2.702 | -12.408 | 10.262 | 11.681 | torch.Size([3]) || fft.mag_bn.running_mean
 | 438.558 | 183.946 | 672.207 | 244.805 | torch.Size([3]) || fft.mag_bn.running_var
 |  0.008 | -0.300 |  0.173 |  0.159 | torch.Size([3, 3, 1, 1]) || fft.pha.0.weight
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.0.bias
 |  1.211 |  0.873 |  1.464 |  0.305 | torch.Size([3]) || fft.pha.1.weight
 |  0.352 |  0.232 |  0.427 |  0.105 | torch.Size([3]) || fft.pha.1.bias
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.1.running_mean
 |  0.025 |  0.019 |  0.036 |  0.009 | torch.Size([3]) || fft.pha.1.running_var
 | -0.089 | -0.696 |  0.924 |  0.529 | torch.Size([3, 3, 1, 1]) || fft.pha.3.weight
 |  0.013 | -0.156 |  0.155 |  0.157 | torch.Size([3]) || fft.pha.3.bias
 |  0.375 | -0.152 |  2.389 |  0.989 | torch.Size([1, 6, 1, 1]) || fft.conv1.weight
 |  0.024 |  0.024 |  0.024 |    nan | torch.Size([1]) || fft.conv1.bias
 | -0.000 | -0.083 |  0.078 |  0.023 | torch.Size([96, 96, 1, 1]) || conv1.weight
 | -0.000 | -0.016 |  0.021 |  0.005 | torch.Size([96]) || conv1.bias
 |  0.376 |  0.000 |  0.886 |  0.224 | torch.Size([96]) || bn1.weight
 | -0.107 | -0.254 | -0.011 |  0.053 | torch.Size([96]) || bn1.bias
 | -0.001 | -0.037 |  0.043 |  0.025 | torch.Size([96]) || bn1.running_mean
 |  0.002 |  0.000 |  0.006 |  0.001 | torch.Size([96]) || bn1.running_var
 | -0.002 | -0.065 |  0.057 |  0.014 | torch.Size([192, 96, 2, 2]) || conv2.weight
 | -0.000 | -0.011 |  0.012 |  0.004 | torch.Size([192]) || conv2.bias
 |  0.394 |  0.013 |  0.884 |  0.227 | torch.Size([192]) || bn2.weight
 | -0.093 | -0.230 | -0.012 |  0.044 | torch.Size([192]) || bn2.bias
 | -0.022 | -0.101 |  0.081 |  0.040 | torch.Size([192]) || bn2.running_mean
 |  0.027 |  0.000 |  0.088 |  0.017 | torch.Size([192]) || bn2.running_var
 | -0.001 | -0.044 |  0.041 |  0.007 | torch.Size([384, 96, 4, 4]) || conv3.weight
 | -0.000 | -0.022 |  0.014 |  0.005 | torch.Size([384]) || conv3.bias
 |  0.425 |  0.030 |  0.914 |  0.224 | torch.Size([384]) || bn3.weight
 | -0.074 | -0.214 |  0.040 |  0.038 | torch.Size([384]) || bn3.bias
 | -0.055 | -0.166 |  0.140 |  0.038 | torch.Size([384]) || bn3.running_mean
 |  0.073 |  0.004 |  0.263 |  0.036 | torch.Size([384]) || bn3.running_var

25-05-15 11:50:30.068 : <epoch: 12, iter:   5,000, lr:1.000e-05> G_loss: 2.616e-06 
25-05-15 11:50:30.069 : Saving the model.
25-05-15 11:50:31.586 : ---1-->      0.png | 28.48dB
25-05-15 11:50:32.277 : ---2-->      1.png | 30.37dB
25-05-15 11:50:32.973 : ---3-->     10.png | 28.26dB
25-05-15 11:50:33.675 : ---4-->    100.png | 30.54dB
25-05-15 11:50:34.380 : ---5-->     11.png | 29.37dB
25-05-15 11:50:35.086 : ---6-->     12.png | 28.58dB
25-05-15 11:50:35.790 : ---7-->     13.png | 29.74dB
25-05-15 11:50:36.497 : ---8-->     14.png | 28.82dB
25-05-15 11:50:37.203 : ---9-->     15.png | 29.02dB
25-05-15 11:50:37.900 : --10-->     16.png | 29.25dB
25-05-15 11:50:38.602 : --11-->     17.png | 29.55dB
25-05-15 11:50:39.318 : --12-->     18.png | 28.94dB
25-05-15 11:50:40.026 : --13-->     19.png | 28.15dB
25-05-15 11:50:40.736 : --14-->      2.png | 29.37dB
25-05-15 11:50:41.438 : --15-->     20.png | 28.74dB
25-05-15 11:50:42.133 : --16-->     21.png | 29.47dB
25-05-15 11:50:42.840 : --17-->     22.png | 29.51dB
25-05-15 11:50:43.538 : --18-->     23.png | 29.72dB
25-05-15 11:50:44.236 : --19-->     24.png | 29.64dB
25-05-15 11:50:44.938 : --20-->     25.png | 27.90dB
25-05-15 11:50:45.639 : --21-->     26.png | 28.68dB
25-05-15 11:50:46.343 : --22-->     27.png | 28.87dB
25-05-15 11:50:47.051 : --23-->     28.png | 28.39dB
25-05-15 11:50:47.745 : --24-->     29.png | 29.29dB
25-05-15 11:50:48.455 : --25-->      3.png | 29.57dB
25-05-15 11:50:49.153 : --26-->     30.png | 29.83dB
25-05-15 11:50:49.858 : --27-->     31.png | 30.69dB
25-05-15 11:50:50.553 : --28-->     32.png | 28.92dB
25-05-15 11:50:51.247 : --29-->     33.png | 29.35dB
25-05-15 11:50:51.945 : --30-->     34.png | 28.85dB
25-05-15 11:50:52.636 : --31-->     35.png | 29.19dB
25-05-15 11:50:53.332 : --32-->     36.png | 28.81dB
25-05-15 11:50:54.040 : --33-->     37.png | 29.28dB
25-05-15 11:50:54.749 : --34-->     38.png | 29.12dB
25-05-15 11:50:55.459 : --35-->     39.png | 30.30dB
25-05-15 11:50:56.157 : --36-->      4.png | 29.41dB
25-05-15 11:50:56.854 : --37-->     40.png | 29.93dB
25-05-15 11:50:57.552 : --38-->     41.png | 29.62dB
25-05-15 11:50:58.250 : --39-->     42.png | 29.19dB
25-05-15 11:50:58.947 : --40-->     43.png | 29.79dB
25-05-15 11:50:59.645 : --41-->     44.png | 29.15dB
25-05-15 11:51:00.351 : --42-->     45.png | 29.18dB
25-05-15 11:51:01.054 : --43-->     46.png | 28.90dB
25-05-15 11:51:01.757 : --44-->     47.png | 28.66dB
25-05-15 11:51:02.454 : --45-->     48.png | 29.75dB
25-05-15 11:51:03.149 : --46-->     49.png | 30.23dB
25-05-15 11:51:03.851 : --47-->      5.png | 28.87dB
25-05-15 11:51:04.549 : --48-->     50.png | 30.02dB
25-05-15 11:51:05.244 : --49-->     51.png | 27.79dB
25-05-15 11:51:05.937 : --50-->     52.png | 29.30dB
25-05-15 11:51:06.629 : --51-->     53.png | 29.86dB
25-05-15 11:51:07.323 : --52-->     54.png | 33.79dB
25-05-15 11:51:08.019 : --53-->     55.png | 32.84dB
25-05-15 11:51:08.719 : --54-->     56.png | 33.87dB
25-05-15 11:51:09.426 : --55-->     57.png | 33.77dB
25-05-15 11:51:10.141 : --56-->     58.png | 33.89dB
25-05-15 11:51:10.848 : --57-->     59.png | 33.14dB
25-05-15 11:51:11.542 : --58-->      6.png | 30.15dB
25-05-15 11:51:12.238 : --59-->     60.png | 32.67dB
25-05-15 11:51:12.938 : --60-->     61.png | 33.32dB
25-05-15 11:51:13.635 : --61-->     62.png | 32.98dB
25-05-15 11:51:14.336 : --62-->     63.png | 32.56dB
25-05-15 11:51:15.038 : --63-->     64.png | 32.42dB
25-05-15 11:51:15.735 : --64-->     65.png | 32.68dB
25-05-15 11:51:16.433 : --65-->     66.png | 33.85dB
25-05-15 11:51:17.127 : --66-->     67.png | 33.54dB
25-05-15 11:51:17.829 : --67-->     68.png | 33.33dB
25-05-15 11:51:18.536 : --68-->     69.png | 33.83dB
25-05-15 11:51:19.242 : --69-->      7.png | 29.04dB
25-05-15 11:51:19.940 : --70-->     70.png | 32.83dB
25-05-15 11:51:20.641 : --71-->     71.png | 31.20dB
25-05-15 11:51:21.346 : --72-->     72.png | 32.68dB
25-05-15 11:51:22.055 : --73-->     73.png | 31.08dB
25-05-15 11:51:22.758 : --74-->     74.png | 31.51dB
25-05-15 11:51:23.455 : --75-->     75.png | 32.67dB
25-05-15 11:51:24.149 : --76-->     76.png | 33.51dB
25-05-15 11:51:24.847 : --77-->     77.png | 33.50dB
25-05-15 11:51:25.553 : --78-->     78.png | 32.95dB
25-05-15 11:51:26.264 : --79-->     79.png | 31.20dB
25-05-15 11:51:26.970 : --80-->      8.png | 28.93dB
25-05-15 11:51:27.673 : --81-->     80.png | 31.23dB
25-05-15 11:51:28.367 : --82-->     81.png | 32.10dB
25-05-15 11:51:29.067 : --83-->     82.png | 32.22dB
25-05-15 11:51:29.776 : --84-->     83.png | 31.87dB
25-05-15 11:51:30.473 : --85-->     84.png | 30.57dB
25-05-15 11:51:31.176 : --86-->     85.png | 32.52dB
25-05-15 11:51:31.882 : --87-->     86.png | 33.03dB
25-05-15 11:51:32.587 : --88-->     87.png | 33.32dB
25-05-15 11:51:33.286 : --89-->     88.png | 29.57dB
25-05-15 11:51:33.983 : --90-->     89.png | 32.09dB
25-05-15 11:51:34.690 : --91-->      9.png | 28.74dB
25-05-15 11:51:35.389 : --92-->     90.png | 33.08dB
25-05-15 11:51:36.095 : --93-->     91.png | 31.45dB
25-05-15 11:51:36.797 : --94-->     92.png | 31.53dB
25-05-15 11:51:37.498 : --95-->     93.png | 31.94dB
25-05-15 11:51:38.198 : --96-->     94.png | 32.99dB
25-05-15 11:51:38.895 : --97-->     95.png | 31.45dB
25-05-15 11:51:39.590 : --98-->     96.png | 32.65dB
25-05-15 11:51:40.304 : --99-->     97.png | 32.49dB
25-05-15 11:51:41.001 : -100-->     98.png | 32.10dB
25-05-15 11:51:41.702 : -101-->     99.png | 32.07dB
25-05-15 11:51:41.716 : <epoch: 12, iter:   5,000, Average PSNR : 30.74dB

25-05-15 12:35:19.017 : <epoch: 25, iter:  10,000, lr:1.000e-05> G_loss: 1.597e-04 
25-05-15 12:35:19.018 : Saving the model.
25-05-15 12:35:20.604 : ---1-->      0.png | 28.48dB
25-05-15 12:35:21.352 : ---2-->      1.png | 30.38dB
25-05-15 12:35:22.112 : ---3-->     10.png | 28.26dB
25-05-15 12:35:22.867 : ---4-->    100.png | 30.54dB
25-05-15 12:35:23.617 : ---5-->     11.png | 29.37dB
25-05-15 12:35:24.421 : ---6-->     12.png | 28.58dB
25-05-15 12:35:25.187 : ---7-->     13.png | 29.75dB
25-05-15 12:35:25.950 : ---8-->     14.png | 28.81dB
25-05-15 12:35:26.709 : ---9-->     15.png | 29.03dB
25-05-15 12:35:27.462 : --10-->     16.png | 29.25dB
25-05-15 12:35:28.225 : --11-->     17.png | 29.55dB
25-05-15 12:35:28.990 : --12-->     18.png | 28.94dB
25-05-15 12:35:29.747 : --13-->     19.png | 28.14dB
25-05-15 12:35:30.516 : --14-->      2.png | 29.37dB
25-05-15 12:35:31.271 : --15-->     20.png | 28.74dB
25-05-15 12:35:32.024 : --16-->     21.png | 29.46dB
25-05-15 12:35:32.780 : --17-->     22.png | 29.51dB
25-05-15 12:35:33.540 : --18-->     23.png | 29.73dB
25-05-15 12:35:34.300 : --19-->     24.png | 29.65dB
25-05-15 12:35:35.069 : --20-->     25.png | 27.90dB
25-05-15 12:35:35.824 : --21-->     26.png | 28.68dB
25-05-15 12:35:36.583 : --22-->     27.png | 28.87dB
25-05-15 12:35:37.349 : --23-->     28.png | 28.38dB
25-05-15 12:35:38.106 : --24-->     29.png | 29.28dB
25-05-15 12:35:36.360 : --25-->      3.png | 29.58dB
25-05-15 12:35:37.115 : --26-->     30.png | 29.84dB
25-05-15 12:35:37.875 : --27-->     31.png | 30.69dB
25-05-15 12:35:38.634 : --28-->     32.png | 28.92dB
25-05-15 12:35:39.394 : --29-->     33.png | 29.36dB
25-05-15 12:35:40.153 : --30-->     34.png | 28.85dB
25-05-15 12:35:40.925 : --31-->     35.png | 29.19dB
25-05-15 12:35:41.677 : --32-->     36.png | 28.81dB
25-05-15 12:35:42.434 : --33-->     37.png | 29.28dB
25-05-15 12:35:43.197 : --34-->     38.png | 29.12dB
25-05-15 12:35:43.962 : --35-->     39.png | 30.30dB
25-05-15 12:35:44.728 : --36-->      4.png | 29.41dB
25-05-15 12:35:45.500 : --37-->     40.png | 29.94dB
25-05-15 12:35:46.257 : --38-->     41.png | 29.63dB
25-05-15 12:35:47.008 : --39-->     42.png | 29.19dB
25-05-15 12:35:47.770 : --40-->     43.png | 29.80dB
25-05-15 12:35:48.528 : --41-->     44.png | 29.15dB
25-05-15 12:35:49.286 : --42-->     45.png | 29.18dB
25-05-15 12:35:50.061 : --43-->     46.png | 28.91dB
25-05-15 12:35:50.814 : --44-->     47.png | 28.66dB
25-05-15 12:35:51.564 : --45-->     48.png | 29.75dB
25-05-15 12:35:52.331 : --46-->     49.png | 30.23dB
25-05-15 12:35:53.084 : --47-->      5.png | 28.87dB
25-05-15 12:35:53.844 : --48-->     50.png | 30.02dB
25-05-15 12:35:54.607 : --49-->     51.png | 27.78dB
25-05-15 12:35:55.366 : --50-->     52.png | 29.30dB
25-05-15 12:35:56.126 : --51-->     53.png | 29.87dB
25-05-15 12:35:56.879 : --52-->     54.png | 33.79dB
25-05-15 12:35:57.632 : --53-->     55.png | 32.84dB
25-05-15 12:35:58.404 : --54-->     56.png | 33.86dB
25-05-15 12:35:59.166 : --55-->     57.png | 33.77dB
25-05-15 12:35:59.926 : --56-->     58.png | 33.89dB
25-05-15 12:36:00.685 : --57-->     59.png | 33.13dB
25-05-15 12:36:01.445 : --58-->      6.png | 30.16dB
25-05-15 12:36:02.203 : --59-->     60.png | 32.67dB
25-05-15 12:36:02.955 : --60-->     61.png | 33.31dB
25-05-15 12:36:03.722 : --61-->     62.png | 32.98dB
25-05-15 12:36:04.481 : --62-->     63.png | 32.55dB
25-05-15 12:36:05.240 : --63-->     64.png | 32.42dB
25-05-15 12:36:06.003 : --64-->     65.png | 32.68dB
25-05-15 12:36:06.770 : --65-->     66.png | 33.85dB
25-05-15 12:36:07.527 : --66-->     67.png | 33.53dB
25-05-15 12:36:08.303 : --67-->     68.png | 33.32dB
25-05-15 12:36:06.534 : --68-->     69.png | 33.83dB
25-05-15 12:36:07.292 : --69-->      7.png | 29.04dB
25-05-15 12:36:08.041 : --70-->     70.png | 32.83dB
25-05-15 12:36:08.785 : --71-->     71.png | 31.19dB
25-05-15 12:36:09.540 : --72-->     72.png | 32.68dB
25-05-15 12:36:10.294 : --73-->     73.png | 31.08dB
25-05-15 12:36:11.057 : --74-->     74.png | 31.51dB
25-05-15 12:36:11.809 : --75-->     75.png | 32.66dB
25-05-15 12:36:12.565 : --76-->     76.png | 33.50dB
25-05-15 12:36:13.327 : --77-->     77.png | 33.49dB
25-05-15 12:36:14.099 : --78-->     78.png | 32.94dB
25-05-15 12:36:14.856 : --79-->     79.png | 31.20dB
25-05-15 12:36:15.612 : --80-->      8.png | 28.93dB
25-05-15 12:36:16.372 : --81-->     80.png | 31.22dB
25-05-15 12:36:17.129 : --82-->     81.png | 32.10dB
25-05-15 12:36:17.883 : --83-->     82.png | 32.23dB
25-05-15 12:36:18.642 : --84-->     83.png | 31.87dB
25-05-15 12:36:19.397 : --85-->     84.png | 30.57dB
25-05-15 12:36:20.163 : --86-->     85.png | 32.51dB
25-05-15 12:36:20.918 : --87-->     86.png | 33.02dB
25-05-15 12:36:21.671 : --88-->     87.png | 33.31dB
25-05-15 12:36:22.430 : --89-->     88.png | 29.57dB
25-05-15 12:36:23.180 : --90-->     89.png | 32.08dB
25-05-15 12:36:23.936 : --91-->      9.png | 28.73dB
25-05-15 12:36:24.698 : --92-->     90.png | 33.08dB
25-05-15 12:36:25.450 : --93-->     91.png | 31.46dB
25-05-15 12:36:26.206 : --94-->     92.png | 31.52dB
25-05-15 12:36:26.957 : --95-->     93.png | 31.93dB
25-05-15 12:36:27.714 : --96-->     94.png | 32.99dB
25-05-15 12:36:28.471 : --97-->     95.png | 31.44dB
25-05-15 12:36:29.242 : --98-->     96.png | 32.64dB
25-05-15 12:36:30.013 : --99-->     97.png | 32.48dB
25-05-15 12:36:30.771 : -100-->     98.png | 32.09dB
25-05-15 12:36:31.524 : -101-->     99.png | 32.06dB
25-05-15 12:36:31.539 : <epoch: 25, iter:  10,000, Average PSNR : 30.74dB

25-05-15 13:20:16.037 : <epoch: 38, iter:  15,000, lr:1.000e-05> G_loss: 3.010e-06 
25-05-15 13:20:16.039 : Saving the model.
25-05-15 13:20:17.465 : ---1-->      0.png | 28.48dB
25-05-15 13:20:18.224 : ---2-->      1.png | 30.38dB
25-05-15 13:20:18.988 : ---3-->     10.png | 28.26dB
25-05-15 13:20:19.738 : ---4-->    100.png | 30.54dB
25-05-15 13:20:20.490 : ---5-->     11.png | 29.37dB
25-05-15 13:20:21.260 : ---6-->     12.png | 28.58dB
25-05-15 13:20:22.016 : ---7-->     13.png | 29.75dB
25-05-15 13:20:22.785 : ---8-->     14.png | 28.82dB
25-05-15 13:20:20.991 : ---9-->     15.png | 29.03dB
25-05-15 13:20:21.742 : --10-->     16.png | 29.25dB
25-05-15 13:20:22.491 : --11-->     17.png | 29.55dB
25-05-15 13:20:23.254 : --12-->     18.png | 28.94dB
25-05-15 13:20:24.012 : --13-->     19.png | 28.14dB
25-05-15 13:20:24.767 : --14-->      2.png | 29.37dB
25-05-15 13:20:25.516 : --15-->     20.png | 28.75dB
25-05-15 13:20:26.272 : --16-->     21.png | 29.47dB
25-05-15 13:20:27.020 : --17-->     22.png | 29.52dB
25-05-15 13:20:27.776 : --18-->     23.png | 29.73dB
25-05-15 13:20:28.532 : --19-->     24.png | 29.65dB
25-05-15 13:20:29.292 : --20-->     25.png | 27.90dB
25-05-15 13:20:30.060 : --21-->     26.png | 28.68dB
25-05-15 13:20:30.813 : --22-->     27.png | 28.87dB
25-05-15 13:20:31.572 : --23-->     28.png | 28.39dB
25-05-15 13:20:32.327 : --24-->     29.png | 29.29dB
25-05-15 13:20:33.093 : --25-->      3.png | 29.58dB
25-05-15 13:20:33.848 : --26-->     30.png | 29.84dB
25-05-15 13:20:34.598 : --27-->     31.png | 30.69dB
25-05-15 13:20:35.352 : --28-->     32.png | 28.93dB
25-05-15 13:20:36.111 : --29-->     33.png | 29.36dB
25-05-15 13:20:36.866 : --30-->     34.png | 28.85dB
25-05-15 13:20:37.649 : --31-->     35.png | 29.20dB
25-05-15 13:20:38.409 : --32-->     36.png | 28.82dB
25-05-15 13:20:39.167 : --33-->     37.png | 29.28dB
25-05-15 13:20:39.926 : --34-->     38.png | 29.12dB
25-05-15 13:20:40.690 : --35-->     39.png | 30.30dB
25-05-15 13:20:41.447 : --36-->      4.png | 29.42dB
25-05-15 13:20:42.206 : --37-->     40.png | 29.94dB
25-05-15 13:20:42.964 : --38-->     41.png | 29.63dB
25-05-15 13:20:43.726 : --39-->     42.png | 29.19dB
25-05-15 13:20:44.484 : --40-->     43.png | 29.80dB
25-05-15 13:20:45.240 : --41-->     44.png | 29.15dB
25-05-15 13:20:46.001 : --42-->     45.png | 29.18dB
25-05-15 13:20:46.767 : --43-->     46.png | 28.91dB
25-05-15 13:20:47.533 : --44-->     47.png | 28.66dB
25-05-15 13:20:48.301 : --45-->     48.png | 29.75dB
25-05-15 13:20:49.067 : --46-->     49.png | 30.23dB
25-05-15 13:20:49.832 : --47-->      5.png | 28.88dB
25-05-15 13:20:50.597 : --48-->     50.png | 30.02dB
25-05-15 13:20:51.357 : --49-->     51.png | 27.78dB
25-05-15 13:20:52.118 : --50-->     52.png | 29.30dB
25-05-15 13:20:52.874 : --51-->     53.png | 29.87dB
25-05-15 13:20:51.149 : --52-->     54.png | 33.78dB
25-05-15 13:20:51.919 : --53-->     55.png | 32.84dB
25-05-15 13:20:52.676 : --54-->     56.png | 33.86dB
25-05-15 13:20:53.433 : --55-->     57.png | 33.76dB
25-05-15 13:20:54.206 : --56-->     58.png | 33.88dB
25-05-15 13:20:54.966 : --57-->     59.png | 33.13dB
25-05-15 13:20:55.724 : --58-->      6.png | 30.16dB
25-05-15 13:20:56.499 : --59-->     60.png | 32.66dB
25-05-15 13:20:57.268 : --60-->     61.png | 33.30dB
25-05-15 13:20:58.042 : --61-->     62.png | 32.98dB
25-05-15 13:20:58.805 : --62-->     63.png | 32.55dB
25-05-15 13:20:59.565 : --63-->     64.png | 32.42dB
25-05-15 13:21:00.325 : --64-->     65.png | 32.68dB
25-05-15 13:21:01.073 : --65-->     66.png | 33.84dB
25-05-15 13:21:01.822 : --66-->     67.png | 33.52dB
25-05-15 13:21:02.574 : --67-->     68.png | 33.32dB
25-05-15 13:21:03.325 : --68-->     69.png | 33.82dB
25-05-15 13:21:04.077 : --69-->      7.png | 29.04dB
25-05-15 13:21:04.838 : --70-->     70.png | 32.82dB
25-05-15 13:21:05.594 : --71-->     71.png | 31.19dB
25-05-15 13:21:06.352 : --72-->     72.png | 32.68dB
25-05-15 13:21:07.116 : --73-->     73.png | 31.08dB
25-05-15 13:21:07.874 : --74-->     74.png | 31.51dB
25-05-15 13:21:08.637 : --75-->     75.png | 32.66dB
25-05-15 13:21:09.392 : --76-->     76.png | 33.50dB
25-05-15 13:21:10.147 : --77-->     77.png | 33.49dB
25-05-15 13:21:10.905 : --78-->     78.png | 32.94dB
25-05-15 13:21:11.658 : --79-->     79.png | 31.20dB
25-05-15 13:21:12.416 : --80-->      8.png | 28.93dB
25-05-15 13:21:13.176 : --81-->     80.png | 31.22dB
25-05-15 13:21:13.930 : --82-->     81.png | 32.09dB
25-05-15 13:21:14.689 : --83-->     82.png | 32.22dB
25-05-15 13:21:15.442 : --84-->     83.png | 31.87dB
25-05-15 13:21:16.202 : --85-->     84.png | 30.57dB
25-05-15 13:21:16.965 : --86-->     85.png | 32.51dB
25-05-15 13:21:17.724 : --87-->     86.png | 33.02dB
25-05-15 13:21:18.477 : --88-->     87.png | 33.30dB
25-05-15 13:21:19.236 : --89-->     88.png | 29.56dB
25-05-15 13:21:20.006 : --90-->     89.png | 32.07dB
25-05-15 13:21:20.768 : --91-->      9.png | 28.74dB
25-05-15 13:21:21.528 : --92-->     90.png | 33.08dB
25-05-15 13:21:22.284 : --93-->     91.png | 31.46dB
25-05-15 13:21:23.038 : --94-->     92.png | 31.53dB
25-05-15 13:21:21.293 : --95-->     93.png | 31.93dB
25-05-15 13:21:22.068 : --96-->     94.png | 32.99dB
25-05-15 13:21:22.820 : --97-->     95.png | 31.44dB
25-05-15 13:21:23.594 : --98-->     96.png | 32.64dB
25-05-15 13:21:24.342 : --99-->     97.png | 32.48dB
25-05-15 13:21:25.098 : -100-->     98.png | 32.09dB
25-05-15 13:21:25.858 : -101-->     99.png | 32.06dB
25-05-15 13:21:25.877 : <epoch: 38, iter:  15,000, Average PSNR : 30.74dB

25-05-15 14:05:04.197 : <epoch: 51, iter:  20,000, lr:1.000e-05> G_loss: 2.577e-06 
25-05-15 14:05:04.198 : Saving the model.
25-05-15 14:05:05.686 : ---1-->      0.png | 28.48dB
25-05-15 14:05:06.445 : ---2-->      1.png | 30.38dB
25-05-15 14:05:07.188 : ---3-->     10.png | 28.26dB
25-05-15 14:05:07.935 : ---4-->    100.png | 30.54dB
25-05-15 14:05:08.684 : ---5-->     11.png | 29.38dB
25-05-15 14:05:09.437 : ---6-->     12.png | 28.59dB
25-05-15 14:05:10.193 : ---7-->     13.png | 29.76dB
25-05-15 14:05:10.947 : ---8-->     14.png | 28.82dB
25-05-15 14:05:11.702 : ---9-->     15.png | 29.03dB
25-05-15 14:05:12.461 : --10-->     16.png | 29.25dB
25-05-15 14:05:13.216 : --11-->     17.png | 29.55dB
25-05-15 14:05:13.968 : --12-->     18.png | 28.94dB
25-05-15 14:05:14.713 : --13-->     19.png | 28.14dB
25-05-15 14:05:15.459 : --14-->      2.png | 29.38dB
25-05-15 14:05:16.203 : --15-->     20.png | 28.75dB
25-05-15 14:05:16.957 : --16-->     21.png | 29.47dB
25-05-15 14:05:17.706 : --17-->     22.png | 29.52dB
25-05-15 14:05:18.459 : --18-->     23.png | 29.73dB
25-05-15 14:05:19.212 : --19-->     24.png | 29.64dB
25-05-15 14:05:19.968 : --20-->     25.png | 27.90dB
25-05-15 14:05:20.727 : --21-->     26.png | 28.68dB
25-05-15 14:05:21.486 : --22-->     27.png | 28.87dB
25-05-15 14:05:22.249 : --23-->     28.png | 28.39dB
25-05-15 14:05:22.990 : --24-->     29.png | 29.29dB
25-05-15 14:05:21.240 : --25-->      3.png | 29.58dB
25-05-15 14:05:21.990 : --26-->     30.png | 29.84dB
25-05-15 14:05:22.745 : --27-->     31.png | 30.70dB
25-05-15 14:05:23.491 : --28-->     32.png | 28.93dB
25-05-15 14:05:24.254 : --29-->     33.png | 29.36dB
25-05-15 14:05:25.000 : --30-->     34.png | 28.85dB
25-05-15 14:05:25.753 : --31-->     35.png | 29.19dB
25-05-15 14:05:26.504 : --32-->     36.png | 28.82dB
25-05-15 14:05:27.267 : --33-->     37.png | 29.28dB
25-05-15 14:05:28.022 : --34-->     38.png | 29.12dB
25-05-15 14:05:28.776 : --35-->     39.png | 30.30dB
25-05-15 14:05:29.525 : --36-->      4.png | 29.42dB
25-05-15 14:05:30.279 : --37-->     40.png | 29.94dB
25-05-15 14:05:31.033 : --38-->     41.png | 29.63dB
25-05-15 14:05:31.793 : --39-->     42.png | 29.19dB
25-05-15 14:05:32.548 : --40-->     43.png | 29.80dB
25-05-15 14:05:33.300 : --41-->     44.png | 29.15dB
25-05-15 14:05:34.044 : --42-->     45.png | 29.18dB
25-05-15 14:05:34.796 : --43-->     46.png | 28.91dB
25-05-15 14:05:35.550 : --44-->     47.png | 28.66dB
25-05-15 14:05:36.297 : --45-->     48.png | 29.75dB
25-05-15 14:05:37.045 : --46-->     49.png | 30.23dB
25-05-15 14:05:37.791 : --47-->      5.png | 28.88dB
25-05-15 14:05:38.544 : --48-->     50.png | 30.02dB
25-05-15 14:05:39.301 : --49-->     51.png | 27.79dB
25-05-15 14:05:40.050 : --50-->     52.png | 29.30dB
25-05-15 14:05:40.808 : --51-->     53.png | 29.87dB
25-05-15 14:05:41.553 : --52-->     54.png | 33.78dB
25-05-15 14:05:42.311 : --53-->     55.png | 32.84dB
25-05-15 14:05:43.067 : --54-->     56.png | 33.86dB
25-05-15 14:05:43.826 : --55-->     57.png | 33.77dB
25-05-15 14:05:44.576 : --56-->     58.png | 33.89dB
25-05-15 14:05:45.328 : --57-->     59.png | 33.14dB
25-05-15 14:05:46.083 : --58-->      6.png | 30.16dB
25-05-15 14:05:46.838 : --59-->     60.png | 32.67dB
25-05-15 14:05:47.592 : --60-->     61.png | 33.31dB
25-05-15 14:05:48.349 : --61-->     62.png | 32.98dB
25-05-15 14:05:49.103 : --62-->     63.png | 32.55dB
25-05-15 14:05:49.857 : --63-->     64.png | 32.42dB
25-05-15 14:05:50.608 : --64-->     65.png | 32.69dB
25-05-15 14:05:51.364 : --65-->     66.png | 33.84dB
25-05-15 14:05:52.114 : --66-->     67.png | 33.53dB
25-05-15 14:05:52.860 : --67-->     68.png | 33.32dB
25-05-15 14:05:51.134 : --68-->     69.png | 33.83dB
25-05-15 14:05:51.894 : --69-->      7.png | 29.04dB
25-05-15 14:05:52.664 : --70-->     70.png | 32.82dB
25-05-15 14:05:53.410 : --71-->     71.png | 31.19dB
25-05-15 14:05:54.157 : --72-->     72.png | 32.69dB
25-05-15 14:05:54.904 : --73-->     73.png | 31.09dB
25-05-15 14:05:55.657 : --74-->     74.png | 31.51dB
25-05-15 14:05:56.412 : --75-->     75.png | 32.67dB
25-05-15 14:05:57.161 : --76-->     76.png | 33.51dB
25-05-15 14:05:57.919 : --77-->     77.png | 33.51dB
25-05-15 14:05:58.666 : --78-->     78.png | 32.95dB
25-05-15 14:05:59.420 : --79-->     79.png | 31.20dB
25-05-15 14:06:00.177 : --80-->      8.png | 28.94dB
25-05-15 14:06:00.935 : --81-->     80.png | 31.22dB
25-05-15 14:06:01.694 : --82-->     81.png | 32.10dB
25-05-15 14:06:02.456 : --83-->     82.png | 32.23dB
25-05-15 14:06:03.217 : --84-->     83.png | 31.87dB
25-05-15 14:06:03.984 : --85-->     84.png | 30.57dB
25-05-15 14:06:04.740 : --86-->     85.png | 32.52dB
25-05-15 14:06:05.496 : --87-->     86.png | 33.03dB
25-05-15 14:06:06.260 : --88-->     87.png | 33.31dB
25-05-15 14:06:07.022 : --89-->     88.png | 29.56dB
25-05-15 14:06:07.776 : --90-->     89.png | 32.08dB
25-05-15 14:06:08.526 : --91-->      9.png | 28.74dB
25-05-15 14:06:09.274 : --92-->     90.png | 33.08dB
25-05-15 14:06:10.036 : --93-->     91.png | 31.46dB
25-05-15 14:06:10.784 : --94-->     92.png | 31.53dB
25-05-15 14:06:11.537 : --95-->     93.png | 31.93dB
25-05-15 14:06:12.294 : --96-->     94.png | 32.99dB
25-05-15 14:06:13.051 : --97-->     95.png | 31.44dB
25-05-15 14:06:13.800 : --98-->     96.png | 32.65dB
25-05-15 14:06:14.557 : --99-->     97.png | 32.49dB
25-05-15 14:06:15.312 : -100-->     98.png | 32.10dB
25-05-15 14:06:16.067 : -101-->     99.png | 32.06dB
25-05-15 14:06:16.078 : <epoch: 51, iter:  20,000, Average PSNR : 30.74dB

25-05-16 13:45:23.239 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising\DRNet25\models\10_G.pth
    task: denoising\DRNet25
    log: denoising\DRNet25
    options: denoising\DRNet25\options
    models: denoising\DRNet25\models
    images: denoising\DRNet25\images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-16 13:45:23.239 : Random seed: 9963
25-05-16 13:45:23.321 : Number of train images: 31,005, iters: 31,005
25-05-16 13:45:23.873 : 
Networks name: DRNet
Params number: 17746115
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-16 13:45:26.441 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.002 | -0.431 |  0.525 |  0.178 | torch.Size([64, 3, 3, 3]) || head1.weight
 | -0.001 | -0.329 |  0.276 |  0.180 | torch.Size([64]) || head1.bias
 |  0.000 | -0.495 |  0.459 |  0.097 | torch.Size([64, 64, 3, 3]) || head1_1.body.0.weight
 |  0.074 | -0.072 |  0.204 |  0.065 | torch.Size([64]) || head1_1.body.0.bias
 | -0.000 | -0.513 |  0.543 |  0.083 | torch.Size([64, 64, 3, 3]) || head1_1.body.2.weight
 |  0.010 | -0.100 |  0.126 |  0.053 | torch.Size([64]) || head1_1.body.2.bias
 |  0.000 | -0.276 |  0.284 |  0.057 | torch.Size([768, 256]) || head1_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.001 | -0.305 |  0.275 |  0.061 | torch.Size([256, 256]) || head1_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.289 |  0.269 |  0.055 | torch.Size([1024, 256]) || head1_3.encoder.layers.0.linear1.weight
 | -0.020 | -0.164 |  0.093 |  0.041 | torch.Size([1024]) || head1_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.386 |  0.382 |  0.045 | torch.Size([256, 1024]) || head1_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.072 |  0.077 |  0.028 | torch.Size([256]) || head1_3.encoder.layers.0.linear2.bias
 |  1.012 |  0.775 |  1.163 |  0.059 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.weight
 |  0.004 | -0.167 |  0.277 |  0.052 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.bias
 |  1.076 |  0.945 |  1.226 |  0.051 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.weight
 |  0.002 | -0.067 |  0.086 |  0.028 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || head1_3.position_encoding.position_ids
 |  0.000 | -5.338 |  4.747 |  0.991 | torch.Size([4096, 256]) || head1_3.position_encoding.pe.weight
 |  0.000 | -0.882 |  0.949 |  0.033 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.0.weight
 |  0.026 | -0.097 |  0.106 |  0.042 | torch.Size([64]) || body1_1.0.body.0.bias
 | -0.001 | -0.343 |  0.336 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.2.weight
 | -0.014 | -0.134 |  0.111 |  0.059 | torch.Size([64]) || body1_1.0.body.2.bias
 | -0.001 | -0.447 |  0.425 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_1.1.weight
 |  0.046 | -0.053 |  0.147 |  0.045 | torch.Size([64]) || body1_1.1.bias
 |  0.000 | -0.167 |  0.174 |  0.041 | torch.Size([768, 256]) || body1_2.0.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.156 |  0.136 |  0.037 | torch.Size([256, 256]) || body1_2.0.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.290 |  0.236 |  0.042 | torch.Size([1024, 256]) || body1_2.0.encoder.layers.0.linear1.weight
 |  0.002 | -0.074 |  0.093 |  0.038 | torch.Size([1024]) || body1_2.0.encoder.layers.0.linear1.bias
 | -0.003 | -0.253 |  0.202 |  0.027 | torch.Size([256, 1024]) || body1_2.0.encoder.layers.0.linear2.weight
 | -0.006 | -0.057 |  0.044 |  0.020 | torch.Size([256]) || body1_2.0.encoder.layers.0.linear2.bias
 |  0.990 |  0.813 |  1.118 |  0.063 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.weight
 |  0.008 | -0.135 |  0.146 |  0.063 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.bias
 |  0.990 |  0.807 |  1.147 |  0.053 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.weight
 |  0.010 | -0.208 |  0.233 |  0.077 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body1_2.0.position_encoding.position_ids
 |  0.001 | -4.538 |  4.875 |  0.995 | torch.Size([4096, 256]) || body1_2.0.position_encoding.pe.weight
 | -0.001 | -0.285 |  0.215 |  0.036 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.0.weight
 |  0.002 | -0.102 |  0.081 |  0.033 | torch.Size([64]) || body1_2.1.body.0.bias
 | -0.005 | -0.256 |  0.258 |  0.033 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.2.weight
 | -0.015 | -0.099 |  0.047 |  0.032 | torch.Size([64]) || body1_2.1.body.2.bias
 |  0.000 | -0.258 |  0.223 |  0.048 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.0.weight
 |  0.014 | -0.103 |  0.110 |  0.042 | torch.Size([64]) || body2_1.0.body.0.bias
 |  0.000 | -0.271 |  0.448 |  0.046 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.2.weight
 | -0.005 | -0.124 |  0.150 |  0.071 | torch.Size([64]) || body2_1.0.body.2.bias
 |  0.000 | -0.303 |  0.341 |  0.058 | torch.Size([768, 256]) || body2_1.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.293 |  0.303 |  0.066 | torch.Size([256, 256]) || body2_1.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.278 |  0.288 |  0.057 | torch.Size([1024, 256]) || body2_1.1.encoder.layers.0.linear1.weight
 |  0.009 | -0.113 |  0.121 |  0.041 | torch.Size([1024]) || body2_1.1.encoder.layers.0.linear1.bias
 | -0.000 | -0.259 |  0.247 |  0.046 | torch.Size([256, 1024]) || body2_1.1.encoder.layers.0.linear2.weight
 | -0.001 | -0.066 |  0.068 |  0.029 | torch.Size([256]) || body2_1.1.encoder.layers.0.linear2.bias
 |  1.064 |  0.947 |  1.177 |  0.043 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.weight
 |  0.003 | -0.123 |  0.142 |  0.058 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.bias
 |  1.154 |  0.989 |  1.326 |  0.061 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.096 |  0.103 |  0.031 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_1.1.position_encoding.position_ids
 | -0.001 | -4.994 |  4.878 |  0.999 | torch.Size([4096, 256]) || body2_1.1.position_encoding.pe.weight
 | -0.003 | -0.328 |  0.342 |  0.112 | torch.Size([128, 1, 5, 5]) || fusion2_1.0.weight
 |  0.015 | -0.256 |  0.240 |  0.120 | torch.Size([128]) || fusion2_1.0.bias
 |  0.000 | -0.220 |  0.215 |  0.054 | torch.Size([64, 128, 1, 1]) || fusion2_1.1.weight
 | -0.004 | -0.169 |  0.144 |  0.080 | torch.Size([64]) || fusion2_1.1.bias
 |  0.002 | -0.174 |  0.203 |  0.041 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.0.weight
 |  0.004 | -0.133 |  0.204 |  0.074 | torch.Size([64]) || body2_2.0.body.0.bias
 |  0.000 | -0.204 |  0.201 |  0.040 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.2.weight
 | -0.004 | -0.206 |  0.186 |  0.095 | torch.Size([64]) || body2_2.0.body.2.bias
 | -0.000 | -0.398 |  0.312 |  0.062 | torch.Size([768, 256]) || body2_2.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.312 |  0.352 |  0.075 | torch.Size([256, 256]) || body2_2.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.238 |  0.245 |  0.058 | torch.Size([1024, 256]) || body2_2.1.encoder.layers.0.linear1.weight
 | -0.002 | -0.144 |  0.129 |  0.049 | torch.Size([1024]) || body2_2.1.encoder.layers.0.linear1.bias
 |  0.000 | -0.240 |  0.267 |  0.046 | torch.Size([256, 1024]) || body2_2.1.encoder.layers.0.linear2.weight
 |  0.002 | -0.048 |  0.054 |  0.023 | torch.Size([256]) || body2_2.1.encoder.layers.0.linear2.bias
 |  1.092 |  0.957 |  1.206 |  0.044 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.weight
 |  0.001 | -0.160 |  0.185 |  0.068 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.bias
 |  1.119 |  0.943 |  1.277 |  0.049 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.097 |  0.093 |  0.031 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_2.1.position_encoding.position_ids
 | -0.001 | -4.834 |  4.669 |  0.998 | torch.Size([4096, 256]) || body2_2.1.position_encoding.pe.weight
 | -0.000 | -0.287 |  0.353 |  0.105 | torch.Size([128, 1, 5, 5]) || fusion2_2.0.weight
 | -0.014 | -0.203 |  0.212 |  0.115 | torch.Size([128]) || fusion2_2.0.bias
 | -0.001 | -0.189 |  0.248 |  0.056 | torch.Size([64, 128, 1, 1]) || fusion2_2.1.weight
 | -0.019 | -0.130 |  0.141 |  0.060 | torch.Size([64]) || fusion2_2.1.bias
 | -0.000 | -0.229 |  0.211 |  0.051 | torch.Size([768, 256]) || body2_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.222 |  0.218 |  0.053 | torch.Size([256, 256]) || body2_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.214 |  0.205 |  0.049 | torch.Size([1024, 256]) || body2_3.encoder.layers.0.linear1.weight
 | -0.029 | -0.135 |  0.086 |  0.040 | torch.Size([1024]) || body2_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.179 |  0.173 |  0.036 | torch.Size([256, 1024]) || body2_3.encoder.layers.0.linear2.weight
 |  0.002 | -0.041 |  0.073 |  0.021 | torch.Size([256]) || body2_3.encoder.layers.0.linear2.bias
 |  1.047 |  0.954 |  1.182 |  0.038 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.112 |  0.142 |  0.043 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.bias
 |  0.979 |  0.858 |  1.114 |  0.039 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.080 |  0.070 |  0.027 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_3.position_encoding.position_ids
 | -0.000 | -4.715 |  5.525 |  0.998 | torch.Size([4096, 256]) || body2_3.position_encoding.pe.weight
 |  0.000 | -0.228 |  0.222 |  0.038 | torch.Size([64, 64, 3, 3]) || body3_1.0.weight
 |  0.019 | -0.055 |  0.070 |  0.030 | torch.Size([64]) || body3_1.0.bias
 |  0.000 | -0.164 |  0.162 |  0.039 | torch.Size([768, 256]) || body3_1.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.161 |  0.166 |  0.040 | torch.Size([256, 256]) || body3_1.2.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.283 |  0.246 |  0.047 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.0.linear1.weight
 | -0.010 | -0.099 |  0.095 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.285 |  0.296 |  0.033 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.0.linear2.weight
 | -0.006 | -0.067 |  0.073 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.linear2.bias
 |  1.000 |  0.922 |  1.073 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.085 |  0.076 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.bias
 |  1.105 |  0.980 |  1.255 |  0.049 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.weight
 |  0.002 | -0.072 |  0.087 |  0.032 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.134 |  0.163 |  0.038 | torch.Size([768, 256]) || body3_1.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.127 |  0.128 |  0.038 | torch.Size([256, 256]) || body3_1.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.339 |  0.290 |  0.046 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.1.linear1.weight
 | -0.006 | -0.095 |  0.090 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.1.linear1.bias
 | -0.002 | -0.359 |  0.420 |  0.032 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.1.linear2.weight
 | -0.007 | -0.064 |  0.045 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.linear2.bias
 |  0.995 |  0.945 |  1.094 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.weight
 | -0.001 | -0.059 |  0.062 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.bias
 |  1.122 |  0.994 |  1.290 |  0.049 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.weight
 |  0.001 | -0.051 |  0.053 |  0.020 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_1.2.position_encoding.position_ids
 |  0.002 | -4.658 |  4.616 |  1.000 | torch.Size([4096, 256]) || body3_1.2.position_encoding.pe.weight
 |  0.001 | -0.205 |  0.215 |  0.075 | torch.Size([128, 1, 5, 5]) || fusion3_1.0.weight
 |  0.006 | -0.234 |  0.245 |  0.123 | torch.Size([128]) || fusion3_1.0.bias
 | -0.000 | -0.136 |  0.158 |  0.030 | torch.Size([64, 128, 1, 1]) || fusion3_1.1.weight
 | -0.008 | -0.184 |  0.153 |  0.085 | torch.Size([64]) || fusion3_1.1.bias
 | -0.000 | -0.109 |  0.112 |  0.027 | torch.Size([64, 64, 3, 3]) || body3_2.0.weight
 |  0.055 | -0.103 |  0.115 |  0.036 | torch.Size([64]) || body3_2.0.bias
 |  0.000 | -0.144 |  0.126 |  0.040 | torch.Size([768, 256]) || body3_2.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.110 |  0.108 |  0.037 | torch.Size([256, 256]) || body3_2.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.197 |  0.214 |  0.051 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.0.linear1.weight
 | -0.042 | -0.131 |  0.063 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.170 |  0.151 |  0.036 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.0.linear2.weight
 | -0.008 | -0.062 |  0.038 |  0.022 | torch.Size([256]) || body3_2.2.encoder.layers.0.linear2.bias
 |  0.996 |  0.839 |  1.076 |  0.030 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.120 |  0.174 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.bias
 |  1.048 |  0.924 |  1.175 |  0.044 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.weight
 | -0.001 | -0.130 |  0.095 |  0.040 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.110 |  0.115 |  0.038 | torch.Size([768, 256]) || body3_2.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.115 |  0.104 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.186 |  0.193 |  0.049 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.1.linear1.weight
 | -0.026 | -0.111 |  0.086 |  0.037 | torch.Size([1024]) || body3_2.2.encoder.layers.1.linear1.bias
 | -0.001 | -0.155 |  0.168 |  0.035 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.1.linear2.weight
 | -0.009 | -0.067 |  0.045 |  0.024 | torch.Size([256]) || body3_2.2.encoder.layers.1.linear2.bias
 |  0.987 |  0.919 |  1.031 |  0.020 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.weight
 | -0.000 | -0.102 |  0.110 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.bias
 |  1.052 |  0.957 |  1.143 |  0.034 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.weight
 | -0.000 | -0.052 |  0.048 |  0.018 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_2.2.position_encoding.position_ids
 |  0.001 | -5.085 |  5.020 |  1.000 | torch.Size([4096, 256]) || body3_2.2.position_encoding.pe.weight
 |  0.002 | -0.229 |  0.257 |  0.090 | torch.Size([128, 1, 5, 5]) || fusion3_2.0.weight
 |  0.003 | -0.196 |  0.231 |  0.106 | torch.Size([128]) || fusion3_2.0.bias
 |  0.001 | -0.147 |  0.146 |  0.046 | torch.Size([64, 128, 1, 1]) || fusion3_2.1.weight
 |  0.006 | -0.088 |  0.127 |  0.049 | torch.Size([64]) || fusion3_2.1.bias
 | -0.001 | -0.204 |  0.188 |  0.047 | torch.Size([256, 256]) || body3_3.linear_encoding.weight
 | -0.004 | -0.129 |  0.130 |  0.056 | torch.Size([256]) || body3_3.linear_encoding.bias
 | -0.000 | -0.224 |  0.192 |  0.045 | torch.Size([1024, 256]) || body3_3.mlp_head.0.weight
 | -0.026 | -0.120 |  0.072 |  0.038 | torch.Size([1024]) || body3_3.mlp_head.0.bias
 | -0.000 | -0.209 |  0.188 |  0.032 | torch.Size([256, 1024]) || body3_3.mlp_head.3.weight
 |  0.002 | -0.082 |  0.075 |  0.028 | torch.Size([256]) || body3_3.mlp_head.3.bias
 |  0.000 | -0.130 |  0.132 |  0.039 | torch.Size([768, 256]) || body3_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.141 |  0.153 |  0.037 | torch.Size([256, 256]) || body3_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.214 |  0.188 |  0.044 | torch.Size([1024, 256]) || body3_3.encoder.layers.0.linear1.weight
 | -0.036 | -0.132 |  0.054 |  0.036 | torch.Size([1024]) || body3_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.179 |  0.229 |  0.031 | torch.Size([256, 1024]) || body3_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.073 |  0.066 |  0.024 | torch.Size([256]) || body3_3.encoder.layers.0.linear2.bias
 |  0.924 |  0.834 |  1.000 |  0.026 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.weight
 |  0.001 | -0.067 |  0.098 |  0.030 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.bias
 |  0.875 |  0.790 |  1.027 |  0.039 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.189 |  0.175 |  0.063 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.bias
 | -0.000 | -0.164 |  0.174 |  0.046 | torch.Size([192, 1, 5, 5]) || fusion3_3.0.weight
 |  0.004 | -0.188 |  0.217 |  0.083 | torch.Size([192]) || fusion3_3.0.bias
 |  0.000 | -0.115 |  0.106 |  0.021 | torch.Size([64, 192, 1, 1]) || fusion3_3.1.weight
 | -0.004 | -0.046 |  0.040 |  0.020 | torch.Size([64]) || fusion3_3.1.bias
 | -0.001 | -0.422 |  0.127 |  0.036 | torch.Size([256, 256]) || body3_4.linear_encoding.weight
 |  0.004 | -0.070 |  0.103 |  0.027 | torch.Size([256]) || body3_4.linear_encoding.bias
 | -0.001 | -0.242 |  0.266 |  0.045 | torch.Size([1024, 256]) || body3_4.mlp_head.0.weight
 | -0.048 | -0.153 |  0.070 |  0.037 | torch.Size([1024]) || body3_4.mlp_head.0.bias
 | -0.000 | -0.253 |  0.279 |  0.029 | torch.Size([256, 1024]) || body3_4.mlp_head.3.weight
 | -0.003 | -0.120 |  0.087 |  0.033 | torch.Size([256]) || body3_4.mlp_head.3.bias
 | -0.000 | -0.206 |  0.223 |  0.042 | torch.Size([768, 256]) || body3_4.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.142 |  0.141 |  0.032 | torch.Size([256, 256]) || body3_4.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.203 |  0.204 |  0.039 | torch.Size([1024, 256]) || body3_4.encoder.layers.0.linear1.weight
 | -0.039 | -0.130 |  0.059 |  0.037 | torch.Size([1024]) || body3_4.encoder.layers.0.linear1.bias
 |  0.000 | -0.210 |  0.170 |  0.021 | torch.Size([256, 1024]) || body3_4.encoder.layers.0.linear2.weight
 |  0.001 | -0.072 |  0.060 |  0.024 | torch.Size([256]) || body3_4.encoder.layers.0.linear2.bias
 |  0.803 |  0.654 |  0.952 |  0.065 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.weight
 | -0.002 | -0.177 |  0.127 |  0.051 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.bias
 |  0.788 |  0.498 |  1.070 |  0.097 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.weight
 |  0.000 | -0.201 |  0.187 |  0.082 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.bias
 |  0.000 | -0.041 |  0.042 |  0.009 | torch.Size([3, 64, 3, 3]) || tail.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([3]) || tail.bias

25-05-16 13:46:02.924 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising\DRNet25\models\10_G.pth
    task: denoising\DRNet25
    log: denoising\DRNet25
    options: denoising\DRNet25\options
    models: denoising\DRNet25\models
    images: denoising\DRNet25\images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-16 13:46:02.925 : Random seed: 5000
25-05-16 13:46:03.011 : Number of train images: 31,005, iters: 31,005
25-05-16 13:46:03.590 : 
Networks name: DRNet
Params number: 39766211
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(16384, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(16384, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(16384, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(16384, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(16384, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(16384, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(16384, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-16 13:46:19.465 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: None
    task: denoising\DRNet25
    log: denoising\DRNet25
    options: denoising\DRNet25\options
    models: denoising\DRNet25\models
    images: denoising\DRNet25\images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-16 13:46:19.465 : Random seed: 4754
25-05-16 13:46:19.549 : Number of train images: 31,005, iters: 31,005
25-05-16 13:46:19.928 : 
Networks name: DRNet
Params number: 39766211
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(16384, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(16384, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(16384, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(16384, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(16384, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(16384, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(16384, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-16 13:46:21.192 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.003 | -0.192 |  0.192 |  0.108 | torch.Size([64, 3, 3, 3]) || head1.weight
 | -0.018 | -0.187 |  0.190 |  0.111 | torch.Size([64]) || head1.bias
 | -0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || head1_1.body.0.weight
 | -0.003 | -0.042 |  0.040 |  0.025 | torch.Size([64]) || head1_1.body.0.bias
 | -0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || head1_1.body.2.weight
 |  0.002 | -0.041 |  0.041 |  0.023 | torch.Size([64]) || head1_1.body.2.bias
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([768, 256]) || head1_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || head1_3.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || head1_3.encoder.layers.0.linear1.weight
 | -0.002 | -0.062 |  0.062 |  0.035 | torch.Size([1024]) || head1_3.encoder.layers.0.linear1.bias
 | -0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || head1_3.encoder.layers.0.linear2.weight
 |  0.001 | -0.031 |  0.031 |  0.019 | torch.Size([256]) || head1_3.encoder.layers.0.linear2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.bias
 | 8191.500 |  0.000 | 16383.000 | 4729.798 | torch.Size([1, 16384]) || head1_3.position_encoding.position_ids
 |  0.000 | -5.034 |  5.421 |  1.000 | torch.Size([16384, 256]) || head1_3.position_encoding.pe.weight
 |  0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.0.weight
 |  0.002 | -0.041 |  0.041 |  0.025 | torch.Size([64]) || body1_1.0.body.0.bias
 |  0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.2.weight
 | -0.001 | -0.041 |  0.041 |  0.028 | torch.Size([64]) || body1_1.0.body.2.bias
 |  0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || body1_1.1.weight
 | -0.002 | -0.037 |  0.041 |  0.024 | torch.Size([64]) || body1_1.1.bias
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([768, 256]) || body1_2.0.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body1_2.0.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body1_2.0.encoder.layers.0.linear1.weight
 |  0.002 | -0.062 |  0.062 |  0.036 | torch.Size([1024]) || body1_2.0.encoder.layers.0.linear1.bias
 | -0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body1_2.0.encoder.layers.0.linear2.weight
 | -0.001 | -0.031 |  0.031 |  0.018 | torch.Size([256]) || body1_2.0.encoder.layers.0.linear2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.bias
 | 8191.500 |  0.000 | 16383.000 | 4729.798 | torch.Size([1, 16384]) || body1_2.0.position_encoding.position_ids
 | -0.000 | -5.110 |  5.051 |  1.000 | torch.Size([16384, 256]) || body1_2.0.position_encoding.pe.weight
 | -0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.0.weight
 |  0.002 | -0.041 |  0.041 |  0.024 | torch.Size([64]) || body1_2.1.body.0.bias
 | -0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.2.weight
 |  0.002 | -0.041 |  0.042 |  0.022 | torch.Size([64]) || body1_2.1.body.2.bias
 | -0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.0.weight
 |  0.001 | -0.040 |  0.041 |  0.024 | torch.Size([64]) || body2_1.0.body.0.bias
 |  0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.2.weight
 | -0.002 | -0.042 |  0.041 |  0.027 | torch.Size([64]) || body2_1.0.body.2.bias
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([768, 256]) || body2_1.1.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body2_1.1.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body2_1.1.encoder.layers.0.linear1.weight
 | -0.000 | -0.062 |  0.062 |  0.037 | torch.Size([1024]) || body2_1.1.encoder.layers.0.linear1.bias
 |  0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body2_1.1.encoder.layers.0.linear2.weight
 |  0.001 | -0.031 |  0.031 |  0.017 | torch.Size([256]) || body2_1.1.encoder.layers.0.linear2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.bias
 | 8191.500 |  0.000 | 16383.000 | 4729.798 | torch.Size([1, 16384]) || body2_1.1.position_encoding.position_ids
 |  0.000 | -5.005 |  5.212 |  0.999 | torch.Size([16384, 256]) || body2_1.1.position_encoding.pe.weight
 |  0.000 | -0.200 |  0.200 |  0.116 | torch.Size([128, 1, 5, 5]) || fusion2_1.0.weight
 |  0.014 | -0.199 |  0.196 |  0.110 | torch.Size([128]) || fusion2_1.0.bias
 | -0.000 | -0.088 |  0.088 |  0.051 | torch.Size([64, 128, 1, 1]) || fusion2_1.1.weight
 |  0.003 | -0.088 |  0.088 |  0.053 | torch.Size([64]) || fusion2_1.1.bias
 |  0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.0.weight
 |  0.000 | -0.041 |  0.040 |  0.025 | torch.Size([64]) || body2_2.0.body.0.bias
 | -0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.2.weight
 | -0.000 | -0.039 |  0.041 |  0.024 | torch.Size([64]) || body2_2.0.body.2.bias
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([768, 256]) || body2_2.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body2_2.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body2_2.1.encoder.layers.0.linear1.weight
 | -0.000 | -0.062 |  0.062 |  0.037 | torch.Size([1024]) || body2_2.1.encoder.layers.0.linear1.bias
 | -0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body2_2.1.encoder.layers.0.linear2.weight
 |  0.002 | -0.031 |  0.031 |  0.018 | torch.Size([256]) || body2_2.1.encoder.layers.0.linear2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.bias
 | 8191.500 |  0.000 | 16383.000 | 4729.798 | torch.Size([1, 16384]) || body2_2.1.position_encoding.position_ids
 | -0.000 | -5.635 |  5.127 |  1.000 | torch.Size([16384, 256]) || body2_2.1.position_encoding.pe.weight
 |  0.002 | -0.200 |  0.200 |  0.116 | torch.Size([128, 1, 5, 5]) || fusion2_2.0.weight
 |  0.013 | -0.195 |  0.198 |  0.113 | torch.Size([128]) || fusion2_2.0.bias
 |  0.000 | -0.088 |  0.088 |  0.051 | torch.Size([64, 128, 1, 1]) || fusion2_2.1.weight
 |  0.003 | -0.088 |  0.087 |  0.056 | torch.Size([64]) || fusion2_2.1.bias
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([768, 256]) || body2_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body2_3.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body2_3.encoder.layers.0.linear1.weight
 | -0.000 | -0.062 |  0.062 |  0.037 | torch.Size([1024]) || body2_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body2_3.encoder.layers.0.linear2.weight
 |  0.001 | -0.031 |  0.031 |  0.017 | torch.Size([256]) || body2_3.encoder.layers.0.linear2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.bias
 | 8191.500 |  0.000 | 16383.000 | 4729.798 | torch.Size([1, 16384]) || body2_3.position_encoding.position_ids
 | -0.000 | -5.122 |  5.083 |  1.000 | torch.Size([16384, 256]) || body2_3.position_encoding.pe.weight
 | -0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || body3_1.0.weight
 | -0.002 | -0.041 |  0.038 |  0.023 | torch.Size([64]) || body3_1.0.bias
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([768, 256]) || body3_1.2.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body3_1.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.0.linear1.weight
 | -0.001 | -0.062 |  0.062 |  0.036 | torch.Size([1024]) || body3_1.2.encoder.layers.0.linear1.bias
 | -0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.0.linear2.weight
 | -0.001 | -0.031 |  0.031 |  0.018 | torch.Size([256]) || body3_1.2.encoder.layers.0.linear2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([768, 256]) || body3_1.2.encoder.layers.1.self_attn.in_proj_weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body3_1.2.encoder.layers.1.self_attn.out_proj.weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.1.linear1.weight
 | -0.001 | -0.062 |  0.062 |  0.036 | torch.Size([1024]) || body3_1.2.encoder.layers.1.linear1.bias
 | -0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.1.linear2.weight
 | -0.001 | -0.031 |  0.031 |  0.018 | torch.Size([256]) || body3_1.2.encoder.layers.1.linear2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.bias
 | 8191.500 |  0.000 | 16383.000 | 4729.798 | torch.Size([1, 16384]) || body3_1.2.position_encoding.position_ids
 |  0.000 | -5.104 |  4.738 |  1.000 | torch.Size([16384, 256]) || body3_1.2.position_encoding.pe.weight
 |  0.001 | -0.200 |  0.200 |  0.115 | torch.Size([128, 1, 5, 5]) || fusion3_1.0.weight
 | -0.015 | -0.200 |  0.172 |  0.113 | torch.Size([128]) || fusion3_1.0.bias
 |  0.001 | -0.088 |  0.088 |  0.051 | torch.Size([64, 128, 1, 1]) || fusion3_1.1.weight
 | -0.001 | -0.088 |  0.087 |  0.047 | torch.Size([64]) || fusion3_1.1.bias
 | -0.000 | -0.042 |  0.042 |  0.024 | torch.Size([64, 64, 3, 3]) || body3_2.0.weight
 | -0.003 | -0.040 |  0.042 |  0.024 | torch.Size([64]) || body3_2.0.bias
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([768, 256]) || body3_2.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.0.linear1.weight
 |  0.001 | -0.062 |  0.062 |  0.036 | torch.Size([1024]) || body3_2.2.encoder.layers.0.linear1.bias
 |  0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.0.linear2.weight
 | -0.001 | -0.031 |  0.031 |  0.018 | torch.Size([256]) || body3_2.2.encoder.layers.0.linear2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([768, 256]) || body3_2.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.1.self_attn.out_proj.weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.1.linear1.weight
 |  0.001 | -0.062 |  0.062 |  0.036 | torch.Size([1024]) || body3_2.2.encoder.layers.1.linear1.bias
 |  0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.1.linear2.weight
 | -0.001 | -0.031 |  0.031 |  0.018 | torch.Size([256]) || body3_2.2.encoder.layers.1.linear2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.bias
 | 8191.500 |  0.000 | 16383.000 | 4729.798 | torch.Size([1, 16384]) || body3_2.2.position_encoding.position_ids
 | -0.000 | -5.189 |  4.843 |  1.000 | torch.Size([16384, 256]) || body3_2.2.position_encoding.pe.weight
 | -0.001 | -0.200 |  0.200 |  0.116 | torch.Size([128, 1, 5, 5]) || fusion3_2.0.weight
 |  0.015 | -0.199 |  0.199 |  0.120 | torch.Size([128]) || fusion3_2.0.bias
 | -0.000 | -0.088 |  0.088 |  0.051 | torch.Size([64, 128, 1, 1]) || fusion3_2.1.weight
 | -0.002 | -0.084 |  0.086 |  0.044 | torch.Size([64]) || fusion3_2.1.bias
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body3_3.linear_encoding.weight
 | -0.001 | -0.062 |  0.062 |  0.037 | torch.Size([256]) || body3_3.linear_encoding.bias
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body3_3.mlp_head.0.weight
 |  0.001 | -0.062 |  0.062 |  0.036 | torch.Size([1024]) || body3_3.mlp_head.0.bias
 | -0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body3_3.mlp_head.3.weight
 |  0.002 | -0.031 |  0.031 |  0.018 | torch.Size([256]) || body3_3.mlp_head.3.bias
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([768, 256]) || body3_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body3_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body3_3.encoder.layers.0.linear1.weight
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024]) || body3_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body3_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.031 |  0.031 |  0.017 | torch.Size([256]) || body3_3.encoder.layers.0.linear2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.bias
 |  0.000 | -0.200 |  0.200 |  0.116 | torch.Size([192, 1, 5, 5]) || fusion3_3.0.weight
 | -0.004 | -0.194 |  0.197 |  0.108 | torch.Size([192]) || fusion3_3.0.bias
 | -0.000 | -0.072 |  0.072 |  0.042 | torch.Size([64, 192, 1, 1]) || fusion3_3.1.weight
 | -0.008 | -0.071 |  0.067 |  0.041 | torch.Size([64]) || fusion3_3.1.bias
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body3_4.linear_encoding.weight
 | -0.000 | -0.062 |  0.062 |  0.037 | torch.Size([256]) || body3_4.linear_encoding.bias
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body3_4.mlp_head.0.weight
 | -0.001 | -0.062 |  0.062 |  0.036 | torch.Size([1024]) || body3_4.mlp_head.0.bias
 |  0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body3_4.mlp_head.3.weight
 |  0.001 | -0.031 |  0.031 |  0.017 | torch.Size([256]) || body3_4.mlp_head.3.bias
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([768, 256]) || body3_4.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.062 |  0.062 |  0.036 | torch.Size([256, 256]) || body3_4.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.062 |  0.062 |  0.036 | torch.Size([1024, 256]) || body3_4.encoder.layers.0.linear1.weight
 | -0.002 | -0.062 |  0.062 |  0.036 | torch.Size([1024]) || body3_4.encoder.layers.0.linear1.bias
 | -0.000 | -0.031 |  0.031 |  0.018 | torch.Size([256, 1024]) || body3_4.encoder.layers.0.linear2.weight
 | -0.001 | -0.031 |  0.031 |  0.019 | torch.Size([256]) || body3_4.encoder.layers.0.linear2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.bias
 | -0.000 | -0.042 |  0.042 |  0.024 | torch.Size([3, 64, 3, 3]) || tail.weight
 | -0.011 | -0.018 |  0.002 |  0.011 | torch.Size([3]) || tail.bias

25-05-16 13:47:11.652 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising\DRNet25\models\10_G.pth
    task: denoising\DRNet25
    log: denoising\DRNet25
    options: denoising\DRNet25\options
    models: denoising\DRNet25\models
    images: denoising\DRNet25\images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages_4fen
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-16 13:47:11.652 : Random seed: 2001
25-05-16 13:47:13.028 : Number of train images: 124,020, iters: 124,020
25-05-16 13:47:13.370 : 
Networks name: DRNet
Params number: 17746115
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-16 13:47:14.880 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.002 | -0.431 |  0.525 |  0.178 | torch.Size([64, 3, 3, 3]) || head1.weight
 | -0.001 | -0.329 |  0.276 |  0.180 | torch.Size([64]) || head1.bias
 |  0.000 | -0.495 |  0.459 |  0.097 | torch.Size([64, 64, 3, 3]) || head1_1.body.0.weight
 |  0.074 | -0.072 |  0.204 |  0.065 | torch.Size([64]) || head1_1.body.0.bias
 | -0.000 | -0.513 |  0.543 |  0.083 | torch.Size([64, 64, 3, 3]) || head1_1.body.2.weight
 |  0.010 | -0.100 |  0.126 |  0.053 | torch.Size([64]) || head1_1.body.2.bias
 |  0.000 | -0.276 |  0.284 |  0.057 | torch.Size([768, 256]) || head1_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.001 | -0.305 |  0.275 |  0.061 | torch.Size([256, 256]) || head1_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.289 |  0.269 |  0.055 | torch.Size([1024, 256]) || head1_3.encoder.layers.0.linear1.weight
 | -0.020 | -0.164 |  0.093 |  0.041 | torch.Size([1024]) || head1_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.386 |  0.382 |  0.045 | torch.Size([256, 1024]) || head1_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.072 |  0.077 |  0.028 | torch.Size([256]) || head1_3.encoder.layers.0.linear2.bias
 |  1.012 |  0.775 |  1.163 |  0.059 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.weight
 |  0.004 | -0.167 |  0.277 |  0.052 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.bias
 |  1.076 |  0.945 |  1.226 |  0.051 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.weight
 |  0.002 | -0.067 |  0.086 |  0.028 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || head1_3.position_encoding.position_ids
 |  0.000 | -5.338 |  4.747 |  0.991 | torch.Size([4096, 256]) || head1_3.position_encoding.pe.weight
 |  0.000 | -0.882 |  0.949 |  0.033 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.0.weight
 |  0.026 | -0.097 |  0.106 |  0.042 | torch.Size([64]) || body1_1.0.body.0.bias
 | -0.001 | -0.343 |  0.336 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.2.weight
 | -0.014 | -0.134 |  0.111 |  0.059 | torch.Size([64]) || body1_1.0.body.2.bias
 | -0.001 | -0.447 |  0.425 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_1.1.weight
 |  0.046 | -0.053 |  0.147 |  0.045 | torch.Size([64]) || body1_1.1.bias
 |  0.000 | -0.167 |  0.174 |  0.041 | torch.Size([768, 256]) || body1_2.0.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.156 |  0.136 |  0.037 | torch.Size([256, 256]) || body1_2.0.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.290 |  0.236 |  0.042 | torch.Size([1024, 256]) || body1_2.0.encoder.layers.0.linear1.weight
 |  0.002 | -0.074 |  0.093 |  0.038 | torch.Size([1024]) || body1_2.0.encoder.layers.0.linear1.bias
 | -0.003 | -0.253 |  0.202 |  0.027 | torch.Size([256, 1024]) || body1_2.0.encoder.layers.0.linear2.weight
 | -0.006 | -0.057 |  0.044 |  0.020 | torch.Size([256]) || body1_2.0.encoder.layers.0.linear2.bias
 |  0.990 |  0.813 |  1.118 |  0.063 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.weight
 |  0.008 | -0.135 |  0.146 |  0.063 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.bias
 |  0.990 |  0.807 |  1.147 |  0.053 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.weight
 |  0.010 | -0.208 |  0.233 |  0.077 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body1_2.0.position_encoding.position_ids
 |  0.001 | -4.538 |  4.875 |  0.995 | torch.Size([4096, 256]) || body1_2.0.position_encoding.pe.weight
 | -0.001 | -0.285 |  0.215 |  0.036 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.0.weight
 |  0.002 | -0.102 |  0.081 |  0.033 | torch.Size([64]) || body1_2.1.body.0.bias
 | -0.005 | -0.256 |  0.258 |  0.033 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.2.weight
 | -0.015 | -0.099 |  0.047 |  0.032 | torch.Size([64]) || body1_2.1.body.2.bias
 |  0.000 | -0.258 |  0.223 |  0.048 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.0.weight
 |  0.014 | -0.103 |  0.110 |  0.042 | torch.Size([64]) || body2_1.0.body.0.bias
 |  0.000 | -0.271 |  0.448 |  0.046 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.2.weight
 | -0.005 | -0.124 |  0.150 |  0.071 | torch.Size([64]) || body2_1.0.body.2.bias
 |  0.000 | -0.303 |  0.341 |  0.058 | torch.Size([768, 256]) || body2_1.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.293 |  0.303 |  0.066 | torch.Size([256, 256]) || body2_1.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.278 |  0.288 |  0.057 | torch.Size([1024, 256]) || body2_1.1.encoder.layers.0.linear1.weight
 |  0.009 | -0.113 |  0.121 |  0.041 | torch.Size([1024]) || body2_1.1.encoder.layers.0.linear1.bias
 | -0.000 | -0.259 |  0.247 |  0.046 | torch.Size([256, 1024]) || body2_1.1.encoder.layers.0.linear2.weight
 | -0.001 | -0.066 |  0.068 |  0.029 | torch.Size([256]) || body2_1.1.encoder.layers.0.linear2.bias
 |  1.064 |  0.947 |  1.177 |  0.043 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.weight
 |  0.003 | -0.123 |  0.142 |  0.058 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.bias
 |  1.154 |  0.989 |  1.326 |  0.061 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.096 |  0.103 |  0.031 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_1.1.position_encoding.position_ids
 | -0.001 | -4.994 |  4.878 |  0.999 | torch.Size([4096, 256]) || body2_1.1.position_encoding.pe.weight
 | -0.003 | -0.328 |  0.342 |  0.112 | torch.Size([128, 1, 5, 5]) || fusion2_1.0.weight
 |  0.015 | -0.256 |  0.240 |  0.120 | torch.Size([128]) || fusion2_1.0.bias
 |  0.000 | -0.220 |  0.215 |  0.054 | torch.Size([64, 128, 1, 1]) || fusion2_1.1.weight
 | -0.004 | -0.169 |  0.144 |  0.080 | torch.Size([64]) || fusion2_1.1.bias
 |  0.002 | -0.174 |  0.203 |  0.041 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.0.weight
 |  0.004 | -0.133 |  0.204 |  0.074 | torch.Size([64]) || body2_2.0.body.0.bias
 |  0.000 | -0.204 |  0.201 |  0.040 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.2.weight
 | -0.004 | -0.206 |  0.186 |  0.095 | torch.Size([64]) || body2_2.0.body.2.bias
 | -0.000 | -0.398 |  0.312 |  0.062 | torch.Size([768, 256]) || body2_2.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.312 |  0.352 |  0.075 | torch.Size([256, 256]) || body2_2.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.238 |  0.245 |  0.058 | torch.Size([1024, 256]) || body2_2.1.encoder.layers.0.linear1.weight
 | -0.002 | -0.144 |  0.129 |  0.049 | torch.Size([1024]) || body2_2.1.encoder.layers.0.linear1.bias
 |  0.000 | -0.240 |  0.267 |  0.046 | torch.Size([256, 1024]) || body2_2.1.encoder.layers.0.linear2.weight
 |  0.002 | -0.048 |  0.054 |  0.023 | torch.Size([256]) || body2_2.1.encoder.layers.0.linear2.bias
 |  1.092 |  0.957 |  1.206 |  0.044 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.weight
 |  0.001 | -0.160 |  0.185 |  0.068 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.bias
 |  1.119 |  0.943 |  1.277 |  0.049 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.097 |  0.093 |  0.031 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_2.1.position_encoding.position_ids
 | -0.001 | -4.834 |  4.669 |  0.998 | torch.Size([4096, 256]) || body2_2.1.position_encoding.pe.weight
 | -0.000 | -0.287 |  0.353 |  0.105 | torch.Size([128, 1, 5, 5]) || fusion2_2.0.weight
 | -0.014 | -0.203 |  0.212 |  0.115 | torch.Size([128]) || fusion2_2.0.bias
 | -0.001 | -0.189 |  0.248 |  0.056 | torch.Size([64, 128, 1, 1]) || fusion2_2.1.weight
 | -0.019 | -0.130 |  0.141 |  0.060 | torch.Size([64]) || fusion2_2.1.bias
 | -0.000 | -0.229 |  0.211 |  0.051 | torch.Size([768, 256]) || body2_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.222 |  0.218 |  0.053 | torch.Size([256, 256]) || body2_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.214 |  0.205 |  0.049 | torch.Size([1024, 256]) || body2_3.encoder.layers.0.linear1.weight
 | -0.029 | -0.135 |  0.086 |  0.040 | torch.Size([1024]) || body2_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.179 |  0.173 |  0.036 | torch.Size([256, 1024]) || body2_3.encoder.layers.0.linear2.weight
 |  0.002 | -0.041 |  0.073 |  0.021 | torch.Size([256]) || body2_3.encoder.layers.0.linear2.bias
 |  1.047 |  0.954 |  1.182 |  0.038 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.112 |  0.142 |  0.043 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.bias
 |  0.979 |  0.858 |  1.114 |  0.039 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.080 |  0.070 |  0.027 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_3.position_encoding.position_ids
 | -0.000 | -4.715 |  5.525 |  0.998 | torch.Size([4096, 256]) || body2_3.position_encoding.pe.weight
 |  0.000 | -0.228 |  0.222 |  0.038 | torch.Size([64, 64, 3, 3]) || body3_1.0.weight
 |  0.019 | -0.055 |  0.070 |  0.030 | torch.Size([64]) || body3_1.0.bias
 |  0.000 | -0.164 |  0.162 |  0.039 | torch.Size([768, 256]) || body3_1.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.161 |  0.166 |  0.040 | torch.Size([256, 256]) || body3_1.2.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.283 |  0.246 |  0.047 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.0.linear1.weight
 | -0.010 | -0.099 |  0.095 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.285 |  0.296 |  0.033 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.0.linear2.weight
 | -0.006 | -0.067 |  0.073 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.linear2.bias
 |  1.000 |  0.922 |  1.073 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.085 |  0.076 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.bias
 |  1.105 |  0.980 |  1.255 |  0.049 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.weight
 |  0.002 | -0.072 |  0.087 |  0.032 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.134 |  0.163 |  0.038 | torch.Size([768, 256]) || body3_1.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.127 |  0.128 |  0.038 | torch.Size([256, 256]) || body3_1.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.339 |  0.290 |  0.046 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.1.linear1.weight
 | -0.006 | -0.095 |  0.090 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.1.linear1.bias
 | -0.002 | -0.359 |  0.420 |  0.032 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.1.linear2.weight
 | -0.007 | -0.064 |  0.045 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.linear2.bias
 |  0.995 |  0.945 |  1.094 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.weight
 | -0.001 | -0.059 |  0.062 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.bias
 |  1.122 |  0.994 |  1.290 |  0.049 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.weight
 |  0.001 | -0.051 |  0.053 |  0.020 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_1.2.position_encoding.position_ids
 |  0.002 | -4.658 |  4.616 |  1.000 | torch.Size([4096, 256]) || body3_1.2.position_encoding.pe.weight
 |  0.001 | -0.205 |  0.215 |  0.075 | torch.Size([128, 1, 5, 5]) || fusion3_1.0.weight
 |  0.006 | -0.234 |  0.245 |  0.123 | torch.Size([128]) || fusion3_1.0.bias
 | -0.000 | -0.136 |  0.158 |  0.030 | torch.Size([64, 128, 1, 1]) || fusion3_1.1.weight
 | -0.008 | -0.184 |  0.153 |  0.085 | torch.Size([64]) || fusion3_1.1.bias
 | -0.000 | -0.109 |  0.112 |  0.027 | torch.Size([64, 64, 3, 3]) || body3_2.0.weight
 |  0.055 | -0.103 |  0.115 |  0.036 | torch.Size([64]) || body3_2.0.bias
 |  0.000 | -0.144 |  0.126 |  0.040 | torch.Size([768, 256]) || body3_2.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.110 |  0.108 |  0.037 | torch.Size([256, 256]) || body3_2.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.197 |  0.214 |  0.051 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.0.linear1.weight
 | -0.042 | -0.131 |  0.063 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.170 |  0.151 |  0.036 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.0.linear2.weight
 | -0.008 | -0.062 |  0.038 |  0.022 | torch.Size([256]) || body3_2.2.encoder.layers.0.linear2.bias
 |  0.996 |  0.839 |  1.076 |  0.030 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.120 |  0.174 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.bias
 |  1.048 |  0.924 |  1.175 |  0.044 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.weight
 | -0.001 | -0.130 |  0.095 |  0.040 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.110 |  0.115 |  0.038 | torch.Size([768, 256]) || body3_2.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.115 |  0.104 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.186 |  0.193 |  0.049 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.1.linear1.weight
 | -0.026 | -0.111 |  0.086 |  0.037 | torch.Size([1024]) || body3_2.2.encoder.layers.1.linear1.bias
 | -0.001 | -0.155 |  0.168 |  0.035 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.1.linear2.weight
 | -0.009 | -0.067 |  0.045 |  0.024 | torch.Size([256]) || body3_2.2.encoder.layers.1.linear2.bias
 |  0.987 |  0.919 |  1.031 |  0.020 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.weight
 | -0.000 | -0.102 |  0.110 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.bias
 |  1.052 |  0.957 |  1.143 |  0.034 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.weight
 | -0.000 | -0.052 |  0.048 |  0.018 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_2.2.position_encoding.position_ids
 |  0.001 | -5.085 |  5.020 |  1.000 | torch.Size([4096, 256]) || body3_2.2.position_encoding.pe.weight
 |  0.002 | -0.229 |  0.257 |  0.090 | torch.Size([128, 1, 5, 5]) || fusion3_2.0.weight
 |  0.003 | -0.196 |  0.231 |  0.106 | torch.Size([128]) || fusion3_2.0.bias
 |  0.001 | -0.147 |  0.146 |  0.046 | torch.Size([64, 128, 1, 1]) || fusion3_2.1.weight
 |  0.006 | -0.088 |  0.127 |  0.049 | torch.Size([64]) || fusion3_2.1.bias
 | -0.001 | -0.204 |  0.188 |  0.047 | torch.Size([256, 256]) || body3_3.linear_encoding.weight
 | -0.004 | -0.129 |  0.130 |  0.056 | torch.Size([256]) || body3_3.linear_encoding.bias
 | -0.000 | -0.224 |  0.192 |  0.045 | torch.Size([1024, 256]) || body3_3.mlp_head.0.weight
 | -0.026 | -0.120 |  0.072 |  0.038 | torch.Size([1024]) || body3_3.mlp_head.0.bias
 | -0.000 | -0.209 |  0.188 |  0.032 | torch.Size([256, 1024]) || body3_3.mlp_head.3.weight
 |  0.002 | -0.082 |  0.075 |  0.028 | torch.Size([256]) || body3_3.mlp_head.3.bias
 |  0.000 | -0.130 |  0.132 |  0.039 | torch.Size([768, 256]) || body3_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.141 |  0.153 |  0.037 | torch.Size([256, 256]) || body3_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.214 |  0.188 |  0.044 | torch.Size([1024, 256]) || body3_3.encoder.layers.0.linear1.weight
 | -0.036 | -0.132 |  0.054 |  0.036 | torch.Size([1024]) || body3_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.179 |  0.229 |  0.031 | torch.Size([256, 1024]) || body3_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.073 |  0.066 |  0.024 | torch.Size([256]) || body3_3.encoder.layers.0.linear2.bias
 |  0.924 |  0.834 |  1.000 |  0.026 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.weight
 |  0.001 | -0.067 |  0.098 |  0.030 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.bias
 |  0.875 |  0.790 |  1.027 |  0.039 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.189 |  0.175 |  0.063 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.bias
 | -0.000 | -0.164 |  0.174 |  0.046 | torch.Size([192, 1, 5, 5]) || fusion3_3.0.weight
 |  0.004 | -0.188 |  0.217 |  0.083 | torch.Size([192]) || fusion3_3.0.bias
 |  0.000 | -0.115 |  0.106 |  0.021 | torch.Size([64, 192, 1, 1]) || fusion3_3.1.weight
 | -0.004 | -0.046 |  0.040 |  0.020 | torch.Size([64]) || fusion3_3.1.bias
 | -0.001 | -0.422 |  0.127 |  0.036 | torch.Size([256, 256]) || body3_4.linear_encoding.weight
 |  0.004 | -0.070 |  0.103 |  0.027 | torch.Size([256]) || body3_4.linear_encoding.bias
 | -0.001 | -0.242 |  0.266 |  0.045 | torch.Size([1024, 256]) || body3_4.mlp_head.0.weight
 | -0.048 | -0.153 |  0.070 |  0.037 | torch.Size([1024]) || body3_4.mlp_head.0.bias
 | -0.000 | -0.253 |  0.279 |  0.029 | torch.Size([256, 1024]) || body3_4.mlp_head.3.weight
 | -0.003 | -0.120 |  0.087 |  0.033 | torch.Size([256]) || body3_4.mlp_head.3.bias
 | -0.000 | -0.206 |  0.223 |  0.042 | torch.Size([768, 256]) || body3_4.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.142 |  0.141 |  0.032 | torch.Size([256, 256]) || body3_4.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.203 |  0.204 |  0.039 | torch.Size([1024, 256]) || body3_4.encoder.layers.0.linear1.weight
 | -0.039 | -0.130 |  0.059 |  0.037 | torch.Size([1024]) || body3_4.encoder.layers.0.linear1.bias
 |  0.000 | -0.210 |  0.170 |  0.021 | torch.Size([256, 1024]) || body3_4.encoder.layers.0.linear2.weight
 |  0.001 | -0.072 |  0.060 |  0.024 | torch.Size([256]) || body3_4.encoder.layers.0.linear2.bias
 |  0.803 |  0.654 |  0.952 |  0.065 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.weight
 | -0.002 | -0.177 |  0.127 |  0.051 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.bias
 |  0.788 |  0.498 |  1.070 |  0.097 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.weight
 |  0.000 | -0.201 |  0.187 |  0.082 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.bias
 |  0.000 | -0.041 |  0.042 |  0.009 | torch.Size([3, 64, 3, 3]) || tail.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([3]) || tail.bias

25-05-16 13:47:58.019 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising\DRNet25\models\10_G.pth
    task: denoising\DRNet25
    log: denoising\DRNet25
    options: denoising\DRNet25\options
    models: denoising\DRNet25\models
    images: denoising\DRNet25\images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages_4fen
      dataroot_L: None
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-16 13:47:58.019 : Random seed: 2269
25-05-16 13:47:59.600 : Number of train images: 124,020, iters: 124,020
25-05-16 13:47:59.948 : 
Networks name: DRNet
Params number: 17746115
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-16 13:48:02.363 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.002 | -0.431 |  0.525 |  0.178 | torch.Size([64, 3, 3, 3]) || head1.weight
 | -0.001 | -0.329 |  0.276 |  0.180 | torch.Size([64]) || head1.bias
 |  0.000 | -0.495 |  0.459 |  0.097 | torch.Size([64, 64, 3, 3]) || head1_1.body.0.weight
 |  0.074 | -0.072 |  0.204 |  0.065 | torch.Size([64]) || head1_1.body.0.bias
 | -0.000 | -0.513 |  0.543 |  0.083 | torch.Size([64, 64, 3, 3]) || head1_1.body.2.weight
 |  0.010 | -0.100 |  0.126 |  0.053 | torch.Size([64]) || head1_1.body.2.bias
 |  0.000 | -0.276 |  0.284 |  0.057 | torch.Size([768, 256]) || head1_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.001 | -0.305 |  0.275 |  0.061 | torch.Size([256, 256]) || head1_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.289 |  0.269 |  0.055 | torch.Size([1024, 256]) || head1_3.encoder.layers.0.linear1.weight
 | -0.020 | -0.164 |  0.093 |  0.041 | torch.Size([1024]) || head1_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.386 |  0.382 |  0.045 | torch.Size([256, 1024]) || head1_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.072 |  0.077 |  0.028 | torch.Size([256]) || head1_3.encoder.layers.0.linear2.bias
 |  1.012 |  0.775 |  1.163 |  0.059 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.weight
 |  0.004 | -0.167 |  0.277 |  0.052 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.bias
 |  1.076 |  0.945 |  1.226 |  0.051 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.weight
 |  0.002 | -0.067 |  0.086 |  0.028 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || head1_3.position_encoding.position_ids
 |  0.000 | -5.338 |  4.747 |  0.991 | torch.Size([4096, 256]) || head1_3.position_encoding.pe.weight
 |  0.000 | -0.882 |  0.949 |  0.033 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.0.weight
 |  0.026 | -0.097 |  0.106 |  0.042 | torch.Size([64]) || body1_1.0.body.0.bias
 | -0.001 | -0.343 |  0.336 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.2.weight
 | -0.014 | -0.134 |  0.111 |  0.059 | torch.Size([64]) || body1_1.0.body.2.bias
 | -0.001 | -0.447 |  0.425 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_1.1.weight
 |  0.046 | -0.053 |  0.147 |  0.045 | torch.Size([64]) || body1_1.1.bias
 |  0.000 | -0.167 |  0.174 |  0.041 | torch.Size([768, 256]) || body1_2.0.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.156 |  0.136 |  0.037 | torch.Size([256, 256]) || body1_2.0.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.290 |  0.236 |  0.042 | torch.Size([1024, 256]) || body1_2.0.encoder.layers.0.linear1.weight
 |  0.002 | -0.074 |  0.093 |  0.038 | torch.Size([1024]) || body1_2.0.encoder.layers.0.linear1.bias
 | -0.003 | -0.253 |  0.202 |  0.027 | torch.Size([256, 1024]) || body1_2.0.encoder.layers.0.linear2.weight
 | -0.006 | -0.057 |  0.044 |  0.020 | torch.Size([256]) || body1_2.0.encoder.layers.0.linear2.bias
 |  0.990 |  0.813 |  1.118 |  0.063 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.weight
 |  0.008 | -0.135 |  0.146 |  0.063 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.bias
 |  0.990 |  0.807 |  1.147 |  0.053 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.weight
 |  0.010 | -0.208 |  0.233 |  0.077 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body1_2.0.position_encoding.position_ids
 |  0.001 | -4.538 |  4.875 |  0.995 | torch.Size([4096, 256]) || body1_2.0.position_encoding.pe.weight
 | -0.001 | -0.285 |  0.215 |  0.036 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.0.weight
 |  0.002 | -0.102 |  0.081 |  0.033 | torch.Size([64]) || body1_2.1.body.0.bias
 | -0.005 | -0.256 |  0.258 |  0.033 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.2.weight
 | -0.015 | -0.099 |  0.047 |  0.032 | torch.Size([64]) || body1_2.1.body.2.bias
 |  0.000 | -0.258 |  0.223 |  0.048 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.0.weight
 |  0.014 | -0.103 |  0.110 |  0.042 | torch.Size([64]) || body2_1.0.body.0.bias
 |  0.000 | -0.271 |  0.448 |  0.046 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.2.weight
 | -0.005 | -0.124 |  0.150 |  0.071 | torch.Size([64]) || body2_1.0.body.2.bias
 |  0.000 | -0.303 |  0.341 |  0.058 | torch.Size([768, 256]) || body2_1.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.293 |  0.303 |  0.066 | torch.Size([256, 256]) || body2_1.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.278 |  0.288 |  0.057 | torch.Size([1024, 256]) || body2_1.1.encoder.layers.0.linear1.weight
 |  0.009 | -0.113 |  0.121 |  0.041 | torch.Size([1024]) || body2_1.1.encoder.layers.0.linear1.bias
 | -0.000 | -0.259 |  0.247 |  0.046 | torch.Size([256, 1024]) || body2_1.1.encoder.layers.0.linear2.weight
 | -0.001 | -0.066 |  0.068 |  0.029 | torch.Size([256]) || body2_1.1.encoder.layers.0.linear2.bias
 |  1.064 |  0.947 |  1.177 |  0.043 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.weight
 |  0.003 | -0.123 |  0.142 |  0.058 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.bias
 |  1.154 |  0.989 |  1.326 |  0.061 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.096 |  0.103 |  0.031 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_1.1.position_encoding.position_ids
 | -0.001 | -4.994 |  4.878 |  0.999 | torch.Size([4096, 256]) || body2_1.1.position_encoding.pe.weight
 | -0.003 | -0.328 |  0.342 |  0.112 | torch.Size([128, 1, 5, 5]) || fusion2_1.0.weight
 |  0.015 | -0.256 |  0.240 |  0.120 | torch.Size([128]) || fusion2_1.0.bias
 |  0.000 | -0.220 |  0.215 |  0.054 | torch.Size([64, 128, 1, 1]) || fusion2_1.1.weight
 | -0.004 | -0.169 |  0.144 |  0.080 | torch.Size([64]) || fusion2_1.1.bias
 |  0.002 | -0.174 |  0.203 |  0.041 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.0.weight
 |  0.004 | -0.133 |  0.204 |  0.074 | torch.Size([64]) || body2_2.0.body.0.bias
 |  0.000 | -0.204 |  0.201 |  0.040 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.2.weight
 | -0.004 | -0.206 |  0.186 |  0.095 | torch.Size([64]) || body2_2.0.body.2.bias
 | -0.000 | -0.398 |  0.312 |  0.062 | torch.Size([768, 256]) || body2_2.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.312 |  0.352 |  0.075 | torch.Size([256, 256]) || body2_2.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.238 |  0.245 |  0.058 | torch.Size([1024, 256]) || body2_2.1.encoder.layers.0.linear1.weight
 | -0.002 | -0.144 |  0.129 |  0.049 | torch.Size([1024]) || body2_2.1.encoder.layers.0.linear1.bias
 |  0.000 | -0.240 |  0.267 |  0.046 | torch.Size([256, 1024]) || body2_2.1.encoder.layers.0.linear2.weight
 |  0.002 | -0.048 |  0.054 |  0.023 | torch.Size([256]) || body2_2.1.encoder.layers.0.linear2.bias
 |  1.092 |  0.957 |  1.206 |  0.044 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.weight
 |  0.001 | -0.160 |  0.185 |  0.068 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.bias
 |  1.119 |  0.943 |  1.277 |  0.049 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.097 |  0.093 |  0.031 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_2.1.position_encoding.position_ids
 | -0.001 | -4.834 |  4.669 |  0.998 | torch.Size([4096, 256]) || body2_2.1.position_encoding.pe.weight
 | -0.000 | -0.287 |  0.353 |  0.105 | torch.Size([128, 1, 5, 5]) || fusion2_2.0.weight
 | -0.014 | -0.203 |  0.212 |  0.115 | torch.Size([128]) || fusion2_2.0.bias
 | -0.001 | -0.189 |  0.248 |  0.056 | torch.Size([64, 128, 1, 1]) || fusion2_2.1.weight
 | -0.019 | -0.130 |  0.141 |  0.060 | torch.Size([64]) || fusion2_2.1.bias
 | -0.000 | -0.229 |  0.211 |  0.051 | torch.Size([768, 256]) || body2_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.222 |  0.218 |  0.053 | torch.Size([256, 256]) || body2_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.214 |  0.205 |  0.049 | torch.Size([1024, 256]) || body2_3.encoder.layers.0.linear1.weight
 | -0.029 | -0.135 |  0.086 |  0.040 | torch.Size([1024]) || body2_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.179 |  0.173 |  0.036 | torch.Size([256, 1024]) || body2_3.encoder.layers.0.linear2.weight
 |  0.002 | -0.041 |  0.073 |  0.021 | torch.Size([256]) || body2_3.encoder.layers.0.linear2.bias
 |  1.047 |  0.954 |  1.182 |  0.038 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.112 |  0.142 |  0.043 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.bias
 |  0.979 |  0.858 |  1.114 |  0.039 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.080 |  0.070 |  0.027 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_3.position_encoding.position_ids
 | -0.000 | -4.715 |  5.525 |  0.998 | torch.Size([4096, 256]) || body2_3.position_encoding.pe.weight
 |  0.000 | -0.228 |  0.222 |  0.038 | torch.Size([64, 64, 3, 3]) || body3_1.0.weight
 |  0.019 | -0.055 |  0.070 |  0.030 | torch.Size([64]) || body3_1.0.bias
 |  0.000 | -0.164 |  0.162 |  0.039 | torch.Size([768, 256]) || body3_1.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.161 |  0.166 |  0.040 | torch.Size([256, 256]) || body3_1.2.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.283 |  0.246 |  0.047 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.0.linear1.weight
 | -0.010 | -0.099 |  0.095 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.285 |  0.296 |  0.033 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.0.linear2.weight
 | -0.006 | -0.067 |  0.073 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.linear2.bias
 |  1.000 |  0.922 |  1.073 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.085 |  0.076 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.bias
 |  1.105 |  0.980 |  1.255 |  0.049 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.weight
 |  0.002 | -0.072 |  0.087 |  0.032 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.134 |  0.163 |  0.038 | torch.Size([768, 256]) || body3_1.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.127 |  0.128 |  0.038 | torch.Size([256, 256]) || body3_1.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.339 |  0.290 |  0.046 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.1.linear1.weight
 | -0.006 | -0.095 |  0.090 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.1.linear1.bias
 | -0.002 | -0.359 |  0.420 |  0.032 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.1.linear2.weight
 | -0.007 | -0.064 |  0.045 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.linear2.bias
 |  0.995 |  0.945 |  1.094 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.weight
 | -0.001 | -0.059 |  0.062 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.bias
 |  1.122 |  0.994 |  1.290 |  0.049 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.weight
 |  0.001 | -0.051 |  0.053 |  0.020 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_1.2.position_encoding.position_ids
 |  0.002 | -4.658 |  4.616 |  1.000 | torch.Size([4096, 256]) || body3_1.2.position_encoding.pe.weight
 |  0.001 | -0.205 |  0.215 |  0.075 | torch.Size([128, 1, 5, 5]) || fusion3_1.0.weight
 |  0.006 | -0.234 |  0.245 |  0.123 | torch.Size([128]) || fusion3_1.0.bias
 | -0.000 | -0.136 |  0.158 |  0.030 | torch.Size([64, 128, 1, 1]) || fusion3_1.1.weight
 | -0.008 | -0.184 |  0.153 |  0.085 | torch.Size([64]) || fusion3_1.1.bias
 | -0.000 | -0.109 |  0.112 |  0.027 | torch.Size([64, 64, 3, 3]) || body3_2.0.weight
 |  0.055 | -0.103 |  0.115 |  0.036 | torch.Size([64]) || body3_2.0.bias
 |  0.000 | -0.144 |  0.126 |  0.040 | torch.Size([768, 256]) || body3_2.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.110 |  0.108 |  0.037 | torch.Size([256, 256]) || body3_2.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.197 |  0.214 |  0.051 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.0.linear1.weight
 | -0.042 | -0.131 |  0.063 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.170 |  0.151 |  0.036 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.0.linear2.weight
 | -0.008 | -0.062 |  0.038 |  0.022 | torch.Size([256]) || body3_2.2.encoder.layers.0.linear2.bias
 |  0.996 |  0.839 |  1.076 |  0.030 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.120 |  0.174 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.bias
 |  1.048 |  0.924 |  1.175 |  0.044 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.weight
 | -0.001 | -0.130 |  0.095 |  0.040 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.110 |  0.115 |  0.038 | torch.Size([768, 256]) || body3_2.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.115 |  0.104 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.186 |  0.193 |  0.049 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.1.linear1.weight
 | -0.026 | -0.111 |  0.086 |  0.037 | torch.Size([1024]) || body3_2.2.encoder.layers.1.linear1.bias
 | -0.001 | -0.155 |  0.168 |  0.035 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.1.linear2.weight
 | -0.009 | -0.067 |  0.045 |  0.024 | torch.Size([256]) || body3_2.2.encoder.layers.1.linear2.bias
 |  0.987 |  0.919 |  1.031 |  0.020 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.weight
 | -0.000 | -0.102 |  0.110 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.bias
 |  1.052 |  0.957 |  1.143 |  0.034 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.weight
 | -0.000 | -0.052 |  0.048 |  0.018 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_2.2.position_encoding.position_ids
 |  0.001 | -5.085 |  5.020 |  1.000 | torch.Size([4096, 256]) || body3_2.2.position_encoding.pe.weight
 |  0.002 | -0.229 |  0.257 |  0.090 | torch.Size([128, 1, 5, 5]) || fusion3_2.0.weight
 |  0.003 | -0.196 |  0.231 |  0.106 | torch.Size([128]) || fusion3_2.0.bias
 |  0.001 | -0.147 |  0.146 |  0.046 | torch.Size([64, 128, 1, 1]) || fusion3_2.1.weight
 |  0.006 | -0.088 |  0.127 |  0.049 | torch.Size([64]) || fusion3_2.1.bias
 | -0.001 | -0.204 |  0.188 |  0.047 | torch.Size([256, 256]) || body3_3.linear_encoding.weight
 | -0.004 | -0.129 |  0.130 |  0.056 | torch.Size([256]) || body3_3.linear_encoding.bias
 | -0.000 | -0.224 |  0.192 |  0.045 | torch.Size([1024, 256]) || body3_3.mlp_head.0.weight
 | -0.026 | -0.120 |  0.072 |  0.038 | torch.Size([1024]) || body3_3.mlp_head.0.bias
 | -0.000 | -0.209 |  0.188 |  0.032 | torch.Size([256, 1024]) || body3_3.mlp_head.3.weight
 |  0.002 | -0.082 |  0.075 |  0.028 | torch.Size([256]) || body3_3.mlp_head.3.bias
 |  0.000 | -0.130 |  0.132 |  0.039 | torch.Size([768, 256]) || body3_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.141 |  0.153 |  0.037 | torch.Size([256, 256]) || body3_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.214 |  0.188 |  0.044 | torch.Size([1024, 256]) || body3_3.encoder.layers.0.linear1.weight
 | -0.036 | -0.132 |  0.054 |  0.036 | torch.Size([1024]) || body3_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.179 |  0.229 |  0.031 | torch.Size([256, 1024]) || body3_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.073 |  0.066 |  0.024 | torch.Size([256]) || body3_3.encoder.layers.0.linear2.bias
 |  0.924 |  0.834 |  1.000 |  0.026 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.weight
 |  0.001 | -0.067 |  0.098 |  0.030 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.bias
 |  0.875 |  0.790 |  1.027 |  0.039 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.189 |  0.175 |  0.063 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.bias
 | -0.000 | -0.164 |  0.174 |  0.046 | torch.Size([192, 1, 5, 5]) || fusion3_3.0.weight
 |  0.004 | -0.188 |  0.217 |  0.083 | torch.Size([192]) || fusion3_3.0.bias
 |  0.000 | -0.115 |  0.106 |  0.021 | torch.Size([64, 192, 1, 1]) || fusion3_3.1.weight
 | -0.004 | -0.046 |  0.040 |  0.020 | torch.Size([64]) || fusion3_3.1.bias
 | -0.001 | -0.422 |  0.127 |  0.036 | torch.Size([256, 256]) || body3_4.linear_encoding.weight
 |  0.004 | -0.070 |  0.103 |  0.027 | torch.Size([256]) || body3_4.linear_encoding.bias
 | -0.001 | -0.242 |  0.266 |  0.045 | torch.Size([1024, 256]) || body3_4.mlp_head.0.weight
 | -0.048 | -0.153 |  0.070 |  0.037 | torch.Size([1024]) || body3_4.mlp_head.0.bias
 | -0.000 | -0.253 |  0.279 |  0.029 | torch.Size([256, 1024]) || body3_4.mlp_head.3.weight
 | -0.003 | -0.120 |  0.087 |  0.033 | torch.Size([256]) || body3_4.mlp_head.3.bias
 | -0.000 | -0.206 |  0.223 |  0.042 | torch.Size([768, 256]) || body3_4.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.142 |  0.141 |  0.032 | torch.Size([256, 256]) || body3_4.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.203 |  0.204 |  0.039 | torch.Size([1024, 256]) || body3_4.encoder.layers.0.linear1.weight
 | -0.039 | -0.130 |  0.059 |  0.037 | torch.Size([1024]) || body3_4.encoder.layers.0.linear1.bias
 |  0.000 | -0.210 |  0.170 |  0.021 | torch.Size([256, 1024]) || body3_4.encoder.layers.0.linear2.weight
 |  0.001 | -0.072 |  0.060 |  0.024 | torch.Size([256]) || body3_4.encoder.layers.0.linear2.bias
 |  0.803 |  0.654 |  0.952 |  0.065 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.weight
 | -0.002 | -0.177 |  0.127 |  0.051 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.bias
 |  0.788 |  0.498 |  1.070 |  0.097 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.weight
 |  0.000 | -0.201 |  0.187 |  0.082 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.bias
 |  0.000 | -0.041 |  0.042 |  0.009 | torch.Size([3, 64, 3, 3]) || tail.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([3]) || tail.bias

25-05-16 14:52:37.519 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/10_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-16 14:52:37.520 : Random seed: 7908
25-05-16 14:52:38.003 : Number of train images: 31,005, iters: 31,005
25-05-16 14:52:43.858 : 
Networks name: DRNet
Params number: 17746115
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-16 14:52:46.701 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.002 | -0.431 |  0.525 |  0.178 | torch.Size([64, 3, 3, 3]) || head1.weight
 | -0.001 | -0.329 |  0.276 |  0.180 | torch.Size([64]) || head1.bias
 |  0.000 | -0.495 |  0.459 |  0.097 | torch.Size([64, 64, 3, 3]) || head1_1.body.0.weight
 |  0.074 | -0.072 |  0.204 |  0.065 | torch.Size([64]) || head1_1.body.0.bias
 | -0.000 | -0.513 |  0.543 |  0.083 | torch.Size([64, 64, 3, 3]) || head1_1.body.2.weight
 |  0.010 | -0.100 |  0.126 |  0.053 | torch.Size([64]) || head1_1.body.2.bias
 |  0.000 | -0.276 |  0.284 |  0.057 | torch.Size([768, 256]) || head1_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.001 | -0.305 |  0.275 |  0.061 | torch.Size([256, 256]) || head1_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.289 |  0.269 |  0.055 | torch.Size([1024, 256]) || head1_3.encoder.layers.0.linear1.weight
 | -0.020 | -0.164 |  0.093 |  0.041 | torch.Size([1024]) || head1_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.386 |  0.382 |  0.045 | torch.Size([256, 1024]) || head1_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.072 |  0.077 |  0.028 | torch.Size([256]) || head1_3.encoder.layers.0.linear2.bias
 |  1.012 |  0.775 |  1.163 |  0.059 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.weight
 |  0.004 | -0.167 |  0.277 |  0.052 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.bias
 |  1.076 |  0.945 |  1.226 |  0.051 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.weight
 |  0.002 | -0.067 |  0.086 |  0.028 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || head1_3.position_encoding.position_ids
 |  0.000 | -5.338 |  4.747 |  0.991 | torch.Size([4096, 256]) || head1_3.position_encoding.pe.weight
 |  0.000 | -0.882 |  0.949 |  0.033 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.0.weight
 |  0.026 | -0.097 |  0.106 |  0.042 | torch.Size([64]) || body1_1.0.body.0.bias
 | -0.001 | -0.343 |  0.336 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.2.weight
 | -0.014 | -0.134 |  0.111 |  0.059 | torch.Size([64]) || body1_1.0.body.2.bias
 | -0.001 | -0.447 |  0.425 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_1.1.weight
 |  0.046 | -0.053 |  0.147 |  0.045 | torch.Size([64]) || body1_1.1.bias
 |  0.000 | -0.167 |  0.174 |  0.041 | torch.Size([768, 256]) || body1_2.0.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.156 |  0.136 |  0.037 | torch.Size([256, 256]) || body1_2.0.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.290 |  0.236 |  0.042 | torch.Size([1024, 256]) || body1_2.0.encoder.layers.0.linear1.weight
 |  0.002 | -0.074 |  0.093 |  0.038 | torch.Size([1024]) || body1_2.0.encoder.layers.0.linear1.bias
 | -0.003 | -0.253 |  0.202 |  0.027 | torch.Size([256, 1024]) || body1_2.0.encoder.layers.0.linear2.weight
 | -0.006 | -0.057 |  0.044 |  0.020 | torch.Size([256]) || body1_2.0.encoder.layers.0.linear2.bias
 |  0.990 |  0.813 |  1.118 |  0.063 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.weight
 |  0.008 | -0.135 |  0.146 |  0.063 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.bias
 |  0.990 |  0.807 |  1.147 |  0.053 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.weight
 |  0.010 | -0.208 |  0.233 |  0.077 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body1_2.0.position_encoding.position_ids
 |  0.001 | -4.538 |  4.875 |  0.995 | torch.Size([4096, 256]) || body1_2.0.position_encoding.pe.weight
 | -0.001 | -0.285 |  0.215 |  0.036 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.0.weight
 |  0.002 | -0.102 |  0.081 |  0.033 | torch.Size([64]) || body1_2.1.body.0.bias
 | -0.005 | -0.256 |  0.258 |  0.033 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.2.weight
 | -0.015 | -0.099 |  0.047 |  0.032 | torch.Size([64]) || body1_2.1.body.2.bias
 |  0.000 | -0.258 |  0.223 |  0.048 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.0.weight
 |  0.014 | -0.103 |  0.110 |  0.042 | torch.Size([64]) || body2_1.0.body.0.bias
 |  0.000 | -0.271 |  0.448 |  0.046 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.2.weight
 | -0.005 | -0.124 |  0.150 |  0.071 | torch.Size([64]) || body2_1.0.body.2.bias
 |  0.000 | -0.303 |  0.341 |  0.058 | torch.Size([768, 256]) || body2_1.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.293 |  0.303 |  0.066 | torch.Size([256, 256]) || body2_1.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.278 |  0.288 |  0.057 | torch.Size([1024, 256]) || body2_1.1.encoder.layers.0.linear1.weight
 |  0.009 | -0.113 |  0.121 |  0.041 | torch.Size([1024]) || body2_1.1.encoder.layers.0.linear1.bias
 | -0.000 | -0.259 |  0.247 |  0.046 | torch.Size([256, 1024]) || body2_1.1.encoder.layers.0.linear2.weight
 | -0.001 | -0.066 |  0.068 |  0.029 | torch.Size([256]) || body2_1.1.encoder.layers.0.linear2.bias
 |  1.064 |  0.947 |  1.177 |  0.043 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.weight
 |  0.003 | -0.123 |  0.142 |  0.058 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.bias
 |  1.154 |  0.989 |  1.326 |  0.061 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.096 |  0.103 |  0.031 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_1.1.position_encoding.position_ids
 | -0.001 | -4.994 |  4.878 |  0.999 | torch.Size([4096, 256]) || body2_1.1.position_encoding.pe.weight
 | -0.003 | -0.328 |  0.342 |  0.112 | torch.Size([128, 1, 5, 5]) || fusion2_1.0.weight
 |  0.015 | -0.256 |  0.240 |  0.120 | torch.Size([128]) || fusion2_1.0.bias
 |  0.000 | -0.220 |  0.215 |  0.054 | torch.Size([64, 128, 1, 1]) || fusion2_1.1.weight
 | -0.004 | -0.169 |  0.144 |  0.080 | torch.Size([64]) || fusion2_1.1.bias
 |  0.002 | -0.174 |  0.203 |  0.041 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.0.weight
 |  0.004 | -0.133 |  0.204 |  0.074 | torch.Size([64]) || body2_2.0.body.0.bias
 |  0.000 | -0.204 |  0.201 |  0.040 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.2.weight
 | -0.004 | -0.206 |  0.186 |  0.095 | torch.Size([64]) || body2_2.0.body.2.bias
 | -0.000 | -0.398 |  0.312 |  0.062 | torch.Size([768, 256]) || body2_2.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.312 |  0.352 |  0.075 | torch.Size([256, 256]) || body2_2.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.238 |  0.245 |  0.058 | torch.Size([1024, 256]) || body2_2.1.encoder.layers.0.linear1.weight
 | -0.002 | -0.144 |  0.129 |  0.049 | torch.Size([1024]) || body2_2.1.encoder.layers.0.linear1.bias
 |  0.000 | -0.240 |  0.267 |  0.046 | torch.Size([256, 1024]) || body2_2.1.encoder.layers.0.linear2.weight
 |  0.002 | -0.048 |  0.054 |  0.023 | torch.Size([256]) || body2_2.1.encoder.layers.0.linear2.bias
 |  1.092 |  0.957 |  1.206 |  0.044 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.weight
 |  0.001 | -0.160 |  0.185 |  0.068 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.bias
 |  1.119 |  0.943 |  1.277 |  0.049 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.097 |  0.093 |  0.031 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_2.1.position_encoding.position_ids
 | -0.001 | -4.834 |  4.669 |  0.998 | torch.Size([4096, 256]) || body2_2.1.position_encoding.pe.weight
 | -0.000 | -0.287 |  0.353 |  0.105 | torch.Size([128, 1, 5, 5]) || fusion2_2.0.weight
 | -0.014 | -0.203 |  0.212 |  0.115 | torch.Size([128]) || fusion2_2.0.bias
 | -0.001 | -0.189 |  0.248 |  0.056 | torch.Size([64, 128, 1, 1]) || fusion2_2.1.weight
 | -0.019 | -0.130 |  0.141 |  0.060 | torch.Size([64]) || fusion2_2.1.bias
 | -0.000 | -0.229 |  0.211 |  0.051 | torch.Size([768, 256]) || body2_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.222 |  0.218 |  0.053 | torch.Size([256, 256]) || body2_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.214 |  0.205 |  0.049 | torch.Size([1024, 256]) || body2_3.encoder.layers.0.linear1.weight
 | -0.029 | -0.135 |  0.086 |  0.040 | torch.Size([1024]) || body2_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.179 |  0.173 |  0.036 | torch.Size([256, 1024]) || body2_3.encoder.layers.0.linear2.weight
 |  0.002 | -0.041 |  0.073 |  0.021 | torch.Size([256]) || body2_3.encoder.layers.0.linear2.bias
 |  1.047 |  0.954 |  1.182 |  0.038 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.112 |  0.142 |  0.043 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.bias
 |  0.979 |  0.858 |  1.114 |  0.039 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.080 |  0.070 |  0.027 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_3.position_encoding.position_ids
 | -0.000 | -4.715 |  5.525 |  0.998 | torch.Size([4096, 256]) || body2_3.position_encoding.pe.weight
 |  0.000 | -0.228 |  0.222 |  0.038 | torch.Size([64, 64, 3, 3]) || body3_1.0.weight
 |  0.019 | -0.055 |  0.070 |  0.030 | torch.Size([64]) || body3_1.0.bias
 |  0.000 | -0.164 |  0.162 |  0.039 | torch.Size([768, 256]) || body3_1.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.161 |  0.166 |  0.040 | torch.Size([256, 256]) || body3_1.2.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.283 |  0.246 |  0.047 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.0.linear1.weight
 | -0.010 | -0.099 |  0.095 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.285 |  0.296 |  0.033 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.0.linear2.weight
 | -0.006 | -0.067 |  0.073 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.linear2.bias
 |  1.000 |  0.922 |  1.073 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.085 |  0.076 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.bias
 |  1.105 |  0.980 |  1.255 |  0.049 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.weight
 |  0.002 | -0.072 |  0.087 |  0.032 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.134 |  0.163 |  0.038 | torch.Size([768, 256]) || body3_1.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.127 |  0.128 |  0.038 | torch.Size([256, 256]) || body3_1.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.339 |  0.290 |  0.046 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.1.linear1.weight
 | -0.006 | -0.095 |  0.090 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.1.linear1.bias
 | -0.002 | -0.359 |  0.420 |  0.032 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.1.linear2.weight
 | -0.007 | -0.064 |  0.045 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.linear2.bias
 |  0.995 |  0.945 |  1.094 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.weight
 | -0.001 | -0.059 |  0.062 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.bias
 |  1.122 |  0.994 |  1.290 |  0.049 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.weight
 |  0.001 | -0.051 |  0.053 |  0.020 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_1.2.position_encoding.position_ids
 |  0.002 | -4.658 |  4.616 |  1.000 | torch.Size([4096, 256]) || body3_1.2.position_encoding.pe.weight
 |  0.001 | -0.205 |  0.215 |  0.075 | torch.Size([128, 1, 5, 5]) || fusion3_1.0.weight
 |  0.006 | -0.234 |  0.245 |  0.123 | torch.Size([128]) || fusion3_1.0.bias
 | -0.000 | -0.136 |  0.158 |  0.030 | torch.Size([64, 128, 1, 1]) || fusion3_1.1.weight
 | -0.008 | -0.184 |  0.153 |  0.085 | torch.Size([64]) || fusion3_1.1.bias
 | -0.000 | -0.109 |  0.112 |  0.027 | torch.Size([64, 64, 3, 3]) || body3_2.0.weight
 |  0.055 | -0.103 |  0.115 |  0.036 | torch.Size([64]) || body3_2.0.bias
 |  0.000 | -0.144 |  0.126 |  0.040 | torch.Size([768, 256]) || body3_2.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.110 |  0.108 |  0.037 | torch.Size([256, 256]) || body3_2.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.197 |  0.214 |  0.051 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.0.linear1.weight
 | -0.042 | -0.131 |  0.063 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.170 |  0.151 |  0.036 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.0.linear2.weight
 | -0.008 | -0.062 |  0.038 |  0.022 | torch.Size([256]) || body3_2.2.encoder.layers.0.linear2.bias
 |  0.996 |  0.839 |  1.076 |  0.030 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.120 |  0.174 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.bias
 |  1.048 |  0.924 |  1.175 |  0.044 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.weight
 | -0.001 | -0.130 |  0.095 |  0.040 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.110 |  0.115 |  0.038 | torch.Size([768, 256]) || body3_2.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.115 |  0.104 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.186 |  0.193 |  0.049 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.1.linear1.weight
 | -0.026 | -0.111 |  0.086 |  0.037 | torch.Size([1024]) || body3_2.2.encoder.layers.1.linear1.bias
 | -0.001 | -0.155 |  0.168 |  0.035 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.1.linear2.weight
 | -0.009 | -0.067 |  0.045 |  0.024 | torch.Size([256]) || body3_2.2.encoder.layers.1.linear2.bias
 |  0.987 |  0.919 |  1.031 |  0.020 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.weight
 | -0.000 | -0.102 |  0.110 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.bias
 |  1.052 |  0.957 |  1.143 |  0.034 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.weight
 | -0.000 | -0.052 |  0.048 |  0.018 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_2.2.position_encoding.position_ids
 |  0.001 | -5.085 |  5.020 |  1.000 | torch.Size([4096, 256]) || body3_2.2.position_encoding.pe.weight
 |  0.002 | -0.229 |  0.257 |  0.090 | torch.Size([128, 1, 5, 5]) || fusion3_2.0.weight
 |  0.003 | -0.196 |  0.231 |  0.106 | torch.Size([128]) || fusion3_2.0.bias
 |  0.001 | -0.147 |  0.146 |  0.046 | torch.Size([64, 128, 1, 1]) || fusion3_2.1.weight
 |  0.006 | -0.088 |  0.127 |  0.049 | torch.Size([64]) || fusion3_2.1.bias
 | -0.001 | -0.204 |  0.188 |  0.047 | torch.Size([256, 256]) || body3_3.linear_encoding.weight
 | -0.004 | -0.129 |  0.130 |  0.056 | torch.Size([256]) || body3_3.linear_encoding.bias
 | -0.000 | -0.224 |  0.192 |  0.045 | torch.Size([1024, 256]) || body3_3.mlp_head.0.weight
 | -0.026 | -0.120 |  0.072 |  0.038 | torch.Size([1024]) || body3_3.mlp_head.0.bias
 | -0.000 | -0.209 |  0.188 |  0.032 | torch.Size([256, 1024]) || body3_3.mlp_head.3.weight
 |  0.002 | -0.082 |  0.075 |  0.028 | torch.Size([256]) || body3_3.mlp_head.3.bias
 |  0.000 | -0.130 |  0.132 |  0.039 | torch.Size([768, 256]) || body3_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.141 |  0.153 |  0.037 | torch.Size([256, 256]) || body3_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.214 |  0.188 |  0.044 | torch.Size([1024, 256]) || body3_3.encoder.layers.0.linear1.weight
 | -0.036 | -0.132 |  0.054 |  0.036 | torch.Size([1024]) || body3_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.179 |  0.229 |  0.031 | torch.Size([256, 1024]) || body3_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.073 |  0.066 |  0.024 | torch.Size([256]) || body3_3.encoder.layers.0.linear2.bias
 |  0.924 |  0.834 |  1.000 |  0.026 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.weight
 |  0.001 | -0.067 |  0.098 |  0.030 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.bias
 |  0.875 |  0.790 |  1.027 |  0.039 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.189 |  0.175 |  0.063 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.bias
 | -0.000 | -0.164 |  0.174 |  0.046 | torch.Size([192, 1, 5, 5]) || fusion3_3.0.weight
 |  0.004 | -0.188 |  0.217 |  0.083 | torch.Size([192]) || fusion3_3.0.bias
 |  0.000 | -0.115 |  0.106 |  0.021 | torch.Size([64, 192, 1, 1]) || fusion3_3.1.weight
 | -0.004 | -0.046 |  0.040 |  0.020 | torch.Size([64]) || fusion3_3.1.bias
 | -0.001 | -0.422 |  0.127 |  0.036 | torch.Size([256, 256]) || body3_4.linear_encoding.weight
 |  0.004 | -0.070 |  0.103 |  0.027 | torch.Size([256]) || body3_4.linear_encoding.bias
 | -0.001 | -0.242 |  0.266 |  0.045 | torch.Size([1024, 256]) || body3_4.mlp_head.0.weight
 | -0.048 | -0.153 |  0.070 |  0.037 | torch.Size([1024]) || body3_4.mlp_head.0.bias
 | -0.000 | -0.253 |  0.279 |  0.029 | torch.Size([256, 1024]) || body3_4.mlp_head.3.weight
 | -0.003 | -0.120 |  0.087 |  0.033 | torch.Size([256]) || body3_4.mlp_head.3.bias
 | -0.000 | -0.206 |  0.223 |  0.042 | torch.Size([768, 256]) || body3_4.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.142 |  0.141 |  0.032 | torch.Size([256, 256]) || body3_4.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.203 |  0.204 |  0.039 | torch.Size([1024, 256]) || body3_4.encoder.layers.0.linear1.weight
 | -0.039 | -0.130 |  0.059 |  0.037 | torch.Size([1024]) || body3_4.encoder.layers.0.linear1.bias
 |  0.000 | -0.210 |  0.170 |  0.021 | torch.Size([256, 1024]) || body3_4.encoder.layers.0.linear2.weight
 |  0.001 | -0.072 |  0.060 |  0.024 | torch.Size([256]) || body3_4.encoder.layers.0.linear2.bias
 |  0.803 |  0.654 |  0.952 |  0.065 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.weight
 | -0.002 | -0.177 |  0.127 |  0.051 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.bias
 |  0.788 |  0.498 |  1.070 |  0.097 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.weight
 |  0.000 | -0.201 |  0.187 |  0.082 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.bias
 |  0.000 | -0.041 |  0.042 |  0.009 | torch.Size([3, 64, 3, 3]) || tail.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([3]) || tail.bias

25-05-16 16:34:33.445 : <epoch:  0, iter:   5,000, lr:1.000e-04> G_loss: 5.149e-05 
25-05-16 16:34:33.449 : Saving the model.
25-05-16 20:34:21.318 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/5000_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test_4fen
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-16 20:34:21.319 : Random seed: 5369
25-05-16 20:34:21.456 : Number of train images: 31,005, iters: 31,005
25-05-16 20:34:22.794 : 
Networks name: DRNet
Params number: 17746115
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-16 20:34:23.371 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.002 | -0.418 |  0.503 |  0.174 | torch.Size([64, 3, 3, 3]) || head1.weight
 | -0.001 | -0.343 |  0.293 |  0.193 | torch.Size([64]) || head1.bias
 |  0.000 | -0.487 |  0.448 |  0.095 | torch.Size([64, 64, 3, 3]) || head1_1.body.0.weight
 |  0.081 | -0.079 |  0.213 |  0.068 | torch.Size([64]) || head1_1.body.0.bias
 | -0.000 | -0.507 |  0.544 |  0.082 | torch.Size([64, 64, 3, 3]) || head1_1.body.2.weight
 |  0.010 | -0.102 |  0.128 |  0.054 | torch.Size([64]) || head1_1.body.2.bias
 |  0.000 | -0.275 |  0.290 |  0.057 | torch.Size([768, 256]) || head1_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.001 | -0.315 |  0.286 |  0.063 | torch.Size([256, 256]) || head1_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.297 |  0.276 |  0.056 | torch.Size([1024, 256]) || head1_3.encoder.layers.0.linear1.weight
 | -0.019 | -0.157 |  0.096 |  0.041 | torch.Size([1024]) || head1_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.395 |  0.384 |  0.046 | torch.Size([256, 1024]) || head1_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.074 |  0.077 |  0.029 | torch.Size([256]) || head1_3.encoder.layers.0.linear2.bias
 |  1.017 |  0.774 |  1.174 |  0.060 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.weight
 |  0.004 | -0.168 |  0.275 |  0.052 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.bias
 |  1.083 |  0.957 |  1.240 |  0.052 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.weight
 |  0.002 | -0.066 |  0.088 |  0.029 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || head1_3.position_encoding.position_ids
 |  0.000 | -5.339 |  4.747 |  0.991 | torch.Size([4096, 256]) || head1_3.position_encoding.pe.weight
 |  0.000 | -0.908 |  0.971 |  0.033 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.0.weight
 |  0.027 | -0.101 |  0.107 |  0.042 | torch.Size([64]) || body1_1.0.body.0.bias
 | -0.001 | -0.336 |  0.338 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.2.weight
 | -0.014 | -0.134 |  0.110 |  0.060 | torch.Size([64]) || body1_1.0.body.2.bias
 | -0.001 | -0.455 |  0.433 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_1.1.weight
 |  0.046 | -0.053 |  0.148 |  0.046 | torch.Size([64]) || body1_1.1.bias
 |  0.000 | -0.169 |  0.176 |  0.041 | torch.Size([768, 256]) || body1_2.0.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.155 |  0.136 |  0.037 | torch.Size([256, 256]) || body1_2.0.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.289 |  0.238 |  0.042 | torch.Size([1024, 256]) || body1_2.0.encoder.layers.0.linear1.weight
 |  0.003 | -0.074 |  0.095 |  0.038 | torch.Size([1024]) || body1_2.0.encoder.layers.0.linear1.bias
 | -0.003 | -0.252 |  0.204 |  0.027 | torch.Size([256, 1024]) || body1_2.0.encoder.layers.0.linear2.weight
 | -0.006 | -0.058 |  0.045 |  0.020 | torch.Size([256]) || body1_2.0.encoder.layers.0.linear2.bias
 |  0.991 |  0.814 |  1.120 |  0.063 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.weight
 |  0.008 | -0.134 |  0.146 |  0.063 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.bias
 |  0.993 |  0.803 |  1.154 |  0.054 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.weight
 |  0.010 | -0.216 |  0.238 |  0.079 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body1_2.0.position_encoding.position_ids
 |  0.001 | -4.538 |  4.875 |  0.995 | torch.Size([4096, 256]) || body1_2.0.position_encoding.pe.weight
 | -0.001 | -0.286 |  0.217 |  0.036 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.0.weight
 |  0.003 | -0.101 |  0.082 |  0.033 | torch.Size([64]) || body1_2.1.body.0.bias
 | -0.005 | -0.260 |  0.262 |  0.033 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.2.weight
 | -0.015 | -0.099 |  0.048 |  0.032 | torch.Size([64]) || body1_2.1.body.2.bias
 |  0.000 | -0.259 |  0.237 |  0.048 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.0.weight
 |  0.013 | -0.104 |  0.111 |  0.043 | torch.Size([64]) || body2_1.0.body.0.bias
 |  0.000 | -0.276 |  0.432 |  0.046 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.2.weight
 | -0.005 | -0.125 |  0.151 |  0.071 | torch.Size([64]) || body2_1.0.body.2.bias
 |  0.000 | -0.306 |  0.345 |  0.058 | torch.Size([768, 256]) || body2_1.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.297 |  0.309 |  0.067 | torch.Size([256, 256]) || body2_1.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.282 |  0.291 |  0.058 | torch.Size([1024, 256]) || body2_1.1.encoder.layers.0.linear1.weight
 |  0.010 | -0.113 |  0.124 |  0.041 | torch.Size([1024]) || body2_1.1.encoder.layers.0.linear1.bias
 | -0.000 | -0.259 |  0.253 |  0.047 | torch.Size([256, 1024]) || body2_1.1.encoder.layers.0.linear2.weight
 | -0.001 | -0.067 |  0.069 |  0.030 | torch.Size([256]) || body2_1.1.encoder.layers.0.linear2.bias
 |  1.063 |  0.945 |  1.181 |  0.044 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.weight
 |  0.003 | -0.123 |  0.144 |  0.058 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.bias
 |  1.162 |  0.995 |  1.348 |  0.063 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.103 |  0.106 |  0.032 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_1.1.position_encoding.position_ids
 | -0.001 | -4.994 |  4.878 |  0.999 | torch.Size([4096, 256]) || body2_1.1.position_encoding.pe.weight
 | -0.003 | -0.325 |  0.337 |  0.111 | torch.Size([128, 1, 5, 5]) || fusion2_1.0.weight
 |  0.015 | -0.258 |  0.242 |  0.120 | torch.Size([128]) || fusion2_1.0.bias
 |  0.000 | -0.215 |  0.216 |  0.054 | torch.Size([64, 128, 1, 1]) || fusion2_1.1.weight
 | -0.004 | -0.169 |  0.146 |  0.081 | torch.Size([64]) || fusion2_1.1.bias
 |  0.002 | -0.177 |  0.211 |  0.042 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.0.weight
 |  0.004 | -0.133 |  0.206 |  0.075 | torch.Size([64]) || body2_2.0.body.0.bias
 |  0.000 | -0.204 |  0.202 |  0.041 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.2.weight
 | -0.004 | -0.209 |  0.189 |  0.096 | torch.Size([64]) || body2_2.0.body.2.bias
 | -0.000 | -0.402 |  0.320 |  0.062 | torch.Size([768, 256]) || body2_2.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.319 |  0.362 |  0.076 | torch.Size([256, 256]) || body2_2.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.237 |  0.249 |  0.058 | torch.Size([1024, 256]) || body2_2.1.encoder.layers.0.linear1.weight
 | -0.001 | -0.146 |  0.131 |  0.049 | torch.Size([1024]) || body2_2.1.encoder.layers.0.linear1.bias
 |  0.000 | -0.238 |  0.271 |  0.047 | torch.Size([256, 1024]) || body2_2.1.encoder.layers.0.linear2.weight
 |  0.002 | -0.048 |  0.053 |  0.023 | torch.Size([256]) || body2_2.1.encoder.layers.0.linear2.bias
 |  1.094 |  0.954 |  1.214 |  0.045 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.weight
 |  0.001 | -0.161 |  0.189 |  0.069 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.bias
 |  1.125 |  0.947 |  1.286 |  0.050 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.100 |  0.095 |  0.032 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_2.1.position_encoding.position_ids
 | -0.001 | -4.834 |  4.669 |  0.998 | torch.Size([4096, 256]) || body2_2.1.position_encoding.pe.weight
 | -0.000 | -0.295 |  0.359 |  0.105 | torch.Size([128, 1, 5, 5]) || fusion2_2.0.weight
 | -0.014 | -0.204 |  0.213 |  0.115 | torch.Size([128]) || fusion2_2.0.bias
 | -0.001 | -0.197 |  0.255 |  0.056 | torch.Size([64, 128, 1, 1]) || fusion2_2.1.weight
 | -0.019 | -0.131 |  0.142 |  0.060 | torch.Size([64]) || fusion2_2.1.bias
 | -0.000 | -0.234 |  0.215 |  0.051 | torch.Size([768, 256]) || body2_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.227 |  0.225 |  0.053 | torch.Size([256, 256]) || body2_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.216 |  0.210 |  0.049 | torch.Size([1024, 256]) || body2_3.encoder.layers.0.linear1.weight
 | -0.028 | -0.136 |  0.086 |  0.040 | torch.Size([1024]) || body2_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.180 |  0.178 |  0.037 | torch.Size([256, 1024]) || body2_3.encoder.layers.0.linear2.weight
 |  0.002 | -0.043 |  0.073 |  0.022 | torch.Size([256]) || body2_3.encoder.layers.0.linear2.bias
 |  1.050 |  0.956 |  1.183 |  0.038 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.113 |  0.147 |  0.044 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.bias
 |  0.987 |  0.862 |  1.127 |  0.041 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.081 |  0.069 |  0.027 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_3.position_encoding.position_ids
 | -0.000 | -4.715 |  5.525 |  0.998 | torch.Size([4096, 256]) || body2_3.position_encoding.pe.weight
 |  0.000 | -0.232 |  0.217 |  0.038 | torch.Size([64, 64, 3, 3]) || body3_1.0.weight
 |  0.019 | -0.056 |  0.070 |  0.031 | torch.Size([64]) || body3_1.0.bias
 |  0.000 | -0.166 |  0.164 |  0.039 | torch.Size([768, 256]) || body3_1.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.164 |  0.167 |  0.040 | torch.Size([256, 256]) || body3_1.2.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.282 |  0.245 |  0.047 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.0.linear1.weight
 | -0.009 | -0.099 |  0.094 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.0.linear1.bias
 | -0.003 | -0.284 |  0.296 |  0.033 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.0.linear2.weight
 | -0.006 | -0.068 |  0.074 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.linear2.bias
 |  1.001 |  0.924 |  1.072 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.085 |  0.078 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.bias
 |  1.106 |  0.983 |  1.253 |  0.048 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.weight
 |  0.002 | -0.069 |  0.087 |  0.031 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.136 |  0.167 |  0.038 | torch.Size([768, 256]) || body3_1.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.129 |  0.129 |  0.038 | torch.Size([256, 256]) || body3_1.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.337 |  0.290 |  0.046 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.1.linear1.weight
 | -0.006 | -0.096 |  0.091 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.1.linear1.bias
 | -0.002 | -0.361 |  0.418 |  0.032 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.1.linear2.weight
 | -0.007 | -0.065 |  0.045 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.linear2.bias
 |  0.996 |  0.947 |  1.099 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.weight
 | -0.001 | -0.059 |  0.063 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.bias
 |  1.122 |  0.994 |  1.285 |  0.049 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.weight
 |  0.001 | -0.051 |  0.053 |  0.020 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_1.2.position_encoding.position_ids
 |  0.002 | -4.658 |  4.616 |  1.000 | torch.Size([4096, 256]) || body3_1.2.position_encoding.pe.weight
 |  0.001 | -0.203 |  0.211 |  0.074 | torch.Size([128, 1, 5, 5]) || fusion3_1.0.weight
 |  0.007 | -0.233 |  0.245 |  0.123 | torch.Size([128]) || fusion3_1.0.bias
 | -0.000 | -0.133 |  0.156 |  0.029 | torch.Size([64, 128, 1, 1]) || fusion3_1.1.weight
 | -0.009 | -0.185 |  0.153 |  0.086 | torch.Size([64]) || fusion3_1.1.bias
 | -0.000 | -0.111 |  0.117 |  0.026 | torch.Size([64, 64, 3, 3]) || body3_2.0.weight
 |  0.055 | -0.104 |  0.116 |  0.036 | torch.Size([64]) || body3_2.0.bias
 |  0.000 | -0.144 |  0.126 |  0.040 | torch.Size([768, 256]) || body3_2.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.110 |  0.109 |  0.037 | torch.Size([256, 256]) || body3_2.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.199 |  0.213 |  0.051 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.0.linear1.weight
 | -0.042 | -0.133 |  0.061 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.168 |  0.152 |  0.036 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.0.linear2.weight
 | -0.008 | -0.060 |  0.038 |  0.022 | torch.Size([256]) || body3_2.2.encoder.layers.0.linear2.bias
 |  0.997 |  0.839 |  1.076 |  0.030 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.120 |  0.174 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.bias
 |  1.047 |  0.924 |  1.181 |  0.044 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.weight
 | -0.001 | -0.132 |  0.094 |  0.041 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.110 |  0.114 |  0.038 | torch.Size([768, 256]) || body3_2.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.117 |  0.104 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.188 |  0.191 |  0.049 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.1.linear1.weight
 | -0.026 | -0.111 |  0.089 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.1.linear1.bias
 | -0.001 | -0.152 |  0.167 |  0.035 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.1.linear2.weight
 | -0.009 | -0.066 |  0.049 |  0.024 | torch.Size([256]) || body3_2.2.encoder.layers.1.linear2.bias
 |  0.987 |  0.919 |  1.032 |  0.020 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.weight
 | -0.000 | -0.103 |  0.112 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.bias
 |  1.052 |  0.958 |  1.141 |  0.035 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.weight
 | -0.000 | -0.053 |  0.051 |  0.019 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_2.2.position_encoding.position_ids
 |  0.001 | -5.085 |  5.020 |  1.000 | torch.Size([4096, 256]) || body3_2.2.position_encoding.pe.weight
 |  0.002 | -0.229 |  0.264 |  0.090 | torch.Size([128, 1, 5, 5]) || fusion3_2.0.weight
 |  0.003 | -0.197 |  0.229 |  0.106 | torch.Size([128]) || fusion3_2.0.bias
 |  0.001 | -0.148 |  0.145 |  0.046 | torch.Size([64, 128, 1, 1]) || fusion3_2.1.weight
 |  0.006 | -0.088 |  0.127 |  0.049 | torch.Size([64]) || fusion3_2.1.bias
 | -0.001 | -0.206 |  0.187 |  0.048 | torch.Size([256, 256]) || body3_3.linear_encoding.weight
 | -0.004 | -0.128 |  0.131 |  0.056 | torch.Size([256]) || body3_3.linear_encoding.bias
 | -0.000 | -0.223 |  0.191 |  0.045 | torch.Size([1024, 256]) || body3_3.mlp_head.0.weight
 | -0.026 | -0.123 |  0.060 |  0.038 | torch.Size([1024]) || body3_3.mlp_head.0.bias
 | -0.000 | -0.210 |  0.183 |  0.032 | torch.Size([256, 1024]) || body3_3.mlp_head.3.weight
 |  0.002 | -0.083 |  0.075 |  0.028 | torch.Size([256]) || body3_3.mlp_head.3.bias
 |  0.000 | -0.128 |  0.132 |  0.039 | torch.Size([768, 256]) || body3_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.140 |  0.153 |  0.037 | torch.Size([256, 256]) || body3_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.203 |  0.187 |  0.044 | torch.Size([1024, 256]) || body3_3.encoder.layers.0.linear1.weight
 | -0.036 | -0.131 |  0.057 |  0.036 | torch.Size([1024]) || body3_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.180 |  0.229 |  0.031 | torch.Size([256, 1024]) || body3_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.071 |  0.066 |  0.023 | torch.Size([256]) || body3_3.encoder.layers.0.linear2.bias
 |  0.924 |  0.832 |  0.999 |  0.027 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.weight
 |  0.001 | -0.069 |  0.099 |  0.031 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.bias
 |  0.873 |  0.790 |  1.033 |  0.039 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.184 |  0.176 |  0.062 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.bias
 | -0.001 | -0.165 |  0.175 |  0.046 | torch.Size([192, 1, 5, 5]) || fusion3_3.0.weight
 |  0.004 | -0.188 |  0.216 |  0.083 | torch.Size([192]) || fusion3_3.0.bias
 |  0.000 | -0.111 |  0.106 |  0.021 | torch.Size([64, 192, 1, 1]) || fusion3_3.1.weight
 | -0.003 | -0.045 |  0.041 |  0.021 | torch.Size([64]) || fusion3_3.1.bias
 | -0.001 | -0.431 |  0.131 |  0.036 | torch.Size([256, 256]) || body3_4.linear_encoding.weight
 |  0.004 | -0.075 |  0.108 |  0.029 | torch.Size([256]) || body3_4.linear_encoding.bias
 | -0.001 | -0.246 |  0.265 |  0.045 | torch.Size([1024, 256]) || body3_4.mlp_head.0.weight
 | -0.050 | -0.159 |  0.070 |  0.037 | torch.Size([1024]) || body3_4.mlp_head.0.bias
 | -0.000 | -0.252 |  0.277 |  0.029 | torch.Size([256, 1024]) || body3_4.mlp_head.3.weight
 | -0.003 | -0.122 |  0.091 |  0.034 | torch.Size([256]) || body3_4.mlp_head.3.bias
 | -0.000 | -0.207 |  0.226 |  0.043 | torch.Size([768, 256]) || body3_4.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.143 |  0.140 |  0.033 | torch.Size([256, 256]) || body3_4.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.201 |  0.204 |  0.039 | torch.Size([1024, 256]) || body3_4.encoder.layers.0.linear1.weight
 | -0.039 | -0.135 |  0.060 |  0.037 | torch.Size([1024]) || body3_4.encoder.layers.0.linear1.bias
 |  0.000 | -0.208 |  0.171 |  0.021 | torch.Size([256, 1024]) || body3_4.encoder.layers.0.linear2.weight
 |  0.001 | -0.076 |  0.061 |  0.025 | torch.Size([256]) || body3_4.encoder.layers.0.linear2.bias
 |  0.806 |  0.653 |  0.954 |  0.066 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.weight
 | -0.002 | -0.175 |  0.128 |  0.051 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.bias
 |  0.789 |  0.498 |  1.072 |  0.097 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.weight
 |  0.001 | -0.201 |  0.184 |  0.081 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.bias
 |  0.000 | -0.045 |  0.048 |  0.010 | torch.Size([3, 64, 3, 3]) || tail.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([3]) || tail.bias

25-05-16 21:50:57.411 : <epoch:  0, iter:  10,000, lr:1.000e-04> G_loss: 2.487e-05 
25-05-16 21:50:57.416 : Saving the model.
25-05-16 21:50:58.009 : ---1--> airplane_111_00.jpg | 26.94dB
25-05-16 21:50:58.183 : ---2--> airplane_111_01.jpg | 32.11dB
25-05-16 21:50:58.372 : ---3--> airplane_111_10.jpg | 29.78dB
25-05-16 21:50:58.558 : ---4--> airplane_111_11.jpg | 29.90dB
25-05-16 21:50:58.734 : ---5--> airport_111_00.jpg | 31.67dB
25-05-16 21:50:58.916 : ---6--> airport_111_01.jpg | 29.41dB
25-05-16 21:50:59.099 : ---7--> airport_111_10.jpg | 28.73dB
25-05-16 21:50:59.286 : ---8--> airport_111_11.jpg | 29.70dB
25-05-16 21:50:59.470 : ---9--> baseball_diamond_111_00.jpg | 29.55dB
25-05-16 21:50:59.652 : --10--> baseball_diamond_111_01.jpg | 31.50dB
25-05-16 21:50:59.836 : --11--> baseball_diamond_111_10.jpg | 29.42dB
25-05-16 21:51:00.015 : --12--> baseball_diamond_111_11.jpg | 32.65dB
25-05-16 21:51:00.197 : --13--> basketball_court_111_00.jpg | 27.20dB
25-05-16 21:51:00.383 : --14--> basketball_court_111_01.jpg | 26.89dB
25-05-16 21:51:00.570 : --15--> basketball_court_111_10.jpg | 30.23dB
25-05-16 21:51:00.753 : --16--> basketball_court_111_11.jpg | 28.38dB
25-05-16 21:51:00.930 : --17--> beach_111_00.jpg | 25.49dB
25-05-16 21:51:01.118 : --18--> beach_111_01.jpg | 28.62dB
25-05-16 21:51:01.299 : --19--> beach_111_10.jpg | 26.62dB
25-05-16 21:51:01.480 : --20--> beach_111_11.jpg | 31.72dB
25-05-16 21:51:01.658 : --21--> bridge_111_00.jpg | 38.16dB
25-05-16 21:51:01.835 : --22--> bridge_111_01.jpg | 30.98dB
25-05-16 21:51:02.016 : --23--> bridge_111_10.jpg | 29.80dB
25-05-16 21:51:02.197 : --24--> bridge_111_11.jpg | 33.44dB
25-05-16 21:51:02.377 : --25--> chaparral_111_00.jpg | 27.19dB
25-05-16 21:51:02.564 : --26--> chaparral_111_01.jpg | 27.61dB
25-05-16 21:51:02.748 : --27--> chaparral_111_10.jpg | 28.05dB
25-05-16 21:51:02.931 : --28--> chaparral_111_11.jpg | 25.05dB
25-05-16 21:51:03.116 : --29--> church_111_00.jpg | 28.31dB
25-05-16 21:51:03.296 : --30--> church_111_01.jpg | 27.12dB
25-05-16 21:51:03.479 : --31--> church_111_10.jpg | 31.37dB
25-05-16 21:51:03.666 : --32--> church_111_11.jpg | 26.88dB
25-05-16 21:51:03.847 : --33--> circular_farmland_111_00.jpg | 29.39dB
25-05-16 21:51:04.034 : --34--> circular_farmland_111_01.jpg | 30.67dB
25-05-16 21:51:04.219 : --35--> circular_farmland_111_10.jpg | 31.00dB
25-05-16 21:51:04.397 : --36--> circular_farmland_111_11.jpg | 31.30dB
25-05-16 21:51:04.582 : --37--> cloud_111_00.jpg | 37.72dB
25-05-16 21:51:04.765 : --38--> cloud_111_01.jpg | 33.61dB
25-05-16 21:51:04.946 : --39--> cloud_111_10.jpg | 33.23dB
25-05-16 21:51:05.129 : --40--> cloud_111_11.jpg | 33.52dB
25-05-16 21:51:05.308 : --41--> commercial_area_111_00.jpg | 30.26dB
25-05-16 21:51:05.497 : --42--> commercial_area_111_01.jpg | 28.75dB
25-05-16 21:51:05.681 : --43--> commercial_area_111_10.jpg | 29.75dB
25-05-16 21:51:05.866 : --44--> commercial_area_111_11.jpg | 29.46dB
25-05-16 21:51:06.048 : --45--> dense_residential_111_00.jpg | 26.54dB
25-05-16 21:51:06.229 : --46--> dense_residential_111_01.jpg | 25.63dB
25-05-16 21:51:06.410 : --47--> dense_residential_111_10.jpg | 26.05dB
25-05-16 21:51:06.586 : --48--> dense_residential_111_11.jpg | 25.89dB
25-05-16 21:51:06.769 : --49--> desert_111_00.jpg | 34.33dB
25-05-16 21:51:06.947 : --50--> desert_111_01.jpg | 33.97dB
25-05-16 21:51:07.129 : --51--> desert_111_10.jpg | 34.53dB
25-05-16 21:51:07.309 : --52--> desert_111_11.jpg | 34.38dB
25-05-16 21:51:07.486 : --53--> forest_111_00.jpg | 30.28dB
25-05-16 21:51:07.666 : --54--> forest_111_01.jpg | 29.30dB
25-05-16 21:51:07.848 : --55--> forest_111_10.jpg | 28.61dB
25-05-16 21:51:08.033 : --56--> forest_111_11.jpg | 29.92dB
25-05-16 21:51:08.215 : --57--> freeway_111_00.jpg | 31.19dB
25-05-16 21:51:08.398 : --58--> freeway_111_01.jpg | 31.94dB
25-05-16 21:51:08.579 : --59--> freeway_111_10.jpg | 31.92dB
25-05-16 21:51:08.769 : --60--> freeway_111_11.jpg | 32.05dB
25-05-16 21:51:08.950 : --61--> golf_course_111_00.jpg | 29.64dB
25-05-16 21:51:09.127 : --62--> golf_course_111_01.jpg | 28.62dB
25-05-16 21:51:09.310 : --63--> golf_course_111_10.jpg | 30.47dB
25-05-16 21:51:09.489 : --64--> golf_course_111_11.jpg | 30.81dB
25-05-16 21:51:09.669 : --65--> ground_track_field_111_00.jpg | 29.88dB
25-05-16 21:51:09.855 : --66--> ground_track_field_111_01.jpg | 25.80dB
25-05-16 21:51:10.034 : --67--> ground_track_field_111_10.jpg | 27.42dB
25-05-16 21:51:10.216 : --68--> ground_track_field_111_11.jpg | 26.51dB
25-05-16 21:51:10.399 : --69--> harbor_111_00.jpg | 30.80dB
25-05-16 21:51:10.584 : --70--> harbor_111_01.jpg | 28.04dB
25-05-16 21:51:10.760 : --71--> harbor_111_10.jpg | 27.38dB
25-05-16 21:51:10.945 : --72--> harbor_111_11.jpg | 29.27dB
25-05-16 21:51:11.128 : --73--> industrial_area_111_00.jpg | 28.55dB
25-05-16 21:51:11.312 : --74--> industrial_area_111_01.jpg | 28.25dB
25-05-16 21:51:11.491 : --75--> industrial_area_111_10.jpg | 28.63dB
25-05-16 21:51:11.673 : --76--> industrial_area_111_11.jpg | 27.81dB
25-05-16 21:51:11.858 : --77--> intersection_111_00.jpg | 27.33dB
25-05-16 21:51:12.041 : --78--> intersection_111_01.jpg | 27.38dB
25-05-16 21:51:12.218 : --79--> intersection_111_10.jpg | 26.90dB
25-05-16 21:51:12.401 : --80--> intersection_111_11.jpg | 26.68dB
25-05-16 21:51:12.581 : --81--> island_111_00.jpg | 28.13dB
25-05-16 21:51:12.764 : --82--> island_111_01.jpg | 30.68dB
25-05-16 21:51:12.943 : --83--> island_111_10.jpg | 29.14dB
25-05-16 21:51:13.130 : --84--> island_111_11.jpg | 28.72dB
25-05-16 21:51:13.315 : --85--> lake_111_00.jpg | 29.99dB
25-05-16 21:51:13.492 : --86--> lake_111_01.jpg | 29.84dB
25-05-16 21:51:13.677 : --87--> lake_111_10.jpg | 28.72dB
25-05-16 21:51:13.860 : --88--> lake_111_11.jpg | 28.33dB
25-05-16 21:51:14.042 : --89--> meadow_111_00.jpg | 27.26dB
25-05-16 21:51:14.228 : --90--> meadow_111_01.jpg | 27.25dB
25-05-16 21:51:14.408 : --91--> meadow_111_10.jpg | 27.46dB
25-05-16 21:51:14.593 : --92--> meadow_111_11.jpg | 27.57dB
25-05-16 21:51:14.777 : --93--> medium_residential_111_00.jpg | 25.09dB
25-05-16 21:51:14.955 : --94--> medium_residential_111_01.jpg | 24.52dB
25-05-16 21:51:15.132 : --95--> medium_residential_111_10.jpg | 24.89dB
25-05-16 21:51:15.317 : --96--> medium_residential_111_11.jpg | 25.47dB
25-05-16 21:51:15.501 : --97--> mobile_home_park_111_00.jpg | 27.31dB
25-05-16 21:51:15.681 : --98--> mobile_home_park_111_01.jpg | 27.87dB
25-05-16 21:51:15.866 : --99--> mobile_home_park_111_10.jpg | 28.30dB
25-05-16 21:51:16.045 : -100--> mobile_home_park_111_11.jpg | 28.14dB
25-05-16 21:51:16.225 : -101--> mountain_111_00.jpg | 25.51dB
25-05-16 21:51:16.407 : -102--> mountain_111_01.jpg | 26.44dB
25-05-16 21:51:16.586 : -103--> mountain_111_10.jpg | 26.03dB
25-05-16 21:51:16.768 : -104--> mountain_111_11.jpg | 26.51dB
25-05-16 21:51:16.951 : -105--> overpass_111_00.jpg | 26.97dB
25-05-16 21:51:17.128 : -106--> overpass_111_01.jpg | 26.66dB
25-05-16 21:51:17.314 : -107--> overpass_111_10.jpg | 27.51dB
25-05-16 21:51:17.494 : -108--> overpass_111_11.jpg | 28.12dB
25-05-16 21:51:17.674 : -109--> palace_111_00.jpg | 26.46dB
25-05-16 21:51:17.859 : -110--> palace_111_01.jpg | 26.26dB
25-05-16 21:51:18.045 : -111--> palace_111_10.jpg | 27.80dB
25-05-16 21:51:18.230 : -112--> palace_111_11.jpg | 25.88dB
25-05-16 21:51:18.413 : -113--> parking_lot_111_00.jpg | 25.42dB
25-05-16 21:51:18.595 : -114--> parking_lot_111_01.jpg | 25.68dB
25-05-16 21:51:18.776 : -115--> parking_lot_111_10.jpg | 27.69dB
25-05-16 21:51:18.959 : -116--> parking_lot_111_11.jpg | 26.49dB
25-05-16 21:51:19.137 : -117--> railway_111_00.jpg | 27.08dB
25-05-16 21:51:19.315 : -118--> railway_111_01.jpg | 26.52dB
25-05-16 21:51:19.497 : -119--> railway_111_10.jpg | 29.77dB
25-05-16 21:51:19.677 : -120--> railway_111_11.jpg | 25.52dB
25-05-16 21:51:19.858 : -121--> railway_station_111_00.jpg | 27.66dB
25-05-16 21:51:20.043 : -122--> railway_station_111_01.jpg | 28.51dB
25-05-16 21:51:20.227 : -123--> railway_station_111_10.jpg | 27.88dB
25-05-16 21:51:20.407 : -124--> railway_station_111_11.jpg | 28.58dB
25-05-16 21:51:20.594 : -125--> rectangular_farmland_111_00.jpg | 30.30dB
25-05-16 21:51:20.777 : -126--> rectangular_farmland_111_01.jpg | 28.50dB
25-05-16 21:51:20.963 : -127--> rectangular_farmland_111_10.jpg | 30.53dB
25-05-16 21:51:21.142 : -128--> rectangular_farmland_111_11.jpg | 30.92dB
25-05-16 21:51:21.328 : -129--> river_111_00.jpg | 26.84dB
25-05-16 21:51:21.513 : -130--> river_111_01.jpg | 26.89dB
25-05-16 21:51:21.693 : -131--> river_111_10.jpg | 25.98dB
25-05-16 21:51:21.881 : -132--> river_111_11.jpg | 28.04dB
25-05-16 21:51:22.057 : -133--> roundabout_111_00.jpg | 27.16dB
25-05-16 21:51:22.244 : -134--> roundabout_111_01.jpg | 29.02dB
25-05-16 21:51:22.432 : -135--> roundabout_111_10.jpg | 27.16dB
25-05-16 21:51:22.615 : -136--> roundabout_111_11.jpg | 27.42dB
25-05-16 21:51:22.797 : -137--> runway_111_00.jpg | 33.32dB
25-05-16 21:51:22.978 : -138--> runway_111_01.jpg | 32.67dB
25-05-16 21:51:23.159 : -139--> runway_111_10.jpg | 34.07dB
25-05-16 21:51:23.338 : -140--> runway_111_11.jpg | 33.99dB
25-05-16 21:51:23.519 : -141--> sea_ice_111_00.jpg | 30.21dB
25-05-16 21:51:23.698 : -142--> sea_ice_111_01.jpg | 31.08dB
25-05-16 21:51:23.879 : -143--> sea_ice_111_10.jpg | 30.23dB
25-05-16 21:51:24.061 : -144--> sea_ice_111_11.jpg | 31.36dB
25-05-16 21:51:24.242 : -145--> ship_111_00.jpg | 35.49dB
25-05-16 21:51:24.430 : -146--> ship_111_01.jpg | 31.10dB
25-05-16 21:51:24.612 : -147--> ship_111_10.jpg | 40.23dB
25-05-16 21:51:24.792 : -148--> ship_111_11.jpg | 36.34dB
25-05-16 21:51:24.971 : -149--> snowberg_111_00.jpg | 30.57dB
25-05-16 21:51:25.158 : -150--> snowberg_111_01.jpg | 29.24dB
25-05-16 21:51:25.346 : -151--> snowberg_111_10.jpg | 28.41dB
25-05-16 21:51:25.530 : -152--> snowberg_111_11.jpg | 28.45dB
25-05-16 21:51:25.709 : -153--> sparse_residential_111_00.jpg | 27.20dB
25-05-16 21:51:25.887 : -154--> sparse_residential_111_01.jpg | 27.88dB
25-05-16 21:51:26.074 : -155--> sparse_residential_111_10.jpg | 26.23dB
25-05-16 21:51:26.262 : -156--> sparse_residential_111_11.jpg | 26.90dB
25-05-16 21:51:26.442 : -157--> stadium_111_00.jpg | 26.51dB
25-05-16 21:51:26.629 : -158--> stadium_111_01.jpg | 26.42dB
25-05-16 21:51:26.813 : -159--> stadium_111_10.jpg | 27.90dB
25-05-16 21:51:26.993 : -160--> stadium_111_11.jpg | 26.48dB
25-05-16 21:51:27.180 : -161--> storage_tank_111_00.jpg | 28.61dB
25-05-16 21:51:27.361 : -162--> storage_tank_111_01.jpg | 28.71dB
25-05-16 21:51:27.538 : -163--> storage_tank_111_10.jpg | 27.49dB
25-05-16 21:51:27.728 : -164--> storage_tank_111_11.jpg | 28.00dB
25-05-16 21:51:27.911 : -165--> tennis_court_111_00.jpg | 28.83dB
25-05-16 21:51:28.095 : -166--> tennis_court_111_01.jpg | 28.65dB
25-05-16 21:51:28.279 : -167--> tennis_court_111_10.jpg | 28.48dB
25-05-16 21:51:28.459 : -168--> tennis_court_111_11.jpg | 26.61dB
25-05-16 21:51:28.640 : -169--> terrace_111_00.jpg | 29.16dB
25-05-16 21:51:28.824 : -170--> terrace_111_01.jpg | 30.11dB
25-05-16 21:51:29.008 : -171--> terrace_111_10.jpg | 28.92dB
25-05-16 21:51:29.192 : -172--> terrace_111_11.jpg | 29.12dB
25-05-16 21:51:29.373 : -173--> thermal_power_station_111_00.jpg | 26.73dB
25-05-16 21:51:29.558 : -174--> thermal_power_station_111_01.jpg | 28.07dB
25-05-16 21:51:29.738 : -175--> thermal_power_station_111_10.jpg | 26.24dB
25-05-16 21:51:29.920 : -176--> thermal_power_station_111_11.jpg | 26.74dB
25-05-16 21:51:30.102 : -177--> wetland_111_00.jpg | 28.46dB
25-05-16 21:51:30.280 : -178--> wetland_111_01.jpg | 28.62dB
25-05-16 21:51:30.461 : -179--> wetland_111_10.jpg | 28.84dB
25-05-16 21:51:30.641 : -180--> wetland_111_11.jpg | 28.00dB
25-05-16 21:51:30.649 : <epoch:  0, iter:  10,000, Average PSNR : 28.94dB

25-05-16 23:07:58.665 : <epoch:  0, iter:  15,000, lr:1.000e-04> G_loss: 2.024e-04 
25-05-16 23:07:58.666 : Saving the model.
25-05-16 23:07:59.250 : ---1--> airplane_111_00.jpg | 26.92dB
25-05-16 23:07:59.427 : ---2--> airplane_111_01.jpg | 32.15dB
25-05-16 23:07:59.614 : ---3--> airplane_111_10.jpg | 29.76dB
25-05-16 23:07:59.794 : ---4--> airplane_111_11.jpg | 29.86dB
25-05-16 23:07:59.979 : ---5--> airport_111_00.jpg | 31.66dB
25-05-16 23:08:00.163 : ---6--> airport_111_01.jpg | 29.41dB
25-05-16 23:08:00.343 : ---7--> airport_111_10.jpg | 28.74dB
25-05-16 23:08:00.519 : ---8--> airport_111_11.jpg | 29.70dB
25-05-16 23:08:00.704 : ---9--> baseball_diamond_111_00.jpg | 29.53dB
25-05-16 23:08:00.879 : --10--> baseball_diamond_111_01.jpg | 31.52dB
25-05-16 23:08:01.064 : --11--> baseball_diamond_111_10.jpg | 29.45dB
25-05-16 23:08:01.242 : --12--> baseball_diamond_111_11.jpg | 32.68dB
25-05-16 23:08:01.428 : --13--> basketball_court_111_00.jpg | 27.21dB
25-05-16 23:08:01.615 : --14--> basketball_court_111_01.jpg | 26.90dB
25-05-16 23:08:01.793 : --15--> basketball_court_111_10.jpg | 30.23dB
25-05-16 23:08:01.977 : --16--> basketball_court_111_11.jpg | 28.43dB
25-05-16 23:08:02.157 : --17--> beach_111_00.jpg | 25.47dB
25-05-16 23:08:02.341 : --18--> beach_111_01.jpg | 28.59dB
25-05-16 23:08:02.517 : --19--> beach_111_10.jpg | 26.58dB
25-05-16 23:08:02.698 : --20--> beach_111_11.jpg | 31.74dB
25-05-16 23:08:02.877 : --21--> bridge_111_00.jpg | 38.35dB
25-05-16 23:08:03.064 : --22--> bridge_111_01.jpg | 31.07dB
25-05-16 23:08:03.246 : --23--> bridge_111_10.jpg | 29.87dB
25-05-16 23:08:03.425 : --24--> bridge_111_11.jpg | 33.51dB
25-05-16 23:08:03.608 : --25--> chaparral_111_00.jpg | 27.19dB
25-05-16 23:08:03.790 : --26--> chaparral_111_01.jpg | 27.58dB
25-05-16 23:08:03.966 : --27--> chaparral_111_10.jpg | 28.06dB
25-05-16 23:08:04.150 : --28--> chaparral_111_11.jpg | 25.04dB
25-05-16 23:08:04.329 : --29--> church_111_00.jpg | 28.35dB
25-05-16 23:08:04.507 : --30--> church_111_01.jpg | 27.12dB
25-05-16 23:08:04.689 : --31--> church_111_10.jpg | 31.42dB
25-05-16 23:08:04.869 : --32--> church_111_11.jpg | 26.88dB
25-05-16 23:08:05.049 : --33--> circular_farmland_111_00.jpg | 29.43dB
25-05-16 23:08:05.232 : --34--> circular_farmland_111_01.jpg | 30.73dB
25-05-16 23:08:05.412 : --35--> circular_farmland_111_10.jpg | 31.02dB
25-05-16 23:08:05.591 : --36--> circular_farmland_111_11.jpg | 31.30dB
25-05-16 23:08:05.771 : --37--> cloud_111_00.jpg | 37.75dB
25-05-16 23:08:05.953 : --38--> cloud_111_01.jpg | 33.62dB
25-05-16 23:08:06.129 : --39--> cloud_111_10.jpg | 33.24dB
25-05-16 23:08:06.309 : --40--> cloud_111_11.jpg | 33.62dB
25-05-16 23:08:06.485 : --41--> commercial_area_111_00.jpg | 30.32dB
25-05-16 23:08:06.663 : --42--> commercial_area_111_01.jpg | 28.76dB
25-05-16 23:08:06.846 : --43--> commercial_area_111_10.jpg | 29.73dB
25-05-16 23:08:07.028 : --44--> commercial_area_111_11.jpg | 29.47dB
25-05-16 23:08:07.211 : --45--> dense_residential_111_00.jpg | 26.59dB
25-05-16 23:08:07.392 : --46--> dense_residential_111_01.jpg | 25.67dB
25-05-16 23:08:07.569 : --47--> dense_residential_111_10.jpg | 26.09dB
25-05-16 23:08:07.744 : --48--> dense_residential_111_11.jpg | 25.89dB
25-05-16 23:08:07.924 : --49--> desert_111_00.jpg | 34.25dB
25-05-16 23:08:08.104 : --50--> desert_111_01.jpg | 33.83dB
25-05-16 23:08:08.280 : --51--> desert_111_10.jpg | 34.39dB
25-05-16 23:08:08.460 : --52--> desert_111_11.jpg | 34.29dB
25-05-16 23:08:08.644 : --53--> forest_111_00.jpg | 30.30dB
25-05-16 23:08:08.829 : --54--> forest_111_01.jpg | 29.33dB
25-05-16 23:08:09.005 : --55--> forest_111_10.jpg | 28.62dB
25-05-16 23:08:09.179 : --56--> forest_111_11.jpg | 29.91dB
25-05-16 23:08:09.360 : --57--> freeway_111_00.jpg | 31.19dB
25-05-16 23:08:09.542 : --58--> freeway_111_01.jpg | 31.98dB
25-05-16 23:08:09.722 : --59--> freeway_111_10.jpg | 31.94dB
25-05-16 23:08:09.905 : --60--> freeway_111_11.jpg | 32.10dB
25-05-16 23:08:10.079 : --61--> golf_course_111_00.jpg | 29.67dB
25-05-16 23:08:10.262 : --62--> golf_course_111_01.jpg | 28.67dB
25-05-16 23:08:10.439 : --63--> golf_course_111_10.jpg | 30.45dB
25-05-16 23:08:10.626 : --64--> golf_course_111_11.jpg | 30.85dB
25-05-16 23:08:10.808 : --65--> ground_track_field_111_00.jpg | 29.89dB
25-05-16 23:08:10.989 : --66--> ground_track_field_111_01.jpg | 25.83dB
25-05-16 23:08:11.172 : --67--> ground_track_field_111_10.jpg | 27.44dB
25-05-16 23:08:11.355 : --68--> ground_track_field_111_11.jpg | 26.53dB
25-05-16 23:08:11.539 : --69--> harbor_111_00.jpg | 30.78dB
25-05-16 23:08:11.719 : --70--> harbor_111_01.jpg | 28.06dB
25-05-16 23:08:11.893 : --71--> harbor_111_10.jpg | 27.40dB
25-05-16 23:08:12.067 : --72--> harbor_111_11.jpg | 29.30dB
25-05-16 23:08:12.244 : --73--> industrial_area_111_00.jpg | 28.61dB
25-05-16 23:08:12.432 : --74--> industrial_area_111_01.jpg | 28.23dB
25-05-16 23:08:12.607 : --75--> industrial_area_111_10.jpg | 28.61dB
25-05-16 23:08:12.790 : --76--> industrial_area_111_11.jpg | 27.82dB
25-05-16 23:08:12.968 : --77--> intersection_111_00.jpg | 27.35dB
25-05-16 23:08:13.161 : --78--> intersection_111_01.jpg | 27.40dB
25-05-16 23:08:13.342 : --79--> intersection_111_10.jpg | 26.93dB
25-05-16 23:08:13.527 : --80--> intersection_111_11.jpg | 26.74dB
25-05-16 23:08:13.700 : --81--> island_111_00.jpg | 28.16dB
25-05-16 23:08:13.890 : --82--> island_111_01.jpg | 30.71dB
25-05-16 23:08:14.068 : --83--> island_111_10.jpg | 29.15dB
25-05-16 23:08:14.244 : --84--> island_111_11.jpg | 28.74dB
25-05-16 23:08:14.425 : --85--> lake_111_00.jpg | 29.99dB
25-05-16 23:08:14.607 : --86--> lake_111_01.jpg | 29.81dB
25-05-16 23:08:14.787 : --87--> lake_111_10.jpg | 28.72dB
25-05-16 23:08:14.968 : --88--> lake_111_11.jpg | 28.35dB
25-05-16 23:08:15.150 : --89--> meadow_111_00.jpg | 27.27dB
25-05-16 23:08:15.328 : --90--> meadow_111_01.jpg | 27.25dB
25-05-16 23:08:15.506 : --91--> meadow_111_10.jpg | 27.46dB
25-05-16 23:08:15.693 : --92--> meadow_111_11.jpg | 27.56dB
25-05-16 23:08:15.872 : --93--> medium_residential_111_00.jpg | 25.11dB
25-05-16 23:08:16.053 : --94--> medium_residential_111_01.jpg | 24.50dB
25-05-16 23:08:16.239 : --95--> medium_residential_111_10.jpg | 24.89dB
25-05-16 23:08:16.417 : --96--> medium_residential_111_11.jpg | 25.45dB
25-05-16 23:08:16.600 : --97--> mobile_home_park_111_00.jpg | 27.29dB
25-05-16 23:08:16.779 : --98--> mobile_home_park_111_01.jpg | 27.85dB
25-05-16 23:08:16.962 : --99--> mobile_home_park_111_10.jpg | 28.26dB
25-05-16 23:08:17.146 : -100--> mobile_home_park_111_11.jpg | 28.13dB
25-05-16 23:08:17.327 : -101--> mountain_111_00.jpg | 25.47dB
25-05-16 23:08:17.507 : -102--> mountain_111_01.jpg | 26.42dB
25-05-16 23:08:17.690 : -103--> mountain_111_10.jpg | 26.02dB
25-05-16 23:08:17.874 : -104--> mountain_111_11.jpg | 26.51dB
25-05-16 23:08:18.055 : -105--> overpass_111_00.jpg | 26.90dB
25-05-16 23:08:18.236 : -106--> overpass_111_01.jpg | 26.65dB
25-05-16 23:08:18.419 : -107--> overpass_111_10.jpg | 27.56dB
25-05-16 23:08:18.599 : -108--> overpass_111_11.jpg | 28.08dB
25-05-16 23:08:18.776 : -109--> palace_111_00.jpg | 26.47dB
25-05-16 23:08:18.959 : -110--> palace_111_01.jpg | 26.26dB
25-05-16 23:08:19.138 : -111--> palace_111_10.jpg | 27.83dB
25-05-16 23:08:19.323 : -112--> palace_111_11.jpg | 25.89dB
25-05-16 23:08:19.510 : -113--> parking_lot_111_00.jpg | 25.42dB
25-05-16 23:08:19.685 : -114--> parking_lot_111_01.jpg | 25.63dB
25-05-16 23:08:19.871 : -115--> parking_lot_111_10.jpg | 27.67dB
25-05-16 23:08:20.054 : -116--> parking_lot_111_11.jpg | 26.49dB
25-05-16 23:08:20.240 : -117--> railway_111_00.jpg | 27.08dB
25-05-16 23:08:20.416 : -118--> railway_111_01.jpg | 26.54dB
25-05-16 23:08:20.596 : -119--> railway_111_10.jpg | 29.78dB
25-05-16 23:08:20.778 : -120--> railway_111_11.jpg | 25.54dB
25-05-16 23:08:20.959 : -121--> railway_station_111_00.jpg | 27.61dB
25-05-16 23:08:21.139 : -122--> railway_station_111_01.jpg | 28.51dB
25-05-16 23:08:21.323 : -123--> railway_station_111_10.jpg | 27.93dB
25-05-16 23:08:21.502 : -124--> railway_station_111_11.jpg | 28.60dB
25-05-16 23:08:21.685 : -125--> rectangular_farmland_111_00.jpg | 30.29dB
25-05-16 23:08:21.865 : -126--> rectangular_farmland_111_01.jpg | 28.50dB
25-05-16 23:08:22.043 : -127--> rectangular_farmland_111_10.jpg | 30.56dB
25-05-16 23:08:22.219 : -128--> rectangular_farmland_111_11.jpg | 30.90dB
25-05-16 23:08:22.400 : -129--> river_111_00.jpg | 26.85dB
25-05-16 23:08:22.586 : -130--> river_111_01.jpg | 26.86dB
25-05-16 23:08:22.763 : -131--> river_111_10.jpg | 26.01dB
25-05-16 23:08:22.943 : -132--> river_111_11.jpg | 28.08dB
25-05-16 23:08:23.121 : -133--> roundabout_111_00.jpg | 27.20dB
25-05-16 23:08:23.307 : -134--> roundabout_111_01.jpg | 29.03dB
25-05-16 23:08:23.490 : -135--> roundabout_111_10.jpg | 27.18dB
25-05-16 23:08:23.669 : -136--> roundabout_111_11.jpg | 27.42dB
25-05-16 23:08:23.853 : -137--> runway_111_00.jpg | 33.47dB
25-05-16 23:08:24.031 : -138--> runway_111_01.jpg | 32.83dB
25-05-16 23:08:24.215 : -139--> runway_111_10.jpg | 34.07dB
25-05-16 23:08:24.392 : -140--> runway_111_11.jpg | 34.08dB
25-05-16 23:08:24.574 : -141--> sea_ice_111_00.jpg | 30.25dB
25-05-16 23:08:24.754 : -142--> sea_ice_111_01.jpg | 31.10dB
25-05-16 23:08:24.928 : -143--> sea_ice_111_10.jpg | 30.24dB
25-05-16 23:08:25.110 : -144--> sea_ice_111_11.jpg | 31.41dB
25-05-16 23:08:25.289 : -145--> ship_111_00.jpg | 35.56dB
25-05-16 23:08:25.473 : -146--> ship_111_01.jpg | 31.10dB
25-05-16 23:08:25.651 : -147--> ship_111_10.jpg | 40.42dB
25-05-16 23:08:25.832 : -148--> ship_111_11.jpg | 36.36dB
25-05-16 23:08:26.008 : -149--> snowberg_111_00.jpg | 30.60dB
25-05-16 23:08:26.191 : -150--> snowberg_111_01.jpg | 29.25dB
25-05-16 23:08:26.374 : -151--> snowberg_111_10.jpg | 28.40dB
25-05-16 23:08:26.557 : -152--> snowberg_111_11.jpg | 28.46dB
25-05-16 23:08:26.741 : -153--> sparse_residential_111_00.jpg | 27.19dB
25-05-16 23:08:26.919 : -154--> sparse_residential_111_01.jpg | 27.88dB
25-05-16 23:08:27.101 : -155--> sparse_residential_111_10.jpg | 26.27dB
25-05-16 23:08:27.284 : -156--> sparse_residential_111_11.jpg | 26.86dB
25-05-16 23:08:27.470 : -157--> stadium_111_00.jpg | 26.53dB
25-05-16 23:08:27.657 : -158--> stadium_111_01.jpg | 26.41dB
25-05-16 23:08:27.840 : -159--> stadium_111_10.jpg | 27.88dB
25-05-16 23:08:28.019 : -160--> stadium_111_11.jpg | 26.48dB
25-05-16 23:08:28.203 : -161--> storage_tank_111_00.jpg | 28.64dB
25-05-16 23:08:28.381 : -162--> storage_tank_111_01.jpg | 28.73dB
25-05-16 23:08:28.559 : -163--> storage_tank_111_10.jpg | 27.46dB
25-05-16 23:08:28.734 : -164--> storage_tank_111_11.jpg | 27.97dB
25-05-16 23:08:28.916 : -165--> tennis_court_111_00.jpg | 28.87dB
25-05-16 23:08:29.096 : -166--> tennis_court_111_01.jpg | 28.61dB
25-05-16 23:08:29.273 : -167--> tennis_court_111_10.jpg | 28.48dB
25-05-16 23:08:29.450 : -168--> tennis_court_111_11.jpg | 26.61dB
25-05-16 23:08:29.632 : -169--> terrace_111_00.jpg | 29.16dB
25-05-16 23:08:29.813 : -170--> terrace_111_01.jpg | 30.18dB
25-05-16 23:08:29.989 : -171--> terrace_111_10.jpg | 28.91dB
25-05-16 23:08:30.173 : -172--> terrace_111_11.jpg | 29.15dB
25-05-16 23:08:30.352 : -173--> thermal_power_station_111_00.jpg | 26.72dB
25-05-16 23:08:30.531 : -174--> thermal_power_station_111_01.jpg | 28.08dB
25-05-16 23:08:30.708 : -175--> thermal_power_station_111_10.jpg | 26.24dB
25-05-16 23:08:30.889 : -176--> thermal_power_station_111_11.jpg | 26.77dB
25-05-16 23:08:31.070 : -177--> wetland_111_00.jpg | 28.50dB
25-05-16 23:08:31.251 : -178--> wetland_111_01.jpg | 28.63dB
25-05-16 23:08:31.434 : -179--> wetland_111_10.jpg | 28.82dB
25-05-16 23:08:31.614 : -180--> wetland_111_11.jpg | 28.01dB
25-05-16 23:08:31.621 : <epoch:  0, iter:  15,000, Average PSNR : 28.95dB

25-05-17 00:24:58.909 : <epoch:  0, iter:  20,000, lr:1.000e-04> G_loss: 2.643e-04 
25-05-17 00:24:58.910 : Saving the model.
25-05-17 00:24:59.528 : ---1--> airplane_111_00.jpg | 26.95dB
25-05-17 00:24:59.706 : ---2--> airplane_111_01.jpg | 32.19dB
25-05-17 00:24:59.889 : ---3--> airplane_111_10.jpg | 29.81dB
25-05-17 00:25:00.070 : ---4--> airplane_111_11.jpg | 29.94dB
25-05-17 00:25:00.249 : ---5--> airport_111_00.jpg | 31.72dB
25-05-17 00:25:00.427 : ---6--> airport_111_01.jpg | 29.43dB
25-05-17 00:25:00.609 : ---7--> airport_111_10.jpg | 28.74dB
25-05-17 00:25:00.790 : ---8--> airport_111_11.jpg | 29.75dB
25-05-17 00:25:00.973 : ---9--> baseball_diamond_111_00.jpg | 29.60dB
25-05-17 00:25:01.148 : --10--> baseball_diamond_111_01.jpg | 31.47dB
25-05-17 00:25:01.326 : --11--> baseball_diamond_111_10.jpg | 29.46dB
25-05-17 00:25:01.507 : --12--> baseball_diamond_111_11.jpg | 32.65dB
25-05-17 00:25:01.688 : --13--> basketball_court_111_00.jpg | 27.21dB
25-05-17 00:25:01.870 : --14--> basketball_court_111_01.jpg | 26.90dB
25-05-17 00:25:02.051 : --15--> basketball_court_111_10.jpg | 30.28dB
25-05-17 00:25:02.228 : --16--> basketball_court_111_11.jpg | 28.41dB
25-05-17 00:25:02.408 : --17--> beach_111_00.jpg | 25.48dB
25-05-17 00:25:02.584 : --18--> beach_111_01.jpg | 28.63dB
25-05-17 00:25:02.766 : --19--> beach_111_10.jpg | 26.62dB
25-05-17 00:25:02.944 : --20--> beach_111_11.jpg | 31.78dB
25-05-17 00:25:03.125 : --21--> bridge_111_00.jpg | 38.18dB
25-05-17 00:25:03.308 : --22--> bridge_111_01.jpg | 31.05dB
25-05-17 00:25:03.487 : --23--> bridge_111_10.jpg | 29.87dB
25-05-17 00:25:03.668 : --24--> bridge_111_11.jpg | 33.51dB
25-05-17 00:25:03.841 : --25--> chaparral_111_00.jpg | 27.20dB
25-05-17 00:25:04.017 : --26--> chaparral_111_01.jpg | 27.61dB
25-05-17 00:25:04.196 : --27--> chaparral_111_10.jpg | 28.03dB
25-05-17 00:25:04.372 : --28--> chaparral_111_11.jpg | 25.08dB
25-05-17 00:25:04.557 : --29--> church_111_00.jpg | 28.33dB
25-05-17 00:25:04.740 : --30--> church_111_01.jpg | 27.12dB
25-05-17 00:25:04.918 : --31--> church_111_10.jpg | 31.43dB
25-05-17 00:25:05.102 : --32--> church_111_11.jpg | 26.89dB
25-05-17 00:25:05.277 : --33--> circular_farmland_111_00.jpg | 29.42dB
25-05-17 00:25:05.458 : --34--> circular_farmland_111_01.jpg | 30.77dB
25-05-17 00:25:05.638 : --35--> circular_farmland_111_10.jpg | 31.08dB
25-05-17 00:25:05.818 : --36--> circular_farmland_111_11.jpg | 31.40dB
25-05-17 00:25:05.993 : --37--> cloud_111_00.jpg | 37.73dB
25-05-17 00:25:06.172 : --38--> cloud_111_01.jpg | 33.70dB
25-05-17 00:25:06.352 : --39--> cloud_111_10.jpg | 33.22dB
25-05-17 00:25:06.527 : --40--> cloud_111_11.jpg | 33.62dB
25-05-17 00:25:06.708 : --41--> commercial_area_111_00.jpg | 30.29dB
25-05-17 00:25:06.889 : --42--> commercial_area_111_01.jpg | 28.79dB
25-05-17 00:25:07.068 : --43--> commercial_area_111_10.jpg | 29.75dB
25-05-17 00:25:07.251 : --44--> commercial_area_111_11.jpg | 29.49dB
25-05-17 00:25:07.424 : --45--> dense_residential_111_00.jpg | 26.57dB
25-05-17 00:25:07.598 : --46--> dense_residential_111_01.jpg | 25.66dB
25-05-17 00:25:07.778 : --47--> dense_residential_111_10.jpg | 26.07dB
25-05-17 00:25:07.954 : --48--> dense_residential_111_11.jpg | 25.89dB
25-05-17 00:25:08.134 : --49--> desert_111_00.jpg | 34.27dB
25-05-17 00:25:08.312 : --50--> desert_111_01.jpg | 33.93dB
25-05-17 00:25:08.491 : --51--> desert_111_10.jpg | 34.44dB
25-05-17 00:25:08.670 : --52--> desert_111_11.jpg | 34.40dB
25-05-17 00:25:08.849 : --53--> forest_111_00.jpg | 30.30dB
25-05-17 00:25:09.030 : --54--> forest_111_01.jpg | 29.31dB
25-05-17 00:25:09.204 : --55--> forest_111_10.jpg | 28.64dB
25-05-17 00:25:09.384 : --56--> forest_111_11.jpg | 29.93dB
25-05-17 00:25:09.564 : --57--> freeway_111_00.jpg | 31.21dB
25-05-17 00:25:09.742 : --58--> freeway_111_01.jpg | 31.98dB
25-05-17 00:25:09.915 : --59--> freeway_111_10.jpg | 31.90dB
25-05-17 00:25:10.090 : --60--> freeway_111_11.jpg | 32.07dB
25-05-17 00:25:10.273 : --61--> golf_course_111_00.jpg | 29.71dB
25-05-17 00:25:10.452 : --62--> golf_course_111_01.jpg | 28.68dB
25-05-17 00:25:10.638 : --63--> golf_course_111_10.jpg | 30.48dB
25-05-17 00:25:10.818 : --64--> golf_course_111_11.jpg | 30.83dB
25-05-17 00:25:11.000 : --65--> ground_track_field_111_00.jpg | 29.86dB
25-05-17 00:25:11.174 : --66--> ground_track_field_111_01.jpg | 25.83dB
25-05-17 00:25:11.353 : --67--> ground_track_field_111_10.jpg | 27.42dB
25-05-17 00:25:11.538 : --68--> ground_track_field_111_11.jpg | 26.53dB
25-05-17 00:25:11.723 : --69--> harbor_111_00.jpg | 30.80dB
25-05-17 00:25:11.906 : --70--> harbor_111_01.jpg | 28.05dB
25-05-17 00:25:12.087 : --71--> harbor_111_10.jpg | 27.39dB
25-05-17 00:25:12.266 : --72--> harbor_111_11.jpg | 29.31dB
25-05-17 00:25:12.447 : --73--> industrial_area_111_00.jpg | 28.60dB
25-05-17 00:25:12.625 : --74--> industrial_area_111_01.jpg | 28.27dB
25-05-17 00:25:12.801 : --75--> industrial_area_111_10.jpg | 28.62dB
25-05-17 00:25:12.983 : --76--> industrial_area_111_11.jpg | 27.83dB
25-05-17 00:25:13.168 : --77--> intersection_111_00.jpg | 27.36dB
25-05-17 00:25:13.349 : --78--> intersection_111_01.jpg | 27.37dB
25-05-17 00:25:13.522 : --79--> intersection_111_10.jpg | 26.94dB
25-05-17 00:25:13.702 : --80--> intersection_111_11.jpg | 26.72dB
25-05-17 00:25:13.879 : --81--> island_111_00.jpg | 28.17dB
25-05-17 00:25:14.058 : --82--> island_111_01.jpg | 30.70dB
25-05-17 00:25:14.237 : --83--> island_111_10.jpg | 29.14dB
25-05-17 00:25:14.418 : --84--> island_111_11.jpg | 28.72dB
25-05-17 00:25:14.596 : --85--> lake_111_00.jpg | 30.02dB
25-05-17 00:25:14.774 : --86--> lake_111_01.jpg | 29.84dB
25-05-17 00:25:14.957 : --87--> lake_111_10.jpg | 28.72dB
25-05-17 00:25:15.136 : --88--> lake_111_11.jpg | 28.34dB
25-05-17 00:25:15.317 : --89--> meadow_111_00.jpg | 27.28dB
25-05-17 00:25:15.495 : --90--> meadow_111_01.jpg | 27.26dB
25-05-17 00:25:15.671 : --91--> meadow_111_10.jpg | 27.46dB
25-05-17 00:25:15.849 : --92--> meadow_111_11.jpg | 27.58dB
25-05-17 00:25:16.029 : --93--> medium_residential_111_00.jpg | 25.11dB
25-05-17 00:25:16.209 : --94--> medium_residential_111_01.jpg | 24.54dB
25-05-17 00:25:16.389 : --95--> medium_residential_111_10.jpg | 24.92dB
25-05-17 00:25:16.568 : --96--> medium_residential_111_11.jpg | 25.46dB
25-05-17 00:25:16.748 : --97--> mobile_home_park_111_00.jpg | 27.36dB
25-05-17 00:25:16.929 : --98--> mobile_home_park_111_01.jpg | 27.85dB
25-05-17 00:25:17.116 : --99--> mobile_home_park_111_10.jpg | 28.30dB
25-05-17 00:25:17.297 : -100--> mobile_home_park_111_11.jpg | 28.17dB
25-05-17 00:25:17.472 : -101--> mountain_111_00.jpg | 25.51dB
25-05-17 00:25:17.655 : -102--> mountain_111_01.jpg | 26.45dB
25-05-17 00:25:17.837 : -103--> mountain_111_10.jpg | 26.04dB
25-05-17 00:25:18.017 : -104--> mountain_111_11.jpg | 26.53dB
25-05-17 00:25:18.195 : -105--> overpass_111_00.jpg | 26.98dB
25-05-17 00:25:18.374 : -106--> overpass_111_01.jpg | 26.68dB
25-05-17 00:25:18.557 : -107--> overpass_111_10.jpg | 27.54dB
25-05-17 00:25:18.738 : -108--> overpass_111_11.jpg | 28.16dB
25-05-17 00:25:18.917 : -109--> palace_111_00.jpg | 26.49dB
25-05-17 00:25:19.094 : -110--> palace_111_01.jpg | 26.32dB
25-05-17 00:25:19.283 : -111--> palace_111_10.jpg | 27.84dB
25-05-17 00:25:19.465 : -112--> palace_111_11.jpg | 25.90dB
25-05-17 00:25:19.641 : -113--> parking_lot_111_00.jpg | 25.42dB
25-05-17 00:25:19.818 : -114--> parking_lot_111_01.jpg | 25.68dB
25-05-17 00:25:20.000 : -115--> parking_lot_111_10.jpg | 27.74dB
25-05-17 00:25:20.179 : -116--> parking_lot_111_11.jpg | 26.50dB
25-05-17 00:25:20.359 : -117--> railway_111_00.jpg | 27.07dB
25-05-17 00:25:20.538 : -118--> railway_111_01.jpg | 26.52dB
25-05-17 00:25:20.711 : -119--> railway_111_10.jpg | 29.80dB
25-05-17 00:25:20.898 : -120--> railway_111_11.jpg | 25.55dB
25-05-17 00:25:21.079 : -121--> railway_station_111_00.jpg | 27.66dB
25-05-17 00:25:21.253 : -122--> railway_station_111_01.jpg | 28.55dB
25-05-17 00:25:21.436 : -123--> railway_station_111_10.jpg | 27.91dB
25-05-17 00:25:21.618 : -124--> railway_station_111_11.jpg | 28.61dB
25-05-17 00:25:21.798 : -125--> rectangular_farmland_111_00.jpg | 30.32dB
25-05-17 00:25:21.980 : -126--> rectangular_farmland_111_01.jpg | 28.56dB
25-05-17 00:25:22.154 : -127--> rectangular_farmland_111_10.jpg | 30.58dB
25-05-17 00:25:22.337 : -128--> rectangular_farmland_111_11.jpg | 30.93dB
25-05-17 00:25:22.513 : -129--> river_111_00.jpg | 26.87dB
25-05-17 00:25:22.688 : -130--> river_111_01.jpg | 26.91dB
25-05-17 00:25:22.870 : -131--> river_111_10.jpg | 25.99dB
25-05-17 00:25:23.046 : -132--> river_111_11.jpg | 28.07dB
25-05-17 00:25:23.229 : -133--> roundabout_111_00.jpg | 27.18dB
25-05-17 00:25:23.414 : -134--> roundabout_111_01.jpg | 29.07dB
25-05-17 00:25:23.588 : -135--> roundabout_111_10.jpg | 27.19dB
25-05-17 00:25:23.766 : -136--> roundabout_111_11.jpg | 27.45dB
25-05-17 00:25:23.944 : -137--> runway_111_00.jpg | 33.37dB
25-05-17 00:25:24.127 : -138--> runway_111_01.jpg | 32.72dB
25-05-17 00:25:24.301 : -139--> runway_111_10.jpg | 34.10dB
25-05-17 00:25:24.482 : -140--> runway_111_11.jpg | 34.10dB
25-05-17 00:25:24.663 : -141--> sea_ice_111_00.jpg | 30.25dB
25-05-17 00:25:24.832 : -142--> sea_ice_111_01.jpg | 31.11dB
25-05-17 00:25:25.011 : -143--> sea_ice_111_10.jpg | 30.26dB
25-05-17 00:25:25.188 : -144--> sea_ice_111_11.jpg | 31.43dB
25-05-17 00:25:25.366 : -145--> ship_111_00.jpg | 35.57dB
25-05-17 00:25:25.547 : -146--> ship_111_01.jpg | 31.08dB
25-05-17 00:25:25.732 : -147--> ship_111_10.jpg | 40.27dB
25-05-17 00:25:25.909 : -148--> ship_111_11.jpg | 36.51dB
25-05-17 00:25:26.094 : -149--> snowberg_111_00.jpg | 30.55dB
25-05-17 00:25:26.268 : -150--> snowberg_111_01.jpg | 29.28dB
25-05-17 00:25:26.448 : -151--> snowberg_111_10.jpg | 28.39dB
25-05-17 00:25:26.630 : -152--> snowberg_111_11.jpg | 28.45dB
25-05-17 00:25:26.816 : -153--> sparse_residential_111_00.jpg | 27.23dB
25-05-17 00:25:26.990 : -154--> sparse_residential_111_01.jpg | 27.88dB
25-05-17 00:25:27.171 : -155--> sparse_residential_111_10.jpg | 26.25dB
25-05-17 00:25:27.350 : -156--> sparse_residential_111_11.jpg | 26.90dB
25-05-17 00:25:27.529 : -157--> stadium_111_00.jpg | 26.51dB
25-05-17 00:25:27.710 : -158--> stadium_111_01.jpg | 26.42dB
25-05-17 00:25:27.891 : -159--> stadium_111_10.jpg | 27.92dB
25-05-17 00:25:28.068 : -160--> stadium_111_11.jpg | 26.51dB
25-05-17 00:25:28.248 : -161--> storage_tank_111_00.jpg | 28.63dB
25-05-17 00:25:28.420 : -162--> storage_tank_111_01.jpg | 28.73dB
25-05-17 00:25:28.603 : -163--> storage_tank_111_10.jpg | 27.49dB
25-05-17 00:25:28.784 : -164--> storage_tank_111_11.jpg | 28.00dB
25-05-17 00:25:28.966 : -165--> tennis_court_111_00.jpg | 28.90dB
25-05-17 00:25:29.141 : -166--> tennis_court_111_01.jpg | 28.62dB
25-05-17 00:25:29.325 : -167--> tennis_court_111_10.jpg | 28.49dB
25-05-17 00:25:29.501 : -168--> tennis_court_111_11.jpg | 26.63dB
25-05-17 00:25:29.687 : -169--> terrace_111_00.jpg | 29.23dB
25-05-17 00:25:29.869 : -170--> terrace_111_01.jpg | 30.15dB
25-05-17 00:25:30.045 : -171--> terrace_111_10.jpg | 28.96dB
25-05-17 00:25:30.230 : -172--> terrace_111_11.jpg | 29.15dB
25-05-17 00:25:30.412 : -173--> thermal_power_station_111_00.jpg | 26.75dB
25-05-17 00:25:30.596 : -174--> thermal_power_station_111_01.jpg | 28.09dB
25-05-17 00:25:30.770 : -175--> thermal_power_station_111_10.jpg | 26.25dB
25-05-17 00:25:30.949 : -176--> thermal_power_station_111_11.jpg | 26.74dB
25-05-17 00:25:31.132 : -177--> wetland_111_00.jpg | 28.50dB
25-05-17 00:25:31.311 : -178--> wetland_111_01.jpg | 28.63dB
25-05-17 00:25:31.490 : -179--> wetland_111_10.jpg | 28.87dB
25-05-17 00:25:31.669 : -180--> wetland_111_11.jpg | 28.03dB
25-05-17 00:25:31.676 : <epoch:  0, iter:  20,000, Average PSNR : 28.96dB

25-05-17 00:34:14.697 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/20000_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test_4fen
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [60000, 90000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-17 00:34:14.698 : Random seed: 2617
25-05-17 00:34:15.083 : Number of train images: 31,005, iters: 31,005
25-05-17 00:34:17.472 : 
Networks name: DRNet
Params number: 17746115
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-17 00:34:18.094 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.002 | -0.407 |  0.482 |  0.170 | torch.Size([64, 3, 3, 3]) || head1.weight
 | -0.000 | -0.346 |  0.301 |  0.198 | torch.Size([64]) || head1.bias
 |  0.000 | -0.472 |  0.435 |  0.093 | torch.Size([64, 64, 3, 3]) || head1_1.body.0.weight
 |  0.084 | -0.082 |  0.218 |  0.070 | torch.Size([64]) || head1_1.body.0.bias
 | -0.000 | -0.510 |  0.551 |  0.082 | torch.Size([64, 64, 3, 3]) || head1_1.body.2.weight
 |  0.010 | -0.104 |  0.128 |  0.055 | torch.Size([64]) || head1_1.body.2.bias
 |  0.000 | -0.291 |  0.299 |  0.058 | torch.Size([768, 256]) || head1_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.001 | -0.329 |  0.297 |  0.065 | torch.Size([256, 256]) || head1_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.300 |  0.282 |  0.056 | torch.Size([1024, 256]) || head1_3.encoder.layers.0.linear1.weight
 | -0.020 | -0.160 |  0.096 |  0.041 | torch.Size([1024]) || head1_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.409 |  0.381 |  0.047 | torch.Size([256, 1024]) || head1_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.075 |  0.078 |  0.029 | torch.Size([256]) || head1_3.encoder.layers.0.linear2.bias
 |  1.017 |  0.765 |  1.187 |  0.063 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.weight
 |  0.005 | -0.180 |  0.290 |  0.055 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.bias
 |  1.093 |  0.968 |  1.259 |  0.054 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.weight
 |  0.002 | -0.070 |  0.090 |  0.030 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || head1_3.position_encoding.position_ids
 |  0.000 | -5.339 |  4.746 |  0.991 | torch.Size([4096, 256]) || head1_3.position_encoding.pe.weight
 |  0.000 | -0.932 |  0.989 |  0.033 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.0.weight
 |  0.027 | -0.103 |  0.109 |  0.042 | torch.Size([64]) || body1_1.0.body.0.bias
 | -0.001 | -0.340 |  0.353 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.2.weight
 | -0.014 | -0.136 |  0.111 |  0.061 | torch.Size([64]) || body1_1.0.body.2.bias
 | -0.001 | -0.469 |  0.445 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_1.1.weight
 |  0.047 | -0.053 |  0.151 |  0.046 | torch.Size([64]) || body1_1.1.bias
 |  0.000 | -0.171 |  0.179 |  0.041 | torch.Size([768, 256]) || body1_2.0.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.155 |  0.139 |  0.037 | torch.Size([256, 256]) || body1_2.0.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.293 |  0.240 |  0.043 | torch.Size([1024, 256]) || body1_2.0.encoder.layers.0.linear1.weight
 |  0.003 | -0.073 |  0.097 |  0.038 | torch.Size([1024]) || body1_2.0.encoder.layers.0.linear1.bias
 | -0.003 | -0.253 |  0.206 |  0.027 | torch.Size([256, 1024]) || body1_2.0.encoder.layers.0.linear2.weight
 | -0.006 | -0.059 |  0.044 |  0.020 | torch.Size([256]) || body1_2.0.encoder.layers.0.linear2.bias
 |  0.993 |  0.815 |  1.125 |  0.063 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.weight
 |  0.008 | -0.134 |  0.146 |  0.064 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.bias
 |  0.995 |  0.802 |  1.170 |  0.056 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.weight
 |  0.010 | -0.224 |  0.244 |  0.083 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body1_2.0.position_encoding.position_ids
 |  0.001 | -4.538 |  4.875 |  0.995 | torch.Size([4096, 256]) || body1_2.0.position_encoding.pe.weight
 | -0.001 | -0.288 |  0.221 |  0.036 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.0.weight
 |  0.003 | -0.101 |  0.083 |  0.033 | torch.Size([64]) || body1_2.1.body.0.bias
 | -0.005 | -0.261 |  0.270 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.2.weight
 | -0.015 | -0.101 |  0.048 |  0.033 | torch.Size([64]) || body1_2.1.body.2.bias
 |  0.000 | -0.266 |  0.247 |  0.048 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.0.weight
 |  0.013 | -0.107 |  0.112 |  0.044 | torch.Size([64]) || body2_1.0.body.0.bias
 |  0.000 | -0.282 |  0.422 |  0.047 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.2.weight
 | -0.005 | -0.129 |  0.153 |  0.072 | torch.Size([64]) || body2_1.0.body.2.bias
 |  0.000 | -0.318 |  0.355 |  0.059 | torch.Size([768, 256]) || body2_1.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.304 |  0.323 |  0.068 | torch.Size([256, 256]) || body2_1.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.288 |  0.298 |  0.059 | torch.Size([1024, 256]) || body2_1.1.encoder.layers.0.linear1.weight
 |  0.011 | -0.118 |  0.127 |  0.042 | torch.Size([1024]) || body2_1.1.encoder.layers.0.linear1.bias
 | -0.000 | -0.266 |  0.263 |  0.048 | torch.Size([256, 1024]) || body2_1.1.encoder.layers.0.linear2.weight
 | -0.001 | -0.068 |  0.071 |  0.030 | torch.Size([256]) || body2_1.1.encoder.layers.0.linear2.bias
 |  1.065 |  0.938 |  1.191 |  0.046 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.weight
 |  0.003 | -0.131 |  0.151 |  0.061 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.bias
 |  1.175 |  1.002 |  1.372 |  0.067 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.107 |  0.110 |  0.033 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_1.1.position_encoding.position_ids
 | -0.001 | -4.994 |  4.878 |  0.999 | torch.Size([4096, 256]) || body2_1.1.position_encoding.pe.weight
 | -0.003 | -0.322 |  0.331 |  0.111 | torch.Size([128, 1, 5, 5]) || fusion2_1.0.weight
 |  0.015 | -0.262 |  0.248 |  0.121 | torch.Size([128]) || fusion2_1.0.bias
 |  0.000 | -0.217 |  0.222 |  0.053 | torch.Size([64, 128, 1, 1]) || fusion2_1.1.weight
 | -0.004 | -0.171 |  0.151 |  0.084 | torch.Size([64]) || fusion2_1.1.bias
 |  0.002 | -0.181 |  0.223 |  0.043 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.0.weight
 |  0.003 | -0.136 |  0.213 |  0.078 | torch.Size([64]) || body2_2.0.body.0.bias
 |  0.000 | -0.209 |  0.214 |  0.042 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.2.weight
 | -0.004 | -0.215 |  0.195 |  0.099 | torch.Size([64]) || body2_2.0.body.2.bias
 | -0.000 | -0.408 |  0.330 |  0.063 | torch.Size([768, 256]) || body2_2.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.325 |  0.368 |  0.078 | torch.Size([256, 256]) || body2_2.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.242 |  0.256 |  0.059 | torch.Size([1024, 256]) || body2_2.1.encoder.layers.0.linear1.weight
 | -0.001 | -0.147 |  0.134 |  0.050 | torch.Size([1024]) || body2_2.1.encoder.layers.0.linear1.bias
 |  0.000 | -0.239 |  0.278 |  0.048 | torch.Size([256, 1024]) || body2_2.1.encoder.layers.0.linear2.weight
 |  0.002 | -0.049 |  0.054 |  0.024 | torch.Size([256]) || body2_2.1.encoder.layers.0.linear2.bias
 |  1.098 |  0.949 |  1.230 |  0.047 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.weight
 |  0.001 | -0.169 |  0.197 |  0.073 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.bias
 |  1.133 |  0.952 |  1.298 |  0.051 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.104 |  0.098 |  0.033 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_2.1.position_encoding.position_ids
 | -0.001 | -4.834 |  4.669 |  0.998 | torch.Size([4096, 256]) || body2_2.1.position_encoding.pe.weight
 | -0.000 | -0.299 |  0.366 |  0.104 | torch.Size([128, 1, 5, 5]) || fusion2_2.0.weight
 | -0.014 | -0.205 |  0.213 |  0.116 | torch.Size([128]) || fusion2_2.0.bias
 | -0.001 | -0.206 |  0.256 |  0.057 | torch.Size([64, 128, 1, 1]) || fusion2_2.1.weight
 | -0.019 | -0.138 |  0.146 |  0.062 | torch.Size([64]) || fusion2_2.1.bias
 | -0.000 | -0.242 |  0.222 |  0.052 | torch.Size([768, 256]) || body2_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.235 |  0.228 |  0.054 | torch.Size([256, 256]) || body2_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.213 |  0.219 |  0.050 | torch.Size([1024, 256]) || body2_3.encoder.layers.0.linear1.weight
 | -0.029 | -0.138 |  0.088 |  0.040 | torch.Size([1024]) || body2_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.186 |  0.181 |  0.038 | torch.Size([256, 1024]) || body2_3.encoder.layers.0.linear2.weight
 |  0.002 | -0.045 |  0.073 |  0.022 | torch.Size([256]) || body2_3.encoder.layers.0.linear2.bias
 |  1.051 |  0.953 |  1.181 |  0.039 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.118 |  0.160 |  0.047 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.bias
 |  0.997 |  0.869 |  1.146 |  0.042 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.082 |  0.071 |  0.028 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_3.position_encoding.position_ids
 | -0.000 | -4.715 |  5.525 |  0.998 | torch.Size([4096, 256]) || body2_3.position_encoding.pe.weight
 |  0.000 | -0.239 |  0.217 |  0.038 | torch.Size([64, 64, 3, 3]) || body3_1.0.weight
 |  0.019 | -0.057 |  0.070 |  0.031 | torch.Size([64]) || body3_1.0.bias
 |  0.000 | -0.169 |  0.167 |  0.039 | torch.Size([768, 256]) || body3_1.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.162 |  0.167 |  0.040 | torch.Size([256, 256]) || body3_1.2.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.284 |  0.244 |  0.047 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.0.linear1.weight
 | -0.010 | -0.100 |  0.094 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.281 |  0.294 |  0.033 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.0.linear2.weight
 | -0.006 | -0.068 |  0.072 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.linear2.bias
 |  1.001 |  0.923 |  1.076 |  0.026 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.085 |  0.079 |  0.029 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.bias
 |  1.105 |  0.985 |  1.245 |  0.048 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.weight
 |  0.002 | -0.071 |  0.090 |  0.033 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.142 |  0.162 |  0.038 | torch.Size([768, 256]) || body3_1.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.132 |  0.129 |  0.038 | torch.Size([256, 256]) || body3_1.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.334 |  0.289 |  0.046 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.1.linear1.weight
 | -0.007 | -0.095 |  0.090 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.1.linear1.bias
 | -0.002 | -0.359 |  0.416 |  0.032 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.1.linear2.weight
 | -0.007 | -0.064 |  0.044 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.linear2.bias
 |  0.996 |  0.948 |  1.104 |  0.023 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.weight
 | -0.001 | -0.060 |  0.065 |  0.026 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.bias
 |  1.121 |  0.993 |  1.278 |  0.048 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.weight
 |  0.001 | -0.054 |  0.052 |  0.021 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_1.2.position_encoding.position_ids
 |  0.002 | -4.658 |  4.616 |  1.000 | torch.Size([4096, 256]) || body3_1.2.position_encoding.pe.weight
 |  0.001 | -0.202 |  0.203 |  0.071 | torch.Size([128, 1, 5, 5]) || fusion3_1.0.weight
 |  0.007 | -0.233 |  0.244 |  0.123 | torch.Size([128]) || fusion3_1.0.bias
 | -0.000 | -0.131 |  0.146 |  0.026 | torch.Size([64, 128, 1, 1]) || fusion3_1.1.weight
 | -0.008 | -0.184 |  0.154 |  0.085 | torch.Size([64]) || fusion3_1.1.bias
 | -0.000 | -0.113 |  0.117 |  0.025 | torch.Size([64, 64, 3, 3]) || body3_2.0.weight
 |  0.056 | -0.103 |  0.115 |  0.036 | torch.Size([64]) || body3_2.0.bias
 |  0.000 | -0.144 |  0.126 |  0.040 | torch.Size([768, 256]) || body3_2.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.110 |  0.110 |  0.037 | torch.Size([256, 256]) || body3_2.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.199 |  0.212 |  0.051 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.0.linear1.weight
 | -0.042 | -0.132 |  0.061 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.165 |  0.148 |  0.036 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.0.linear2.weight
 | -0.008 | -0.061 |  0.039 |  0.022 | torch.Size([256]) || body3_2.2.encoder.layers.0.linear2.bias
 |  0.997 |  0.838 |  1.076 |  0.030 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.119 |  0.176 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.bias
 |  1.048 |  0.924 |  1.191 |  0.045 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.weight
 | -0.001 | -0.138 |  0.099 |  0.041 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.110 |  0.114 |  0.038 | torch.Size([768, 256]) || body3_2.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.119 |  0.104 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.191 |  0.186 |  0.049 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.1.linear1.weight
 | -0.026 | -0.112 |  0.089 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.1.linear1.bias
 | -0.001 | -0.152 |  0.163 |  0.035 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.1.linear2.weight
 | -0.009 | -0.066 |  0.049 |  0.024 | torch.Size([256]) || body3_2.2.encoder.layers.1.linear2.bias
 |  0.987 |  0.918 |  1.033 |  0.020 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.weight
 | -0.000 | -0.104 |  0.113 |  0.044 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.bias
 |  1.054 |  0.959 |  1.144 |  0.035 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.weight
 | -0.000 | -0.052 |  0.053 |  0.019 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_2.2.position_encoding.position_ids
 |  0.001 | -5.085 |  5.020 |  1.000 | torch.Size([4096, 256]) || body3_2.2.position_encoding.pe.weight
 |  0.002 | -0.227 |  0.263 |  0.091 | torch.Size([128, 1, 5, 5]) || fusion3_2.0.weight
 |  0.003 | -0.193 |  0.228 |  0.105 | torch.Size([128]) || fusion3_2.0.bias
 |  0.001 | -0.149 |  0.154 |  0.048 | torch.Size([64, 128, 1, 1]) || fusion3_2.1.weight
 |  0.006 | -0.086 |  0.123 |  0.049 | torch.Size([64]) || fusion3_2.1.bias
 | -0.001 | -0.213 |  0.189 |  0.048 | torch.Size([256, 256]) || body3_3.linear_encoding.weight
 | -0.004 | -0.130 |  0.137 |  0.058 | torch.Size([256]) || body3_3.linear_encoding.bias
 | -0.000 | -0.223 |  0.189 |  0.045 | torch.Size([1024, 256]) || body3_3.mlp_head.0.weight
 | -0.027 | -0.127 |  0.060 |  0.038 | torch.Size([1024]) || body3_3.mlp_head.0.bias
 | -0.000 | -0.215 |  0.181 |  0.032 | torch.Size([256, 1024]) || body3_3.mlp_head.3.weight
 |  0.002 | -0.086 |  0.074 |  0.028 | torch.Size([256]) || body3_3.mlp_head.3.bias
 |  0.000 | -0.128 |  0.132 |  0.039 | torch.Size([768, 256]) || body3_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.142 |  0.147 |  0.037 | torch.Size([256, 256]) || body3_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.198 |  0.188 |  0.044 | torch.Size([1024, 256]) || body3_3.encoder.layers.0.linear1.weight
 | -0.036 | -0.132 |  0.062 |  0.036 | torch.Size([1024]) || body3_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.180 |  0.228 |  0.031 | torch.Size([256, 1024]) || body3_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.071 |  0.065 |  0.024 | torch.Size([256]) || body3_3.encoder.layers.0.linear2.bias
 |  0.924 |  0.829 |  1.002 |  0.027 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.weight
 |  0.001 | -0.074 |  0.104 |  0.032 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.bias
 |  0.869 |  0.790 |  1.027 |  0.038 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.184 |  0.181 |  0.062 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.bias
 | -0.000 | -0.162 |  0.175 |  0.045 | torch.Size([192, 1, 5, 5]) || fusion3_3.0.weight
 |  0.004 | -0.186 |  0.217 |  0.082 | torch.Size([192]) || fusion3_3.0.bias
 |  0.000 | -0.116 |  0.109 |  0.022 | torch.Size([64, 192, 1, 1]) || fusion3_3.1.weight
 | -0.003 | -0.045 |  0.036 |  0.020 | torch.Size([64]) || fusion3_3.1.bias
 | -0.001 | -0.448 |  0.133 |  0.036 | torch.Size([256, 256]) || body3_4.linear_encoding.weight
 |  0.004 | -0.075 |  0.110 |  0.029 | torch.Size([256]) || body3_4.linear_encoding.bias
 | -0.001 | -0.253 |  0.264 |  0.045 | torch.Size([1024, 256]) || body3_4.mlp_head.0.weight
 | -0.051 | -0.163 |  0.068 |  0.037 | torch.Size([1024]) || body3_4.mlp_head.0.bias
 | -0.000 | -0.252 |  0.273 |  0.029 | torch.Size([256, 1024]) || body3_4.mlp_head.3.weight
 | -0.003 | -0.125 |  0.101 |  0.036 | torch.Size([256]) || body3_4.mlp_head.3.bias
 | -0.000 | -0.206 |  0.230 |  0.043 | torch.Size([768, 256]) || body3_4.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.141 |  0.141 |  0.033 | torch.Size([256, 256]) || body3_4.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.203 |  0.201 |  0.039 | torch.Size([1024, 256]) || body3_4.encoder.layers.0.linear1.weight
 | -0.039 | -0.142 |  0.062 |  0.037 | torch.Size([1024]) || body3_4.encoder.layers.0.linear1.bias
 |  0.000 | -0.211 |  0.173 |  0.022 | torch.Size([256, 1024]) || body3_4.encoder.layers.0.linear2.weight
 |  0.001 | -0.076 |  0.066 |  0.026 | torch.Size([256]) || body3_4.encoder.layers.0.linear2.bias
 |  0.802 |  0.644 |  0.954 |  0.066 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.weight
 | -0.002 | -0.180 |  0.133 |  0.054 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.bias
 |  0.786 |  0.473 |  1.070 |  0.101 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.weight
 |  0.000 | -0.208 |  0.189 |  0.084 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.bias
 |  0.000 | -0.050 |  0.052 |  0.011 | torch.Size([3, 64, 3, 3]) || tail.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([3]) || tail.bias

25-05-17 01:54:21.052 : <epoch:  0, iter:  25,000, lr:1.000e-04> G_loss: 1.530e-04 
25-05-17 01:54:21.054 : Saving the model.
25-05-17 01:54:21.720 : ---1--> airplane_111_00.jpg | 26.98dB
25-05-17 01:54:21.898 : ---2--> airplane_111_01.jpg | 32.18dB
25-05-17 01:54:22.078 : ---3--> airplane_111_10.jpg | 29.80dB
25-05-17 01:54:22.257 : ---4--> airplane_111_11.jpg | 29.95dB
25-05-17 01:54:22.432 : ---5--> airport_111_00.jpg | 31.67dB
25-05-17 01:54:22.622 : ---6--> airport_111_01.jpg | 29.41dB
25-05-17 01:54:22.802 : ---7--> airport_111_10.jpg | 28.67dB
25-05-17 01:54:22.977 : ---8--> airport_111_11.jpg | 29.74dB
25-05-17 01:54:23.161 : ---9--> baseball_diamond_111_00.jpg | 29.59dB
25-05-17 01:54:23.340 : --10--> baseball_diamond_111_01.jpg | 31.48dB
25-05-17 01:54:23.519 : --11--> baseball_diamond_111_10.jpg | 29.47dB
25-05-17 01:54:23.700 : --12--> baseball_diamond_111_11.jpg | 32.69dB
25-05-17 01:54:23.884 : --13--> basketball_court_111_00.jpg | 27.22dB
25-05-17 01:54:24.062 : --14--> basketball_court_111_01.jpg | 26.89dB
25-05-17 01:54:24.243 : --15--> basketball_court_111_10.jpg | 30.21dB
25-05-17 01:54:24.429 : --16--> basketball_court_111_11.jpg | 28.40dB
25-05-17 01:54:24.610 : --17--> beach_111_00.jpg | 25.52dB
25-05-17 01:54:24.783 : --18--> beach_111_01.jpg | 28.64dB
25-05-17 01:54:24.964 : --19--> beach_111_10.jpg | 26.66dB
25-05-17 01:54:25.153 : --20--> beach_111_11.jpg | 31.75dB
25-05-17 01:54:25.330 : --21--> bridge_111_00.jpg | 38.22dB
25-05-17 01:54:25.508 : --22--> bridge_111_01.jpg | 31.02dB
25-05-17 01:54:25.687 : --23--> bridge_111_10.jpg | 29.88dB
25-05-17 01:54:25.866 : --24--> bridge_111_11.jpg | 33.43dB
25-05-17 01:54:26.046 : --25--> chaparral_111_00.jpg | 27.20dB
25-05-17 01:54:26.235 : --26--> chaparral_111_01.jpg | 27.57dB
25-05-17 01:54:26.418 : --27--> chaparral_111_10.jpg | 28.03dB
25-05-17 01:54:26.602 : --28--> chaparral_111_11.jpg | 25.04dB
25-05-17 01:54:26.780 : --29--> church_111_00.jpg | 28.36dB
25-05-17 01:54:26.963 : --30--> church_111_01.jpg | 27.11dB
25-05-17 01:54:27.146 : --31--> church_111_10.jpg | 31.40dB
25-05-17 01:54:27.328 : --32--> church_111_11.jpg | 26.91dB
25-05-17 01:54:27.514 : --33--> circular_farmland_111_00.jpg | 29.43dB
25-05-17 01:54:27.696 : --34--> circular_farmland_111_01.jpg | 30.76dB
25-05-17 01:54:27.874 : --35--> circular_farmland_111_10.jpg | 31.07dB
25-05-17 01:54:28.056 : --36--> circular_farmland_111_11.jpg | 31.36dB
25-05-17 01:54:28.240 : --37--> cloud_111_00.jpg | 37.93dB
25-05-17 01:54:28.414 : --38--> cloud_111_01.jpg | 33.69dB
25-05-17 01:54:28.596 : --39--> cloud_111_10.jpg | 33.34dB
25-05-17 01:54:28.775 : --40--> cloud_111_11.jpg | 33.54dB
25-05-17 01:54:28.948 : --41--> commercial_area_111_00.jpg | 30.32dB
25-05-17 01:54:29.132 : --42--> commercial_area_111_01.jpg | 28.78dB
25-05-17 01:54:29.310 : --43--> commercial_area_111_10.jpg | 29.71dB
25-05-17 01:54:29.488 : --44--> commercial_area_111_11.jpg | 29.52dB
25-05-17 01:54:29.676 : --45--> dense_residential_111_00.jpg | 26.59dB
25-05-17 01:54:29.854 : --46--> dense_residential_111_01.jpg | 25.68dB
25-05-17 01:54:30.035 : --47--> dense_residential_111_10.jpg | 26.08dB
25-05-17 01:54:30.214 : --48--> dense_residential_111_11.jpg | 25.92dB
25-05-17 01:54:30.394 : --49--> desert_111_00.jpg | 34.33dB
25-05-17 01:54:30.574 : --50--> desert_111_01.jpg | 33.89dB
25-05-17 01:54:30.753 : --51--> desert_111_10.jpg | 34.50dB
25-05-17 01:54:30.936 : --52--> desert_111_11.jpg | 34.47dB
25-05-17 01:54:31.114 : --53--> forest_111_00.jpg | 30.29dB
25-05-17 01:54:31.295 : --54--> forest_111_01.jpg | 29.34dB
25-05-17 01:54:31.471 : --55--> forest_111_10.jpg | 28.63dB
25-05-17 01:54:31.656 : --56--> forest_111_11.jpg | 29.91dB
25-05-17 01:54:31.834 : --57--> freeway_111_00.jpg | 31.15dB
25-05-17 01:54:32.014 : --58--> freeway_111_01.jpg | 32.00dB
25-05-17 01:54:32.194 : --59--> freeway_111_10.jpg | 31.97dB
25-05-17 01:54:32.379 : --60--> freeway_111_11.jpg | 32.16dB
25-05-17 01:54:32.553 : --61--> golf_course_111_00.jpg | 29.71dB
25-05-17 01:54:32.730 : --62--> golf_course_111_01.jpg | 28.68dB
25-05-17 01:54:32.912 : --63--> golf_course_111_10.jpg | 30.51dB
25-05-17 01:54:33.087 : --64--> golf_course_111_11.jpg | 30.90dB
25-05-17 01:54:33.267 : --65--> ground_track_field_111_00.jpg | 29.89dB
25-05-17 01:54:33.443 : --66--> ground_track_field_111_01.jpg | 25.83dB
25-05-17 01:54:33.634 : --67--> ground_track_field_111_10.jpg | 27.45dB
25-05-17 01:54:33.815 : --68--> ground_track_field_111_11.jpg | 26.55dB
25-05-17 01:54:33.999 : --69--> harbor_111_00.jpg | 30.74dB
25-05-17 01:54:34.175 : --70--> harbor_111_01.jpg | 28.07dB
25-05-17 01:54:34.353 : --71--> harbor_111_10.jpg | 27.36dB
25-05-17 01:54:34.533 : --72--> harbor_111_11.jpg | 29.29dB
25-05-17 01:54:34.715 : --73--> industrial_area_111_00.jpg | 28.67dB
25-05-17 01:54:34.897 : --74--> industrial_area_111_01.jpg | 28.24dB
25-05-17 01:54:35.074 : --75--> industrial_area_111_10.jpg | 28.64dB
25-05-17 01:54:35.255 : --76--> industrial_area_111_11.jpg | 27.85dB
25-05-17 01:54:35.438 : --77--> intersection_111_00.jpg | 27.33dB
25-05-17 01:54:35.622 : --78--> intersection_111_01.jpg | 27.40dB
25-05-17 01:54:35.796 : --79--> intersection_111_10.jpg | 26.93dB
25-05-17 01:54:35.975 : --80--> intersection_111_11.jpg | 26.73dB
25-05-17 01:54:36.154 : --81--> island_111_00.jpg | 28.16dB
25-05-17 01:54:36.335 : --82--> island_111_01.jpg | 30.68dB
25-05-17 01:54:36.510 : --83--> island_111_10.jpg | 29.16dB
25-05-17 01:54:36.689 : --84--> island_111_11.jpg | 28.76dB
25-05-17 01:54:36.875 : --85--> lake_111_00.jpg | 29.98dB
25-05-17 01:54:37.053 : --86--> lake_111_01.jpg | 29.83dB
25-05-17 01:54:37.228 : --87--> lake_111_10.jpg | 28.72dB
25-05-17 01:54:37.413 : --88--> lake_111_11.jpg | 28.34dB
25-05-17 01:54:37.595 : --89--> meadow_111_00.jpg | 27.24dB
25-05-17 01:54:37.775 : --90--> meadow_111_01.jpg | 27.26dB
25-05-17 01:54:37.951 : --91--> meadow_111_10.jpg | 27.44dB
25-05-17 01:54:38.126 : --92--> meadow_111_11.jpg | 27.56dB
25-05-17 01:54:38.309 : --93--> medium_residential_111_00.jpg | 25.12dB
25-05-17 01:54:38.494 : --94--> medium_residential_111_01.jpg | 24.53dB
25-05-17 01:54:38.674 : --95--> medium_residential_111_10.jpg | 24.92dB
25-05-17 01:54:38.851 : --96--> medium_residential_111_11.jpg | 25.49dB
25-05-17 01:54:39.034 : --97--> mobile_home_park_111_00.jpg | 27.30dB
25-05-17 01:54:39.215 : --98--> mobile_home_park_111_01.jpg | 27.82dB
25-05-17 01:54:39.394 : --99--> mobile_home_park_111_10.jpg | 28.28dB
25-05-17 01:54:39.573 : -100--> mobile_home_park_111_11.jpg | 28.12dB
25-05-17 01:54:39.757 : -101--> mountain_111_00.jpg | 25.49dB
25-05-17 01:54:39.931 : -102--> mountain_111_01.jpg | 26.42dB
25-05-17 01:54:40.115 : -103--> mountain_111_10.jpg | 26.03dB
25-05-17 01:54:40.295 : -104--> mountain_111_11.jpg | 26.53dB
25-05-17 01:54:40.474 : -105--> overpass_111_00.jpg | 26.95dB
25-05-17 01:54:40.654 : -106--> overpass_111_01.jpg | 26.69dB
25-05-17 01:54:40.835 : -107--> overpass_111_10.jpg | 27.54dB
25-05-17 01:54:41.013 : -108--> overpass_111_11.jpg | 28.07dB
25-05-17 01:54:41.192 : -109--> palace_111_00.jpg | 26.47dB
25-05-17 01:54:41.368 : -110--> palace_111_01.jpg | 26.30dB
25-05-17 01:54:41.550 : -111--> palace_111_10.jpg | 27.82dB
25-05-17 01:54:41.729 : -112--> palace_111_11.jpg | 25.89dB
25-05-17 01:54:41.911 : -113--> parking_lot_111_00.jpg | 25.45dB
25-05-17 01:54:42.091 : -114--> parking_lot_111_01.jpg | 25.68dB
25-05-17 01:54:42.268 : -115--> parking_lot_111_10.jpg | 27.69dB
25-05-17 01:54:42.448 : -116--> parking_lot_111_11.jpg | 26.50dB
25-05-17 01:54:42.628 : -117--> railway_111_00.jpg | 27.10dB
25-05-17 01:54:42.805 : -118--> railway_111_01.jpg | 26.57dB
25-05-17 01:54:42.982 : -119--> railway_111_10.jpg | 29.79dB
25-05-17 01:54:43.164 : -120--> railway_111_11.jpg | 25.58dB
25-05-17 01:54:43.344 : -121--> railway_station_111_00.jpg | 27.64dB
25-05-17 01:54:43.529 : -122--> railway_station_111_01.jpg | 28.56dB
25-05-17 01:54:43.711 : -123--> railway_station_111_10.jpg | 27.93dB
25-05-17 01:54:43.892 : -124--> railway_station_111_11.jpg | 28.60dB
25-05-17 01:54:44.072 : -125--> rectangular_farmland_111_00.jpg | 30.33dB
25-05-17 01:54:44.248 : -126--> rectangular_farmland_111_01.jpg | 28.52dB
25-05-17 01:54:44.430 : -127--> rectangular_farmland_111_10.jpg | 30.57dB
25-05-17 01:54:44.608 : -128--> rectangular_farmland_111_11.jpg | 30.92dB
25-05-17 01:54:44.783 : -129--> river_111_00.jpg | 26.87dB
25-05-17 01:54:44.960 : -130--> river_111_01.jpg | 26.89dB
25-05-17 01:54:45.141 : -131--> river_111_10.jpg | 26.03dB
25-05-17 01:54:45.316 : -132--> river_111_11.jpg | 28.10dB
25-05-17 01:54:45.495 : -133--> roundabout_111_00.jpg | 27.20dB
25-05-17 01:54:45.674 : -134--> roundabout_111_01.jpg | 29.07dB
25-05-17 01:54:45.855 : -135--> roundabout_111_10.jpg | 27.19dB
25-05-17 01:54:46.035 : -136--> roundabout_111_11.jpg | 27.50dB
25-05-17 01:54:46.214 : -137--> runway_111_00.jpg | 33.30dB
25-05-17 01:54:46.401 : -138--> runway_111_01.jpg | 32.72dB
25-05-17 01:54:46.580 : -139--> runway_111_10.jpg | 34.07dB
25-05-17 01:54:46.756 : -140--> runway_111_11.jpg | 34.09dB
25-05-17 01:54:46.939 : -141--> sea_ice_111_00.jpg | 30.20dB
25-05-17 01:54:47.117 : -142--> sea_ice_111_01.jpg | 31.08dB
25-05-17 01:54:47.296 : -143--> sea_ice_111_10.jpg | 30.21dB
25-05-17 01:54:47.476 : -144--> sea_ice_111_11.jpg | 31.42dB
25-05-17 01:54:47.658 : -145--> ship_111_00.jpg | 35.53dB
25-05-17 01:54:47.845 : -146--> ship_111_01.jpg | 31.06dB
25-05-17 01:54:48.030 : -147--> ship_111_10.jpg | 40.48dB
25-05-17 01:54:48.212 : -148--> ship_111_11.jpg | 36.39dB
25-05-17 01:54:48.387 : -149--> snowberg_111_00.jpg | 30.57dB
25-05-17 01:54:48.564 : -150--> snowberg_111_01.jpg | 29.25dB
25-05-17 01:54:48.750 : -151--> snowberg_111_10.jpg | 28.42dB
25-05-17 01:54:48.926 : -152--> snowberg_111_11.jpg | 28.46dB
25-05-17 01:54:49.107 : -153--> sparse_residential_111_00.jpg | 27.21dB
25-05-17 01:54:49.291 : -154--> sparse_residential_111_01.jpg | 27.88dB
25-05-17 01:54:49.469 : -155--> sparse_residential_111_10.jpg | 26.24dB
25-05-17 01:54:49.647 : -156--> sparse_residential_111_11.jpg | 26.87dB
25-05-17 01:54:49.829 : -157--> stadium_111_00.jpg | 26.52dB
25-05-17 01:54:50.004 : -158--> stadium_111_01.jpg | 26.41dB
25-05-17 01:54:50.189 : -159--> stadium_111_10.jpg | 27.89dB
25-05-17 01:54:50.369 : -160--> stadium_111_11.jpg | 26.49dB
25-05-17 01:54:50.553 : -161--> storage_tank_111_00.jpg | 28.61dB
25-05-17 01:54:50.726 : -162--> storage_tank_111_01.jpg | 28.76dB
25-05-17 01:54:50.906 : -163--> storage_tank_111_10.jpg | 27.48dB
25-05-17 01:54:51.090 : -164--> storage_tank_111_11.jpg | 27.97dB
25-05-17 01:54:51.276 : -165--> tennis_court_111_00.jpg | 28.86dB
25-05-17 01:54:51.451 : -166--> tennis_court_111_01.jpg | 28.62dB
25-05-17 01:54:51.629 : -167--> tennis_court_111_10.jpg | 28.52dB
25-05-17 01:54:51.807 : -168--> tennis_court_111_11.jpg | 26.63dB
25-05-17 01:54:51.989 : -169--> terrace_111_00.jpg | 29.15dB
25-05-17 01:54:52.167 : -170--> terrace_111_01.jpg | 30.11dB
25-05-17 01:54:52.353 : -171--> terrace_111_10.jpg | 28.91dB
25-05-17 01:54:52.528 : -172--> terrace_111_11.jpg | 29.14dB
25-05-17 01:54:52.711 : -173--> thermal_power_station_111_00.jpg | 26.72dB
25-05-17 01:54:52.893 : -174--> thermal_power_station_111_01.jpg | 28.08dB
25-05-17 01:54:53.072 : -175--> thermal_power_station_111_10.jpg | 26.23dB
25-05-17 01:54:53.255 : -176--> thermal_power_station_111_11.jpg | 26.77dB
25-05-17 01:54:53.434 : -177--> wetland_111_00.jpg | 28.51dB
25-05-17 01:54:53.611 : -178--> wetland_111_01.jpg | 28.64dB
25-05-17 01:54:53.794 : -179--> wetland_111_10.jpg | 28.85dB
25-05-17 01:54:53.968 : -180--> wetland_111_11.jpg | 28.01dB
25-05-17 01:54:53.979 : <epoch:  0, iter:  25,000, Average PSNR : 28.96dB

25-05-17 03:14:49.799 : <epoch:  0, iter:  30,000, lr:1.000e-04> G_loss: 1.464e-04 
25-05-17 03:14:49.800 : Saving the model.
25-05-17 03:14:50.418 : ---1--> airplane_111_00.jpg | 26.97dB
25-05-17 03:14:50.595 : ---2--> airplane_111_01.jpg | 32.21dB
25-05-17 03:14:50.777 : ---3--> airplane_111_10.jpg | 29.79dB
25-05-17 03:14:50.960 : ---4--> airplane_111_11.jpg | 29.98dB
25-05-17 03:14:51.142 : ---5--> airport_111_00.jpg | 31.72dB
25-05-17 03:14:51.324 : ---6--> airport_111_01.jpg | 29.42dB
25-05-17 03:14:51.501 : ---7--> airport_111_10.jpg | 28.75dB
25-05-17 03:14:51.687 : ---8--> airport_111_11.jpg | 29.71dB
25-05-17 03:14:51.864 : ---9--> baseball_diamond_111_00.jpg | 29.60dB
25-05-17 03:14:52.048 : --10--> baseball_diamond_111_01.jpg | 31.51dB
25-05-17 03:14:52.221 : --11--> baseball_diamond_111_10.jpg | 29.54dB
25-05-17 03:14:52.405 : --12--> baseball_diamond_111_11.jpg | 32.68dB
25-05-17 03:14:52.594 : --13--> basketball_court_111_00.jpg | 27.21dB
25-05-17 03:14:52.775 : --14--> basketball_court_111_01.jpg | 26.88dB
25-05-17 03:14:52.955 : --15--> basketball_court_111_10.jpg | 30.26dB
25-05-17 03:14:53.135 : --16--> basketball_court_111_11.jpg | 28.39dB
25-05-17 03:14:53.314 : --17--> beach_111_00.jpg | 25.50dB
25-05-17 03:14:53.496 : --18--> beach_111_01.jpg | 28.63dB
25-05-17 03:14:53.673 : --19--> beach_111_10.jpg | 26.66dB
25-05-17 03:14:53.853 : --20--> beach_111_11.jpg | 31.80dB
25-05-17 03:14:54.033 : --21--> bridge_111_00.jpg | 38.23dB
25-05-17 03:14:54.214 : --22--> bridge_111_01.jpg | 31.03dB
25-05-17 03:14:54.393 : --23--> bridge_111_10.jpg | 29.86dB
25-05-17 03:14:54.574 : --24--> bridge_111_11.jpg | 33.53dB
25-05-17 03:14:54.756 : --25--> chaparral_111_00.jpg | 27.22dB
25-05-17 03:14:54.935 : --26--> chaparral_111_01.jpg | 27.59dB
25-05-17 03:14:55.114 : --27--> chaparral_111_10.jpg | 28.05dB
25-05-17 03:14:55.290 : --28--> chaparral_111_11.jpg | 25.04dB
25-05-17 03:14:55.479 : --29--> church_111_00.jpg | 28.38dB
25-05-17 03:14:55.654 : --30--> church_111_01.jpg | 27.11dB
25-05-17 03:14:55.831 : --31--> church_111_10.jpg | 31.43dB
25-05-17 03:14:56.011 : --32--> church_111_11.jpg | 26.92dB
25-05-17 03:14:56.188 : --33--> circular_farmland_111_00.jpg | 29.42dB
25-05-17 03:14:56.374 : --34--> circular_farmland_111_01.jpg | 30.73dB
25-05-17 03:14:56.548 : --35--> circular_farmland_111_10.jpg | 31.09dB
25-05-17 03:14:56.730 : --36--> circular_farmland_111_11.jpg | 31.37dB
25-05-17 03:14:56.911 : --37--> cloud_111_00.jpg | 37.78dB
25-05-17 03:14:57.098 : --38--> cloud_111_01.jpg | 33.68dB
25-05-17 03:14:57.280 : --39--> cloud_111_10.jpg | 33.30dB
25-05-17 03:14:57.462 : --40--> cloud_111_11.jpg | 33.63dB
25-05-17 03:14:57.637 : --41--> commercial_area_111_00.jpg | 30.32dB
25-05-17 03:14:57.814 : --42--> commercial_area_111_01.jpg | 28.73dB
25-05-17 03:14:57.998 : --43--> commercial_area_111_10.jpg | 29.73dB
25-05-17 03:14:58.172 : --44--> commercial_area_111_11.jpg | 29.50dB
25-05-17 03:14:58.354 : --45--> dense_residential_111_00.jpg | 26.58dB
25-05-17 03:14:58.533 : --46--> dense_residential_111_01.jpg | 25.69dB
25-05-17 03:14:58.712 : --47--> dense_residential_111_10.jpg | 26.09dB
25-05-17 03:14:58.892 : --48--> dense_residential_111_11.jpg | 25.92dB
25-05-17 03:14:59.065 : --49--> desert_111_00.jpg | 34.42dB
25-05-17 03:14:59.247 : --50--> desert_111_01.jpg | 34.03dB
25-05-17 03:14:59.425 : --51--> desert_111_10.jpg | 34.54dB
25-05-17 03:14:59.602 : --52--> desert_111_11.jpg | 34.46dB
25-05-17 03:14:59.777 : --53--> forest_111_00.jpg | 30.35dB
25-05-17 03:14:59.960 : --54--> forest_111_01.jpg | 29.33dB
25-05-17 03:15:00.133 : --55--> forest_111_10.jpg | 28.66dB
25-05-17 03:15:00.316 : --56--> forest_111_11.jpg | 29.92dB
25-05-17 03:15:00.491 : --57--> freeway_111_00.jpg | 31.20dB
25-05-17 03:15:00.672 : --58--> freeway_111_01.jpg | 32.00dB
25-05-17 03:15:00.854 : --59--> freeway_111_10.jpg | 31.95dB
25-05-17 03:15:01.033 : --60--> freeway_111_11.jpg | 32.17dB
25-05-17 03:15:01.213 : --61--> golf_course_111_00.jpg | 29.71dB
25-05-17 03:15:01.391 : --62--> golf_course_111_01.jpg | 28.70dB
25-05-17 03:15:01.571 : --63--> golf_course_111_10.jpg | 30.49dB
25-05-17 03:15:01.753 : --64--> golf_course_111_11.jpg | 30.85dB
25-05-17 03:15:01.928 : --65--> ground_track_field_111_00.jpg | 29.88dB
25-05-17 03:15:02.106 : --66--> ground_track_field_111_01.jpg | 25.85dB
25-05-17 03:15:02.283 : --67--> ground_track_field_111_10.jpg | 27.46dB
25-05-17 03:15:02.457 : --68--> ground_track_field_111_11.jpg | 26.55dB
25-05-17 03:15:02.643 : --69--> harbor_111_00.jpg | 30.80dB
25-05-17 03:15:02.823 : --70--> harbor_111_01.jpg | 28.08dB
25-05-17 03:15:02.999 : --71--> harbor_111_10.jpg | 27.41dB
25-05-17 03:15:03.181 : --72--> harbor_111_11.jpg | 29.34dB
25-05-17 03:15:03.355 : --73--> industrial_area_111_00.jpg | 28.63dB
25-05-17 03:15:03.534 : --74--> industrial_area_111_01.jpg | 28.30dB
25-05-17 03:15:03.713 : --75--> industrial_area_111_10.jpg | 28.65dB
25-05-17 03:15:03.889 : --76--> industrial_area_111_11.jpg | 27.87dB
25-05-17 03:15:04.071 : --77--> intersection_111_00.jpg | 27.33dB
25-05-17 03:15:04.254 : --78--> intersection_111_01.jpg | 27.38dB
25-05-17 03:15:04.431 : --79--> intersection_111_10.jpg | 26.94dB
25-05-17 03:15:04.612 : --80--> intersection_111_11.jpg | 26.74dB
25-05-17 03:15:04.794 : --81--> island_111_00.jpg | 28.17dB
25-05-17 03:15:04.971 : --82--> island_111_01.jpg | 30.72dB
25-05-17 03:15:05.154 : --83--> island_111_10.jpg | 29.14dB
25-05-17 03:15:05.332 : --84--> island_111_11.jpg | 28.76dB
25-05-17 03:15:05.509 : --85--> lake_111_00.jpg | 29.98dB
25-05-17 03:15:05.690 : --86--> lake_111_01.jpg | 29.80dB
25-05-17 03:15:05.870 : --87--> lake_111_10.jpg | 28.72dB
25-05-17 03:15:06.044 : --88--> lake_111_11.jpg | 28.35dB
25-05-17 03:15:06.231 : --89--> meadow_111_00.jpg | 27.27dB
25-05-17 03:15:06.411 : --90--> meadow_111_01.jpg | 27.26dB
25-05-17 03:15:06.586 : --91--> meadow_111_10.jpg | 27.45dB
25-05-17 03:15:06.769 : --92--> meadow_111_11.jpg | 27.56dB
25-05-17 03:15:06.952 : --93--> medium_residential_111_00.jpg | 25.10dB
25-05-17 03:15:07.126 : --94--> medium_residential_111_01.jpg | 24.53dB
25-05-17 03:15:07.306 : --95--> medium_residential_111_10.jpg | 24.91dB
25-05-17 03:15:07.489 : --96--> medium_residential_111_11.jpg | 25.47dB
25-05-17 03:15:07.663 : --97--> mobile_home_park_111_00.jpg | 27.31dB
25-05-17 03:15:07.844 : --98--> mobile_home_park_111_01.jpg | 27.86dB
25-05-17 03:15:08.019 : --99--> mobile_home_park_111_10.jpg | 28.29dB
25-05-17 03:15:08.196 : -100--> mobile_home_park_111_11.jpg | 28.14dB
25-05-17 03:15:08.374 : -101--> mountain_111_00.jpg | 25.49dB
25-05-17 03:15:08.564 : -102--> mountain_111_01.jpg | 26.42dB
25-05-17 03:15:08.737 : -103--> mountain_111_10.jpg | 26.04dB
25-05-17 03:15:08.917 : -104--> mountain_111_11.jpg | 26.51dB
25-05-17 03:15:09.092 : -105--> overpass_111_00.jpg | 26.96dB
25-05-17 03:15:09.271 : -106--> overpass_111_01.jpg | 26.67dB
25-05-17 03:15:09.453 : -107--> overpass_111_10.jpg | 27.57dB
25-05-17 03:15:09.633 : -108--> overpass_111_11.jpg | 28.12dB
25-05-17 03:15:09.815 : -109--> palace_111_00.jpg | 26.49dB
25-05-17 03:15:09.995 : -110--> palace_111_01.jpg | 26.29dB
25-05-17 03:15:10.174 : -111--> palace_111_10.jpg | 27.85dB
25-05-17 03:15:10.352 : -112--> palace_111_11.jpg | 25.90dB
25-05-17 03:15:10.526 : -113--> parking_lot_111_00.jpg | 25.46dB
25-05-17 03:15:10.714 : -114--> parking_lot_111_01.jpg | 25.67dB
25-05-17 03:15:10.894 : -115--> parking_lot_111_10.jpg | 27.73dB
25-05-17 03:15:11.074 : -116--> parking_lot_111_11.jpg | 26.54dB
25-05-17 03:15:11.251 : -117--> railway_111_00.jpg | 27.08dB
25-05-17 03:15:11.434 : -118--> railway_111_01.jpg | 26.58dB
25-05-17 03:15:11.614 : -119--> railway_111_10.jpg | 29.80dB
25-05-17 03:15:11.791 : -120--> railway_111_11.jpg | 25.57dB
25-05-17 03:15:11.973 : -121--> railway_station_111_00.jpg | 27.64dB
25-05-17 03:15:12.149 : -122--> railway_station_111_01.jpg | 28.57dB
25-05-17 03:15:12.326 : -123--> railway_station_111_10.jpg | 27.94dB
25-05-17 03:15:12.507 : -124--> railway_station_111_11.jpg | 28.64dB
25-05-17 03:15:12.687 : -125--> rectangular_farmland_111_00.jpg | 30.30dB
25-05-17 03:15:12.864 : -126--> rectangular_farmland_111_01.jpg | 28.55dB
25-05-17 03:15:13.041 : -127--> rectangular_farmland_111_10.jpg | 30.60dB
25-05-17 03:15:13.219 : -128--> rectangular_farmland_111_11.jpg | 30.97dB
25-05-17 03:15:13.403 : -129--> river_111_00.jpg | 26.86dB
25-05-17 03:15:13.582 : -130--> river_111_01.jpg | 26.90dB
25-05-17 03:15:13.761 : -131--> river_111_10.jpg | 26.01dB
25-05-17 03:15:13.935 : -132--> river_111_11.jpg | 28.10dB
25-05-17 03:15:14.115 : -133--> roundabout_111_00.jpg | 27.23dB
25-05-17 03:15:14.292 : -134--> roundabout_111_01.jpg | 29.09dB
25-05-17 03:15:14.472 : -135--> roundabout_111_10.jpg | 27.21dB
25-05-17 03:15:14.654 : -136--> roundabout_111_11.jpg | 27.48dB
25-05-17 03:15:14.832 : -137--> runway_111_00.jpg | 33.41dB
25-05-17 03:15:15.017 : -138--> runway_111_01.jpg | 32.77dB
25-05-17 03:15:15.193 : -139--> runway_111_10.jpg | 34.09dB
25-05-17 03:15:15.374 : -140--> runway_111_11.jpg | 34.07dB
25-05-17 03:15:15.554 : -141--> sea_ice_111_00.jpg | 30.24dB
25-05-17 03:15:15.732 : -142--> sea_ice_111_01.jpg | 31.09dB
25-05-17 03:15:15.914 : -143--> sea_ice_111_10.jpg | 30.24dB
25-05-17 03:15:16.094 : -144--> sea_ice_111_11.jpg | 31.43dB
25-05-17 03:15:16.274 : -145--> ship_111_00.jpg | 35.51dB
25-05-17 03:15:16.454 : -146--> ship_111_01.jpg | 31.12dB
25-05-17 03:15:16.630 : -147--> ship_111_10.jpg | 40.49dB
25-05-17 03:15:16.808 : -148--> ship_111_11.jpg | 36.53dB
25-05-17 03:15:16.993 : -149--> snowberg_111_00.jpg | 30.58dB
25-05-17 03:15:17.178 : -150--> snowberg_111_01.jpg | 29.28dB
25-05-17 03:15:17.357 : -151--> snowberg_111_10.jpg | 28.42dB
25-05-17 03:15:17.533 : -152--> snowberg_111_11.jpg | 28.46dB
25-05-17 03:15:17.717 : -153--> sparse_residential_111_00.jpg | 27.21dB
25-05-17 03:15:17.891 : -154--> sparse_residential_111_01.jpg | 27.87dB
25-05-17 03:15:18.077 : -155--> sparse_residential_111_10.jpg | 26.25dB
25-05-17 03:15:18.263 : -156--> sparse_residential_111_11.jpg | 26.85dB
25-05-17 03:15:18.439 : -157--> stadium_111_00.jpg | 26.53dB
25-05-17 03:15:18.616 : -158--> stadium_111_01.jpg | 26.41dB
25-05-17 03:15:18.797 : -159--> stadium_111_10.jpg | 27.90dB
25-05-17 03:15:18.973 : -160--> stadium_111_11.jpg | 26.50dB
25-05-17 03:15:19.154 : -161--> storage_tank_111_00.jpg | 28.65dB
25-05-17 03:15:19.337 : -162--> storage_tank_111_01.jpg | 28.75dB
25-05-17 03:15:19.515 : -163--> storage_tank_111_10.jpg | 27.51dB
25-05-17 03:15:19.694 : -164--> storage_tank_111_11.jpg | 28.01dB
25-05-17 03:15:19.877 : -165--> tennis_court_111_00.jpg | 28.95dB
25-05-17 03:15:20.058 : -166--> tennis_court_111_01.jpg | 28.61dB
25-05-17 03:15:20.237 : -167--> tennis_court_111_10.jpg | 28.51dB
25-05-17 03:15:20.418 : -168--> tennis_court_111_11.jpg | 26.61dB
25-05-17 03:15:20.601 : -169--> terrace_111_00.jpg | 29.18dB
25-05-17 03:15:20.784 : -170--> terrace_111_01.jpg | 30.15dB
25-05-17 03:15:20.960 : -171--> terrace_111_10.jpg | 28.94dB
25-05-17 03:15:21.139 : -172--> terrace_111_11.jpg | 29.15dB
25-05-17 03:15:21.316 : -173--> thermal_power_station_111_00.jpg | 26.73dB
25-05-17 03:15:21.495 : -174--> thermal_power_station_111_01.jpg | 28.08dB
25-05-17 03:15:21.676 : -175--> thermal_power_station_111_10.jpg | 26.24dB
25-05-17 03:15:21.855 : -176--> thermal_power_station_111_11.jpg | 26.78dB
25-05-17 03:15:22.037 : -177--> wetland_111_00.jpg | 28.50dB
25-05-17 03:15:22.214 : -178--> wetland_111_01.jpg | 28.63dB
25-05-17 03:15:22.396 : -179--> wetland_111_10.jpg | 28.86dB
25-05-17 03:15:22.573 : -180--> wetland_111_11.jpg | 28.02dB
25-05-17 03:15:22.583 : <epoch:  0, iter:  30,000, Average PSNR : 28.97dB

25-05-17 04:35:18.552 : <epoch:  0, iter:  35,000, lr:1.000e-04> G_loss: 2.764e-04 
25-05-17 04:35:18.553 : Saving the model.
25-05-17 04:35:19.169 : ---1--> airplane_111_00.jpg | 26.93dB
25-05-17 04:35:19.346 : ---2--> airplane_111_01.jpg | 32.17dB
25-05-17 04:35:19.521 : ---3--> airplane_111_10.jpg | 29.77dB
25-05-17 04:35:19.695 : ---4--> airplane_111_11.jpg | 29.93dB
25-05-17 04:35:19.877 : ---5--> airport_111_00.jpg | 31.69dB
25-05-17 04:35:20.055 : ---6--> airport_111_01.jpg | 29.41dB
25-05-17 04:35:20.239 : ---7--> airport_111_10.jpg | 28.68dB
25-05-17 04:35:20.418 : ---8--> airport_111_11.jpg | 29.68dB
25-05-17 04:35:20.592 : ---9--> baseball_diamond_111_00.jpg | 29.59dB
25-05-17 04:35:20.774 : --10--> baseball_diamond_111_01.jpg | 31.50dB
25-05-17 04:35:20.953 : --11--> baseball_diamond_111_10.jpg | 29.51dB
25-05-17 04:35:21.132 : --12--> baseball_diamond_111_11.jpg | 32.64dB
25-05-17 04:35:21.313 : --13--> basketball_court_111_00.jpg | 27.22dB
25-05-17 04:35:21.493 : --14--> basketball_court_111_01.jpg | 26.88dB
25-05-17 04:35:21.671 : --15--> basketball_court_111_10.jpg | 30.21dB
25-05-17 04:35:21.852 : --16--> basketball_court_111_11.jpg | 28.43dB
25-05-17 04:35:22.033 : --17--> beach_111_00.jpg | 25.44dB
25-05-17 04:35:22.208 : --18--> beach_111_01.jpg | 28.57dB
25-05-17 04:35:22.383 : --19--> beach_111_10.jpg | 26.56dB
25-05-17 04:35:22.559 : --20--> beach_111_11.jpg | 31.74dB
25-05-17 04:35:22.736 : --21--> bridge_111_00.jpg | 38.20dB
25-05-17 04:35:22.915 : --22--> bridge_111_01.jpg | 31.08dB
25-05-17 04:35:23.095 : --23--> bridge_111_10.jpg | 29.89dB
25-05-17 04:35:23.276 : --24--> bridge_111_11.jpg | 33.53dB
25-05-17 04:35:23.457 : --25--> chaparral_111_00.jpg | 27.19dB
25-05-17 04:35:23.634 : --26--> chaparral_111_01.jpg | 27.57dB
25-05-17 04:35:23.808 : --27--> chaparral_111_10.jpg | 28.02dB
25-05-17 04:35:23.986 : --28--> chaparral_111_11.jpg | 25.04dB
25-05-17 04:35:24.163 : --29--> church_111_00.jpg | 28.35dB
25-05-17 04:35:24.347 : --30--> church_111_01.jpg | 27.09dB
25-05-17 04:35:24.523 : --31--> church_111_10.jpg | 31.39dB
25-05-17 04:35:24.698 : --32--> church_111_11.jpg | 26.90dB
25-05-17 04:35:24.878 : --33--> circular_farmland_111_00.jpg | 29.42dB
25-05-17 04:35:25.057 : --34--> circular_farmland_111_01.jpg | 30.72dB
25-05-17 04:35:25.233 : --35--> circular_farmland_111_10.jpg | 30.98dB
25-05-17 04:35:25.418 : --36--> circular_farmland_111_11.jpg | 31.33dB
25-05-17 04:35:25.594 : --37--> cloud_111_00.jpg | 37.73dB
25-05-17 04:35:25.774 : --38--> cloud_111_01.jpg | 33.72dB
25-05-17 04:35:25.954 : --39--> cloud_111_10.jpg | 33.29dB
25-05-17 04:35:26.134 : --40--> cloud_111_11.jpg | 33.57dB
25-05-17 04:35:26.316 : --41--> commercial_area_111_00.jpg | 30.32dB
25-05-17 04:35:26.493 : --42--> commercial_area_111_01.jpg | 28.72dB
25-05-17 04:35:26.671 : --43--> commercial_area_111_10.jpg | 29.73dB
25-05-17 04:35:26.854 : --44--> commercial_area_111_11.jpg | 29.48dB
25-05-17 04:35:27.031 : --45--> dense_residential_111_00.jpg | 26.61dB
25-05-17 04:35:27.210 : --46--> dense_residential_111_01.jpg | 25.68dB
25-05-17 04:35:27.391 : --47--> dense_residential_111_10.jpg | 26.08dB
25-05-17 04:35:27.578 : --48--> dense_residential_111_11.jpg | 25.91dB
25-05-17 04:35:27.764 : --49--> desert_111_00.jpg | 34.38dB
25-05-17 04:35:27.939 : --50--> desert_111_01.jpg | 33.96dB
25-05-17 04:35:28.117 : --51--> desert_111_10.jpg | 34.54dB
25-05-17 04:35:28.295 : --52--> desert_111_11.jpg | 34.43dB
25-05-17 04:35:28.477 : --53--> forest_111_00.jpg | 30.29dB
25-05-17 04:35:28.654 : --54--> forest_111_01.jpg | 29.33dB
25-05-17 04:35:28.831 : --55--> forest_111_10.jpg | 28.63dB
25-05-17 04:35:29.013 : --56--> forest_111_11.jpg | 29.91dB
25-05-17 04:35:29.190 : --57--> freeway_111_00.jpg | 31.17dB
25-05-17 04:35:29.368 : --58--> freeway_111_01.jpg | 31.98dB
25-05-17 04:35:29.542 : --59--> freeway_111_10.jpg | 32.00dB
25-05-17 04:35:29.718 : --60--> freeway_111_11.jpg | 32.14dB
25-05-17 04:35:29.897 : --61--> golf_course_111_00.jpg | 29.67dB
25-05-17 04:35:30.076 : --62--> golf_course_111_01.jpg | 28.67dB
25-05-17 04:35:30.255 : --63--> golf_course_111_10.jpg | 30.51dB
25-05-17 04:35:30.433 : --64--> golf_course_111_11.jpg | 30.84dB
25-05-17 04:35:30.612 : --65--> ground_track_field_111_00.jpg | 29.88dB
25-05-17 04:35:30.793 : --66--> ground_track_field_111_01.jpg | 25.84dB
25-05-17 04:35:30.978 : --67--> ground_track_field_111_10.jpg | 27.45dB
25-05-17 04:35:31.156 : --68--> ground_track_field_111_11.jpg | 26.56dB
25-05-17 04:35:31.344 : --69--> harbor_111_00.jpg | 30.75dB
25-05-17 04:35:31.519 : --70--> harbor_111_01.jpg | 28.08dB
25-05-17 04:35:31.698 : --71--> harbor_111_10.jpg | 27.40dB
25-05-17 04:35:31.877 : --72--> harbor_111_11.jpg | 29.28dB
25-05-17 04:35:32.051 : --73--> industrial_area_111_00.jpg | 28.65dB
25-05-17 04:35:32.232 : --74--> industrial_area_111_01.jpg | 28.27dB
25-05-17 04:35:32.415 : --75--> industrial_area_111_10.jpg | 28.65dB
25-05-17 04:35:32.595 : --76--> industrial_area_111_11.jpg | 27.87dB
25-05-17 04:35:32.774 : --77--> intersection_111_00.jpg | 27.30dB
25-05-17 04:35:32.955 : --78--> intersection_111_01.jpg | 27.39dB
25-05-17 04:35:33.131 : --79--> intersection_111_10.jpg | 26.92dB
25-05-17 04:35:33.310 : --80--> intersection_111_11.jpg | 26.73dB
25-05-17 04:35:33.493 : --81--> island_111_00.jpg | 28.13dB
25-05-17 04:35:33.674 : --82--> island_111_01.jpg | 30.64dB
25-05-17 04:35:33.851 : --83--> island_111_10.jpg | 29.10dB
25-05-17 04:35:34.034 : --84--> island_111_11.jpg | 28.73dB
25-05-17 04:35:34.213 : --85--> lake_111_00.jpg | 29.97dB
25-05-17 04:35:34.394 : --86--> lake_111_01.jpg | 29.79dB
25-05-17 04:35:34.574 : --87--> lake_111_10.jpg | 28.70dB
25-05-17 04:35:34.750 : --88--> lake_111_11.jpg | 28.33dB
25-05-17 04:35:34.934 : --89--> meadow_111_00.jpg | 27.26dB
25-05-17 04:35:35.109 : --90--> meadow_111_01.jpg | 27.26dB
25-05-17 04:35:35.294 : --91--> meadow_111_10.jpg | 27.45dB
25-05-17 04:35:35.473 : --92--> meadow_111_11.jpg | 27.55dB
25-05-17 04:35:35.654 : --93--> medium_residential_111_00.jpg | 25.10dB
25-05-17 04:35:35.834 : --94--> medium_residential_111_01.jpg | 24.52dB
25-05-17 04:35:36.011 : --95--> medium_residential_111_10.jpg | 24.90dB
25-05-17 04:35:36.194 : --96--> medium_residential_111_11.jpg | 25.46dB
25-05-17 04:35:36.377 : --97--> mobile_home_park_111_00.jpg | 27.34dB
25-05-17 04:35:36.556 : --98--> mobile_home_park_111_01.jpg | 27.87dB
25-05-17 04:35:36.735 : --99--> mobile_home_park_111_10.jpg | 28.30dB
25-05-17 04:35:36.916 : -100--> mobile_home_park_111_11.jpg | 28.18dB
25-05-17 04:35:37.091 : -101--> mountain_111_00.jpg | 25.47dB
25-05-17 04:35:37.267 : -102--> mountain_111_01.jpg | 26.40dB
25-05-17 04:35:37.444 : -103--> mountain_111_10.jpg | 26.01dB
25-05-17 04:35:37.631 : -104--> mountain_111_11.jpg | 26.49dB
25-05-17 04:35:37.814 : -105--> overpass_111_00.jpg | 26.93dB
25-05-17 04:35:37.989 : -106--> overpass_111_01.jpg | 26.68dB
25-05-17 04:35:38.172 : -107--> overpass_111_10.jpg | 27.59dB
25-05-17 04:35:38.350 : -108--> overpass_111_11.jpg | 28.11dB
25-05-17 04:35:38.526 : -109--> palace_111_00.jpg | 26.45dB
25-05-17 04:35:38.706 : -110--> palace_111_01.jpg | 26.28dB
25-05-17 04:35:38.883 : -111--> palace_111_10.jpg | 27.81dB
25-05-17 04:35:39.065 : -112--> palace_111_11.jpg | 25.85dB
25-05-17 04:35:39.243 : -113--> parking_lot_111_00.jpg | 25.44dB
25-05-17 04:35:39.425 : -114--> parking_lot_111_01.jpg | 25.64dB
25-05-17 04:35:39.608 : -115--> parking_lot_111_10.jpg | 27.66dB
25-05-17 04:35:39.783 : -116--> parking_lot_111_11.jpg | 26.49dB
25-05-17 04:35:39.966 : -117--> railway_111_00.jpg | 27.07dB
25-05-17 04:35:40.143 : -118--> railway_111_01.jpg | 26.57dB
25-05-17 04:35:40.326 : -119--> railway_111_10.jpg | 29.79dB
25-05-17 04:35:40.506 : -120--> railway_111_11.jpg | 25.56dB
25-05-17 04:35:40.684 : -121--> railway_station_111_00.jpg | 27.64dB
25-05-17 04:35:40.864 : -122--> railway_station_111_01.jpg | 28.51dB
25-05-17 04:35:41.040 : -123--> railway_station_111_10.jpg | 27.94dB
25-05-17 04:35:41.221 : -124--> railway_station_111_11.jpg | 28.61dB
25-05-17 04:35:41.400 : -125--> rectangular_farmland_111_00.jpg | 30.29dB
25-05-17 04:35:41.579 : -126--> rectangular_farmland_111_01.jpg | 28.52dB
25-05-17 04:35:41.756 : -127--> rectangular_farmland_111_10.jpg | 30.58dB
25-05-17 04:35:41.939 : -128--> rectangular_farmland_111_11.jpg | 30.95dB
25-05-17 04:35:42.118 : -129--> river_111_00.jpg | 26.83dB
25-05-17 04:35:42.301 : -130--> river_111_01.jpg | 26.88dB
25-05-17 04:35:42.480 : -131--> river_111_10.jpg | 26.00dB
25-05-17 04:35:42.661 : -132--> river_111_11.jpg | 28.08dB
25-05-17 04:35:42.839 : -133--> roundabout_111_00.jpg | 27.18dB
25-05-17 04:35:43.024 : -134--> roundabout_111_01.jpg | 29.08dB
25-05-17 04:35:43.204 : -135--> roundabout_111_10.jpg | 27.22dB
25-05-17 04:35:43.384 : -136--> roundabout_111_11.jpg | 27.48dB
25-05-17 04:35:43.563 : -137--> runway_111_00.jpg | 33.33dB
25-05-17 04:35:43.744 : -138--> runway_111_01.jpg | 32.73dB
25-05-17 04:35:43.924 : -139--> runway_111_10.jpg | 34.05dB
25-05-17 04:35:44.106 : -140--> runway_111_11.jpg | 34.01dB
25-05-17 04:35:44.283 : -141--> sea_ice_111_00.jpg | 30.25dB
25-05-17 04:35:44.459 : -142--> sea_ice_111_01.jpg | 31.14dB
25-05-17 04:35:44.638 : -143--> sea_ice_111_10.jpg | 30.29dB
25-05-17 04:35:44.818 : -144--> sea_ice_111_11.jpg | 31.44dB
25-05-17 04:35:44.998 : -145--> ship_111_00.jpg | 35.54dB
25-05-17 04:35:45.174 : -146--> ship_111_01.jpg | 31.10dB
25-05-17 04:35:45.359 : -147--> ship_111_10.jpg | 40.48dB
25-05-17 04:35:45.537 : -148--> ship_111_11.jpg | 36.41dB
25-05-17 04:35:45.718 : -149--> snowberg_111_00.jpg | 30.47dB
25-05-17 04:35:45.898 : -150--> snowberg_111_01.jpg | 29.25dB
25-05-17 04:35:46.075 : -151--> snowberg_111_10.jpg | 28.39dB
25-05-17 04:35:46.249 : -152--> snowberg_111_11.jpg | 28.44dB
25-05-17 04:35:46.434 : -153--> sparse_residential_111_00.jpg | 27.19dB
25-05-17 04:35:46.612 : -154--> sparse_residential_111_01.jpg | 27.86dB
25-05-17 04:35:46.789 : -155--> sparse_residential_111_10.jpg | 26.27dB
25-05-17 04:35:46.967 : -156--> sparse_residential_111_11.jpg | 26.85dB
25-05-17 04:35:47.150 : -157--> stadium_111_00.jpg | 26.55dB
25-05-17 04:35:47.327 : -158--> stadium_111_01.jpg | 26.41dB
25-05-17 04:35:47.509 : -159--> stadium_111_10.jpg | 27.88dB
25-05-17 04:35:47.687 : -160--> stadium_111_11.jpg | 26.52dB
25-05-17 04:35:47.869 : -161--> storage_tank_111_00.jpg | 28.61dB
25-05-17 04:35:48.048 : -162--> storage_tank_111_01.jpg | 28.71dB
25-05-17 04:35:48.233 : -163--> storage_tank_111_10.jpg | 27.44dB
25-05-17 04:35:48.411 : -164--> storage_tank_111_11.jpg | 27.98dB
25-05-17 04:35:48.594 : -165--> tennis_court_111_00.jpg | 28.96dB
25-05-17 04:35:48.770 : -166--> tennis_court_111_01.jpg | 28.60dB
25-05-17 04:35:48.960 : -167--> tennis_court_111_10.jpg | 28.49dB
25-05-17 04:35:49.136 : -168--> tennis_court_111_11.jpg | 26.60dB
25-05-17 04:35:49.312 : -169--> terrace_111_00.jpg | 29.13dB
25-05-17 04:35:49.494 : -170--> terrace_111_01.jpg | 30.13dB
25-05-17 04:35:49.675 : -171--> terrace_111_10.jpg | 28.95dB
25-05-17 04:35:49.853 : -172--> terrace_111_11.jpg | 29.13dB
25-05-17 04:35:50.036 : -173--> thermal_power_station_111_00.jpg | 26.70dB
25-05-17 04:35:50.212 : -174--> thermal_power_station_111_01.jpg | 28.08dB
25-05-17 04:35:50.394 : -175--> thermal_power_station_111_10.jpg | 26.22dB
25-05-17 04:35:50.574 : -176--> thermal_power_station_111_11.jpg | 26.76dB
25-05-17 04:35:50.753 : -177--> wetland_111_00.jpg | 28.51dB
25-05-17 04:35:50.929 : -178--> wetland_111_01.jpg | 28.62dB
25-05-17 04:35:51.113 : -179--> wetland_111_10.jpg | 28.84dB
25-05-17 04:35:51.295 : -180--> wetland_111_11.jpg | 28.00dB
25-05-17 04:35:51.301 : <epoch:  0, iter:  35,000, Average PSNR : 28.95dB

25-05-17 05:55:47.549 : <epoch:  0, iter:  40,000, lr:1.000e-04> G_loss: 3.137e-05 
25-05-17 05:55:47.550 : Saving the model.
25-05-17 05:55:48.122 : ---1--> airplane_111_00.jpg | 26.99dB
25-05-17 05:55:48.297 : ---2--> airplane_111_01.jpg | 32.22dB
25-05-17 05:55:48.477 : ---3--> airplane_111_10.jpg | 29.80dB
25-05-17 05:55:48.653 : ---4--> airplane_111_11.jpg | 29.95dB
25-05-17 05:55:48.835 : ---5--> airport_111_00.jpg | 31.67dB
25-05-17 05:55:49.015 : ---6--> airport_111_01.jpg | 29.41dB
25-05-17 05:55:49.196 : ---7--> airport_111_10.jpg | 28.73dB
25-05-17 05:55:49.371 : ---8--> airport_111_11.jpg | 29.69dB
25-05-17 05:55:49.550 : ---9--> baseball_diamond_111_00.jpg | 29.58dB
25-05-17 05:55:49.736 : --10--> baseball_diamond_111_01.jpg | 31.51dB
25-05-17 05:55:49.916 : --11--> baseball_diamond_111_10.jpg | 29.50dB
25-05-17 05:55:50.093 : --12--> baseball_diamond_111_11.jpg | 32.68dB
25-05-17 05:55:50.271 : --13--> basketball_court_111_00.jpg | 27.22dB
25-05-17 05:55:50.454 : --14--> basketball_court_111_01.jpg | 26.88dB
25-05-17 05:55:50.635 : --15--> basketball_court_111_10.jpg | 30.23dB
25-05-17 05:55:50.810 : --16--> basketball_court_111_11.jpg | 28.40dB
25-05-17 05:55:50.988 : --17--> beach_111_00.jpg | 25.53dB
25-05-17 05:55:51.165 : --18--> beach_111_01.jpg | 28.62dB
25-05-17 05:55:51.345 : --19--> beach_111_10.jpg | 26.67dB
25-05-17 05:55:51.526 : --20--> beach_111_11.jpg | 31.73dB
25-05-17 05:55:51.706 : --21--> bridge_111_00.jpg | 38.33dB
25-05-17 05:55:51.887 : --22--> bridge_111_01.jpg | 31.08dB
25-05-17 05:55:52.066 : --23--> bridge_111_10.jpg | 29.91dB
25-05-17 05:55:52.245 : --24--> bridge_111_11.jpg | 33.50dB
25-05-17 05:55:52.422 : --25--> chaparral_111_00.jpg | 27.23dB
25-05-17 05:55:52.603 : --26--> chaparral_111_01.jpg | 27.59dB
25-05-17 05:55:52.780 : --27--> chaparral_111_10.jpg | 28.05dB
25-05-17 05:55:52.959 : --28--> chaparral_111_11.jpg | 25.05dB
25-05-17 05:55:53.133 : --29--> church_111_00.jpg | 28.36dB
25-05-17 05:55:53.319 : --30--> church_111_01.jpg | 27.11dB
25-05-17 05:55:53.501 : --31--> church_111_10.jpg | 31.43dB
25-05-17 05:55:53.680 : --32--> church_111_11.jpg | 26.93dB
25-05-17 05:55:53.860 : --33--> circular_farmland_111_00.jpg | 29.43dB
25-05-17 05:55:54.040 : --34--> circular_farmland_111_01.jpg | 30.70dB
25-05-17 05:55:54.216 : --35--> circular_farmland_111_10.jpg | 31.04dB
25-05-17 05:55:54.393 : --36--> circular_farmland_111_11.jpg | 31.33dB
25-05-17 05:55:54.569 : --37--> cloud_111_00.jpg | 37.76dB
25-05-17 05:55:54.743 : --38--> cloud_111_01.jpg | 33.72dB
25-05-17 05:55:54.920 : --39--> cloud_111_10.jpg | 33.29dB
25-05-17 05:55:55.103 : --40--> cloud_111_11.jpg | 33.61dB
25-05-17 05:55:55.280 : --41--> commercial_area_111_00.jpg | 30.30dB
25-05-17 05:55:55.466 : --42--> commercial_area_111_01.jpg | 28.76dB
25-05-17 05:55:55.645 : --43--> commercial_area_111_10.jpg | 29.77dB
25-05-17 05:55:55.820 : --44--> commercial_area_111_11.jpg | 29.48dB
25-05-17 05:55:56.004 : --45--> dense_residential_111_00.jpg | 26.57dB
25-05-17 05:55:56.186 : --46--> dense_residential_111_01.jpg | 25.68dB
25-05-17 05:55:56.365 : --47--> dense_residential_111_10.jpg | 26.07dB
25-05-17 05:55:56.545 : --48--> dense_residential_111_11.jpg | 25.90dB
25-05-17 05:55:56.734 : --49--> desert_111_00.jpg | 34.35dB
25-05-17 05:55:56.907 : --50--> desert_111_01.jpg | 33.95dB
25-05-17 05:55:57.085 : --51--> desert_111_10.jpg | 34.50dB
25-05-17 05:55:57.264 : --52--> desert_111_11.jpg | 34.43dB
25-05-17 05:55:57.446 : --53--> forest_111_00.jpg | 30.32dB
25-05-17 05:55:57.626 : --54--> forest_111_01.jpg | 29.33dB
25-05-17 05:55:57.805 : --55--> forest_111_10.jpg | 28.65dB
25-05-17 05:55:57.985 : --56--> forest_111_11.jpg | 29.94dB
25-05-17 05:55:58.169 : --57--> freeway_111_00.jpg | 31.14dB
25-05-17 05:55:58.347 : --58--> freeway_111_01.jpg | 32.00dB
25-05-17 05:55:58.529 : --59--> freeway_111_10.jpg | 31.98dB
25-05-17 05:55:58.705 : --60--> freeway_111_11.jpg | 32.14dB
25-05-17 05:55:58.888 : --61--> golf_course_111_00.jpg | 29.66dB
25-05-17 05:55:59.071 : --62--> golf_course_111_01.jpg | 28.69dB
25-05-17 05:55:59.249 : --63--> golf_course_111_10.jpg | 30.47dB
25-05-17 05:55:59.427 : --64--> golf_course_111_11.jpg | 30.88dB
25-05-17 05:55:59.605 : --65--> ground_track_field_111_00.jpg | 29.88dB
25-05-17 05:55:59.786 : --66--> ground_track_field_111_01.jpg | 25.85dB
25-05-17 05:55:59.966 : --67--> ground_track_field_111_10.jpg | 27.45dB
25-05-17 05:56:00.144 : --68--> ground_track_field_111_11.jpg | 26.55dB
25-05-17 05:56:00.324 : --69--> harbor_111_00.jpg | 30.77dB
25-05-17 05:56:00.500 : --70--> harbor_111_01.jpg | 28.09dB
25-05-17 05:56:00.683 : --71--> harbor_111_10.jpg | 27.40dB
25-05-17 05:56:00.859 : --72--> harbor_111_11.jpg | 29.31dB
25-05-17 05:56:01.043 : --73--> industrial_area_111_00.jpg | 28.64dB
25-05-17 05:56:01.224 : --74--> industrial_area_111_01.jpg | 28.32dB
25-05-17 05:56:01.401 : --75--> industrial_area_111_10.jpg | 28.66dB
25-05-17 05:56:01.586 : --76--> industrial_area_111_11.jpg | 27.87dB
25-05-17 05:56:01.766 : --77--> intersection_111_00.jpg | 27.33dB
25-05-17 05:56:01.944 : --78--> intersection_111_01.jpg | 27.37dB
25-05-17 05:56:02.123 : --79--> intersection_111_10.jpg | 26.92dB
25-05-17 05:56:02.311 : --80--> intersection_111_11.jpg | 26.72dB
25-05-17 05:56:02.487 : --81--> island_111_00.jpg | 28.17dB
25-05-17 05:56:02.668 : --82--> island_111_01.jpg | 30.70dB
25-05-17 05:56:02.846 : --83--> island_111_10.jpg | 29.13dB
25-05-17 05:56:03.027 : --84--> island_111_11.jpg | 28.73dB
25-05-17 05:56:03.209 : --85--> lake_111_00.jpg | 29.99dB
25-05-17 05:56:03.392 : --86--> lake_111_01.jpg | 29.82dB
25-05-17 05:56:03.574 : --87--> lake_111_10.jpg | 28.72dB
25-05-17 05:56:03.754 : --88--> lake_111_11.jpg | 28.33dB
25-05-17 05:56:03.934 : --89--> meadow_111_00.jpg | 27.27dB
25-05-17 05:56:04.112 : --90--> meadow_111_01.jpg | 27.25dB
25-05-17 05:56:04.290 : --91--> meadow_111_10.jpg | 27.47dB
25-05-17 05:56:04.473 : --92--> meadow_111_11.jpg | 27.57dB
25-05-17 05:56:04.654 : --93--> medium_residential_111_00.jpg | 25.09dB
25-05-17 05:56:04.835 : --94--> medium_residential_111_01.jpg | 24.51dB
25-05-17 05:56:05.009 : --95--> medium_residential_111_10.jpg | 24.91dB
25-05-17 05:56:05.185 : --96--> medium_residential_111_11.jpg | 25.48dB
25-05-17 05:56:05.361 : --97--> mobile_home_park_111_00.jpg | 27.32dB
25-05-17 05:56:05.543 : --98--> mobile_home_park_111_01.jpg | 27.84dB
25-05-17 05:56:05.722 : --99--> mobile_home_park_111_10.jpg | 28.32dB
25-05-17 05:56:05.898 : -100--> mobile_home_park_111_11.jpg | 28.17dB
25-05-17 05:56:06.085 : -101--> mountain_111_00.jpg | 25.48dB
25-05-17 05:56:06.261 : -102--> mountain_111_01.jpg | 26.41dB
25-05-17 05:56:06.442 : -103--> mountain_111_10.jpg | 26.02dB
25-05-17 05:56:06.621 : -104--> mountain_111_11.jpg | 26.52dB
25-05-17 05:56:06.802 : -105--> overpass_111_00.jpg | 26.97dB
25-05-17 05:56:06.984 : -106--> overpass_111_01.jpg | 26.69dB
25-05-17 05:56:07.162 : -107--> overpass_111_10.jpg | 27.57dB
25-05-17 05:56:07.344 : -108--> overpass_111_11.jpg | 28.10dB
25-05-17 05:56:07.528 : -109--> palace_111_00.jpg | 26.51dB
25-05-17 05:56:07.704 : -110--> palace_111_01.jpg | 26.25dB
25-05-17 05:56:07.887 : -111--> palace_111_10.jpg | 27.82dB
25-05-17 05:56:08.061 : -112--> palace_111_11.jpg | 25.91dB
25-05-17 05:56:08.242 : -113--> parking_lot_111_00.jpg | 25.42dB
25-05-17 05:56:08.424 : -114--> parking_lot_111_01.jpg | 25.66dB
25-05-17 05:56:08.599 : -115--> parking_lot_111_10.jpg | 27.68dB
25-05-17 05:56:08.774 : -116--> parking_lot_111_11.jpg | 26.48dB
25-05-17 05:56:08.953 : -117--> railway_111_00.jpg | 27.09dB
25-05-17 05:56:09.133 : -118--> railway_111_01.jpg | 26.58dB
25-05-17 05:56:09.314 : -119--> railway_111_10.jpg | 29.77dB
25-05-17 05:56:09.494 : -120--> railway_111_11.jpg | 25.57dB
25-05-17 05:56:09.673 : -121--> railway_station_111_00.jpg | 27.66dB
25-05-17 05:56:09.858 : -122--> railway_station_111_01.jpg | 28.58dB
25-05-17 05:56:10.038 : -123--> railway_station_111_10.jpg | 27.94dB
25-05-17 05:56:10.217 : -124--> railway_station_111_11.jpg | 28.65dB
25-05-17 05:56:10.394 : -125--> rectangular_farmland_111_00.jpg | 30.29dB
25-05-17 05:56:10.572 : -126--> rectangular_farmland_111_01.jpg | 28.54dB
25-05-17 05:56:10.753 : -127--> rectangular_farmland_111_10.jpg | 30.61dB
25-05-17 05:56:10.933 : -128--> rectangular_farmland_111_11.jpg | 30.93dB
25-05-17 05:56:11.111 : -129--> river_111_00.jpg | 26.88dB
25-05-17 05:56:11.291 : -130--> river_111_01.jpg | 26.88dB
25-05-17 05:56:11.474 : -131--> river_111_10.jpg | 26.01dB
25-05-17 05:56:11.654 : -132--> river_111_11.jpg | 28.08dB
25-05-17 05:56:11.837 : -133--> roundabout_111_00.jpg | 27.23dB
25-05-17 05:56:12.019 : -134--> roundabout_111_01.jpg | 29.06dB
25-05-17 05:56:12.197 : -135--> roundabout_111_10.jpg | 27.19dB
25-05-17 05:56:12.374 : -136--> roundabout_111_11.jpg | 27.49dB
25-05-17 05:56:12.552 : -137--> runway_111_00.jpg | 33.50dB
25-05-17 05:56:12.732 : -138--> runway_111_01.jpg | 32.88dB
25-05-17 05:56:12.909 : -139--> runway_111_10.jpg | 34.04dB
25-05-17 05:56:13.094 : -140--> runway_111_11.jpg | 34.14dB
25-05-17 05:56:13.273 : -141--> sea_ice_111_00.jpg | 30.26dB
25-05-17 05:56:13.450 : -142--> sea_ice_111_01.jpg | 31.11dB
25-05-17 05:56:13.629 : -143--> sea_ice_111_10.jpg | 30.29dB
25-05-17 05:56:13.808 : -144--> sea_ice_111_11.jpg | 31.42dB
25-05-17 05:56:13.984 : -145--> ship_111_00.jpg | 35.57dB
25-05-17 05:56:14.164 : -146--> ship_111_01.jpg | 31.13dB
25-05-17 05:56:14.343 : -147--> ship_111_10.jpg | 40.50dB
25-05-17 05:56:14.524 : -148--> ship_111_11.jpg | 36.48dB
25-05-17 05:56:14.703 : -149--> snowberg_111_00.jpg | 30.57dB
25-05-17 05:56:14.885 : -150--> snowberg_111_01.jpg | 29.28dB
25-05-17 05:56:15.057 : -151--> snowberg_111_10.jpg | 28.42dB
25-05-17 05:56:15.238 : -152--> snowberg_111_11.jpg | 28.47dB
25-05-17 05:56:15.420 : -153--> sparse_residential_111_00.jpg | 27.20dB
25-05-17 05:56:15.596 : -154--> sparse_residential_111_01.jpg | 27.87dB
25-05-17 05:56:15.773 : -155--> sparse_residential_111_10.jpg | 26.24dB
25-05-17 05:56:15.952 : -156--> sparse_residential_111_11.jpg | 26.88dB
25-05-17 05:56:16.131 : -157--> stadium_111_00.jpg | 26.57dB
25-05-17 05:56:16.313 : -158--> stadium_111_01.jpg | 26.39dB
25-05-17 05:56:16.490 : -159--> stadium_111_10.jpg | 27.89dB
25-05-17 05:56:16.673 : -160--> stadium_111_11.jpg | 26.54dB
25-05-17 05:56:16.856 : -161--> storage_tank_111_00.jpg | 28.65dB
25-05-17 05:56:17.037 : -162--> storage_tank_111_01.jpg | 28.71dB
25-05-17 05:56:17.214 : -163--> storage_tank_111_10.jpg | 27.50dB
25-05-17 05:56:17.394 : -164--> storage_tank_111_11.jpg | 28.00dB
25-05-17 05:56:17.571 : -165--> tennis_court_111_00.jpg | 28.92dB
25-05-17 05:56:17.754 : -166--> tennis_court_111_01.jpg | 28.56dB
25-05-17 05:56:17.935 : -167--> tennis_court_111_10.jpg | 28.52dB
25-05-17 05:56:18.119 : -168--> tennis_court_111_11.jpg | 26.63dB
25-05-17 05:56:18.295 : -169--> terrace_111_00.jpg | 29.17dB
25-05-17 05:56:18.475 : -170--> terrace_111_01.jpg | 30.17dB
25-05-17 05:56:18.653 : -171--> terrace_111_10.jpg | 28.98dB
25-05-17 05:56:18.833 : -172--> terrace_111_11.jpg | 29.15dB
25-05-17 05:56:19.007 : -173--> thermal_power_station_111_00.jpg | 26.73dB
25-05-17 05:56:19.184 : -174--> thermal_power_station_111_01.jpg | 28.09dB
25-05-17 05:56:19.372 : -175--> thermal_power_station_111_10.jpg | 26.24dB
25-05-17 05:56:19.554 : -176--> thermal_power_station_111_11.jpg | 26.75dB
25-05-17 05:56:19.734 : -177--> wetland_111_00.jpg | 28.51dB
25-05-17 05:56:19.919 : -178--> wetland_111_01.jpg | 28.63dB
25-05-17 05:56:20.094 : -179--> wetland_111_10.jpg | 28.85dB
25-05-17 05:56:20.269 : -180--> wetland_111_11.jpg | 28.03dB
25-05-17 05:56:20.276 : <epoch:  0, iter:  40,000, Average PSNR : 28.97dB

25-05-17 07:16:17.236 : <epoch:  0, iter:  45,000, lr:1.000e-04> G_loss: 2.782e-04 
25-05-17 07:16:17.238 : Saving the model.
25-05-17 07:16:17.878 : ---1--> airplane_111_00.jpg | 26.96dB
25-05-17 07:16:18.055 : ---2--> airplane_111_01.jpg | 32.21dB
25-05-17 07:16:18.235 : ---3--> airplane_111_10.jpg | 29.80dB
25-05-17 07:16:18.418 : ---4--> airplane_111_11.jpg | 29.98dB
25-05-17 07:16:18.603 : ---5--> airport_111_00.jpg | 31.64dB
25-05-17 07:16:18.780 : ---6--> airport_111_01.jpg | 29.40dB
25-05-17 07:16:18.961 : ---7--> airport_111_10.jpg | 28.72dB
25-05-17 07:16:19.144 : ---8--> airport_111_11.jpg | 29.68dB
25-05-17 07:16:19.324 : ---9--> baseball_diamond_111_00.jpg | 29.61dB
25-05-17 07:16:19.503 : --10--> baseball_diamond_111_01.jpg | 31.49dB
25-05-17 07:16:19.689 : --11--> baseball_diamond_111_10.jpg | 29.50dB
25-05-17 07:16:19.869 : --12--> baseball_diamond_111_11.jpg | 32.64dB
25-05-17 07:16:20.049 : --13--> basketball_court_111_00.jpg | 27.21dB
25-05-17 07:16:20.225 : --14--> basketball_court_111_01.jpg | 26.87dB
25-05-17 07:16:20.406 : --15--> basketball_court_111_10.jpg | 30.28dB
25-05-17 07:16:20.587 : --16--> basketball_court_111_11.jpg | 28.44dB
25-05-17 07:16:20.767 : --17--> beach_111_00.jpg | 25.50dB
25-05-17 07:16:20.942 : --18--> beach_111_01.jpg | 28.61dB
25-05-17 07:16:21.126 : --19--> beach_111_10.jpg | 26.64dB
25-05-17 07:16:21.309 : --20--> beach_111_11.jpg | 31.73dB
25-05-17 07:16:21.489 : --21--> bridge_111_00.jpg | 38.27dB
25-05-17 07:16:21.671 : --22--> bridge_111_01.jpg | 31.05dB
25-05-17 07:16:21.847 : --23--> bridge_111_10.jpg | 29.87dB
25-05-17 07:16:22.027 : --24--> bridge_111_11.jpg | 33.56dB
25-05-17 07:16:22.202 : --25--> chaparral_111_00.jpg | 27.18dB
25-05-17 07:16:22.384 : --26--> chaparral_111_01.jpg | 27.56dB
25-05-17 07:16:22.561 : --27--> chaparral_111_10.jpg | 28.04dB
25-05-17 07:16:22.744 : --28--> chaparral_111_11.jpg | 25.05dB
25-05-17 07:16:22.926 : --29--> church_111_00.jpg | 28.34dB
25-05-17 07:16:23.107 : --30--> church_111_01.jpg | 27.12dB
25-05-17 07:16:23.290 : --31--> church_111_10.jpg | 31.47dB
25-05-17 07:16:23.466 : --32--> church_111_11.jpg | 26.91dB
25-05-17 07:16:23.645 : --33--> circular_farmland_111_00.jpg | 29.45dB
25-05-17 07:16:23.825 : --34--> circular_farmland_111_01.jpg | 30.73dB
25-05-17 07:16:23.999 : --35--> circular_farmland_111_10.jpg | 31.04dB
25-05-17 07:16:24.180 : --36--> circular_farmland_111_11.jpg | 31.38dB
25-05-17 07:16:24.365 : --37--> cloud_111_00.jpg | 37.78dB
25-05-17 07:16:24.544 : --38--> cloud_111_01.jpg | 33.65dB
25-05-17 07:16:24.725 : --39--> cloud_111_10.jpg | 33.26dB
25-05-17 07:16:24.905 : --40--> cloud_111_11.jpg | 33.57dB
25-05-17 07:16:25.084 : --41--> commercial_area_111_00.jpg | 30.32dB
25-05-17 07:16:25.264 : --42--> commercial_area_111_01.jpg | 28.76dB
25-05-17 07:16:25.443 : --43--> commercial_area_111_10.jpg | 29.77dB
25-05-17 07:16:25.626 : --44--> commercial_area_111_11.jpg | 29.53dB
25-05-17 07:16:25.805 : --45--> dense_residential_111_00.jpg | 26.58dB
25-05-17 07:16:25.992 : --46--> dense_residential_111_01.jpg | 25.65dB
25-05-17 07:16:26.168 : --47--> dense_residential_111_10.jpg | 26.09dB
25-05-17 07:16:26.346 : --48--> dense_residential_111_11.jpg | 25.92dB
25-05-17 07:16:26.526 : --49--> desert_111_00.jpg | 34.37dB
25-05-17 07:16:26.705 : --50--> desert_111_01.jpg | 33.90dB
25-05-17 07:16:26.886 : --51--> desert_111_10.jpg | 34.44dB
25-05-17 07:16:27.064 : --52--> desert_111_11.jpg | 34.42dB
25-05-17 07:16:27.246 : --53--> forest_111_00.jpg | 30.30dB
25-05-17 07:16:27.426 : --54--> forest_111_01.jpg | 29.31dB
25-05-17 07:16:27.610 : --55--> forest_111_10.jpg | 28.65dB
25-05-17 07:16:27.791 : --56--> forest_111_11.jpg | 29.91dB
25-05-17 07:16:27.966 : --57--> freeway_111_00.jpg | 31.20dB
25-05-17 07:16:28.145 : --58--> freeway_111_01.jpg | 32.06dB
25-05-17 07:16:28.325 : --59--> freeway_111_10.jpg | 32.04dB
25-05-17 07:16:28.505 : --60--> freeway_111_11.jpg | 32.13dB
25-05-17 07:16:28.688 : --61--> golf_course_111_00.jpg | 29.74dB
25-05-17 07:16:28.865 : --62--> golf_course_111_01.jpg | 28.70dB
25-05-17 07:16:29.045 : --63--> golf_course_111_10.jpg | 30.50dB
25-05-17 07:16:29.225 : --64--> golf_course_111_11.jpg | 30.87dB
25-05-17 07:16:29.407 : --65--> ground_track_field_111_00.jpg | 29.89dB
25-05-17 07:16:29.590 : --66--> ground_track_field_111_01.jpg | 25.82dB
25-05-17 07:16:29.776 : --67--> ground_track_field_111_10.jpg | 27.44dB
25-05-17 07:16:29.957 : --68--> ground_track_field_111_11.jpg | 26.53dB
25-05-17 07:16:30.138 : --69--> harbor_111_00.jpg | 30.76dB
25-05-17 07:16:30.314 : --70--> harbor_111_01.jpg | 28.07dB
25-05-17 07:16:30.490 : --71--> harbor_111_10.jpg | 27.40dB
25-05-17 07:16:30.673 : --72--> harbor_111_11.jpg | 29.27dB
25-05-17 07:16:30.851 : --73--> industrial_area_111_00.jpg | 28.63dB
25-05-17 07:16:31.030 : --74--> industrial_area_111_01.jpg | 28.30dB
25-05-17 07:16:31.209 : --75--> industrial_area_111_10.jpg | 28.63dB
25-05-17 07:16:31.389 : --76--> industrial_area_111_11.jpg | 27.85dB
25-05-17 07:16:31.564 : --77--> intersection_111_00.jpg | 27.33dB
25-05-17 07:16:31.749 : --78--> intersection_111_01.jpg | 27.38dB
25-05-17 07:16:31.925 : --79--> intersection_111_10.jpg | 26.95dB
25-05-17 07:16:32.106 : --80--> intersection_111_11.jpg | 26.71dB
25-05-17 07:16:32.284 : --81--> island_111_00.jpg | 28.17dB
25-05-17 07:16:32.472 : --82--> island_111_01.jpg | 30.71dB
25-05-17 07:16:32.655 : --83--> island_111_10.jpg | 29.16dB
25-05-17 07:16:32.835 : --84--> island_111_11.jpg | 28.74dB
25-05-17 07:16:33.014 : --85--> lake_111_00.jpg | 30.01dB
25-05-17 07:16:33.201 : --86--> lake_111_01.jpg | 29.81dB
25-05-17 07:16:33.376 : --87--> lake_111_10.jpg | 28.73dB
25-05-17 07:16:33.555 : --88--> lake_111_11.jpg | 28.34dB
25-05-17 07:16:33.734 : --89--> meadow_111_00.jpg | 27.26dB
25-05-17 07:16:33.914 : --90--> meadow_111_01.jpg | 27.24dB
25-05-17 07:16:34.094 : --91--> meadow_111_10.jpg | 27.45dB
25-05-17 07:16:34.274 : --92--> meadow_111_11.jpg | 27.55dB
25-05-17 07:16:34.453 : --93--> medium_residential_111_00.jpg | 25.11dB
25-05-17 07:16:34.631 : --94--> medium_residential_111_01.jpg | 24.54dB
25-05-17 07:16:34.810 : --95--> medium_residential_111_10.jpg | 24.92dB
25-05-17 07:16:34.991 : --96--> medium_residential_111_11.jpg | 25.48dB
25-05-17 07:16:35.176 : --97--> mobile_home_park_111_00.jpg | 27.29dB
25-05-17 07:16:35.361 : --98--> mobile_home_park_111_01.jpg | 27.85dB
25-05-17 07:16:35.539 : --99--> mobile_home_park_111_10.jpg | 28.32dB
25-05-17 07:16:35.712 : -100--> mobile_home_park_111_11.jpg | 28.13dB
25-05-17 07:16:35.890 : -101--> mountain_111_00.jpg | 25.49dB
25-05-17 07:16:36.076 : -102--> mountain_111_01.jpg | 26.42dB
25-05-17 07:16:36.254 : -103--> mountain_111_10.jpg | 26.04dB
25-05-17 07:16:36.435 : -104--> mountain_111_11.jpg | 26.50dB
25-05-17 07:16:36.614 : -105--> overpass_111_00.jpg | 27.00dB
25-05-17 07:16:36.792 : -106--> overpass_111_01.jpg | 26.72dB
25-05-17 07:16:36.970 : -107--> overpass_111_10.jpg | 27.64dB
25-05-17 07:16:37.149 : -108--> overpass_111_11.jpg | 28.13dB
25-05-17 07:16:37.326 : -109--> palace_111_00.jpg | 26.47dB
25-05-17 07:16:37.507 : -110--> palace_111_01.jpg | 26.28dB
25-05-17 07:16:37.688 : -111--> palace_111_10.jpg | 27.83dB
25-05-17 07:16:37.865 : -112--> palace_111_11.jpg | 25.86dB
25-05-17 07:16:38.048 : -113--> parking_lot_111_00.jpg | 25.43dB
25-05-17 07:16:38.228 : -114--> parking_lot_111_01.jpg | 25.67dB
25-05-17 07:16:38.415 : -115--> parking_lot_111_10.jpg | 27.72dB
25-05-17 07:16:38.591 : -116--> parking_lot_111_11.jpg | 26.50dB
25-05-17 07:16:38.774 : -117--> railway_111_00.jpg | 27.09dB
25-05-17 07:16:38.949 : -118--> railway_111_01.jpg | 26.59dB
25-05-17 07:16:39.132 : -119--> railway_111_10.jpg | 29.80dB
25-05-17 07:16:39.308 : -120--> railway_111_11.jpg | 25.56dB
25-05-17 07:16:39.485 : -121--> railway_station_111_00.jpg | 27.65dB
25-05-17 07:16:39.668 : -122--> railway_station_111_01.jpg | 28.60dB
25-05-17 07:16:39.851 : -123--> railway_station_111_10.jpg | 27.93dB
25-05-17 07:16:40.031 : -124--> railway_station_111_11.jpg | 28.61dB
25-05-17 07:16:40.212 : -125--> rectangular_farmland_111_00.jpg | 30.31dB
25-05-17 07:16:40.393 : -126--> rectangular_farmland_111_01.jpg | 28.56dB
25-05-17 07:16:40.576 : -127--> rectangular_farmland_111_10.jpg | 30.59dB
25-05-17 07:16:40.759 : -128--> rectangular_farmland_111_11.jpg | 31.00dB
25-05-17 07:16:40.936 : -129--> river_111_00.jpg | 26.87dB
25-05-17 07:16:41.113 : -130--> river_111_01.jpg | 26.89dB
25-05-17 07:16:41.288 : -131--> river_111_10.jpg | 26.00dB
25-05-17 07:16:41.466 : -132--> river_111_11.jpg | 28.09dB
25-05-17 07:16:41.649 : -133--> roundabout_111_00.jpg | 27.20dB
25-05-17 07:16:41.834 : -134--> roundabout_111_01.jpg | 29.06dB
25-05-17 07:16:42.013 : -135--> roundabout_111_10.jpg | 27.21dB
25-05-17 07:16:42.193 : -136--> roundabout_111_11.jpg | 27.50dB
25-05-17 07:16:42.368 : -137--> runway_111_00.jpg | 33.33dB
25-05-17 07:16:42.549 : -138--> runway_111_01.jpg | 32.72dB
25-05-17 07:16:42.725 : -139--> runway_111_10.jpg | 34.08dB
25-05-17 07:16:42.907 : -140--> runway_111_11.jpg | 34.06dB
25-05-17 07:16:43.091 : -141--> sea_ice_111_00.jpg | 30.26dB
25-05-17 07:16:43.273 : -142--> sea_ice_111_01.jpg | 31.12dB
25-05-17 07:16:43.454 : -143--> sea_ice_111_10.jpg | 30.28dB
25-05-17 07:16:43.632 : -144--> sea_ice_111_11.jpg | 31.37dB
25-05-17 07:16:43.805 : -145--> ship_111_00.jpg | 35.58dB
25-05-17 07:16:43.987 : -146--> ship_111_01.jpg | 31.07dB
25-05-17 07:16:44.168 : -147--> ship_111_10.jpg | 40.49dB
25-05-17 07:16:44.351 : -148--> ship_111_11.jpg | 36.47dB
25-05-17 07:16:44.532 : -149--> snowberg_111_00.jpg | 30.53dB
25-05-17 07:16:44.714 : -150--> snowberg_111_01.jpg | 29.27dB
25-05-17 07:16:44.888 : -151--> snowberg_111_10.jpg | 28.41dB
25-05-17 07:16:45.066 : -152--> snowberg_111_11.jpg | 28.43dB
25-05-17 07:16:45.247 : -153--> sparse_residential_111_00.jpg | 27.23dB
25-05-17 07:16:45.434 : -154--> sparse_residential_111_01.jpg | 27.86dB
25-05-17 07:16:45.608 : -155--> sparse_residential_111_10.jpg | 26.26dB
25-05-17 07:16:45.793 : -156--> sparse_residential_111_11.jpg | 26.87dB
25-05-17 07:16:45.982 : -157--> stadium_111_00.jpg | 26.52dB
25-05-17 07:16:46.165 : -158--> stadium_111_01.jpg | 26.43dB
25-05-17 07:16:46.343 : -159--> stadium_111_10.jpg | 27.90dB
25-05-17 07:16:46.523 : -160--> stadium_111_11.jpg | 26.49dB
25-05-17 07:16:46.698 : -161--> storage_tank_111_00.jpg | 28.63dB
25-05-17 07:16:46.877 : -162--> storage_tank_111_01.jpg | 28.78dB
25-05-17 07:16:47.058 : -163--> storage_tank_111_10.jpg | 27.52dB
25-05-17 07:16:47.238 : -164--> storage_tank_111_11.jpg | 28.02dB
25-05-17 07:16:47.418 : -165--> tennis_court_111_00.jpg | 28.94dB
25-05-17 07:16:47.597 : -166--> tennis_court_111_01.jpg | 28.61dB
25-05-17 07:16:47.773 : -167--> tennis_court_111_10.jpg | 28.56dB
25-05-17 07:16:47.959 : -168--> tennis_court_111_11.jpg | 26.62dB
25-05-17 07:16:48.134 : -169--> terrace_111_00.jpg | 29.17dB
25-05-17 07:16:48.309 : -170--> terrace_111_01.jpg | 30.12dB
25-05-17 07:16:48.490 : -171--> terrace_111_10.jpg | 28.94dB
25-05-17 07:16:48.674 : -172--> terrace_111_11.jpg | 29.14dB
25-05-17 07:16:48.855 : -173--> thermal_power_station_111_00.jpg | 26.76dB
25-05-17 07:16:49.034 : -174--> thermal_power_station_111_01.jpg | 28.09dB
25-05-17 07:16:49.215 : -175--> thermal_power_station_111_10.jpg | 26.23dB
25-05-17 07:16:49.393 : -176--> thermal_power_station_111_11.jpg | 26.77dB
25-05-17 07:16:49.574 : -177--> wetland_111_00.jpg | 28.52dB
25-05-17 07:16:49.754 : -178--> wetland_111_01.jpg | 28.63dB
25-05-17 07:16:49.937 : -179--> wetland_111_10.jpg | 28.86dB
25-05-17 07:16:50.116 : -180--> wetland_111_11.jpg | 28.02dB
25-05-17 07:16:50.126 : <epoch:  0, iter:  45,000, Average PSNR : 28.97dB

25-05-17 08:36:47.800 : <epoch:  0, iter:  50,000, lr:1.000e-04> G_loss: 1.300e-04 
25-05-17 08:36:47.802 : Saving the model.
25-05-17 08:36:48.402 : ---1--> airplane_111_00.jpg | 26.95dB
25-05-17 08:36:48.582 : ---2--> airplane_111_01.jpg | 32.23dB
25-05-17 08:36:48.762 : ---3--> airplane_111_10.jpg | 29.79dB
25-05-17 08:36:48.934 : ---4--> airplane_111_11.jpg | 29.91dB
25-05-17 08:36:49.114 : ---5--> airport_111_00.jpg | 31.71dB
25-05-17 08:36:49.292 : ---6--> airport_111_01.jpg | 29.43dB
25-05-17 08:36:49.473 : ---7--> airport_111_10.jpg | 28.69dB
25-05-17 08:36:49.654 : ---8--> airport_111_11.jpg | 29.73dB
25-05-17 08:36:49.836 : ---9--> baseball_diamond_111_00.jpg | 29.62dB
25-05-17 08:36:50.009 : --10--> baseball_diamond_111_01.jpg | 31.52dB
25-05-17 08:36:50.184 : --11--> baseball_diamond_111_10.jpg | 29.48dB
25-05-17 08:36:50.364 : --12--> baseball_diamond_111_11.jpg | 32.68dB
25-05-17 08:36:50.553 : --13--> basketball_court_111_00.jpg | 27.24dB
25-05-17 08:36:50.729 : --14--> basketball_court_111_01.jpg | 26.90dB
25-05-17 08:36:50.911 : --15--> basketball_court_111_10.jpg | 30.26dB
25-05-17 08:36:51.090 : --16--> basketball_court_111_11.jpg | 28.43dB
25-05-17 08:36:51.273 : --17--> beach_111_00.jpg | 25.47dB
25-05-17 08:36:51.448 : --18--> beach_111_01.jpg | 28.62dB
25-05-17 08:36:51.630 : --19--> beach_111_10.jpg | 26.60dB
25-05-17 08:36:51.808 : --20--> beach_111_11.jpg | 31.78dB
25-05-17 08:36:51.987 : --21--> bridge_111_00.jpg | 38.33dB
25-05-17 08:36:52.166 : --22--> bridge_111_01.jpg | 31.10dB
25-05-17 08:36:52.349 : --23--> bridge_111_10.jpg | 29.90dB
25-05-17 08:36:52.534 : --24--> bridge_111_11.jpg | 33.54dB
25-05-17 08:36:52.715 : --25--> chaparral_111_00.jpg | 27.19dB
25-05-17 08:36:52.895 : --26--> chaparral_111_01.jpg | 27.55dB
25-05-17 08:36:53.072 : --27--> chaparral_111_10.jpg | 28.06dB
25-05-17 08:36:53.254 : --28--> chaparral_111_11.jpg | 25.05dB
25-05-17 08:36:53.428 : --29--> church_111_00.jpg | 28.34dB
25-05-17 08:36:53.608 : --30--> church_111_01.jpg | 27.15dB
25-05-17 08:36:53.786 : --31--> church_111_10.jpg | 31.46dB
25-05-17 08:36:53.970 : --32--> church_111_11.jpg | 26.90dB
25-05-17 08:36:54.149 : --33--> circular_farmland_111_00.jpg | 29.42dB
25-05-17 08:36:54.331 : --34--> circular_farmland_111_01.jpg | 30.75dB
25-05-17 08:36:54.507 : --35--> circular_farmland_111_10.jpg | 31.10dB
25-05-17 08:36:54.690 : --36--> circular_farmland_111_11.jpg | 31.35dB
25-05-17 08:36:54.867 : --37--> cloud_111_00.jpg | 37.70dB
25-05-17 08:36:55.042 : --38--> cloud_111_01.jpg | 33.71dB
25-05-17 08:36:55.224 : --39--> cloud_111_10.jpg | 33.27dB
25-05-17 08:36:55.401 : --40--> cloud_111_11.jpg | 33.56dB
25-05-17 08:36:55.575 : --41--> commercial_area_111_00.jpg | 30.27dB
25-05-17 08:36:55.764 : --42--> commercial_area_111_01.jpg | 28.78dB
25-05-17 08:36:55.940 : --43--> commercial_area_111_10.jpg | 29.74dB
25-05-17 08:36:56.115 : --44--> commercial_area_111_11.jpg | 29.50dB
25-05-17 08:36:56.295 : --45--> dense_residential_111_00.jpg | 26.58dB
25-05-17 08:36:56.474 : --46--> dense_residential_111_01.jpg | 25.69dB
25-05-17 08:36:56.655 : --47--> dense_residential_111_10.jpg | 26.10dB
25-05-17 08:36:56.830 : --48--> dense_residential_111_11.jpg | 25.92dB
25-05-17 08:36:57.015 : --49--> desert_111_00.jpg | 34.25dB
25-05-17 08:36:57.194 : --50--> desert_111_01.jpg | 33.84dB
25-05-17 08:36:57.377 : --51--> desert_111_10.jpg | 34.49dB
25-05-17 08:36:57.564 : --52--> desert_111_11.jpg | 34.35dB
25-05-17 08:36:57.746 : --53--> forest_111_00.jpg | 30.30dB
25-05-17 08:36:57.924 : --54--> forest_111_01.jpg | 29.32dB
25-05-17 08:36:58.107 : --55--> forest_111_10.jpg | 28.64dB
25-05-17 08:36:58.289 : --56--> forest_111_11.jpg | 29.92dB
25-05-17 08:36:58.467 : --57--> freeway_111_00.jpg | 31.20dB
25-05-17 08:36:58.646 : --58--> freeway_111_01.jpg | 32.05dB
25-05-17 08:36:58.825 : --59--> freeway_111_10.jpg | 32.00dB
25-05-17 08:36:59.003 : --60--> freeway_111_11.jpg | 32.17dB
25-05-17 08:36:59.184 : --61--> golf_course_111_00.jpg | 29.69dB
25-05-17 08:36:59.363 : --62--> golf_course_111_01.jpg | 28.67dB
25-05-17 08:36:59.541 : --63--> golf_course_111_10.jpg | 30.51dB
25-05-17 08:36:59.716 : --64--> golf_course_111_11.jpg | 30.89dB
25-05-17 08:36:59.894 : --65--> ground_track_field_111_00.jpg | 29.95dB
25-05-17 08:37:00.069 : --66--> ground_track_field_111_01.jpg | 25.85dB
25-05-17 08:37:00.250 : --67--> ground_track_field_111_10.jpg | 27.48dB
25-05-17 08:37:00.429 : --68--> ground_track_field_111_11.jpg | 26.56dB
25-05-17 08:37:00.610 : --69--> harbor_111_00.jpg | 30.82dB
25-05-17 08:37:00.792 : --70--> harbor_111_01.jpg | 28.08dB
25-05-17 08:37:00.971 : --71--> harbor_111_10.jpg | 27.45dB
25-05-17 08:37:01.150 : --72--> harbor_111_11.jpg | 29.34dB
25-05-17 08:37:01.332 : --73--> industrial_area_111_00.jpg | 28.66dB
25-05-17 08:37:01.513 : --74--> industrial_area_111_01.jpg | 28.28dB
25-05-17 08:37:01.693 : --75--> industrial_area_111_10.jpg | 28.65dB
25-05-17 08:37:01.876 : --76--> industrial_area_111_11.jpg | 27.86dB
25-05-17 08:37:02.051 : --77--> intersection_111_00.jpg | 27.35dB
25-05-17 08:37:02.230 : --78--> intersection_111_01.jpg | 27.41dB
25-05-17 08:37:02.410 : --79--> intersection_111_10.jpg | 26.96dB
25-05-17 08:37:02.595 : --80--> intersection_111_11.jpg | 26.79dB
25-05-17 08:37:02.778 : --81--> island_111_00.jpg | 28.15dB
25-05-17 08:37:02.956 : --82--> island_111_01.jpg | 30.70dB
25-05-17 08:37:03.140 : --83--> island_111_10.jpg | 29.12dB
25-05-17 08:37:03.322 : --84--> island_111_11.jpg | 28.74dB
25-05-17 08:37:03.497 : --85--> lake_111_00.jpg | 29.99dB
25-05-17 08:37:03.675 : --86--> lake_111_01.jpg | 29.82dB
25-05-17 08:37:03.857 : --87--> lake_111_10.jpg | 28.72dB
25-05-17 08:37:04.035 : --88--> lake_111_11.jpg | 28.35dB
25-05-17 08:37:04.210 : --89--> meadow_111_00.jpg | 27.26dB
25-05-17 08:37:04.390 : --90--> meadow_111_01.jpg | 27.26dB
25-05-17 08:37:04.566 : --91--> meadow_111_10.jpg | 27.46dB
25-05-17 08:37:04.755 : --92--> meadow_111_11.jpg | 27.56dB
25-05-17 08:37:04.935 : --93--> medium_residential_111_00.jpg | 25.10dB
25-05-17 08:37:05.111 : --94--> medium_residential_111_01.jpg | 24.54dB
25-05-17 08:37:05.293 : --95--> medium_residential_111_10.jpg | 24.92dB
25-05-17 08:37:05.471 : --96--> medium_residential_111_11.jpg | 25.49dB
25-05-17 08:37:05.649 : --97--> mobile_home_park_111_00.jpg | 27.33dB
25-05-17 08:37:05.834 : --98--> mobile_home_park_111_01.jpg | 27.88dB
25-05-17 08:37:06.017 : --99--> mobile_home_park_111_10.jpg | 28.34dB
25-05-17 08:37:06.194 : -100--> mobile_home_park_111_11.jpg | 28.16dB
25-05-17 08:37:06.392 : -101--> mountain_111_00.jpg | 25.48dB
25-05-17 08:37:06.573 : -102--> mountain_111_01.jpg | 26.40dB
25-05-17 08:37:06.753 : -103--> mountain_111_10.jpg | 26.02dB
25-05-17 08:37:06.934 : -104--> mountain_111_11.jpg | 26.51dB
25-05-17 08:37:07.117 : -105--> overpass_111_00.jpg | 27.00dB
25-05-17 08:37:07.292 : -106--> overpass_111_01.jpg | 26.75dB
25-05-17 08:37:07.469 : -107--> overpass_111_10.jpg | 27.66dB
25-05-17 08:37:07.653 : -108--> overpass_111_11.jpg | 28.16dB
25-05-17 08:37:07.829 : -109--> palace_111_00.jpg | 26.50dB
25-05-17 08:37:08.010 : -110--> palace_111_01.jpg | 26.30dB
25-05-17 08:37:08.187 : -111--> palace_111_10.jpg | 27.83dB
25-05-17 08:37:08.365 : -112--> palace_111_11.jpg | 25.91dB
25-05-17 08:37:08.548 : -113--> parking_lot_111_00.jpg | 25.45dB
25-05-17 08:37:08.729 : -114--> parking_lot_111_01.jpg | 25.68dB
25-05-17 08:37:08.909 : -115--> parking_lot_111_10.jpg | 27.74dB
25-05-17 08:37:09.087 : -116--> parking_lot_111_11.jpg | 26.50dB
25-05-17 08:37:09.268 : -117--> railway_111_00.jpg | 27.12dB
25-05-17 08:37:09.450 : -118--> railway_111_01.jpg | 26.59dB
25-05-17 08:37:09.637 : -119--> railway_111_10.jpg | 29.79dB
25-05-17 08:37:09.817 : -120--> railway_111_11.jpg | 25.56dB
25-05-17 08:37:09.994 : -121--> railway_station_111_00.jpg | 27.66dB
25-05-17 08:37:10.176 : -122--> railway_station_111_01.jpg | 28.58dB
25-05-17 08:37:10.361 : -123--> railway_station_111_10.jpg | 27.96dB
25-05-17 08:37:10.536 : -124--> railway_station_111_11.jpg | 28.65dB
25-05-17 08:37:10.719 : -125--> rectangular_farmland_111_00.jpg | 30.35dB
25-05-17 08:37:10.906 : -126--> rectangular_farmland_111_01.jpg | 28.54dB
25-05-17 08:37:11.081 : -127--> rectangular_farmland_111_10.jpg | 30.63dB
25-05-17 08:37:11.261 : -128--> rectangular_farmland_111_11.jpg | 30.95dB
25-05-17 08:37:11.442 : -129--> river_111_00.jpg | 26.88dB
25-05-17 08:37:11.615 : -130--> river_111_01.jpg | 26.90dB
25-05-17 08:37:11.790 : -131--> river_111_10.jpg | 26.01dB
25-05-17 08:37:11.970 : -132--> river_111_11.jpg | 28.09dB
25-05-17 08:37:12.147 : -133--> roundabout_111_00.jpg | 27.23dB
25-05-17 08:37:12.326 : -134--> roundabout_111_01.jpg | 29.09dB
25-05-17 08:37:12.504 : -135--> roundabout_111_10.jpg | 27.22dB
25-05-17 08:37:12.687 : -136--> roundabout_111_11.jpg | 27.52dB
25-05-17 08:37:12.866 : -137--> runway_111_00.jpg | 33.60dB
25-05-17 08:37:13.049 : -138--> runway_111_01.jpg | 32.93dB
25-05-17 08:37:13.226 : -139--> runway_111_10.jpg | 34.04dB
25-05-17 08:37:13.403 : -140--> runway_111_11.jpg | 34.19dB
25-05-17 08:37:13.588 : -141--> sea_ice_111_00.jpg | 30.24dB
25-05-17 08:37:13.767 : -142--> sea_ice_111_01.jpg | 31.14dB
25-05-17 08:37:13.945 : -143--> sea_ice_111_10.jpg | 30.27dB
25-05-17 08:37:14.125 : -144--> sea_ice_111_11.jpg | 31.49dB
25-05-17 08:37:14.300 : -145--> ship_111_00.jpg | 35.58dB
25-05-17 08:37:14.485 : -146--> ship_111_01.jpg | 31.09dB
25-05-17 08:37:14.674 : -147--> ship_111_10.jpg | 40.39dB
25-05-17 08:37:14.859 : -148--> ship_111_11.jpg | 36.53dB
25-05-17 08:37:15.036 : -149--> snowberg_111_00.jpg | 30.58dB
25-05-17 08:37:15.217 : -150--> snowberg_111_01.jpg | 29.26dB
25-05-17 08:37:15.395 : -151--> snowberg_111_10.jpg | 28.38dB
25-05-17 08:37:15.576 : -152--> snowberg_111_11.jpg | 28.46dB
25-05-17 08:37:15.758 : -153--> sparse_residential_111_00.jpg | 27.25dB
25-05-17 08:37:15.939 : -154--> sparse_residential_111_01.jpg | 27.88dB
25-05-17 08:37:16.120 : -155--> sparse_residential_111_10.jpg | 26.25dB
25-05-17 08:37:16.306 : -156--> sparse_residential_111_11.jpg | 26.89dB
25-05-17 08:37:16.495 : -157--> stadium_111_00.jpg | 26.54dB
25-05-17 08:37:16.676 : -158--> stadium_111_01.jpg | 26.43dB
25-05-17 08:37:16.860 : -159--> stadium_111_10.jpg | 27.89dB
25-05-17 08:37:17.038 : -160--> stadium_111_11.jpg | 26.50dB
25-05-17 08:37:17.223 : -161--> storage_tank_111_00.jpg | 28.66dB
25-05-17 08:37:17.403 : -162--> storage_tank_111_01.jpg | 28.72dB
25-05-17 08:37:17.579 : -163--> storage_tank_111_10.jpg | 27.49dB
25-05-17 08:37:17.761 : -164--> storage_tank_111_11.jpg | 28.04dB
25-05-17 08:37:17.937 : -165--> tennis_court_111_00.jpg | 28.92dB
25-05-17 08:37:18.118 : -166--> tennis_court_111_01.jpg | 28.59dB
25-05-17 08:37:18.300 : -167--> tennis_court_111_10.jpg | 28.53dB
25-05-17 08:37:18.484 : -168--> tennis_court_111_11.jpg | 26.62dB
25-05-17 08:37:18.668 : -169--> terrace_111_00.jpg | 29.11dB
25-05-17 08:37:18.849 : -170--> terrace_111_01.jpg | 30.20dB
25-05-17 08:37:19.031 : -171--> terrace_111_10.jpg | 28.91dB
25-05-17 08:37:19.214 : -172--> terrace_111_11.jpg | 29.12dB
25-05-17 08:37:19.392 : -173--> thermal_power_station_111_00.jpg | 26.72dB
25-05-17 08:37:19.573 : -174--> thermal_power_station_111_01.jpg | 28.10dB
25-05-17 08:37:19.759 : -175--> thermal_power_station_111_10.jpg | 26.23dB
25-05-17 08:37:19.934 : -176--> thermal_power_station_111_11.jpg | 26.78dB
25-05-17 08:37:20.115 : -177--> wetland_111_00.jpg | 28.48dB
25-05-17 08:37:20.298 : -178--> wetland_111_01.jpg | 28.63dB
25-05-17 08:37:20.479 : -179--> wetland_111_10.jpg | 28.85dB
25-05-17 08:37:20.660 : -180--> wetland_111_11.jpg | 28.00dB
25-05-17 08:37:20.668 : <epoch:  0, iter:  50,000, Average PSNR : 28.97dB

25-05-17 09:06:12.464 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/50000_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 50
      sigma_test: 50
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test_4fen
      dataroot_L: None
      sigma: 50
      sigma_test: 50
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [30000, 50000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-17 09:06:12.464 : Random seed: 958
25-05-17 09:06:12.636 : Number of train images: 31,005, iters: 31,005
25-05-17 09:06:14.072 : 
Networks name: DRNet
Params number: 17746115
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-17 09:06:14.452 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.002 | -0.401 |  0.467 |  0.168 | torch.Size([64, 3, 3, 3]) || head1.weight
 | -0.000 | -0.349 |  0.303 |  0.200 | torch.Size([64]) || head1.bias
 |  0.000 | -0.482 |  0.434 |  0.092 | torch.Size([64, 64, 3, 3]) || head1_1.body.0.weight
 |  0.086 | -0.086 |  0.221 |  0.072 | torch.Size([64]) || head1_1.body.0.bias
 | -0.000 | -0.525 |  0.573 |  0.082 | torch.Size([64, 64, 3, 3]) || head1_1.body.2.weight
 |  0.010 | -0.106 |  0.128 |  0.056 | torch.Size([64]) || head1_1.body.2.bias
 |  0.000 | -0.311 |  0.321 |  0.059 | torch.Size([768, 256]) || head1_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.001 | -0.349 |  0.310 |  0.067 | torch.Size([256, 256]) || head1_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.304 |  0.288 |  0.057 | torch.Size([1024, 256]) || head1_3.encoder.layers.0.linear1.weight
 | -0.021 | -0.164 |  0.097 |  0.042 | torch.Size([1024]) || head1_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.431 |  0.379 |  0.048 | torch.Size([256, 1024]) || head1_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.077 |  0.081 |  0.030 | torch.Size([256]) || head1_3.encoder.layers.0.linear2.bias
 |  1.016 |  0.750 |  1.207 |  0.067 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.weight
 |  0.005 | -0.189 |  0.312 |  0.059 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.bias
 |  1.106 |  0.978 |  1.283 |  0.059 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.weight
 |  0.002 | -0.079 |  0.094 |  0.032 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || head1_3.position_encoding.position_ids
 |  0.000 | -5.337 |  4.745 |  0.991 | torch.Size([4096, 256]) || head1_3.position_encoding.pe.weight
 |  0.000 | -0.955 |  1.003 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.0.weight
 |  0.027 | -0.103 |  0.113 |  0.044 | torch.Size([64]) || body1_1.0.body.0.bias
 | -0.001 | -0.351 |  0.376 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.2.weight
 | -0.015 | -0.139 |  0.114 |  0.063 | torch.Size([64]) || body1_1.0.body.2.bias
 | -0.001 | -0.490 |  0.463 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.1.weight
 |  0.048 | -0.053 |  0.155 |  0.047 | torch.Size([64]) || body1_1.1.bias
 |  0.000 | -0.175 |  0.185 |  0.041 | torch.Size([768, 256]) || body1_2.0.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.154 |  0.145 |  0.037 | torch.Size([256, 256]) || body1_2.0.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.293 |  0.245 |  0.043 | torch.Size([1024, 256]) || body1_2.0.encoder.layers.0.linear1.weight
 |  0.003 | -0.073 |  0.100 |  0.038 | torch.Size([1024]) || body1_2.0.encoder.layers.0.linear1.bias
 | -0.003 | -0.256 |  0.207 |  0.028 | torch.Size([256, 1024]) || body1_2.0.encoder.layers.0.linear2.weight
 | -0.007 | -0.059 |  0.044 |  0.021 | torch.Size([256]) || body1_2.0.encoder.layers.0.linear2.bias
 |  0.994 |  0.812 |  1.133 |  0.065 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.weight
 |  0.008 | -0.135 |  0.147 |  0.065 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.bias
 |  0.998 |  0.796 |  1.189 |  0.059 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.weight
 |  0.011 | -0.236 |  0.253 |  0.087 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body1_2.0.position_encoding.position_ids
 |  0.001 | -4.538 |  4.876 |  0.995 | torch.Size([4096, 256]) || body1_2.0.position_encoding.pe.weight
 | -0.001 | -0.290 |  0.224 |  0.037 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.0.weight
 |  0.003 | -0.101 |  0.084 |  0.033 | torch.Size([64]) || body1_2.1.body.0.bias
 | -0.005 | -0.262 |  0.283 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.2.weight
 | -0.016 | -0.103 |  0.047 |  0.033 | torch.Size([64]) || body1_2.1.body.2.bias
 |  0.000 | -0.277 |  0.259 |  0.050 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.0.weight
 |  0.013 | -0.113 |  0.115 |  0.046 | torch.Size([64]) || body2_1.0.body.0.bias
 |  0.000 | -0.282 |  0.421 |  0.048 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.2.weight
 | -0.005 | -0.138 |  0.157 |  0.075 | torch.Size([64]) || body2_1.0.body.2.bias
 |  0.000 | -0.330 |  0.369 |  0.060 | torch.Size([768, 256]) || body2_1.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.315 |  0.347 |  0.070 | torch.Size([256, 256]) || body2_1.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.293 |  0.304 |  0.060 | torch.Size([1024, 256]) || body2_1.1.encoder.layers.0.linear1.weight
 |  0.011 | -0.124 |  0.131 |  0.042 | torch.Size([1024]) || body2_1.1.encoder.layers.0.linear1.bias
 | -0.000 | -0.269 |  0.274 |  0.049 | torch.Size([256, 1024]) || body2_1.1.encoder.layers.0.linear2.weight
 | -0.001 | -0.069 |  0.074 |  0.031 | torch.Size([256]) || body2_1.1.encoder.layers.0.linear2.bias
 |  1.067 |  0.928 |  1.202 |  0.049 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.weight
 |  0.003 | -0.147 |  0.162 |  0.068 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.bias
 |  1.194 |  1.020 |  1.401 |  0.073 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.114 |  0.114 |  0.033 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_1.1.position_encoding.position_ids
 | -0.001 | -4.994 |  4.878 |  0.999 | torch.Size([4096, 256]) || body2_1.1.position_encoding.pe.weight
 | -0.003 | -0.326 |  0.330 |  0.110 | torch.Size([128, 1, 5, 5]) || fusion2_1.0.weight
 |  0.015 | -0.267 |  0.256 |  0.121 | torch.Size([128]) || fusion2_1.0.bias
 |  0.000 | -0.211 |  0.226 |  0.054 | torch.Size([64, 128, 1, 1]) || fusion2_1.1.weight
 | -0.005 | -0.176 |  0.159 |  0.088 | torch.Size([64]) || fusion2_1.1.bias
 |  0.002 | -0.195 |  0.230 |  0.044 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.0.weight
 |  0.001 | -0.143 |  0.222 |  0.083 | torch.Size([64]) || body2_2.0.body.0.bias
 |  0.000 | -0.212 |  0.237 |  0.043 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.2.weight
 | -0.004 | -0.228 |  0.209 |  0.104 | torch.Size([64]) || body2_2.0.body.2.bias
 | -0.000 | -0.417 |  0.343 |  0.065 | torch.Size([768, 256]) || body2_2.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.341 |  0.377 |  0.080 | torch.Size([256, 256]) || body2_2.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.248 |  0.264 |  0.060 | torch.Size([1024, 256]) || body2_2.1.encoder.layers.0.linear1.weight
 | -0.001 | -0.154 |  0.139 |  0.051 | torch.Size([1024]) || body2_2.1.encoder.layers.0.linear1.bias
 |  0.000 | -0.248 |  0.289 |  0.049 | torch.Size([256, 1024]) || body2_2.1.encoder.layers.0.linear2.weight
 |  0.002 | -0.052 |  0.056 |  0.024 | torch.Size([256]) || body2_2.1.encoder.layers.0.linear2.bias
 |  1.101 |  0.942 |  1.256 |  0.051 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.weight
 |  0.001 | -0.181 |  0.207 |  0.078 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.bias
 |  1.147 |  0.961 |  1.311 |  0.053 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.117 |  0.100 |  0.036 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_2.1.position_encoding.position_ids
 | -0.001 | -4.834 |  4.669 |  0.998 | torch.Size([4096, 256]) || body2_2.1.position_encoding.pe.weight
 | -0.000 | -0.307 |  0.375 |  0.104 | torch.Size([128, 1, 5, 5]) || fusion2_2.0.weight
 | -0.015 | -0.208 |  0.214 |  0.116 | torch.Size([128]) || fusion2_2.0.bias
 | -0.001 | -0.225 |  0.257 |  0.058 | torch.Size([64, 128, 1, 1]) || fusion2_2.1.weight
 | -0.019 | -0.149 |  0.151 |  0.065 | torch.Size([64]) || fusion2_2.1.bias
 | -0.000 | -0.245 |  0.239 |  0.053 | torch.Size([768, 256]) || body2_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.248 |  0.240 |  0.056 | torch.Size([256, 256]) || body2_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.222 |  0.233 |  0.051 | torch.Size([1024, 256]) || body2_3.encoder.layers.0.linear1.weight
 | -0.029 | -0.146 |  0.089 |  0.041 | torch.Size([1024]) || body2_3.encoder.layers.0.linear1.bias
 | -0.000 | -0.199 |  0.195 |  0.039 | torch.Size([256, 1024]) || body2_3.encoder.layers.0.linear2.weight
 |  0.002 | -0.049 |  0.074 |  0.022 | torch.Size([256]) || body2_3.encoder.layers.0.linear2.bias
 |  1.053 |  0.947 |  1.180 |  0.041 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.133 |  0.175 |  0.051 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.bias
 |  1.014 |  0.881 |  1.166 |  0.046 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.092 |  0.076 |  0.029 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_3.position_encoding.position_ids
 | -0.000 | -4.715 |  5.524 |  0.998 | torch.Size([4096, 256]) || body2_3.position_encoding.pe.weight
 |  0.000 | -0.248 |  0.224 |  0.039 | torch.Size([64, 64, 3, 3]) || body3_1.0.weight
 |  0.018 | -0.061 |  0.070 |  0.031 | torch.Size([64]) || body3_1.0.bias
 |  0.000 | -0.183 |  0.180 |  0.039 | torch.Size([768, 256]) || body3_1.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.163 |  0.171 |  0.040 | torch.Size([256, 256]) || body3_1.2.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.281 |  0.240 |  0.047 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.0.linear1.weight
 | -0.010 | -0.101 |  0.096 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.0.linear1.bias
 | -0.003 | -0.280 |  0.293 |  0.033 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.0.linear2.weight
 | -0.006 | -0.068 |  0.071 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.linear2.bias
 |  1.000 |  0.918 |  1.085 |  0.027 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.089 |  0.084 |  0.031 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.bias
 |  1.105 |  0.989 |  1.244 |  0.048 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.weight
 |  0.002 | -0.073 |  0.092 |  0.035 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.153 |  0.161 |  0.038 | torch.Size([768, 256]) || body3_1.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.135 |  0.128 |  0.038 | torch.Size([256, 256]) || body3_1.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.329 |  0.287 |  0.046 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.1.linear1.weight
 | -0.007 | -0.094 |  0.088 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.1.linear1.bias
 | -0.002 | -0.357 |  0.414 |  0.032 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.1.linear2.weight
 | -0.007 | -0.063 |  0.044 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.linear2.bias
 |  0.997 |  0.948 |  1.118 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.weight
 | -0.001 | -0.062 |  0.069 |  0.027 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.bias
 |  1.122 |  0.992 |  1.276 |  0.048 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.weight
 |  0.000 | -0.057 |  0.053 |  0.023 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_1.2.position_encoding.position_ids
 |  0.002 | -4.658 |  4.616 |  1.000 | torch.Size([4096, 256]) || body3_1.2.position_encoding.pe.weight
 |  0.001 | -0.198 |  0.198 |  0.068 | torch.Size([128, 1, 5, 5]) || fusion3_1.0.weight
 |  0.007 | -0.232 |  0.244 |  0.122 | torch.Size([128]) || fusion3_1.0.bias
 | -0.000 | -0.125 |  0.129 |  0.024 | torch.Size([64, 128, 1, 1]) || fusion3_1.1.weight
 | -0.008 | -0.187 |  0.158 |  0.087 | torch.Size([64]) || fusion3_1.1.bias
 | -0.000 | -0.116 |  0.116 |  0.024 | torch.Size([64, 64, 3, 3]) || body3_2.0.weight
 |  0.057 | -0.105 |  0.118 |  0.037 | torch.Size([64]) || body3_2.0.bias
 |  0.000 | -0.144 |  0.126 |  0.040 | torch.Size([768, 256]) || body3_2.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.110 |  0.110 |  0.037 | torch.Size([256, 256]) || body3_2.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.198 |  0.202 |  0.051 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.0.linear1.weight
 | -0.043 | -0.133 |  0.061 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.161 |  0.154 |  0.037 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.0.linear2.weight
 | -0.008 | -0.062 |  0.038 |  0.022 | torch.Size([256]) || body3_2.2.encoder.layers.0.linear2.bias
 |  0.997 |  0.835 |  1.076 |  0.031 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.120 |  0.178 |  0.044 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.bias
 |  1.049 |  0.924 |  1.200 |  0.046 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.weight
 | -0.001 | -0.150 |  0.103 |  0.042 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.109 |  0.115 |  0.038 | torch.Size([768, 256]) || body3_2.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.118 |  0.104 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.194 |  0.184 |  0.049 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.1.linear1.weight
 | -0.026 | -0.111 |  0.087 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.1.linear1.bias
 | -0.001 | -0.152 |  0.163 |  0.036 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.1.linear2.weight
 | -0.009 | -0.066 |  0.049 |  0.024 | torch.Size([256]) || body3_2.2.encoder.layers.1.linear2.bias
 |  0.987 |  0.918 |  1.035 |  0.020 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.weight
 | -0.000 | -0.105 |  0.115 |  0.045 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.bias
 |  1.058 |  0.955 |  1.147 |  0.036 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.weight
 | -0.000 | -0.052 |  0.056 |  0.020 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_2.2.position_encoding.position_ids
 |  0.001 | -5.085 |  5.020 |  1.000 | torch.Size([4096, 256]) || body3_2.2.position_encoding.pe.weight
 |  0.003 | -0.231 |  0.259 |  0.091 | torch.Size([128, 1, 5, 5]) || fusion3_2.0.weight
 |  0.002 | -0.196 |  0.229 |  0.105 | torch.Size([128]) || fusion3_2.0.bias
 |  0.001 | -0.155 |  0.160 |  0.049 | torch.Size([64, 128, 1, 1]) || fusion3_2.1.weight
 |  0.005 | -0.085 |  0.118 |  0.048 | torch.Size([64]) || fusion3_2.1.bias
 | -0.001 | -0.214 |  0.196 |  0.049 | torch.Size([256, 256]) || body3_3.linear_encoding.weight
 | -0.004 | -0.134 |  0.146 |  0.061 | torch.Size([256]) || body3_3.linear_encoding.bias
 | -0.000 | -0.220 |  0.193 |  0.045 | torch.Size([1024, 256]) || body3_3.mlp_head.0.weight
 | -0.028 | -0.128 |  0.062 |  0.038 | torch.Size([1024]) || body3_3.mlp_head.0.bias
 | -0.000 | -0.216 |  0.177 |  0.032 | torch.Size([256, 1024]) || body3_3.mlp_head.3.weight
 |  0.002 | -0.089 |  0.076 |  0.029 | torch.Size([256]) || body3_3.mlp_head.3.bias
 |  0.000 | -0.130 |  0.138 |  0.039 | torch.Size([768, 256]) || body3_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.148 |  0.143 |  0.037 | torch.Size([256, 256]) || body3_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.195 |  0.190 |  0.044 | torch.Size([1024, 256]) || body3_3.encoder.layers.0.linear1.weight
 | -0.036 | -0.133 |  0.064 |  0.036 | torch.Size([1024]) || body3_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.180 |  0.228 |  0.031 | torch.Size([256, 1024]) || body3_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.072 |  0.071 |  0.025 | torch.Size([256]) || body3_3.encoder.layers.0.linear2.bias
 |  0.924 |  0.830 |  1.020 |  0.028 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.082 |  0.111 |  0.033 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.bias
 |  0.864 |  0.784 |  1.020 |  0.039 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.weight
 | -0.000 | -0.182 |  0.182 |  0.061 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.bias
 | -0.000 | -0.157 |  0.171 |  0.043 | torch.Size([192, 1, 5, 5]) || fusion3_3.0.weight
 |  0.004 | -0.182 |  0.217 |  0.080 | torch.Size([192]) || fusion3_3.0.bias
 |  0.000 | -0.118 |  0.119 |  0.023 | torch.Size([64, 192, 1, 1]) || fusion3_3.1.weight
 | -0.003 | -0.044 |  0.033 |  0.020 | torch.Size([64]) || fusion3_3.1.bias
 | -0.001 | -0.483 |  0.139 |  0.037 | torch.Size([256, 256]) || body3_4.linear_encoding.weight
 |  0.004 | -0.074 |  0.110 |  0.028 | torch.Size([256]) || body3_4.linear_encoding.bias
 | -0.001 | -0.256 |  0.263 |  0.046 | torch.Size([1024, 256]) || body3_4.mlp_head.0.weight
 | -0.053 | -0.173 |  0.067 |  0.038 | torch.Size([1024]) || body3_4.mlp_head.0.bias
 | -0.000 | -0.252 |  0.271 |  0.029 | torch.Size([256, 1024]) || body3_4.mlp_head.3.weight
 | -0.004 | -0.137 |  0.107 |  0.039 | torch.Size([256]) || body3_4.mlp_head.3.bias
 | -0.000 | -0.212 |  0.229 |  0.044 | torch.Size([768, 256]) || body3_4.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.147 |  0.137 |  0.033 | torch.Size([256, 256]) || body3_4.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.207 |  0.201 |  0.039 | torch.Size([1024, 256]) || body3_4.encoder.layers.0.linear1.weight
 | -0.040 | -0.148 |  0.054 |  0.037 | torch.Size([1024]) || body3_4.encoder.layers.0.linear1.bias
 |  0.000 | -0.209 |  0.176 |  0.022 | torch.Size([256, 1024]) || body3_4.encoder.layers.0.linear2.weight
 |  0.001 | -0.078 |  0.068 |  0.026 | torch.Size([256]) || body3_4.encoder.layers.0.linear2.bias
 |  0.794 |  0.635 |  0.948 |  0.067 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.weight
 | -0.001 | -0.195 |  0.146 |  0.060 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.bias
 |  0.778 |  0.451 |  1.065 |  0.105 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.weight
 |  0.000 | -0.211 |  0.200 |  0.087 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.bias
 |  0.000 | -0.056 |  0.058 |  0.012 | torch.Size([3, 64, 3, 3]) || tail.weight
 |  0.000 | -0.000 |  0.000 |  0.000 | torch.Size([3]) || tail.bias

25-05-17 10:28:37.140 : <epoch:  0, iter:  55,000, lr:2.500e-05> G_loss: 1.056e-04 
25-05-17 10:28:37.141 : Saving the model.
25-05-17 10:28:37.729 : ---1--> airplane_111_00.jpg | 27.00dB
25-05-17 10:28:37.911 : ---2--> airplane_111_01.jpg | 32.28dB
25-05-17 10:28:38.091 : ---3--> airplane_111_10.jpg | 29.84dB
25-05-17 10:28:38.271 : ---4--> airplane_111_11.jpg | 30.03dB
25-05-17 10:28:38.449 : ---5--> airport_111_00.jpg | 31.77dB
25-05-17 10:28:38.629 : ---6--> airport_111_01.jpg | 29.47dB
25-05-17 10:28:38.805 : ---7--> airport_111_10.jpg | 28.74dB
25-05-17 10:28:38.983 : ---8--> airport_111_11.jpg | 29.77dB
25-05-17 10:28:39.165 : ---9--> baseball_diamond_111_00.jpg | 29.64dB
25-05-17 10:28:39.339 : --10--> baseball_diamond_111_01.jpg | 31.53dB
25-05-17 10:28:39.520 : --11--> baseball_diamond_111_10.jpg | 29.53dB
25-05-17 10:28:39.701 : --12--> baseball_diamond_111_11.jpg | 32.73dB
25-05-17 10:28:39.875 : --13--> basketball_court_111_00.jpg | 27.23dB
25-05-17 10:28:40.060 : --14--> basketball_court_111_01.jpg | 26.91dB
25-05-17 10:28:40.238 : --15--> basketball_court_111_10.jpg | 30.30dB
25-05-17 10:28:40.423 : --16--> basketball_court_111_11.jpg | 28.44dB
25-05-17 10:28:40.602 : --17--> beach_111_00.jpg | 25.52dB
25-05-17 10:28:40.781 : --18--> beach_111_01.jpg | 28.66dB
25-05-17 10:28:40.964 : --19--> beach_111_10.jpg | 26.67dB
25-05-17 10:28:41.147 : --20--> beach_111_11.jpg | 31.79dB
25-05-17 10:28:41.327 : --21--> bridge_111_00.jpg | 38.52dB
25-05-17 10:28:41.505 : --22--> bridge_111_01.jpg | 31.16dB
25-05-17 10:28:41.688 : --23--> bridge_111_10.jpg | 29.95dB
25-05-17 10:28:41.871 : --24--> bridge_111_11.jpg | 33.62dB
25-05-17 10:28:42.051 : --25--> chaparral_111_00.jpg | 27.24dB
25-05-17 10:28:42.230 : --26--> chaparral_111_01.jpg | 27.61dB
25-05-17 10:28:42.405 : --27--> chaparral_111_10.jpg | 28.08dB
25-05-17 10:28:42.590 : --28--> chaparral_111_11.jpg | 25.07dB
25-05-17 10:28:42.765 : --29--> church_111_00.jpg | 28.37dB
25-05-17 10:28:42.951 : --30--> church_111_01.jpg | 27.16dB
25-05-17 10:28:43.131 : --31--> church_111_10.jpg | 31.49dB
25-05-17 10:28:43.311 : --32--> church_111_11.jpg | 26.93dB
25-05-17 10:28:43.492 : --33--> circular_farmland_111_00.jpg | 29.48dB
25-05-17 10:28:43.675 : --34--> circular_farmland_111_01.jpg | 30.77dB
25-05-17 10:28:43.847 : --35--> circular_farmland_111_10.jpg | 31.09dB
25-05-17 10:28:44.025 : --36--> circular_farmland_111_11.jpg | 31.43dB
25-05-17 10:28:44.202 : --37--> cloud_111_00.jpg | 38.04dB
25-05-17 10:28:44.385 : --38--> cloud_111_01.jpg | 33.77dB
25-05-17 10:28:44.565 : --39--> cloud_111_10.jpg | 33.36dB
25-05-17 10:28:44.746 : --40--> cloud_111_11.jpg | 33.66dB
25-05-17 10:28:44.924 : --41--> commercial_area_111_00.jpg | 30.33dB
25-05-17 10:28:45.107 : --42--> commercial_area_111_01.jpg | 28.78dB
25-05-17 10:28:45.284 : --43--> commercial_area_111_10.jpg | 29.79dB
25-05-17 10:28:45.463 : --44--> commercial_area_111_11.jpg | 29.54dB
25-05-17 10:28:45.645 : --45--> dense_residential_111_00.jpg | 26.63dB
25-05-17 10:28:45.827 : --46--> dense_residential_111_01.jpg | 25.72dB
25-05-17 10:28:46.006 : --47--> dense_residential_111_10.jpg | 26.12dB
25-05-17 10:28:46.185 : --48--> dense_residential_111_11.jpg | 25.95dB
25-05-17 10:28:46.364 : --49--> desert_111_00.jpg | 34.49dB
25-05-17 10:28:46.545 : --50--> desert_111_01.jpg | 34.00dB
25-05-17 10:28:46.724 : --51--> desert_111_10.jpg | 34.59dB
25-05-17 10:28:46.906 : --52--> desert_111_11.jpg | 34.47dB
25-05-17 10:28:47.085 : --53--> forest_111_00.jpg | 30.34dB
25-05-17 10:28:47.267 : --54--> forest_111_01.jpg | 29.36dB
25-05-17 10:28:47.443 : --55--> forest_111_10.jpg | 28.67dB
25-05-17 10:28:47.627 : --56--> forest_111_11.jpg | 29.95dB
25-05-17 10:28:47.803 : --57--> freeway_111_00.jpg | 31.25dB
25-05-17 10:28:47.983 : --58--> freeway_111_01.jpg | 32.08dB
25-05-17 10:28:48.160 : --59--> freeway_111_10.jpg | 32.10dB
25-05-17 10:28:48.343 : --60--> freeway_111_11.jpg | 32.21dB
25-05-17 10:28:48.523 : --61--> golf_course_111_00.jpg | 29.73dB
25-05-17 10:28:48.702 : --62--> golf_course_111_01.jpg | 28.71dB
25-05-17 10:28:48.884 : --63--> golf_course_111_10.jpg | 30.55dB
25-05-17 10:28:49.060 : --64--> golf_course_111_11.jpg | 30.92dB
25-05-17 10:28:49.244 : --65--> ground_track_field_111_00.jpg | 29.99dB
25-05-17 10:28:49.419 : --66--> ground_track_field_111_01.jpg | 25.86dB
25-05-17 10:28:49.602 : --67--> ground_track_field_111_10.jpg | 27.49dB
25-05-17 10:28:49.784 : --68--> ground_track_field_111_11.jpg | 26.57dB
25-05-17 10:28:49.966 : --69--> harbor_111_00.jpg | 30.83dB
25-05-17 10:28:50.145 : --70--> harbor_111_01.jpg | 28.10dB
25-05-17 10:28:50.322 : --71--> harbor_111_10.jpg | 27.44dB
25-05-17 10:28:50.505 : --72--> harbor_111_11.jpg | 29.35dB
25-05-17 10:28:50.684 : --73--> industrial_area_111_00.jpg | 28.68dB
25-05-17 10:28:50.867 : --74--> industrial_area_111_01.jpg | 28.34dB
25-05-17 10:28:51.041 : --75--> industrial_area_111_10.jpg | 28.68dB
25-05-17 10:28:51.225 : --76--> industrial_area_111_11.jpg | 27.92dB
25-05-17 10:28:51.403 : --77--> intersection_111_00.jpg | 27.37dB
25-05-17 10:28:51.580 : --78--> intersection_111_01.jpg | 27.44dB
25-05-17 10:28:51.763 : --79--> intersection_111_10.jpg | 26.97dB
25-05-17 10:28:51.942 : --80--> intersection_111_11.jpg | 26.79dB
25-05-17 10:28:52.120 : --81--> island_111_00.jpg | 28.20dB
25-05-17 10:28:52.304 : --82--> island_111_01.jpg | 30.75dB
25-05-17 10:28:52.484 : --83--> island_111_10.jpg | 29.18dB
25-05-17 10:28:52.662 : --84--> island_111_11.jpg | 28.78dB
25-05-17 10:28:52.842 : --85--> lake_111_00.jpg | 30.01dB
25-05-17 10:28:53.021 : --86--> lake_111_01.jpg | 29.84dB
25-05-17 10:28:53.197 : --87--> lake_111_10.jpg | 28.74dB
25-05-17 10:28:53.379 : --88--> lake_111_11.jpg | 28.36dB
25-05-17 10:28:53.558 : --89--> meadow_111_00.jpg | 27.28dB
25-05-17 10:28:53.739 : --90--> meadow_111_01.jpg | 27.27dB
25-05-17 10:28:53.920 : --91--> meadow_111_10.jpg | 27.47dB
25-05-17 10:28:54.097 : --92--> meadow_111_11.jpg | 27.58dB
25-05-17 10:28:54.283 : --93--> medium_residential_111_00.jpg | 25.13dB
25-05-17 10:28:54.461 : --94--> medium_residential_111_01.jpg | 24.55dB
25-05-17 10:28:54.637 : --95--> medium_residential_111_10.jpg | 24.95dB
25-05-17 10:28:54.823 : --96--> medium_residential_111_11.jpg | 25.51dB
25-05-17 10:28:54.996 : --97--> mobile_home_park_111_00.jpg | 27.37dB
25-05-17 10:28:55.179 : --98--> mobile_home_park_111_01.jpg | 27.89dB
25-05-17 10:28:55.357 : --99--> mobile_home_park_111_10.jpg | 28.35dB
25-05-17 10:28:55.538 : -100--> mobile_home_park_111_11.jpg | 28.20dB
25-05-17 10:28:55.719 : -101--> mountain_111_00.jpg | 25.49dB
25-05-17 10:28:55.901 : -102--> mountain_111_01.jpg | 26.42dB
25-05-17 10:28:56.080 : -103--> mountain_111_10.jpg | 26.05dB
25-05-17 10:28:56.254 : -104--> mountain_111_11.jpg | 26.52dB
25-05-17 10:28:56.435 : -105--> overpass_111_00.jpg | 27.02dB
25-05-17 10:28:56.614 : -106--> overpass_111_01.jpg | 26.74dB
25-05-17 10:28:56.794 : -107--> overpass_111_10.jpg | 27.65dB
25-05-17 10:28:56.981 : -108--> overpass_111_11.jpg | 28.15dB
25-05-17 10:28:57.157 : -109--> palace_111_00.jpg | 26.51dB
25-05-17 10:28:57.336 : -110--> palace_111_01.jpg | 26.32dB
25-05-17 10:28:57.515 : -111--> palace_111_10.jpg | 27.87dB
25-05-17 10:28:57.696 : -112--> palace_111_11.jpg | 25.92dB
25-05-17 10:28:57.871 : -113--> parking_lot_111_00.jpg | 25.47dB
25-05-17 10:28:58.054 : -114--> parking_lot_111_01.jpg | 25.68dB
25-05-17 10:28:58.235 : -115--> parking_lot_111_10.jpg | 27.74dB
25-05-17 10:28:58.418 : -116--> parking_lot_111_11.jpg | 26.53dB
25-05-17 10:28:58.596 : -117--> railway_111_00.jpg | 27.10dB
25-05-17 10:28:58.777 : -118--> railway_111_01.jpg | 26.62dB
25-05-17 10:28:58.957 : -119--> railway_111_10.jpg | 29.81dB
25-05-17 10:28:59.132 : -120--> railway_111_11.jpg | 25.59dB
25-05-17 10:28:59.314 : -121--> railway_station_111_00.jpg | 27.70dB
25-05-17 10:28:59.493 : -122--> railway_station_111_01.jpg | 28.64dB
25-05-17 10:28:59.672 : -123--> railway_station_111_10.jpg | 27.97dB
25-05-17 10:28:59.857 : -124--> railway_station_111_11.jpg | 28.67dB
25-05-17 10:29:00.036 : -125--> rectangular_farmland_111_00.jpg | 30.33dB
25-05-17 10:29:00.214 : -126--> rectangular_farmland_111_01.jpg | 28.58dB
25-05-17 10:29:00.391 : -127--> rectangular_farmland_111_10.jpg | 30.68dB
25-05-17 10:29:00.567 : -128--> rectangular_farmland_111_11.jpg | 31.00dB
25-05-17 10:29:00.753 : -129--> river_111_00.jpg | 26.88dB
25-05-17 10:29:00.934 : -130--> river_111_01.jpg | 26.88dB
25-05-17 10:29:01.116 : -131--> river_111_10.jpg | 26.02dB
25-05-17 10:29:01.294 : -132--> river_111_11.jpg | 28.11dB
25-05-17 10:29:01.475 : -133--> roundabout_111_00.jpg | 27.23dB
25-05-17 10:29:01.654 : -134--> roundabout_111_01.jpg | 29.12dB
25-05-17 10:29:01.834 : -135--> roundabout_111_10.jpg | 27.24dB
25-05-17 10:29:02.008 : -136--> roundabout_111_11.jpg | 27.55dB
25-05-17 10:29:02.188 : -137--> runway_111_00.jpg | 33.47dB
25-05-17 10:29:02.367 : -138--> runway_111_01.jpg | 32.88dB
25-05-17 10:29:02.548 : -139--> runway_111_10.jpg | 34.13dB
25-05-17 10:29:02.728 : -140--> runway_111_11.jpg | 34.16dB
25-05-17 10:29:02.906 : -141--> sea_ice_111_00.jpg | 30.31dB
25-05-17 10:29:03.092 : -142--> sea_ice_111_01.jpg | 31.21dB
25-05-17 10:29:03.272 : -143--> sea_ice_111_10.jpg | 30.33dB
25-05-17 10:29:03.447 : -144--> sea_ice_111_11.jpg | 31.48dB
25-05-17 10:29:03.628 : -145--> ship_111_00.jpg | 35.67dB
25-05-17 10:29:03.808 : -146--> ship_111_01.jpg | 31.12dB
25-05-17 10:29:03.988 : -147--> ship_111_10.jpg | 40.80dB
25-05-17 10:29:04.162 : -148--> ship_111_11.jpg | 36.61dB
25-05-17 10:29:04.350 : -149--> snowberg_111_00.jpg | 30.62dB
25-05-17 10:29:04.525 : -150--> snowberg_111_01.jpg | 29.31dB
25-05-17 10:29:04.699 : -151--> snowberg_111_10.jpg | 28.46dB
25-05-17 10:29:04.886 : -152--> snowberg_111_11.jpg | 28.51dB
25-05-17 10:29:05.066 : -153--> sparse_residential_111_00.jpg | 27.23dB
25-05-17 10:29:05.240 : -154--> sparse_residential_111_01.jpg | 27.89dB
25-05-17 10:29:05.425 : -155--> sparse_residential_111_10.jpg | 26.27dB
25-05-17 10:29:05.605 : -156--> sparse_residential_111_11.jpg | 26.88dB
25-05-17 10:29:05.782 : -157--> stadium_111_00.jpg | 26.59dB
25-05-17 10:29:05.963 : -158--> stadium_111_01.jpg | 26.45dB
25-05-17 10:29:06.150 : -159--> stadium_111_10.jpg | 27.92dB
25-05-17 10:29:06.331 : -160--> stadium_111_11.jpg | 26.55dB
25-05-17 10:29:06.514 : -161--> storage_tank_111_00.jpg | 28.68dB
25-05-17 10:29:06.691 : -162--> storage_tank_111_01.jpg | 28.75dB
25-05-17 10:29:06.875 : -163--> storage_tank_111_10.jpg | 27.51dB
25-05-17 10:29:07.053 : -164--> storage_tank_111_11.jpg | 28.02dB
25-05-17 10:29:07.233 : -165--> tennis_court_111_00.jpg | 29.01dB
25-05-17 10:29:07.417 : -166--> tennis_court_111_01.jpg | 28.63dB
25-05-17 10:29:07.590 : -167--> tennis_court_111_10.jpg | 28.64dB
25-05-17 10:29:07.769 : -168--> tennis_court_111_11.jpg | 26.64dB
25-05-17 10:29:07.944 : -169--> terrace_111_00.jpg | 29.20dB
25-05-17 10:29:08.130 : -170--> terrace_111_01.jpg | 30.20dB
25-05-17 10:29:08.311 : -171--> terrace_111_10.jpg | 29.00dB
25-05-17 10:29:08.493 : -172--> terrace_111_11.jpg | 29.18dB
25-05-17 10:29:08.673 : -173--> thermal_power_station_111_00.jpg | 26.74dB
25-05-17 10:29:08.855 : -174--> thermal_power_station_111_01.jpg | 28.11dB
25-05-17 10:29:09.032 : -175--> thermal_power_station_111_10.jpg | 26.25dB
25-05-17 10:29:09.212 : -176--> thermal_power_station_111_11.jpg | 26.80dB
25-05-17 10:29:09.396 : -177--> wetland_111_00.jpg | 28.53dB
25-05-17 10:29:09.574 : -178--> wetland_111_01.jpg | 28.64dB
25-05-17 10:29:09.751 : -179--> wetland_111_10.jpg | 28.89dB
25-05-17 10:29:09.928 : -180--> wetland_111_11.jpg | 28.03dB
25-05-17 10:29:09.937 : <epoch:  0, iter:  55,000, Average PSNR : 29.01dB

25-05-17 11:51:31.718 : <epoch:  0, iter:  60,000, lr:2.500e-05> G_loss: 2.708e-04 
25-05-17 11:51:31.719 : Saving the model.
25-05-17 11:51:32.312 : ---1--> airplane_111_00.jpg | 27.01dB
25-05-17 11:51:32.492 : ---2--> airplane_111_01.jpg | 32.31dB
25-05-17 11:51:32.670 : ---3--> airplane_111_10.jpg | 29.86dB
25-05-17 11:51:32.854 : ---4--> airplane_111_11.jpg | 30.03dB
25-05-17 11:51:33.037 : ---5--> airport_111_00.jpg | 31.77dB
25-05-17 11:51:33.221 : ---6--> airport_111_01.jpg | 29.47dB
25-05-17 11:51:33.401 : ---7--> airport_111_10.jpg | 28.78dB
25-05-17 11:51:33.584 : ---8--> airport_111_11.jpg | 29.79dB
25-05-17 11:51:33.767 : ---9--> baseball_diamond_111_00.jpg | 29.65dB
25-05-17 11:51:33.947 : --10--> baseball_diamond_111_01.jpg | 31.58dB
25-05-17 11:51:34.128 : --11--> baseball_diamond_111_10.jpg | 29.53dB
25-05-17 11:51:34.305 : --12--> baseball_diamond_111_11.jpg | 32.74dB
25-05-17 11:51:34.485 : --13--> basketball_court_111_00.jpg | 27.24dB
25-05-17 11:51:34.665 : --14--> basketball_court_111_01.jpg | 26.92dB
25-05-17 11:51:34.850 : --15--> basketball_court_111_10.jpg | 30.34dB
25-05-17 11:51:35.032 : --16--> basketball_court_111_11.jpg | 28.45dB
25-05-17 11:51:35.208 : --17--> beach_111_00.jpg | 25.54dB
25-05-17 11:51:35.388 : --18--> beach_111_01.jpg | 28.68dB
25-05-17 11:51:35.568 : --19--> beach_111_10.jpg | 26.68dB
25-05-17 11:51:35.747 : --20--> beach_111_11.jpg | 31.82dB
25-05-17 11:51:35.929 : --21--> bridge_111_00.jpg | 38.57dB
25-05-17 11:51:36.114 : --22--> bridge_111_01.jpg | 31.19dB
25-05-17 11:51:36.294 : --23--> bridge_111_10.jpg | 29.97dB
25-05-17 11:51:36.470 : --24--> bridge_111_11.jpg | 33.64dB
25-05-17 11:51:36.653 : --25--> chaparral_111_00.jpg | 27.23dB
25-05-17 11:51:36.836 : --26--> chaparral_111_01.jpg | 27.60dB
25-05-17 11:51:37.015 : --27--> chaparral_111_10.jpg | 28.07dB
25-05-17 11:51:37.195 : --28--> chaparral_111_11.jpg | 25.07dB
25-05-17 11:51:37.374 : --29--> church_111_00.jpg | 28.39dB
25-05-17 11:51:37.559 : --30--> church_111_01.jpg | 27.16dB
25-05-17 11:51:37.738 : --31--> church_111_10.jpg | 31.51dB
25-05-17 11:51:37.924 : --32--> church_111_11.jpg | 26.96dB
25-05-17 11:51:38.100 : --33--> circular_farmland_111_00.jpg | 29.48dB
25-05-17 11:51:38.286 : --34--> circular_farmland_111_01.jpg | 30.80dB
25-05-17 11:51:38.465 : --35--> circular_farmland_111_10.jpg | 31.11dB
25-05-17 11:51:38.642 : --36--> circular_farmland_111_11.jpg | 31.45dB
25-05-17 11:51:38.827 : --37--> cloud_111_00.jpg | 38.01dB
25-05-17 11:51:39.008 : --38--> cloud_111_01.jpg | 33.78dB
25-05-17 11:51:39.186 : --39--> cloud_111_10.jpg | 33.38dB
25-05-17 11:51:39.364 : --40--> cloud_111_11.jpg | 33.70dB
25-05-17 11:51:39.544 : --41--> commercial_area_111_00.jpg | 30.35dB
25-05-17 11:51:39.721 : --42--> commercial_area_111_01.jpg | 28.80dB
25-05-17 11:51:39.903 : --43--> commercial_area_111_10.jpg | 29.80dB
25-05-17 11:51:40.081 : --44--> commercial_area_111_11.jpg | 29.53dB
25-05-17 11:51:40.257 : --45--> dense_residential_111_00.jpg | 26.63dB
25-05-17 11:51:40.444 : --46--> dense_residential_111_01.jpg | 25.72dB
25-05-17 11:51:40.625 : --47--> dense_residential_111_10.jpg | 26.13dB
25-05-17 11:51:40.810 : --48--> dense_residential_111_11.jpg | 25.96dB
25-05-17 11:51:40.989 : --49--> desert_111_00.jpg | 34.57dB
25-05-17 11:51:41.175 : --50--> desert_111_01.jpg | 34.09dB
25-05-17 11:51:41.353 : --51--> desert_111_10.jpg | 34.68dB
25-05-17 11:51:41.533 : --52--> desert_111_11.jpg | 34.59dB
25-05-17 11:51:41.717 : --53--> forest_111_00.jpg | 30.35dB
25-05-17 11:51:41.894 : --54--> forest_111_01.jpg | 29.37dB
25-05-17 11:51:42.073 : --55--> forest_111_10.jpg | 28.66dB
25-05-17 11:51:42.255 : --56--> forest_111_11.jpg | 29.97dB
25-05-17 11:51:42.434 : --57--> freeway_111_00.jpg | 31.28dB
25-05-17 11:51:42.614 : --58--> freeway_111_01.jpg | 32.12dB
25-05-17 11:51:42.794 : --59--> freeway_111_10.jpg | 32.10dB
25-05-17 11:51:42.972 : --60--> freeway_111_11.jpg | 32.26dB
25-05-17 11:51:43.152 : --61--> golf_course_111_00.jpg | 29.76dB
25-05-17 11:51:43.329 : --62--> golf_course_111_01.jpg | 28.73dB
25-05-17 11:51:43.514 : --63--> golf_course_111_10.jpg | 30.57dB
25-05-17 11:51:43.695 : --64--> golf_course_111_11.jpg | 30.94dB
25-05-17 11:51:43.874 : --65--> ground_track_field_111_00.jpg | 29.99dB
25-05-17 11:51:44.054 : --66--> ground_track_field_111_01.jpg | 25.87dB
25-05-17 11:51:44.235 : --67--> ground_track_field_111_10.jpg | 27.50dB
25-05-17 11:51:44.419 : --68--> ground_track_field_111_11.jpg | 26.57dB
25-05-17 11:51:44.604 : --69--> harbor_111_00.jpg | 30.83dB
25-05-17 11:51:44.785 : --70--> harbor_111_01.jpg | 28.12dB
25-05-17 11:51:44.961 : --71--> harbor_111_10.jpg | 27.45dB
25-05-17 11:51:45.145 : --72--> harbor_111_11.jpg | 29.38dB
25-05-17 11:51:45.325 : --73--> industrial_area_111_00.jpg | 28.69dB
25-05-17 11:51:45.507 : --74--> industrial_area_111_01.jpg | 28.33dB
25-05-17 11:51:45.687 : --75--> industrial_area_111_10.jpg | 28.71dB
25-05-17 11:51:45.866 : --76--> industrial_area_111_11.jpg | 27.93dB
25-05-17 11:51:46.047 : --77--> intersection_111_00.jpg | 27.37dB
25-05-17 11:51:46.225 : --78--> intersection_111_01.jpg | 27.45dB
25-05-17 11:51:46.406 : --79--> intersection_111_10.jpg | 26.98dB
25-05-17 11:51:46.584 : --80--> intersection_111_11.jpg | 26.79dB
25-05-17 11:51:46.763 : --81--> island_111_00.jpg | 28.20dB
25-05-17 11:51:46.948 : --82--> island_111_01.jpg | 30.76dB
25-05-17 11:51:47.126 : --83--> island_111_10.jpg | 29.19dB
25-05-17 11:51:47.304 : --84--> island_111_11.jpg | 28.79dB
25-05-17 11:51:47.486 : --85--> lake_111_00.jpg | 30.03dB
25-05-17 11:51:47.668 : --86--> lake_111_01.jpg | 29.85dB
25-05-17 11:51:47.844 : --87--> lake_111_10.jpg | 28.76dB
25-05-17 11:51:48.033 : --88--> lake_111_11.jpg | 28.38dB
25-05-17 11:51:48.214 : --89--> meadow_111_00.jpg | 27.29dB
25-05-17 11:51:48.394 : --90--> meadow_111_01.jpg | 27.27dB
25-05-17 11:51:48.568 : --91--> meadow_111_10.jpg | 27.48dB
25-05-17 11:51:48.754 : --92--> meadow_111_11.jpg | 27.59dB
25-05-17 11:51:48.934 : --93--> medium_residential_111_00.jpg | 25.14dB
25-05-17 11:51:49.114 : --94--> medium_residential_111_01.jpg | 24.55dB
25-05-17 11:51:49.297 : --95--> medium_residential_111_10.jpg | 24.95dB
25-05-17 11:51:49.474 : --96--> medium_residential_111_11.jpg | 25.51dB
25-05-17 11:51:49.655 : --97--> mobile_home_park_111_00.jpg | 27.38dB
25-05-17 11:51:49.839 : --98--> mobile_home_park_111_01.jpg | 27.91dB
25-05-17 11:51:50.015 : --99--> mobile_home_park_111_10.jpg | 28.37dB
25-05-17 11:51:50.193 : -100--> mobile_home_park_111_11.jpg | 28.20dB
25-05-17 11:51:50.377 : -101--> mountain_111_00.jpg | 25.50dB
25-05-17 11:51:50.559 : -102--> mountain_111_01.jpg | 26.44dB
25-05-17 11:51:50.736 : -103--> mountain_111_10.jpg | 26.05dB
25-05-17 11:51:50.914 : -104--> mountain_111_11.jpg | 26.53dB
25-05-17 11:51:51.099 : -105--> overpass_111_00.jpg | 26.99dB
25-05-17 11:51:51.278 : -106--> overpass_111_01.jpg | 26.74dB
25-05-17 11:51:51.455 : -107--> overpass_111_10.jpg | 27.68dB
25-05-17 11:51:51.629 : -108--> overpass_111_11.jpg | 28.17dB
25-05-17 11:51:51.805 : -109--> palace_111_00.jpg | 26.54dB
25-05-17 11:51:51.985 : -110--> palace_111_01.jpg | 26.32dB
25-05-17 11:51:52.163 : -111--> palace_111_10.jpg | 27.88dB
25-05-17 11:51:52.343 : -112--> palace_111_11.jpg | 25.93dB
25-05-17 11:51:52.521 : -113--> parking_lot_111_00.jpg | 25.49dB
25-05-17 11:51:52.710 : -114--> parking_lot_111_01.jpg | 25.68dB
25-05-17 11:51:52.888 : -115--> parking_lot_111_10.jpg | 27.76dB
25-05-17 11:51:53.069 : -116--> parking_lot_111_11.jpg | 26.53dB
25-05-17 11:51:53.245 : -117--> railway_111_00.jpg | 27.12dB
25-05-17 11:51:53.425 : -118--> railway_111_01.jpg | 26.63dB
25-05-17 11:51:53.602 : -119--> railway_111_10.jpg | 29.82dB
25-05-17 11:51:53.786 : -120--> railway_111_11.jpg | 25.60dB
25-05-17 11:51:53.961 : -121--> railway_station_111_00.jpg | 27.68dB
25-05-17 11:51:54.143 : -122--> railway_station_111_01.jpg | 28.64dB
25-05-17 11:51:54.324 : -123--> railway_station_111_10.jpg | 27.98dB
25-05-17 11:51:54.505 : -124--> railway_station_111_11.jpg | 28.69dB
25-05-17 11:51:54.686 : -125--> rectangular_farmland_111_00.jpg | 30.37dB
25-05-17 11:51:54.874 : -126--> rectangular_farmland_111_01.jpg | 28.58dB
25-05-17 11:51:55.052 : -127--> rectangular_farmland_111_10.jpg | 30.71dB
25-05-17 11:51:55.232 : -128--> rectangular_farmland_111_11.jpg | 31.03dB
25-05-17 11:51:55.413 : -129--> river_111_00.jpg | 26.89dB
25-05-17 11:51:55.588 : -130--> river_111_01.jpg | 26.91dB
25-05-17 11:51:55.766 : -131--> river_111_10.jpg | 26.03dB
25-05-17 11:51:55.944 : -132--> river_111_11.jpg | 28.11dB
25-05-17 11:51:56.129 : -133--> roundabout_111_00.jpg | 27.25dB
25-05-17 11:51:56.312 : -134--> roundabout_111_01.jpg | 29.11dB
25-05-17 11:51:56.494 : -135--> roundabout_111_10.jpg | 27.25dB
25-05-17 11:51:56.676 : -136--> roundabout_111_11.jpg | 27.56dB
25-05-17 11:51:56.857 : -137--> runway_111_00.jpg | 33.59dB
25-05-17 11:51:57.035 : -138--> runway_111_01.jpg | 32.93dB
25-05-17 11:51:57.214 : -139--> runway_111_10.jpg | 34.17dB
25-05-17 11:51:57.394 : -140--> runway_111_11.jpg | 34.26dB
25-05-17 11:51:57.577 : -141--> sea_ice_111_00.jpg | 30.32dB
25-05-17 11:51:57.760 : -142--> sea_ice_111_01.jpg | 31.22dB
25-05-17 11:51:57.937 : -143--> sea_ice_111_10.jpg | 30.33dB
25-05-17 11:51:58.114 : -144--> sea_ice_111_11.jpg | 31.53dB
25-05-17 11:51:58.292 : -145--> ship_111_00.jpg | 35.73dB
25-05-17 11:51:58.475 : -146--> ship_111_01.jpg | 31.16dB
25-05-17 11:51:58.656 : -147--> ship_111_10.jpg | 40.85dB
25-05-17 11:51:58.836 : -148--> ship_111_11.jpg | 36.66dB
25-05-17 11:51:59.015 : -149--> snowberg_111_00.jpg | 30.62dB
25-05-17 11:51:59.195 : -150--> snowberg_111_01.jpg | 29.34dB
25-05-17 11:51:59.374 : -151--> snowberg_111_10.jpg | 28.47dB
25-05-17 11:51:59.557 : -152--> snowberg_111_11.jpg | 28.52dB
25-05-17 11:51:59.743 : -153--> sparse_residential_111_00.jpg | 27.24dB
25-05-17 11:51:59.919 : -154--> sparse_residential_111_01.jpg | 27.90dB
25-05-17 11:52:00.094 : -155--> sparse_residential_111_10.jpg | 26.27dB
25-05-17 11:52:00.272 : -156--> sparse_residential_111_11.jpg | 26.90dB
25-05-17 11:52:00.454 : -157--> stadium_111_00.jpg | 26.59dB
25-05-17 11:52:00.634 : -158--> stadium_111_01.jpg | 26.46dB
25-05-17 11:52:00.814 : -159--> stadium_111_10.jpg | 27.93dB
25-05-17 11:52:00.993 : -160--> stadium_111_11.jpg | 26.57dB
25-05-17 11:52:01.169 : -161--> storage_tank_111_00.jpg | 28.69dB
25-05-17 11:52:01.345 : -162--> storage_tank_111_01.jpg | 28.78dB
25-05-17 11:52:01.526 : -163--> storage_tank_111_10.jpg | 27.53dB
25-05-17 11:52:01.715 : -164--> storage_tank_111_11.jpg | 28.03dB
25-05-17 11:52:01.898 : -165--> tennis_court_111_00.jpg | 29.02dB
25-05-17 11:52:02.082 : -166--> tennis_court_111_01.jpg | 28.64dB
25-05-17 11:52:02.263 : -167--> tennis_court_111_10.jpg | 28.64dB
25-05-17 11:52:02.444 : -168--> tennis_court_111_11.jpg | 26.64dB
25-05-17 11:52:02.624 : -169--> terrace_111_00.jpg | 29.22dB
25-05-17 11:52:02.807 : -170--> terrace_111_01.jpg | 30.22dB
25-05-17 11:52:02.984 : -171--> terrace_111_10.jpg | 29.00dB
25-05-17 11:52:03.164 : -172--> terrace_111_11.jpg | 29.18dB
25-05-17 11:52:03.344 : -173--> thermal_power_station_111_00.jpg | 26.74dB
25-05-17 11:52:03.527 : -174--> thermal_power_station_111_01.jpg | 28.13dB
25-05-17 11:52:03.705 : -175--> thermal_power_station_111_10.jpg | 26.25dB
25-05-17 11:52:03.883 : -176--> thermal_power_station_111_11.jpg | 26.79dB
25-05-17 11:52:04.062 : -177--> wetland_111_00.jpg | 28.54dB
25-05-17 11:52:04.241 : -178--> wetland_111_01.jpg | 28.65dB
25-05-17 11:52:04.424 : -179--> wetland_111_10.jpg | 28.90dB
25-05-17 11:52:04.609 : -180--> wetland_111_11.jpg | 28.05dB
25-05-17 11:52:04.617 : <epoch:  0, iter:  60,000, Average PSNR : 29.03dB

25-05-17 13:14:25.878 : <epoch:  0, iter:  65,000, lr:2.500e-05> G_loss: 1.855e-04 
25-05-17 13:14:25.879 : Saving the model.
25-05-17 13:14:26.492 : ---1--> airplane_111_00.jpg | 27.01dB
25-05-17 13:14:26.671 : ---2--> airplane_111_01.jpg | 32.34dB
25-05-17 13:14:26.851 : ---3--> airplane_111_10.jpg | 29.85dB
25-05-17 13:14:27.034 : ---4--> airplane_111_11.jpg | 30.03dB
25-05-17 13:14:27.219 : ---5--> airport_111_00.jpg | 31.77dB
25-05-17 13:14:27.393 : ---6--> airport_111_01.jpg | 29.47dB
25-05-17 13:14:27.574 : ---7--> airport_111_10.jpg | 28.80dB
25-05-17 13:14:27.750 : ---8--> airport_111_11.jpg | 29.79dB
25-05-17 13:14:27.933 : ---9--> baseball_diamond_111_00.jpg | 29.64dB
25-05-17 13:14:28.110 : --10--> baseball_diamond_111_01.jpg | 31.56dB
25-05-17 13:14:28.287 : --11--> baseball_diamond_111_10.jpg | 29.55dB
25-05-17 13:14:28.461 : --12--> baseball_diamond_111_11.jpg | 32.74dB
25-05-17 13:14:28.643 : --13--> basketball_court_111_00.jpg | 27.25dB
25-05-17 13:14:28.825 : --14--> basketball_court_111_01.jpg | 26.91dB
25-05-17 13:14:29.004 : --15--> basketball_court_111_10.jpg | 30.32dB
25-05-17 13:14:29.182 : --16--> basketball_court_111_11.jpg | 28.44dB
25-05-17 13:14:29.361 : --17--> beach_111_00.jpg | 25.54dB
25-05-17 13:14:29.544 : --18--> beach_111_01.jpg | 28.68dB
25-05-17 13:14:29.720 : --19--> beach_111_10.jpg | 26.70dB
25-05-17 13:14:29.901 : --20--> beach_111_11.jpg | 31.84dB
25-05-17 13:14:30.084 : --21--> bridge_111_00.jpg | 38.53dB
25-05-17 13:14:30.273 : --22--> bridge_111_01.jpg | 31.18dB
25-05-17 13:14:30.452 : --23--> bridge_111_10.jpg | 29.96dB
25-05-17 13:14:30.634 : --24--> bridge_111_11.jpg | 33.63dB
25-05-17 13:14:30.815 : --25--> chaparral_111_00.jpg | 27.24dB
25-05-17 13:14:30.990 : --26--> chaparral_111_01.jpg | 27.61dB
25-05-17 13:14:31.170 : --27--> chaparral_111_10.jpg | 28.09dB
25-05-17 13:14:31.354 : --28--> chaparral_111_11.jpg | 25.08dB
25-05-17 13:14:31.534 : --29--> church_111_00.jpg | 28.39dB
25-05-17 13:14:31.714 : --30--> church_111_01.jpg | 27.17dB
25-05-17 13:14:31.894 : --31--> church_111_10.jpg | 31.52dB
25-05-17 13:14:32.069 : --32--> church_111_11.jpg | 26.97dB
25-05-17 13:14:32.254 : --33--> circular_farmland_111_00.jpg | 29.47dB
25-05-17 13:14:32.435 : --34--> circular_farmland_111_01.jpg | 30.78dB
25-05-17 13:14:32.614 : --35--> circular_farmland_111_10.jpg | 31.10dB
25-05-17 13:14:32.795 : --36--> circular_farmland_111_11.jpg | 31.44dB
25-05-17 13:14:32.975 : --37--> cloud_111_00.jpg | 37.94dB
25-05-17 13:14:33.154 : --38--> cloud_111_01.jpg | 33.80dB
25-05-17 13:14:33.334 : --39--> cloud_111_10.jpg | 33.35dB
25-05-17 13:14:33.516 : --40--> cloud_111_11.jpg | 33.72dB
25-05-17 13:14:33.694 : --41--> commercial_area_111_00.jpg | 30.33dB
25-05-17 13:14:33.874 : --42--> commercial_area_111_01.jpg | 28.80dB
25-05-17 13:14:34.055 : --43--> commercial_area_111_10.jpg | 29.81dB
25-05-17 13:14:34.234 : --44--> commercial_area_111_11.jpg | 29.54dB
25-05-17 13:14:34.414 : --45--> dense_residential_111_00.jpg | 26.63dB
25-05-17 13:14:34.594 : --46--> dense_residential_111_01.jpg | 25.71dB
25-05-17 13:14:34.772 : --47--> dense_residential_111_10.jpg | 26.14dB
25-05-17 13:14:34.951 : --48--> dense_residential_111_11.jpg | 25.96dB
25-05-17 13:14:35.131 : --49--> desert_111_00.jpg | 34.52dB
25-05-17 13:14:35.310 : --50--> desert_111_01.jpg | 34.04dB
25-05-17 13:14:35.493 : --51--> desert_111_10.jpg | 34.63dB
25-05-17 13:14:35.673 : --52--> desert_111_11.jpg | 34.54dB
25-05-17 13:14:35.854 : --53--> forest_111_00.jpg | 30.36dB
25-05-17 13:14:36.029 : --54--> forest_111_01.jpg | 29.38dB
25-05-17 13:14:36.209 : --55--> forest_111_10.jpg | 28.68dB
25-05-17 13:14:36.385 : --56--> forest_111_11.jpg | 29.95dB
25-05-17 13:14:36.564 : --57--> freeway_111_00.jpg | 31.27dB
25-05-17 13:14:36.744 : --58--> freeway_111_01.jpg | 32.12dB
25-05-17 13:14:36.920 : --59--> freeway_111_10.jpg | 32.11dB
25-05-17 13:14:37.103 : --60--> freeway_111_11.jpg | 32.24dB
25-05-17 13:14:37.278 : --61--> golf_course_111_00.jpg | 29.75dB
25-05-17 13:14:37.467 : --62--> golf_course_111_01.jpg | 28.74dB
25-05-17 13:14:37.644 : --63--> golf_course_111_10.jpg | 30.57dB
25-05-17 13:14:37.820 : --64--> golf_course_111_11.jpg | 30.93dB
25-05-17 13:14:38.004 : --65--> ground_track_field_111_00.jpg | 29.98dB
25-05-17 13:14:38.193 : --66--> ground_track_field_111_01.jpg | 25.86dB
25-05-17 13:14:38.373 : --67--> ground_track_field_111_10.jpg | 27.51dB
25-05-17 13:14:38.554 : --68--> ground_track_field_111_11.jpg | 26.57dB
25-05-17 13:14:38.732 : --69--> harbor_111_00.jpg | 30.83dB
25-05-17 13:14:38.913 : --70--> harbor_111_01.jpg | 28.13dB
25-05-17 13:14:39.094 : --71--> harbor_111_10.jpg | 27.45dB
25-05-17 13:14:39.270 : --72--> harbor_111_11.jpg | 29.37dB
25-05-17 13:14:39.454 : --73--> industrial_area_111_00.jpg | 28.69dB
25-05-17 13:14:39.636 : --74--> industrial_area_111_01.jpg | 28.35dB
25-05-17 13:14:39.815 : --75--> industrial_area_111_10.jpg | 28.73dB
25-05-17 13:14:39.996 : --76--> industrial_area_111_11.jpg | 27.95dB
25-05-17 13:14:40.175 : --77--> intersection_111_00.jpg | 27.37dB
25-05-17 13:14:40.356 : --78--> intersection_111_01.jpg | 27.45dB
25-05-17 13:14:40.538 : --79--> intersection_111_10.jpg | 26.96dB
25-05-17 13:14:40.721 : --80--> intersection_111_11.jpg | 26.78dB
25-05-17 13:14:40.899 : --81--> island_111_00.jpg | 28.19dB
25-05-17 13:14:41.074 : --82--> island_111_01.jpg | 30.74dB
25-05-17 13:14:41.255 : --83--> island_111_10.jpg | 29.19dB
25-05-17 13:14:41.438 : --84--> island_111_11.jpg | 28.80dB
25-05-17 13:14:41.616 : --85--> lake_111_00.jpg | 30.03dB
25-05-17 13:14:41.800 : --86--> lake_111_01.jpg | 29.86dB
25-05-17 13:14:41.983 : --87--> lake_111_10.jpg | 28.76dB
25-05-17 13:14:42.164 : --88--> lake_111_11.jpg | 28.35dB
25-05-17 13:14:42.341 : --89--> meadow_111_00.jpg | 27.28dB
25-05-17 13:14:42.528 : --90--> meadow_111_01.jpg | 27.27dB
25-05-17 13:14:42.703 : --91--> meadow_111_10.jpg | 27.48dB
25-05-17 13:14:42.880 : --92--> meadow_111_11.jpg | 27.58dB
25-05-17 13:14:43.065 : --93--> medium_residential_111_00.jpg | 25.14dB
25-05-17 13:14:43.245 : --94--> medium_residential_111_01.jpg | 24.56dB
25-05-17 13:14:43.430 : --95--> medium_residential_111_10.jpg | 24.96dB
25-05-17 13:14:43.615 : --96--> medium_residential_111_11.jpg | 25.52dB
25-05-17 13:14:43.791 : --97--> mobile_home_park_111_00.jpg | 27.36dB
25-05-17 13:14:43.967 : --98--> mobile_home_park_111_01.jpg | 27.89dB
25-05-17 13:14:44.144 : --99--> mobile_home_park_111_10.jpg | 28.35dB
25-05-17 13:14:44.330 : -100--> mobile_home_park_111_11.jpg | 28.20dB
25-05-17 13:14:44.514 : -101--> mountain_111_00.jpg | 25.51dB
25-05-17 13:14:44.689 : -102--> mountain_111_01.jpg | 26.45dB
25-05-17 13:14:44.873 : -103--> mountain_111_10.jpg | 26.05dB
25-05-17 13:14:45.054 : -104--> mountain_111_11.jpg | 26.53dB
25-05-17 13:14:45.233 : -105--> overpass_111_00.jpg | 27.01dB
25-05-17 13:14:45.414 : -106--> overpass_111_01.jpg | 26.73dB
25-05-17 13:14:45.596 : -107--> overpass_111_10.jpg | 27.66dB
25-05-17 13:14:45.772 : -108--> overpass_111_11.jpg | 28.17dB
25-05-17 13:14:45.952 : -109--> palace_111_00.jpg | 26.54dB
25-05-17 13:14:46.136 : -110--> palace_111_01.jpg | 26.32dB
25-05-17 13:14:46.315 : -111--> palace_111_10.jpg | 27.87dB
25-05-17 13:14:46.494 : -112--> palace_111_11.jpg | 25.94dB
25-05-17 13:14:46.674 : -113--> parking_lot_111_00.jpg | 25.47dB
25-05-17 13:14:46.852 : -114--> parking_lot_111_01.jpg | 25.69dB
25-05-17 13:14:47.034 : -115--> parking_lot_111_10.jpg | 27.76dB
25-05-17 13:14:47.214 : -116--> parking_lot_111_11.jpg | 26.55dB
25-05-17 13:14:47.393 : -117--> railway_111_00.jpg | 27.12dB
25-05-17 13:14:47.571 : -118--> railway_111_01.jpg | 26.63dB
25-05-17 13:14:47.749 : -119--> railway_111_10.jpg | 29.82dB
25-05-17 13:14:47.933 : -120--> railway_111_11.jpg | 25.60dB
25-05-17 13:14:48.115 : -121--> railway_station_111_00.jpg | 27.70dB
25-05-17 13:14:48.295 : -122--> railway_station_111_01.jpg | 28.66dB
25-05-17 13:14:48.476 : -123--> railway_station_111_10.jpg | 27.97dB
25-05-17 13:14:48.658 : -124--> railway_station_111_11.jpg | 28.70dB
25-05-17 13:14:48.842 : -125--> rectangular_farmland_111_00.jpg | 30.37dB
25-05-17 13:14:49.021 : -126--> rectangular_farmland_111_01.jpg | 28.59dB
25-05-17 13:14:49.196 : -127--> rectangular_farmland_111_10.jpg | 30.67dB
25-05-17 13:14:49.382 : -128--> rectangular_farmland_111_11.jpg | 31.02dB
25-05-17 13:14:49.562 : -129--> river_111_00.jpg | 26.91dB
25-05-17 13:14:49.744 : -130--> river_111_01.jpg | 26.91dB
25-05-17 13:14:49.924 : -131--> river_111_10.jpg | 26.03dB
25-05-17 13:14:50.102 : -132--> river_111_11.jpg | 28.12dB
25-05-17 13:14:50.282 : -133--> roundabout_111_00.jpg | 27.26dB
25-05-17 13:14:50.465 : -134--> roundabout_111_01.jpg | 29.13dB
25-05-17 13:14:50.640 : -135--> roundabout_111_10.jpg | 27.25dB
25-05-17 13:14:50.824 : -136--> roundabout_111_11.jpg | 27.56dB
25-05-17 13:14:51.000 : -137--> runway_111_00.jpg | 33.59dB
25-05-17 13:14:51.182 : -138--> runway_111_01.jpg | 32.96dB
25-05-17 13:14:51.362 : -139--> runway_111_10.jpg | 34.15dB
25-05-17 13:14:51.539 : -140--> runway_111_11.jpg | 34.23dB
25-05-17 13:14:51.720 : -141--> sea_ice_111_00.jpg | 30.31dB
25-05-17 13:14:51.900 : -142--> sea_ice_111_01.jpg | 31.21dB
25-05-17 13:14:52.079 : -143--> sea_ice_111_10.jpg | 30.32dB
25-05-17 13:14:52.256 : -144--> sea_ice_111_11.jpg | 31.52dB
25-05-17 13:14:52.436 : -145--> ship_111_00.jpg | 35.71dB
25-05-17 13:14:52.613 : -146--> ship_111_01.jpg | 31.17dB
25-05-17 13:14:52.790 : -147--> ship_111_10.jpg | 40.74dB
25-05-17 13:14:52.973 : -148--> ship_111_11.jpg | 36.67dB
25-05-17 13:14:53.151 : -149--> snowberg_111_00.jpg | 30.62dB
25-05-17 13:14:53.332 : -150--> snowberg_111_01.jpg | 29.31dB
25-05-17 13:14:53.509 : -151--> snowberg_111_10.jpg | 28.46dB
25-05-17 13:14:53.695 : -152--> snowberg_111_11.jpg | 28.50dB
25-05-17 13:14:53.873 : -153--> sparse_residential_111_00.jpg | 27.25dB
25-05-17 13:14:54.054 : -154--> sparse_residential_111_01.jpg | 27.90dB
25-05-17 13:14:54.231 : -155--> sparse_residential_111_10.jpg | 26.28dB
25-05-17 13:14:54.412 : -156--> sparse_residential_111_11.jpg | 26.91dB
25-05-17 13:14:54.591 : -157--> stadium_111_00.jpg | 26.60dB
25-05-17 13:14:54.774 : -158--> stadium_111_01.jpg | 26.45dB
25-05-17 13:14:54.952 : -159--> stadium_111_10.jpg | 27.94dB
25-05-17 13:14:55.136 : -160--> stadium_111_11.jpg | 26.55dB
25-05-17 13:14:55.315 : -161--> storage_tank_111_00.jpg | 28.70dB
25-05-17 13:14:55.502 : -162--> storage_tank_111_01.jpg | 28.78dB
25-05-17 13:14:55.680 : -163--> storage_tank_111_10.jpg | 27.53dB
25-05-17 13:14:55.859 : -164--> storage_tank_111_11.jpg | 28.03dB
25-05-17 13:14:56.042 : -165--> tennis_court_111_00.jpg | 29.03dB
25-05-17 13:14:56.222 : -166--> tennis_court_111_01.jpg | 28.66dB
25-05-17 13:14:56.399 : -167--> tennis_court_111_10.jpg | 28.66dB
25-05-17 13:14:56.581 : -168--> tennis_court_111_11.jpg | 26.65dB
25-05-17 13:14:56.764 : -169--> terrace_111_00.jpg | 29.23dB
25-05-17 13:14:56.940 : -170--> terrace_111_01.jpg | 30.20dB
25-05-17 13:14:57.120 : -171--> terrace_111_10.jpg | 28.99dB
25-05-17 13:14:57.300 : -172--> terrace_111_11.jpg | 29.17dB
25-05-17 13:14:57.490 : -173--> thermal_power_station_111_00.jpg | 26.75dB
25-05-17 13:14:57.671 : -174--> thermal_power_station_111_01.jpg | 28.14dB
25-05-17 13:14:57.853 : -175--> thermal_power_station_111_10.jpg | 26.27dB
25-05-17 13:14:58.033 : -176--> thermal_power_station_111_11.jpg | 26.80dB
25-05-17 13:14:58.217 : -177--> wetland_111_00.jpg | 28.55dB
25-05-17 13:14:58.399 : -178--> wetland_111_01.jpg | 28.65dB
25-05-17 13:14:58.584 : -179--> wetland_111_10.jpg | 28.90dB
25-05-17 13:14:58.763 : -180--> wetland_111_11.jpg | 28.05dB
25-05-17 13:14:58.772 : <epoch:  0, iter:  65,000, Average PSNR : 29.03dB

25-05-17 14:37:20.552 : <epoch:  0, iter:  70,000, lr:2.500e-05> G_loss: 1.814e-04 
25-05-17 14:37:20.553 : Saving the model.
25-05-17 14:37:21.188 : ---1--> airplane_111_00.jpg | 27.00dB
25-05-17 14:37:21.376 : ---2--> airplane_111_01.jpg | 32.31dB
25-05-17 14:37:21.556 : ---3--> airplane_111_10.jpg | 29.85dB
25-05-17 14:37:21.734 : ---4--> airplane_111_11.jpg | 30.04dB
25-05-17 14:37:21.916 : ---5--> airport_111_00.jpg | 31.75dB
25-05-17 14:37:22.094 : ---6--> airport_111_01.jpg | 29.47dB
25-05-17 14:37:22.274 : ---7--> airport_111_10.jpg | 28.79dB
25-05-17 14:37:22.457 : ---8--> airport_111_11.jpg | 29.78dB
25-05-17 14:37:22.635 : ---9--> baseball_diamond_111_00.jpg | 29.65dB
25-05-17 14:37:22.815 : --10--> baseball_diamond_111_01.jpg | 31.56dB
25-05-17 14:37:22.997 : --11--> baseball_diamond_111_10.jpg | 29.53dB
25-05-17 14:37:23.174 : --12--> baseball_diamond_111_11.jpg | 32.76dB
25-05-17 14:37:23.356 : --13--> basketball_court_111_00.jpg | 27.25dB
25-05-17 14:37:23.534 : --14--> basketball_court_111_01.jpg | 26.92dB
25-05-17 14:37:23.713 : --15--> basketball_court_111_10.jpg | 30.34dB
25-05-17 14:37:23.898 : --16--> basketball_court_111_11.jpg | 28.45dB
25-05-17 14:37:24.080 : --17--> beach_111_00.jpg | 25.55dB
25-05-17 14:37:24.255 : --18--> beach_111_01.jpg | 28.67dB
25-05-17 14:37:24.438 : --19--> beach_111_10.jpg | 26.70dB
25-05-17 14:37:24.617 : --20--> beach_111_11.jpg | 31.82dB
25-05-17 14:37:24.795 : --21--> bridge_111_00.jpg | 38.52dB
25-05-17 14:37:24.975 : --22--> bridge_111_01.jpg | 31.18dB
25-05-17 14:37:25.154 : --23--> bridge_111_10.jpg | 29.97dB
25-05-17 14:37:25.333 : --24--> bridge_111_11.jpg | 33.65dB
25-05-17 14:37:25.518 : --25--> chaparral_111_00.jpg | 27.24dB
25-05-17 14:37:25.697 : --26--> chaparral_111_01.jpg | 27.60dB
25-05-17 14:37:25.875 : --27--> chaparral_111_10.jpg | 28.09dB
25-05-17 14:37:26.054 : --28--> chaparral_111_11.jpg | 25.07dB
25-05-17 14:37:26.236 : --29--> church_111_00.jpg | 28.39dB
25-05-17 14:37:26.414 : --30--> church_111_01.jpg | 27.17dB
25-05-17 14:37:26.591 : --31--> church_111_10.jpg | 31.51dB
25-05-17 14:37:26.767 : --32--> church_111_11.jpg | 26.96dB
25-05-17 14:37:26.951 : --33--> circular_farmland_111_00.jpg | 29.48dB
25-05-17 14:37:27.128 : --34--> circular_farmland_111_01.jpg | 30.79dB
25-05-17 14:37:27.306 : --35--> circular_farmland_111_10.jpg | 31.09dB
25-05-17 14:37:27.488 : --36--> circular_farmland_111_11.jpg | 31.46dB
25-05-17 14:37:27.669 : --37--> cloud_111_00.jpg | 37.90dB
25-05-17 14:37:27.845 : --38--> cloud_111_01.jpg | 33.78dB
25-05-17 14:37:28.021 : --39--> cloud_111_10.jpg | 33.37dB
25-05-17 14:37:28.206 : --40--> cloud_111_11.jpg | 33.64dB
25-05-17 14:37:28.382 : --41--> commercial_area_111_00.jpg | 30.35dB
25-05-17 14:37:28.564 : --42--> commercial_area_111_01.jpg | 28.81dB
25-05-17 14:37:28.745 : --43--> commercial_area_111_10.jpg | 29.83dB
25-05-17 14:37:28.921 : --44--> commercial_area_111_11.jpg | 29.54dB
25-05-17 14:37:29.109 : --45--> dense_residential_111_00.jpg | 26.61dB
25-05-17 14:37:29.289 : --46--> dense_residential_111_01.jpg | 25.71dB
25-05-17 14:37:29.463 : --47--> dense_residential_111_10.jpg | 26.13dB
25-05-17 14:37:29.641 : --48--> dense_residential_111_11.jpg | 25.97dB
25-05-17 14:37:29.818 : --49--> desert_111_00.jpg | 34.52dB
25-05-17 14:37:29.993 : --50--> desert_111_01.jpg | 34.04dB
25-05-17 14:37:30.174 : --51--> desert_111_10.jpg | 34.63dB
25-05-17 14:37:30.360 : --52--> desert_111_11.jpg | 34.55dB
25-05-17 14:37:30.535 : --53--> forest_111_00.jpg | 30.36dB
25-05-17 14:37:30.718 : --54--> forest_111_01.jpg | 29.36dB
25-05-17 14:37:30.893 : --55--> forest_111_10.jpg | 28.68dB
25-05-17 14:37:31.077 : --56--> forest_111_11.jpg | 29.96dB
25-05-17 14:37:31.259 : --57--> freeway_111_00.jpg | 31.25dB
25-05-17 14:37:31.434 : --58--> freeway_111_01.jpg | 32.12dB
25-05-17 14:37:31.614 : --59--> freeway_111_10.jpg | 32.11dB
25-05-17 14:37:31.793 : --60--> freeway_111_11.jpg | 32.26dB
25-05-17 14:37:31.975 : --61--> golf_course_111_00.jpg | 29.76dB
25-05-17 14:37:32.156 : --62--> golf_course_111_01.jpg | 28.73dB
25-05-17 14:37:32.340 : --63--> golf_course_111_10.jpg | 30.57dB
25-05-17 14:37:32.517 : --64--> golf_course_111_11.jpg | 30.93dB
25-05-17 14:37:32.694 : --65--> ground_track_field_111_00.jpg | 30.02dB
25-05-17 14:37:32.873 : --66--> ground_track_field_111_01.jpg | 25.85dB
25-05-17 14:37:33.051 : --67--> ground_track_field_111_10.jpg | 27.50dB
25-05-17 14:37:33.233 : --68--> ground_track_field_111_11.jpg | 26.57dB
25-05-17 14:37:33.411 : --69--> harbor_111_00.jpg | 30.82dB
25-05-17 14:37:33.594 : --70--> harbor_111_01.jpg | 28.14dB
25-05-17 14:37:33.779 : --71--> harbor_111_10.jpg | 27.45dB
25-05-17 14:37:33.961 : --72--> harbor_111_11.jpg | 29.35dB
25-05-17 14:37:34.135 : --73--> industrial_area_111_00.jpg | 28.69dB
25-05-17 14:37:34.313 : --74--> industrial_area_111_01.jpg | 28.34dB
25-05-17 14:37:34.493 : --75--> industrial_area_111_10.jpg | 28.72dB
25-05-17 14:37:34.674 : --76--> industrial_area_111_11.jpg | 27.95dB
25-05-17 14:37:34.856 : --77--> intersection_111_00.jpg | 27.38dB
25-05-17 14:37:35.031 : --78--> intersection_111_01.jpg | 27.46dB
25-05-17 14:37:35.208 : --79--> intersection_111_10.jpg | 26.98dB
25-05-17 14:37:35.384 : --80--> intersection_111_11.jpg | 26.79dB
25-05-17 14:37:35.563 : --81--> island_111_00.jpg | 28.21dB
25-05-17 14:37:35.749 : --82--> island_111_01.jpg | 30.74dB
25-05-17 14:37:35.927 : --83--> island_111_10.jpg | 29.22dB
25-05-17 14:37:36.113 : --84--> island_111_11.jpg | 28.80dB
25-05-17 14:37:36.288 : --85--> lake_111_00.jpg | 30.03dB
25-05-17 14:37:36.471 : --86--> lake_111_01.jpg | 29.84dB
25-05-17 14:37:36.651 : --87--> lake_111_10.jpg | 28.76dB
25-05-17 14:37:36.828 : --88--> lake_111_11.jpg | 28.36dB
25-05-17 14:37:37.007 : --89--> meadow_111_00.jpg | 27.28dB
25-05-17 14:37:37.186 : --90--> meadow_111_01.jpg | 27.28dB
25-05-17 14:37:37.369 : --91--> meadow_111_10.jpg | 27.48dB
25-05-17 14:37:37.559 : --92--> meadow_111_11.jpg | 27.59dB
25-05-17 14:37:37.738 : --93--> medium_residential_111_00.jpg | 25.13dB
25-05-17 14:37:37.923 : --94--> medium_residential_111_01.jpg | 24.56dB
25-05-17 14:37:38.097 : --95--> medium_residential_111_10.jpg | 24.96dB
25-05-17 14:37:38.279 : --96--> medium_residential_111_11.jpg | 25.51dB
25-05-17 14:37:38.461 : --97--> mobile_home_park_111_00.jpg | 27.36dB
25-05-17 14:37:38.635 : --98--> mobile_home_park_111_01.jpg | 27.90dB
25-05-17 14:37:38.814 : --99--> mobile_home_park_111_10.jpg | 28.34dB
25-05-17 14:37:38.996 : -100--> mobile_home_park_111_11.jpg | 28.21dB
25-05-17 14:37:39.174 : -101--> mountain_111_00.jpg | 25.51dB
25-05-17 14:37:39.359 : -102--> mountain_111_01.jpg | 26.44dB
25-05-17 14:37:39.542 : -103--> mountain_111_10.jpg | 26.05dB
25-05-17 14:37:39.726 : -104--> mountain_111_11.jpg | 26.54dB
25-05-17 14:37:39.905 : -105--> overpass_111_00.jpg | 27.02dB
25-05-17 14:37:40.084 : -106--> overpass_111_01.jpg | 26.76dB
25-05-17 14:37:40.263 : -107--> overpass_111_10.jpg | 27.66dB
25-05-17 14:37:40.443 : -108--> overpass_111_11.jpg | 28.19dB
25-05-17 14:37:40.625 : -109--> palace_111_00.jpg | 26.53dB
25-05-17 14:37:40.805 : -110--> palace_111_01.jpg | 26.33dB
25-05-17 14:37:40.984 : -111--> palace_111_10.jpg | 27.87dB
25-05-17 14:37:41.158 : -112--> palace_111_11.jpg | 25.94dB
25-05-17 14:37:41.341 : -113--> parking_lot_111_00.jpg | 25.47dB
25-05-17 14:37:41.524 : -114--> parking_lot_111_01.jpg | 25.68dB
25-05-17 14:37:41.705 : -115--> parking_lot_111_10.jpg | 27.77dB
25-05-17 14:37:41.884 : -116--> parking_lot_111_11.jpg | 26.54dB
25-05-17 14:37:42.065 : -117--> railway_111_00.jpg | 27.11dB
25-05-17 14:37:42.245 : -118--> railway_111_01.jpg | 26.63dB
25-05-17 14:37:42.422 : -119--> railway_111_10.jpg | 29.83dB
25-05-17 14:37:42.604 : -120--> railway_111_11.jpg | 25.60dB
25-05-17 14:37:42.780 : -121--> railway_station_111_00.jpg | 27.70dB
25-05-17 14:37:42.960 : -122--> railway_station_111_01.jpg | 28.63dB
25-05-17 14:37:43.145 : -123--> railway_station_111_10.jpg | 27.97dB
25-05-17 14:37:43.320 : -124--> railway_station_111_11.jpg | 28.70dB
25-05-17 14:37:43.504 : -125--> rectangular_farmland_111_00.jpg | 30.38dB
25-05-17 14:37:43.684 : -126--> rectangular_farmland_111_01.jpg | 28.61dB
25-05-17 14:37:43.861 : -127--> rectangular_farmland_111_10.jpg | 30.69dB
25-05-17 14:37:44.044 : -128--> rectangular_farmland_111_11.jpg | 31.05dB
25-05-17 14:37:44.228 : -129--> river_111_00.jpg | 26.91dB
25-05-17 14:37:44.403 : -130--> river_111_01.jpg | 26.91dB
25-05-17 14:37:44.585 : -131--> river_111_10.jpg | 26.03dB
25-05-17 14:37:44.765 : -132--> river_111_11.jpg | 28.12dB
25-05-17 14:37:44.945 : -133--> roundabout_111_00.jpg | 27.24dB
25-05-17 14:37:45.123 : -134--> roundabout_111_01.jpg | 29.12dB
25-05-17 14:37:45.298 : -135--> roundabout_111_10.jpg | 27.23dB
25-05-17 14:37:45.476 : -136--> roundabout_111_11.jpg | 27.56dB
25-05-17 14:37:45.654 : -137--> runway_111_00.jpg | 33.61dB
25-05-17 14:37:45.831 : -138--> runway_111_01.jpg | 32.98dB
25-05-17 14:37:46.014 : -139--> runway_111_10.jpg | 34.16dB
25-05-17 14:37:46.193 : -140--> runway_111_11.jpg | 34.26dB
25-05-17 14:37:46.373 : -141--> sea_ice_111_00.jpg | 30.34dB
25-05-17 14:37:46.554 : -142--> sea_ice_111_01.jpg | 31.21dB
25-05-17 14:37:46.740 : -143--> sea_ice_111_10.jpg | 30.31dB
25-05-17 14:37:46.923 : -144--> sea_ice_111_11.jpg | 31.51dB
25-05-17 14:37:47.104 : -145--> ship_111_00.jpg | 35.66dB
25-05-17 14:37:47.283 : -146--> ship_111_01.jpg | 31.18dB
25-05-17 14:37:47.461 : -147--> ship_111_10.jpg | 40.79dB
25-05-17 14:37:47.638 : -148--> ship_111_11.jpg | 36.57dB
25-05-17 14:37:47.816 : -149--> snowberg_111_00.jpg | 30.63dB
25-05-17 14:37:47.993 : -150--> snowberg_111_01.jpg | 29.31dB
25-05-17 14:37:48.171 : -151--> snowberg_111_10.jpg | 28.47dB
25-05-17 14:37:48.354 : -152--> snowberg_111_11.jpg | 28.51dB
25-05-17 14:37:48.544 : -153--> sparse_residential_111_00.jpg | 27.25dB
25-05-17 14:37:48.719 : -154--> sparse_residential_111_01.jpg | 27.90dB
25-05-17 14:37:48.902 : -155--> sparse_residential_111_10.jpg | 26.27dB
25-05-17 14:37:49.081 : -156--> sparse_residential_111_11.jpg | 26.90dB
25-05-17 14:37:49.264 : -157--> stadium_111_00.jpg | 26.60dB
25-05-17 14:37:49.445 : -158--> stadium_111_01.jpg | 26.46dB
25-05-17 14:37:49.624 : -159--> stadium_111_10.jpg | 27.93dB
25-05-17 14:37:49.804 : -160--> stadium_111_11.jpg | 26.55dB
25-05-17 14:37:49.985 : -161--> storage_tank_111_00.jpg | 28.67dB
25-05-17 14:37:50.163 : -162--> storage_tank_111_01.jpg | 28.77dB
25-05-17 14:37:50.345 : -163--> storage_tank_111_10.jpg | 27.53dB
25-05-17 14:37:50.521 : -164--> storage_tank_111_11.jpg | 28.05dB
25-05-17 14:37:50.705 : -165--> tennis_court_111_00.jpg | 29.00dB
25-05-17 14:37:50.880 : -166--> tennis_court_111_01.jpg | 28.65dB
25-05-17 14:37:51.058 : -167--> tennis_court_111_10.jpg | 28.64dB
25-05-17 14:37:51.242 : -168--> tennis_court_111_11.jpg | 26.65dB
25-05-17 14:37:51.418 : -169--> terrace_111_00.jpg | 29.24dB
25-05-17 14:37:51.595 : -170--> terrace_111_01.jpg | 30.21dB
25-05-17 14:37:51.777 : -171--> terrace_111_10.jpg | 28.99dB
25-05-17 14:37:51.956 : -172--> terrace_111_11.jpg | 29.19dB
25-05-17 14:37:52.135 : -173--> thermal_power_station_111_00.jpg | 26.75dB
25-05-17 14:37:52.312 : -174--> thermal_power_station_111_01.jpg | 28.13dB
25-05-17 14:37:52.490 : -175--> thermal_power_station_111_10.jpg | 26.25dB
25-05-17 14:37:52.664 : -176--> thermal_power_station_111_11.jpg | 26.81dB
25-05-17 14:37:52.843 : -177--> wetland_111_00.jpg | 28.55dB
25-05-17 14:37:53.030 : -178--> wetland_111_01.jpg | 28.68dB
25-05-17 14:37:53.212 : -179--> wetland_111_10.jpg | 28.89dB
25-05-17 14:37:53.392 : -180--> wetland_111_11.jpg | 28.07dB
25-05-17 14:37:53.401 : <epoch:  0, iter:  70,000, Average PSNR : 29.03dB

25-05-17 17:54:49.683 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/10_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 15
      sigma_test: 15
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test_4fen
      dataroot_L: None
      sigma: 15
      sigma_test: 15
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [30000, 50000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-17 17:54:49.684 : Random seed: 8443
25-05-17 17:54:49.822 : Number of train images: 31,005, iters: 31,005
25-05-17 17:54:50.616 : 
Networks name: DRNet
Params number: 17746115
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-17 17:54:50.947 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.002 | -0.400 |  0.464 |  0.168 | torch.Size([64, 3, 3, 3]) || head1.weight
 | -0.000 | -0.351 |  0.305 |  0.202 | torch.Size([64]) || head1.bias
 |  0.000 | -0.482 |  0.433 |  0.092 | torch.Size([64, 64, 3, 3]) || head1_1.body.0.weight
 |  0.087 | -0.085 |  0.223 |  0.072 | torch.Size([64]) || head1_1.body.0.bias
 | -0.000 | -0.527 |  0.578 |  0.082 | torch.Size([64, 64, 3, 3]) || head1_1.body.2.weight
 |  0.010 | -0.107 |  0.128 |  0.056 | torch.Size([64]) || head1_1.body.2.bias
 |  0.000 | -0.316 |  0.326 |  0.059 | torch.Size([768, 256]) || head1_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.001 | -0.351 |  0.310 |  0.067 | torch.Size([256, 256]) || head1_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.303 |  0.290 |  0.058 | torch.Size([1024, 256]) || head1_3.encoder.layers.0.linear1.weight
 | -0.021 | -0.166 |  0.098 |  0.042 | torch.Size([1024]) || head1_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.435 |  0.378 |  0.048 | torch.Size([256, 1024]) || head1_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.076 |  0.081 |  0.030 | torch.Size([256]) || head1_3.encoder.layers.0.linear2.bias
 |  1.017 |  0.750 |  1.210 |  0.068 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.weight
 |  0.005 | -0.191 |  0.313 |  0.059 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.bias
 |  1.108 |  0.979 |  1.291 |  0.059 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.weight
 |  0.002 | -0.080 |  0.095 |  0.032 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || head1_3.position_encoding.position_ids
 |  0.000 | -5.337 |  4.745 |  0.991 | torch.Size([4096, 256]) || head1_3.position_encoding.pe.weight
 |  0.000 | -0.958 |  1.005 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.0.weight
 |  0.027 | -0.103 |  0.115 |  0.044 | torch.Size([64]) || body1_1.0.body.0.bias
 | -0.001 | -0.356 |  0.378 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.2.weight
 | -0.015 | -0.140 |  0.115 |  0.064 | torch.Size([64]) || body1_1.0.body.2.bias
 | -0.001 | -0.492 |  0.465 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.1.weight
 |  0.048 | -0.053 |  0.156 |  0.047 | torch.Size([64]) || body1_1.1.bias
 |  0.000 | -0.176 |  0.185 |  0.041 | torch.Size([768, 256]) || body1_2.0.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.154 |  0.146 |  0.037 | torch.Size([256, 256]) || body1_2.0.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.293 |  0.246 |  0.043 | torch.Size([1024, 256]) || body1_2.0.encoder.layers.0.linear1.weight
 |  0.003 | -0.073 |  0.100 |  0.038 | torch.Size([1024]) || body1_2.0.encoder.layers.0.linear1.bias
 | -0.003 | -0.256 |  0.208 |  0.028 | torch.Size([256, 1024]) || body1_2.0.encoder.layers.0.linear2.weight
 | -0.007 | -0.058 |  0.043 |  0.021 | torch.Size([256]) || body1_2.0.encoder.layers.0.linear2.bias
 |  0.994 |  0.811 |  1.133 |  0.066 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.weight
 |  0.008 | -0.136 |  0.148 |  0.065 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.bias
 |  0.998 |  0.796 |  1.190 |  0.059 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.weight
 |  0.011 | -0.237 |  0.254 |  0.087 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body1_2.0.position_encoding.position_ids
 |  0.001 | -4.538 |  4.876 |  0.995 | torch.Size([4096, 256]) || body1_2.0.position_encoding.pe.weight
 | -0.001 | -0.290 |  0.225 |  0.037 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.0.weight
 |  0.003 | -0.101 |  0.085 |  0.033 | torch.Size([64]) || body1_2.1.body.0.bias
 | -0.005 | -0.262 |  0.283 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.2.weight
 | -0.016 | -0.103 |  0.047 |  0.033 | torch.Size([64]) || body1_2.1.body.2.bias
 |  0.000 | -0.279 |  0.261 |  0.050 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.0.weight
 |  0.013 | -0.113 |  0.116 |  0.046 | torch.Size([64]) || body2_1.0.body.0.bias
 | -0.000 | -0.281 |  0.422 |  0.048 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.2.weight
 | -0.005 | -0.138 |  0.157 |  0.075 | torch.Size([64]) || body2_1.0.body.2.bias
 |  0.000 | -0.330 |  0.370 |  0.060 | torch.Size([768, 256]) || body2_1.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.317 |  0.352 |  0.070 | torch.Size([256, 256]) || body2_1.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.293 |  0.304 |  0.060 | torch.Size([1024, 256]) || body2_1.1.encoder.layers.0.linear1.weight
 |  0.011 | -0.126 |  0.131 |  0.042 | torch.Size([1024]) || body2_1.1.encoder.layers.0.linear1.bias
 | -0.000 | -0.270 |  0.277 |  0.049 | torch.Size([256, 1024]) || body2_1.1.encoder.layers.0.linear2.weight
 | -0.001 | -0.069 |  0.074 |  0.031 | torch.Size([256]) || body2_1.1.encoder.layers.0.linear2.bias
 |  1.068 |  0.931 |  1.207 |  0.049 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.weight
 |  0.003 | -0.148 |  0.164 |  0.069 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.bias
 |  1.196 |  1.020 |  1.407 |  0.074 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.114 |  0.114 |  0.033 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_1.1.position_encoding.position_ids
 | -0.001 | -4.994 |  4.878 |  0.999 | torch.Size([4096, 256]) || body2_1.1.position_encoding.pe.weight
 | -0.003 | -0.327 |  0.332 |  0.110 | torch.Size([128, 1, 5, 5]) || fusion2_1.0.weight
 |  0.015 | -0.267 |  0.256 |  0.121 | torch.Size([128]) || fusion2_1.0.bias
 |  0.000 | -0.212 |  0.224 |  0.053 | torch.Size([64, 128, 1, 1]) || fusion2_1.1.weight
 | -0.005 | -0.175 |  0.159 |  0.088 | torch.Size([64]) || fusion2_1.1.bias
 |  0.002 | -0.196 |  0.225 |  0.044 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.0.weight
 |  0.002 | -0.143 |  0.223 |  0.083 | torch.Size([64]) || body2_2.0.body.0.bias
 |  0.000 | -0.213 |  0.234 |  0.043 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.2.weight
 | -0.004 | -0.229 |  0.209 |  0.105 | torch.Size([64]) || body2_2.0.body.2.bias
 | -0.000 | -0.420 |  0.343 |  0.065 | torch.Size([768, 256]) || body2_2.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.344 |  0.378 |  0.081 | torch.Size([256, 256]) || body2_2.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.248 |  0.265 |  0.060 | torch.Size([1024, 256]) || body2_2.1.encoder.layers.0.linear1.weight
 | -0.001 | -0.155 |  0.139 |  0.052 | torch.Size([1024]) || body2_2.1.encoder.layers.0.linear1.bias
 |  0.000 | -0.248 |  0.289 |  0.049 | torch.Size([256, 1024]) || body2_2.1.encoder.layers.0.linear2.weight
 |  0.002 | -0.052 |  0.056 |  0.024 | torch.Size([256]) || body2_2.1.encoder.layers.0.linear2.bias
 |  1.103 |  0.943 |  1.259 |  0.051 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.weight
 |  0.001 | -0.181 |  0.208 |  0.079 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.bias
 |  1.150 |  0.962 |  1.314 |  0.054 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.118 |  0.100 |  0.036 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_2.1.position_encoding.position_ids
 | -0.001 | -4.834 |  4.669 |  0.998 | torch.Size([4096, 256]) || body2_2.1.position_encoding.pe.weight
 | -0.000 | -0.307 |  0.378 |  0.104 | torch.Size([128, 1, 5, 5]) || fusion2_2.0.weight
 | -0.015 | -0.208 |  0.214 |  0.116 | torch.Size([128]) || fusion2_2.0.bias
 | -0.001 | -0.230 |  0.256 |  0.058 | torch.Size([64, 128, 1, 1]) || fusion2_2.1.weight
 | -0.019 | -0.150 |  0.151 |  0.065 | torch.Size([64]) || fusion2_2.1.bias
 | -0.000 | -0.245 |  0.238 |  0.053 | torch.Size([768, 256]) || body2_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.250 |  0.242 |  0.057 | torch.Size([256, 256]) || body2_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.223 |  0.233 |  0.051 | torch.Size([1024, 256]) || body2_3.encoder.layers.0.linear1.weight
 | -0.029 | -0.146 |  0.089 |  0.041 | torch.Size([1024]) || body2_3.encoder.layers.0.linear1.bias
 | -0.000 | -0.200 |  0.196 |  0.039 | torch.Size([256, 1024]) || body2_3.encoder.layers.0.linear2.weight
 |  0.002 | -0.050 |  0.074 |  0.022 | torch.Size([256]) || body2_3.encoder.layers.0.linear2.bias
 |  1.054 |  0.948 |  1.182 |  0.041 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.132 |  0.174 |  0.051 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.bias
 |  1.018 |  0.884 |  1.172 |  0.046 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.092 |  0.077 |  0.029 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_3.position_encoding.position_ids
 | -0.000 | -4.715 |  5.524 |  0.998 | torch.Size([4096, 256]) || body2_3.position_encoding.pe.weight
 |  0.000 | -0.251 |  0.226 |  0.039 | torch.Size([64, 64, 3, 3]) || body3_1.0.weight
 |  0.018 | -0.061 |  0.069 |  0.031 | torch.Size([64]) || body3_1.0.bias
 |  0.000 | -0.184 |  0.181 |  0.039 | torch.Size([768, 256]) || body3_1.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.162 |  0.171 |  0.040 | torch.Size([256, 256]) || body3_1.2.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.281 |  0.240 |  0.047 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.0.linear1.weight
 | -0.010 | -0.101 |  0.096 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.0.linear1.bias
 | -0.003 | -0.280 |  0.293 |  0.033 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.0.linear2.weight
 | -0.006 | -0.068 |  0.071 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.linear2.bias
 |  1.000 |  0.917 |  1.085 |  0.027 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.090 |  0.084 |  0.031 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.bias
 |  1.105 |  0.988 |  1.243 |  0.048 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.weight
 |  0.002 | -0.074 |  0.093 |  0.035 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.154 |  0.162 |  0.038 | torch.Size([768, 256]) || body3_1.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.136 |  0.129 |  0.038 | torch.Size([256, 256]) || body3_1.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.329 |  0.286 |  0.046 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.1.linear1.weight
 | -0.007 | -0.094 |  0.088 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.1.linear1.bias
 | -0.002 | -0.356 |  0.414 |  0.032 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.1.linear2.weight
 | -0.007 | -0.063 |  0.044 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.linear2.bias
 |  0.997 |  0.948 |  1.119 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.weight
 | -0.001 | -0.063 |  0.070 |  0.027 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.bias
 |  1.122 |  0.992 |  1.276 |  0.048 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.weight
 |  0.000 | -0.057 |  0.053 |  0.023 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_1.2.position_encoding.position_ids
 |  0.002 | -4.658 |  4.616 |  1.000 | torch.Size([4096, 256]) || body3_1.2.position_encoding.pe.weight
 |  0.001 | -0.197 |  0.198 |  0.068 | torch.Size([128, 1, 5, 5]) || fusion3_1.0.weight
 |  0.007 | -0.232 |  0.245 |  0.122 | torch.Size([128]) || fusion3_1.0.bias
 | -0.000 | -0.123 |  0.128 |  0.024 | torch.Size([64, 128, 1, 1]) || fusion3_1.1.weight
 | -0.008 | -0.189 |  0.160 |  0.088 | torch.Size([64]) || fusion3_1.1.bias
 | -0.000 | -0.116 |  0.117 |  0.024 | torch.Size([64, 64, 3, 3]) || body3_2.0.weight
 |  0.058 | -0.105 |  0.119 |  0.037 | torch.Size([64]) || body3_2.0.bias
 |  0.000 | -0.144 |  0.126 |  0.040 | torch.Size([768, 256]) || body3_2.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.111 |  0.110 |  0.037 | torch.Size([256, 256]) || body3_2.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.198 |  0.201 |  0.051 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.0.linear1.weight
 | -0.043 | -0.134 |  0.061 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.162 |  0.153 |  0.037 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.0.linear2.weight
 | -0.008 | -0.062 |  0.039 |  0.022 | torch.Size([256]) || body3_2.2.encoder.layers.0.linear2.bias
 |  0.997 |  0.834 |  1.076 |  0.031 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.120 |  0.179 |  0.044 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.bias
 |  1.050 |  0.924 |  1.200 |  0.046 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.weight
 | -0.001 | -0.150 |  0.103 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.109 |  0.115 |  0.038 | torch.Size([768, 256]) || body3_2.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.118 |  0.105 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.194 |  0.184 |  0.049 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.1.linear1.weight
 | -0.026 | -0.111 |  0.087 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.1.linear1.bias
 | -0.001 | -0.152 |  0.163 |  0.036 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.1.linear2.weight
 | -0.008 | -0.066 |  0.049 |  0.024 | torch.Size([256]) || body3_2.2.encoder.layers.1.linear2.bias
 |  0.987 |  0.917 |  1.035 |  0.020 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.weight
 | -0.000 | -0.105 |  0.115 |  0.045 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.bias
 |  1.059 |  0.954 |  1.150 |  0.036 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.weight
 | -0.000 | -0.052 |  0.056 |  0.020 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_2.2.position_encoding.position_ids
 |  0.001 | -5.085 |  5.020 |  1.000 | torch.Size([4096, 256]) || body3_2.2.position_encoding.pe.weight
 |  0.003 | -0.233 |  0.260 |  0.091 | torch.Size([128, 1, 5, 5]) || fusion3_2.0.weight
 |  0.002 | -0.197 |  0.229 |  0.105 | torch.Size([128]) || fusion3_2.0.bias
 |  0.001 | -0.155 |  0.160 |  0.049 | torch.Size([64, 128, 1, 1]) || fusion3_2.1.weight
 |  0.005 | -0.086 |  0.118 |  0.048 | torch.Size([64]) || fusion3_2.1.bias
 | -0.001 | -0.214 |  0.196 |  0.049 | torch.Size([256, 256]) || body3_3.linear_encoding.weight
 | -0.004 | -0.135 |  0.147 |  0.062 | torch.Size([256]) || body3_3.linear_encoding.bias
 | -0.000 | -0.218 |  0.196 |  0.045 | torch.Size([1024, 256]) || body3_3.mlp_head.0.weight
 | -0.027 | -0.127 |  0.061 |  0.038 | torch.Size([1024]) || body3_3.mlp_head.0.bias
 | -0.000 | -0.214 |  0.176 |  0.032 | torch.Size([256, 1024]) || body3_3.mlp_head.3.weight
 |  0.002 | -0.090 |  0.075 |  0.029 | torch.Size([256]) || body3_3.mlp_head.3.bias
 |  0.000 | -0.131 |  0.139 |  0.039 | torch.Size([768, 256]) || body3_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.147 |  0.143 |  0.037 | torch.Size([256, 256]) || body3_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.194 |  0.191 |  0.044 | torch.Size([1024, 256]) || body3_3.encoder.layers.0.linear1.weight
 | -0.036 | -0.133 |  0.065 |  0.036 | torch.Size([1024]) || body3_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.180 |  0.228 |  0.031 | torch.Size([256, 1024]) || body3_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.071 |  0.072 |  0.025 | torch.Size([256]) || body3_3.encoder.layers.0.linear2.bias
 |  0.925 |  0.831 |  1.021 |  0.028 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.082 |  0.113 |  0.034 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.bias
 |  0.864 |  0.783 |  1.020 |  0.039 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.weight
 | -0.000 | -0.180 |  0.182 |  0.061 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.bias
 | -0.000 | -0.157 |  0.172 |  0.044 | torch.Size([192, 1, 5, 5]) || fusion3_3.0.weight
 |  0.004 | -0.182 |  0.218 |  0.080 | torch.Size([192]) || fusion3_3.0.bias
 |  0.000 | -0.120 |  0.118 |  0.023 | torch.Size([64, 192, 1, 1]) || fusion3_3.1.weight
 | -0.003 | -0.045 |  0.033 |  0.020 | torch.Size([64]) || fusion3_3.1.bias
 | -0.001 | -0.480 |  0.140 |  0.037 | torch.Size([256, 256]) || body3_4.linear_encoding.weight
 |  0.004 | -0.073 |  0.110 |  0.028 | torch.Size([256]) || body3_4.linear_encoding.bias
 | -0.001 | -0.257 |  0.263 |  0.046 | torch.Size([1024, 256]) || body3_4.mlp_head.0.weight
 | -0.053 | -0.174 |  0.068 |  0.038 | torch.Size([1024]) || body3_4.mlp_head.0.bias
 | -0.000 | -0.252 |  0.271 |  0.029 | torch.Size([256, 1024]) || body3_4.mlp_head.3.weight
 | -0.004 | -0.137 |  0.108 |  0.039 | torch.Size([256]) || body3_4.mlp_head.3.bias
 | -0.000 | -0.214 |  0.228 |  0.044 | torch.Size([768, 256]) || body3_4.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.146 |  0.139 |  0.034 | torch.Size([256, 256]) || body3_4.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.209 |  0.203 |  0.039 | torch.Size([1024, 256]) || body3_4.encoder.layers.0.linear1.weight
 | -0.040 | -0.150 |  0.055 |  0.037 | torch.Size([1024]) || body3_4.encoder.layers.0.linear1.bias
 |  0.000 | -0.210 |  0.179 |  0.022 | torch.Size([256, 1024]) || body3_4.encoder.layers.0.linear2.weight
 |  0.001 | -0.076 |  0.070 |  0.026 | torch.Size([256]) || body3_4.encoder.layers.0.linear2.bias
 |  0.795 |  0.637 |  0.949 |  0.067 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.weight
 | -0.001 | -0.196 |  0.147 |  0.060 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.bias
 |  0.777 |  0.452 |  1.063 |  0.105 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.weight
 |  0.000 | -0.210 |  0.199 |  0.087 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.bias
 |  0.000 | -0.058 |  0.059 |  0.012 | torch.Size([3, 64, 3, 3]) || tail.weight
 |  0.000 | -0.000 |  0.001 |  0.000 | torch.Size([3]) || tail.bias

25-05-17 19:15:00.582 : <epoch:  0, iter:   5,000, lr:1.000e-04> G_loss: 5.357e-05 
25-05-17 19:15:00.583 : Saving the model.
25-05-17 19:15:01.219 : ---1--> airplane_111_00.jpg | 33.14dB
25-05-17 19:15:01.401 : ---2--> airplane_111_01.jpg | 37.39dB
25-05-17 19:15:01.581 : ---3--> airplane_111_10.jpg | 35.25dB
25-05-17 19:15:01.764 : ---4--> airplane_111_11.jpg | 35.11dB
25-05-17 19:15:01.947 : ---5--> airport_111_00.jpg | 36.50dB
25-05-17 19:15:02.127 : ---6--> airport_111_01.jpg | 34.64dB
25-05-17 19:15:02.308 : ---7--> airport_111_10.jpg | 34.38dB
25-05-17 19:15:02.491 : ---8--> airport_111_11.jpg | 35.20dB
25-05-17 19:15:02.670 : ---9--> baseball_diamond_111_00.jpg | 35.09dB
25-05-17 19:15:02.853 : --10--> baseball_diamond_111_01.jpg | 36.44dB
25-05-17 19:15:03.030 : --11--> baseball_diamond_111_10.jpg | 34.78dB
25-05-17 19:15:03.203 : --12--> baseball_diamond_111_11.jpg | 37.35dB
25-05-17 19:15:03.385 : --13--> basketball_court_111_00.jpg | 33.26dB
25-05-17 19:15:03.567 : --14--> basketball_court_111_01.jpg | 32.86dB
25-05-17 19:15:03.748 : --15--> basketball_court_111_10.jpg | 35.74dB
25-05-17 19:15:03.930 : --16--> basketball_court_111_11.jpg | 34.30dB
25-05-17 19:15:04.114 : --17--> beach_111_00.jpg | 31.37dB
25-05-17 19:15:04.294 : --18--> beach_111_01.jpg | 34.30dB
25-05-17 19:15:04.476 : --19--> beach_111_10.jpg | 32.48dB
25-05-17 19:15:04.658 : --20--> beach_111_11.jpg | 36.54dB
25-05-17 19:15:04.841 : --21--> bridge_111_00.jpg | 42.50dB
25-05-17 19:15:05.019 : --22--> bridge_111_01.jpg | 36.49dB
25-05-17 19:15:05.203 : --23--> bridge_111_10.jpg | 35.56dB
25-05-17 19:15:05.388 : --24--> bridge_111_11.jpg | 38.78dB
25-05-17 19:15:05.565 : --25--> chaparral_111_00.jpg | 32.90dB
25-05-17 19:15:05.748 : --26--> chaparral_111_01.jpg | 33.25dB
25-05-17 19:15:05.928 : --27--> chaparral_111_10.jpg | 33.37dB
25-05-17 19:15:06.105 : --28--> chaparral_111_11.jpg | 31.63dB
25-05-17 19:15:06.284 : --29--> church_111_00.jpg | 34.06dB
25-05-17 19:15:06.465 : --30--> church_111_01.jpg | 33.16dB
25-05-17 19:15:06.643 : --31--> church_111_10.jpg | 36.50dB
25-05-17 19:15:06.820 : --32--> church_111_11.jpg | 32.98dB
25-05-17 19:15:07.003 : --33--> circular_farmland_111_00.jpg | 35.28dB
25-05-17 19:15:07.186 : --34--> circular_farmland_111_01.jpg | 36.05dB
25-05-17 19:15:07.364 : --35--> circular_farmland_111_10.jpg | 36.39dB
25-05-17 19:15:07.544 : --36--> circular_farmland_111_11.jpg | 36.36dB
25-05-17 19:15:07.723 : --37--> cloud_111_00.jpg | 43.09dB
25-05-17 19:15:07.905 : --38--> cloud_111_01.jpg | 38.96dB
25-05-17 19:15:08.085 : --39--> cloud_111_10.jpg | 38.60dB
25-05-17 19:15:08.264 : --40--> cloud_111_11.jpg | 38.92dB
25-05-17 19:15:08.452 : --41--> commercial_area_111_00.jpg | 35.82dB
25-05-17 19:15:08.630 : --42--> commercial_area_111_01.jpg | 34.98dB
25-05-17 19:15:08.815 : --43--> commercial_area_111_10.jpg | 35.69dB
25-05-17 19:15:09.000 : --44--> commercial_area_111_11.jpg | 35.57dB
25-05-17 19:15:09.176 : --45--> dense_residential_111_00.jpg | 32.68dB
25-05-17 19:15:09.360 : --46--> dense_residential_111_01.jpg | 31.98dB
25-05-17 19:15:09.545 : --47--> dense_residential_111_10.jpg | 32.29dB
25-05-17 19:15:09.727 : --48--> dense_residential_111_11.jpg | 32.15dB
25-05-17 19:15:09.913 : --49--> desert_111_00.jpg | 38.68dB
25-05-17 19:15:10.090 : --50--> desert_111_01.jpg | 38.71dB
25-05-17 19:15:10.265 : --51--> desert_111_10.jpg | 38.88dB
25-05-17 19:15:10.441 : --52--> desert_111_11.jpg | 39.04dB
25-05-17 19:15:10.614 : --53--> forest_111_00.jpg | 35.26dB
25-05-17 19:15:10.795 : --54--> forest_111_01.jpg | 34.39dB
25-05-17 19:15:10.973 : --55--> forest_111_10.jpg | 34.15dB
25-05-17 19:15:11.148 : --56--> forest_111_11.jpg | 34.93dB
25-05-17 19:15:11.324 : --57--> freeway_111_00.jpg | 36.00dB
25-05-17 19:15:11.514 : --58--> freeway_111_01.jpg | 36.54dB
25-05-17 19:15:11.692 : --59--> freeway_111_10.jpg | 36.35dB
25-05-17 19:15:11.874 : --60--> freeway_111_11.jpg | 36.62dB
25-05-17 19:15:12.052 : --61--> golf_course_111_00.jpg | 35.07dB
25-05-17 19:15:12.228 : --62--> golf_course_111_01.jpg | 34.66dB
25-05-17 19:15:12.405 : --63--> golf_course_111_10.jpg | 35.74dB
25-05-17 19:15:12.583 : --64--> golf_course_111_11.jpg | 36.20dB
25-05-17 19:15:12.761 : --65--> ground_track_field_111_00.jpg | 35.63dB
25-05-17 19:15:12.941 : --66--> ground_track_field_111_01.jpg | 32.14dB
25-05-17 19:15:13.119 : --67--> ground_track_field_111_10.jpg | 33.29dB
25-05-17 19:15:13.294 : --68--> ground_track_field_111_11.jpg | 32.64dB
25-05-17 19:15:13.480 : --69--> harbor_111_00.jpg | 34.77dB
25-05-17 19:15:13.662 : --70--> harbor_111_01.jpg | 33.54dB
25-05-17 19:15:13.843 : --71--> harbor_111_10.jpg | 33.34dB
25-05-17 19:15:14.020 : --72--> harbor_111_11.jpg | 34.84dB
25-05-17 19:15:14.204 : --73--> industrial_area_111_00.jpg | 33.84dB
25-05-17 19:15:14.384 : --74--> industrial_area_111_01.jpg | 34.20dB
25-05-17 19:15:14.572 : --75--> industrial_area_111_10.jpg | 34.19dB
25-05-17 19:15:14.752 : --76--> industrial_area_111_11.jpg | 33.77dB
25-05-17 19:15:14.935 : --77--> intersection_111_00.jpg | 33.15dB
25-05-17 19:15:15.113 : --78--> intersection_111_01.jpg | 33.27dB
25-05-17 19:15:15.292 : --79--> intersection_111_10.jpg | 33.05dB
25-05-17 19:15:15.467 : --80--> intersection_111_11.jpg | 32.83dB
25-05-17 19:15:15.641 : --81--> island_111_00.jpg | 34.04dB
25-05-17 19:15:15.819 : --82--> island_111_01.jpg | 36.28dB
25-05-17 19:15:15.997 : --83--> island_111_10.jpg | 34.92dB
25-05-17 19:15:16.176 : --84--> island_111_11.jpg | 34.46dB
25-05-17 19:15:16.356 : --85--> lake_111_00.jpg | 34.69dB
25-05-17 19:15:16.535 : --86--> lake_111_01.jpg | 34.56dB
25-05-17 19:15:16.718 : --87--> lake_111_10.jpg | 34.12dB
25-05-17 19:15:16.898 : --88--> lake_111_11.jpg | 33.44dB
25-05-17 19:15:17.075 : --89--> meadow_111_00.jpg | 32.64dB
25-05-17 19:15:17.253 : --90--> meadow_111_01.jpg | 32.77dB
25-05-17 19:15:17.435 : --91--> meadow_111_10.jpg | 32.71dB
25-05-17 19:15:17.619 : --92--> meadow_111_11.jpg | 32.91dB
25-05-17 19:15:17.798 : --93--> medium_residential_111_00.jpg | 31.54dB
25-05-17 19:15:17.980 : --94--> medium_residential_111_01.jpg | 31.08dB
25-05-17 19:15:18.155 : --95--> medium_residential_111_10.jpg | 31.37dB
25-05-17 19:15:18.334 : --96--> medium_residential_111_11.jpg | 31.80dB
25-05-17 19:15:18.511 : --97--> mobile_home_park_111_00.jpg | 33.60dB
25-05-17 19:15:18.689 : --98--> mobile_home_park_111_01.jpg | 34.01dB
25-05-17 19:15:18.864 : --99--> mobile_home_park_111_10.jpg | 34.29dB
25-05-17 19:15:19.048 : -100--> mobile_home_park_111_11.jpg | 34.42dB
25-05-17 19:15:19.225 : -101--> mountain_111_00.jpg | 31.68dB
25-05-17 19:15:19.405 : -102--> mountain_111_01.jpg | 32.18dB
25-05-17 19:15:19.580 : -103--> mountain_111_10.jpg | 32.04dB
25-05-17 19:15:19.757 : -104--> mountain_111_11.jpg | 32.29dB
25-05-17 19:15:19.933 : -105--> overpass_111_00.jpg | 32.57dB
25-05-17 19:15:20.115 : -106--> overpass_111_01.jpg | 32.57dB
25-05-17 19:15:20.289 : -107--> overpass_111_10.jpg | 32.93dB
25-05-17 19:15:20.471 : -108--> overpass_111_11.jpg | 33.85dB
25-05-17 19:15:20.652 : -109--> palace_111_00.jpg | 32.67dB
25-05-17 19:15:20.832 : -110--> palace_111_01.jpg | 32.50dB
25-05-17 19:15:21.008 : -111--> palace_111_10.jpg | 33.56dB
25-05-17 19:15:21.188 : -112--> palace_111_11.jpg | 32.12dB
25-05-17 19:15:21.366 : -113--> parking_lot_111_00.jpg | 32.22dB
25-05-17 19:15:21.548 : -114--> parking_lot_111_01.jpg | 32.45dB
25-05-17 19:15:21.725 : -115--> parking_lot_111_10.jpg | 33.61dB
25-05-17 19:15:21.911 : -116--> parking_lot_111_11.jpg | 32.65dB
25-05-17 19:15:22.091 : -117--> railway_111_00.jpg | 32.74dB
25-05-17 19:15:22.272 : -118--> railway_111_01.jpg | 32.18dB
25-05-17 19:15:22.451 : -119--> railway_111_10.jpg | 34.67dB
25-05-17 19:15:22.630 : -120--> railway_111_11.jpg | 31.83dB
25-05-17 19:15:22.812 : -121--> railway_station_111_00.jpg | 33.34dB
25-05-17 19:15:22.990 : -122--> railway_station_111_01.jpg | 33.61dB
25-05-17 19:15:23.169 : -123--> railway_station_111_10.jpg | 33.47dB
25-05-17 19:15:23.354 : -124--> railway_station_111_11.jpg | 33.72dB
25-05-17 19:15:23.538 : -125--> rectangular_farmland_111_00.jpg | 35.74dB
25-05-17 19:15:23.718 : -126--> rectangular_farmland_111_01.jpg | 34.41dB
25-05-17 19:15:23.894 : -127--> rectangular_farmland_111_10.jpg | 36.08dB
25-05-17 19:15:24.073 : -128--> rectangular_farmland_111_11.jpg | 36.40dB
25-05-17 19:15:24.251 : -129--> river_111_00.jpg | 32.77dB
25-05-17 19:15:24.434 : -130--> river_111_01.jpg | 32.61dB
25-05-17 19:15:24.609 : -131--> river_111_10.jpg | 32.16dB
25-05-17 19:15:24.792 : -132--> river_111_11.jpg | 33.79dB
25-05-17 19:15:24.971 : -133--> roundabout_111_00.jpg | 32.94dB
25-05-17 19:15:25.150 : -134--> roundabout_111_01.jpg | 34.32dB
25-05-17 19:15:25.325 : -135--> roundabout_111_10.jpg | 32.90dB
25-05-17 19:15:25.504 : -136--> roundabout_111_11.jpg | 33.20dB
25-05-17 19:15:25.682 : -137--> runway_111_00.jpg | 38.16dB
25-05-17 19:15:25.864 : -138--> runway_111_01.jpg | 37.73dB
25-05-17 19:15:26.042 : -139--> runway_111_10.jpg | 38.50dB
25-05-17 19:15:26.223 : -140--> runway_111_11.jpg | 39.37dB
25-05-17 19:15:26.400 : -141--> sea_ice_111_00.jpg | 35.74dB
25-05-17 19:15:26.576 : -142--> sea_ice_111_01.jpg | 36.74dB
25-05-17 19:15:26.755 : -143--> sea_ice_111_10.jpg | 35.71dB
25-05-17 19:15:26.940 : -144--> sea_ice_111_11.jpg | 36.74dB
25-05-17 19:15:27.124 : -145--> ship_111_00.jpg | 40.68dB
25-05-17 19:15:27.302 : -146--> ship_111_01.jpg | 36.93dB
25-05-17 19:15:27.482 : -147--> ship_111_10.jpg | 43.83dB
25-05-17 19:15:27.665 : -148--> ship_111_11.jpg | 42.31dB
25-05-17 19:15:27.847 : -149--> snowberg_111_00.jpg | 36.83dB
25-05-17 19:15:28.025 : -150--> snowberg_111_01.jpg | 35.18dB
25-05-17 19:15:28.204 : -151--> snowberg_111_10.jpg | 34.53dB
25-05-17 19:15:28.385 : -152--> snowberg_111_11.jpg | 34.43dB
25-05-17 19:15:28.570 : -153--> sparse_residential_111_00.jpg | 32.93dB
25-05-17 19:15:28.746 : -154--> sparse_residential_111_01.jpg | 33.24dB
25-05-17 19:15:28.928 : -155--> sparse_residential_111_10.jpg | 32.48dB
25-05-17 19:15:29.111 : -156--> sparse_residential_111_11.jpg | 32.70dB
25-05-17 19:15:29.288 : -157--> stadium_111_00.jpg | 32.82dB
25-05-17 19:15:29.465 : -158--> stadium_111_01.jpg | 32.76dB
25-05-17 19:15:29.652 : -159--> stadium_111_10.jpg | 33.85dB
25-05-17 19:15:29.834 : -160--> stadium_111_11.jpg | 32.81dB
25-05-17 19:15:30.010 : -161--> storage_tank_111_00.jpg | 34.30dB
25-05-17 19:15:30.194 : -162--> storage_tank_111_01.jpg | 34.50dB
25-05-17 19:15:30.374 : -163--> storage_tank_111_10.jpg | 33.31dB
25-05-17 19:15:30.556 : -164--> storage_tank_111_11.jpg | 33.76dB
25-05-17 19:15:30.731 : -165--> tennis_court_111_00.jpg | 34.10dB
25-05-17 19:15:30.915 : -166--> tennis_court_111_01.jpg | 33.94dB
25-05-17 19:15:31.092 : -167--> tennis_court_111_10.jpg | 33.82dB
25-05-17 19:15:31.272 : -168--> tennis_court_111_11.jpg | 32.30dB
25-05-17 19:15:31.448 : -169--> terrace_111_00.jpg | 34.65dB
25-05-17 19:15:31.625 : -170--> terrace_111_01.jpg | 35.56dB
25-05-17 19:15:31.804 : -171--> terrace_111_10.jpg | 34.78dB
25-05-17 19:15:31.984 : -172--> terrace_111_11.jpg | 34.77dB
25-05-17 19:15:32.163 : -173--> thermal_power_station_111_00.jpg | 32.86dB
25-05-17 19:15:32.344 : -174--> thermal_power_station_111_01.jpg | 34.36dB
25-05-17 19:15:32.523 : -175--> thermal_power_station_111_10.jpg | 32.70dB
25-05-17 19:15:32.702 : -176--> thermal_power_station_111_11.jpg | 33.19dB
25-05-17 19:15:32.880 : -177--> wetland_111_00.jpg | 33.67dB
25-05-17 19:15:33.055 : -178--> wetland_111_01.jpg | 33.69dB
25-05-17 19:15:33.236 : -179--> wetland_111_10.jpg | 33.94dB
25-05-17 19:15:33.420 : -180--> wetland_111_11.jpg | 33.39dB
25-05-17 19:15:33.428 : <epoch:  0, iter:   5,000, Average PSNR : 34.56dB

25-05-17 20:36:08.412 : <epoch:  0, iter:  10,000, lr:1.000e-04> G_loss: 6.643e-05 
25-05-17 20:36:08.414 : Saving the model.
25-05-17 20:36:09.317 : ---1--> airplane_111_00.jpg | 33.16dB
25-05-17 20:36:09.498 : ---2--> airplane_111_01.jpg | 37.44dB
25-05-17 20:36:09.678 : ---3--> airplane_111_10.jpg | 35.29dB
25-05-17 20:36:09.864 : ---4--> airplane_111_11.jpg | 35.13dB
25-05-17 20:36:10.051 : ---5--> airport_111_00.jpg | 36.53dB
25-05-17 20:36:10.239 : ---6--> airport_111_01.jpg | 34.66dB
25-05-17 20:36:10.424 : ---7--> airport_111_10.jpg | 34.40dB
25-05-17 20:36:10.606 : ---8--> airport_111_11.jpg | 35.23dB
25-05-17 20:36:10.786 : ---9--> baseball_diamond_111_00.jpg | 35.11dB
25-05-17 20:36:10.964 : --10--> baseball_diamond_111_01.jpg | 36.45dB
25-05-17 20:36:11.143 : --11--> baseball_diamond_111_10.jpg | 34.79dB
25-05-17 20:36:11.322 : --12--> baseball_diamond_111_11.jpg | 37.38dB
25-05-17 20:36:11.500 : --13--> basketball_court_111_00.jpg | 33.28dB
25-05-17 20:36:11.679 : --14--> basketball_court_111_01.jpg | 32.88dB
25-05-17 20:36:11.857 : --15--> basketball_court_111_10.jpg | 35.74dB
25-05-17 20:36:12.035 : --16--> basketball_court_111_11.jpg | 34.33dB
25-05-17 20:36:12.214 : --17--> beach_111_00.jpg | 31.39dB
25-05-17 20:36:12.392 : --18--> beach_111_01.jpg | 34.33dB
25-05-17 20:36:12.570 : --19--> beach_111_10.jpg | 32.52dB
25-05-17 20:36:12.748 : --20--> beach_111_11.jpg | 36.56dB
25-05-17 20:36:12.930 : --21--> bridge_111_00.jpg | 42.50dB
25-05-17 20:36:13.108 : --22--> bridge_111_01.jpg | 36.51dB
25-05-17 20:36:13.288 : --23--> bridge_111_10.jpg | 35.61dB
25-05-17 20:36:13.466 : --24--> bridge_111_11.jpg | 38.81dB
25-05-17 20:36:13.649 : --25--> chaparral_111_00.jpg | 32.93dB
25-05-17 20:36:13.826 : --26--> chaparral_111_01.jpg | 33.25dB
25-05-17 20:36:14.004 : --27--> chaparral_111_10.jpg | 33.39dB
25-05-17 20:36:14.184 : --28--> chaparral_111_11.jpg | 31.65dB
25-05-17 20:36:14.361 : --29--> church_111_00.jpg | 34.09dB
25-05-17 20:36:14.543 : --30--> church_111_01.jpg | 33.19dB
25-05-17 20:36:14.726 : --31--> church_111_10.jpg | 36.53dB
25-05-17 20:36:14.915 : --32--> church_111_11.jpg | 33.01dB
25-05-17 20:36:15.103 : --33--> circular_farmland_111_00.jpg | 35.33dB
25-05-17 20:36:15.284 : --34--> circular_farmland_111_01.jpg | 36.08dB
25-05-17 20:36:15.466 : --35--> circular_farmland_111_10.jpg | 36.42dB
25-05-17 20:36:15.644 : --36--> circular_farmland_111_11.jpg | 36.36dB
25-05-17 20:36:15.823 : --37--> cloud_111_00.jpg | 43.10dB
25-05-17 20:36:16.001 : --38--> cloud_111_01.jpg | 38.98dB
25-05-17 20:36:16.180 : --39--> cloud_111_10.jpg | 38.61dB
25-05-17 20:36:16.357 : --40--> cloud_111_11.jpg | 38.92dB
25-05-17 20:36:16.533 : --41--> commercial_area_111_00.jpg | 35.84dB
25-05-17 20:36:16.715 : --42--> commercial_area_111_01.jpg | 34.99dB
25-05-17 20:36:16.893 : --43--> commercial_area_111_10.jpg | 35.71dB
25-05-17 20:36:17.071 : --44--> commercial_area_111_11.jpg | 35.59dB
25-05-17 20:36:17.251 : --45--> dense_residential_111_00.jpg | 32.73dB
25-05-17 20:36:17.434 : --46--> dense_residential_111_01.jpg | 32.01dB
25-05-17 20:36:17.611 : --47--> dense_residential_111_10.jpg | 32.33dB
25-05-17 20:36:17.789 : --48--> dense_residential_111_11.jpg | 32.17dB
25-05-17 20:36:17.967 : --49--> desert_111_00.jpg | 38.67dB
25-05-17 20:36:18.145 : --50--> desert_111_01.jpg | 38.71dB
25-05-17 20:36:18.324 : --51--> desert_111_10.jpg | 38.89dB
25-05-17 20:36:18.498 : --52--> desert_111_11.jpg | 39.04dB
25-05-17 20:36:18.675 : --53--> forest_111_00.jpg | 35.29dB
25-05-17 20:36:18.862 : --54--> forest_111_01.jpg | 34.42dB
25-05-17 20:36:19.047 : --55--> forest_111_10.jpg | 34.18dB
25-05-17 20:36:19.224 : --56--> forest_111_11.jpg | 34.95dB
25-05-17 20:36:19.401 : --57--> freeway_111_00.jpg | 36.01dB
25-05-17 20:36:19.581 : --58--> freeway_111_01.jpg | 36.57dB
25-05-17 20:36:19.762 : --59--> freeway_111_10.jpg | 36.40dB
25-05-17 20:36:19.946 : --60--> freeway_111_11.jpg | 36.65dB
25-05-17 20:36:20.122 : --61--> golf_course_111_00.jpg | 35.08dB
25-05-17 20:36:20.298 : --62--> golf_course_111_01.jpg | 34.68dB
25-05-17 20:36:20.475 : --63--> golf_course_111_10.jpg | 35.77dB
25-05-17 20:36:20.656 : --64--> golf_course_111_11.jpg | 36.25dB
25-05-17 20:36:20.832 : --65--> ground_track_field_111_00.jpg | 35.66dB
25-05-17 20:36:21.010 : --66--> ground_track_field_111_01.jpg | 32.16dB
25-05-17 20:36:21.186 : --67--> ground_track_field_111_10.jpg | 33.33dB
25-05-17 20:36:21.361 : --68--> ground_track_field_111_11.jpg | 32.65dB
25-05-17 20:36:21.539 : --69--> harbor_111_00.jpg | 34.77dB
25-05-17 20:36:21.714 : --70--> harbor_111_01.jpg | 33.57dB
25-05-17 20:36:21.890 : --71--> harbor_111_10.jpg | 33.36dB
25-05-17 20:36:22.067 : --72--> harbor_111_11.jpg | 34.88dB
25-05-17 20:36:22.244 : --73--> industrial_area_111_00.jpg | 33.88dB
25-05-17 20:36:22.422 : --74--> industrial_area_111_01.jpg | 34.22dB
25-05-17 20:36:22.598 : --75--> industrial_area_111_10.jpg | 34.22dB
25-05-17 20:36:22.780 : --76--> industrial_area_111_11.jpg | 33.79dB
25-05-17 20:36:22.960 : --77--> intersection_111_00.jpg | 33.18dB
25-05-17 20:36:23.137 : --78--> intersection_111_01.jpg | 33.31dB
25-05-17 20:36:23.313 : --79--> intersection_111_10.jpg | 33.07dB
25-05-17 20:36:23.488 : --80--> intersection_111_11.jpg | 32.85dB
25-05-17 20:36:23.664 : --81--> island_111_00.jpg | 34.07dB
25-05-17 20:36:23.842 : --82--> island_111_01.jpg | 36.32dB
25-05-17 20:36:24.022 : --83--> island_111_10.jpg | 34.95dB
25-05-17 20:36:24.202 : --84--> island_111_11.jpg | 34.50dB
25-05-17 20:36:24.383 : --85--> lake_111_00.jpg | 34.72dB
25-05-17 20:36:24.561 : --86--> lake_111_01.jpg | 34.58dB
25-05-17 20:36:24.738 : --87--> lake_111_10.jpg | 34.14dB
25-05-17 20:36:24.915 : --88--> lake_111_11.jpg | 33.47dB
25-05-17 20:36:25.091 : --89--> meadow_111_00.jpg | 32.67dB
25-05-17 20:36:25.270 : --90--> meadow_111_01.jpg | 32.81dB
25-05-17 20:36:25.447 : --91--> meadow_111_10.jpg | 32.74dB
25-05-17 20:36:25.625 : --92--> meadow_111_11.jpg | 32.94dB
25-05-17 20:36:25.803 : --93--> medium_residential_111_00.jpg | 31.58dB
25-05-17 20:36:25.981 : --94--> medium_residential_111_01.jpg | 31.13dB
25-05-17 20:36:26.163 : --95--> medium_residential_111_10.jpg | 31.41dB
25-05-17 20:36:26.339 : --96--> medium_residential_111_11.jpg | 31.84dB
25-05-17 20:36:26.519 : --97--> mobile_home_park_111_00.jpg | 33.63dB
25-05-17 20:36:26.696 : --98--> mobile_home_park_111_01.jpg | 34.04dB
25-05-17 20:36:26.888 : --99--> mobile_home_park_111_10.jpg | 34.30dB
25-05-17 20:36:27.069 : -100--> mobile_home_park_111_11.jpg | 34.44dB
25-05-17 20:36:27.248 : -101--> mountain_111_00.jpg | 31.71dB
25-05-17 20:36:27.427 : -102--> mountain_111_01.jpg | 32.20dB
25-05-17 20:36:27.604 : -103--> mountain_111_10.jpg | 32.08dB
25-05-17 20:36:27.784 : -104--> mountain_111_11.jpg | 32.32dB
25-05-17 20:36:27.965 : -105--> overpass_111_00.jpg | 32.63dB
25-05-17 20:36:28.142 : -106--> overpass_111_01.jpg | 32.62dB
25-05-17 20:36:28.321 : -107--> overpass_111_10.jpg | 32.98dB
25-05-17 20:36:28.504 : -108--> overpass_111_11.jpg | 33.89dB
25-05-17 20:36:28.685 : -109--> palace_111_00.jpg | 32.69dB
25-05-17 20:36:28.870 : -110--> palace_111_01.jpg | 32.54dB
25-05-17 20:36:29.054 : -111--> palace_111_10.jpg | 33.58dB
25-05-17 20:36:29.232 : -112--> palace_111_11.jpg | 32.15dB
25-05-17 20:36:29.411 : -113--> parking_lot_111_00.jpg | 32.27dB
25-05-17 20:36:29.588 : -114--> parking_lot_111_01.jpg | 32.49dB
25-05-17 20:36:29.767 : -115--> parking_lot_111_10.jpg | 33.65dB
25-05-17 20:36:29.945 : -116--> parking_lot_111_11.jpg | 32.67dB
25-05-17 20:36:30.122 : -117--> railway_111_00.jpg | 32.76dB
25-05-17 20:36:30.307 : -118--> railway_111_01.jpg | 32.22dB
25-05-17 20:36:30.484 : -119--> railway_111_10.jpg | 34.69dB
25-05-17 20:36:30.663 : -120--> railway_111_11.jpg | 31.85dB
25-05-17 20:36:30.842 : -121--> railway_station_111_00.jpg | 33.38dB
25-05-17 20:36:31.025 : -122--> railway_station_111_01.jpg | 33.65dB
25-05-17 20:36:31.208 : -123--> railway_station_111_10.jpg | 33.50dB
25-05-17 20:36:31.388 : -124--> railway_station_111_11.jpg | 33.74dB
25-05-17 20:36:31.568 : -125--> rectangular_farmland_111_00.jpg | 35.76dB
25-05-17 20:36:31.746 : -126--> rectangular_farmland_111_01.jpg | 34.42dB
25-05-17 20:36:31.927 : -127--> rectangular_farmland_111_10.jpg | 36.09dB
25-05-17 20:36:32.107 : -128--> rectangular_farmland_111_11.jpg | 36.44dB
25-05-17 20:36:32.287 : -129--> river_111_00.jpg | 32.82dB
25-05-17 20:36:32.465 : -130--> river_111_01.jpg | 32.63dB
25-05-17 20:36:32.645 : -131--> river_111_10.jpg | 32.20dB
25-05-17 20:36:32.828 : -132--> river_111_11.jpg | 33.81dB
25-05-17 20:36:33.009 : -133--> roundabout_111_00.jpg | 32.96dB
25-05-17 20:36:33.192 : -134--> roundabout_111_01.jpg | 34.32dB
25-05-17 20:36:33.371 : -135--> roundabout_111_10.jpg | 32.92dB
25-05-17 20:36:33.554 : -136--> roundabout_111_11.jpg | 33.22dB
25-05-17 20:36:33.734 : -137--> runway_111_00.jpg | 38.18dB
25-05-17 20:36:33.914 : -138--> runway_111_01.jpg | 37.72dB
25-05-17 20:36:34.094 : -139--> runway_111_10.jpg | 38.48dB
25-05-17 20:36:34.275 : -140--> runway_111_11.jpg | 39.39dB
25-05-17 20:36:34.455 : -141--> sea_ice_111_00.jpg | 35.78dB
25-05-17 20:36:34.634 : -142--> sea_ice_111_01.jpg | 36.80dB
25-05-17 20:36:34.814 : -143--> sea_ice_111_10.jpg | 35.74dB
25-05-17 20:36:34.992 : -144--> sea_ice_111_11.jpg | 36.83dB
25-05-17 20:36:35.172 : -145--> ship_111_00.jpg | 40.71dB
25-05-17 20:36:35.360 : -146--> ship_111_01.jpg | 36.96dB
25-05-17 20:36:35.540 : -147--> ship_111_10.jpg | 43.89dB
25-05-17 20:36:35.717 : -148--> ship_111_11.jpg | 42.34dB
25-05-17 20:36:35.897 : -149--> snowberg_111_00.jpg | 36.86dB
25-05-17 20:36:36.077 : -150--> snowberg_111_01.jpg | 35.20dB
25-05-17 20:36:36.257 : -151--> snowberg_111_10.jpg | 34.57dB
25-05-17 20:36:36.440 : -152--> snowberg_111_11.jpg | 34.47dB
25-05-17 20:36:36.620 : -153--> sparse_residential_111_00.jpg | 32.97dB
25-05-17 20:36:36.801 : -154--> sparse_residential_111_01.jpg | 33.26dB
25-05-17 20:36:36.979 : -155--> sparse_residential_111_10.jpg | 32.51dB
25-05-17 20:36:37.160 : -156--> sparse_residential_111_11.jpg | 32.73dB
25-05-17 20:36:37.340 : -157--> stadium_111_00.jpg | 32.85dB
25-05-17 20:36:37.521 : -158--> stadium_111_01.jpg | 32.78dB
25-05-17 20:36:37.701 : -159--> stadium_111_10.jpg | 33.87dB
25-05-17 20:36:37.882 : -160--> stadium_111_11.jpg | 32.84dB
25-05-17 20:36:38.063 : -161--> storage_tank_111_00.jpg | 34.34dB
25-05-17 20:36:38.245 : -162--> storage_tank_111_01.jpg | 34.53dB
25-05-17 20:36:38.425 : -163--> storage_tank_111_10.jpg | 33.34dB
25-05-17 20:36:38.608 : -164--> storage_tank_111_11.jpg | 33.80dB
25-05-17 20:36:38.790 : -165--> tennis_court_111_00.jpg | 34.14dB
25-05-17 20:36:38.971 : -166--> tennis_court_111_01.jpg | 33.97dB
25-05-17 20:36:39.151 : -167--> tennis_court_111_10.jpg | 33.87dB
25-05-17 20:36:39.334 : -168--> tennis_court_111_11.jpg | 32.34dB
25-05-17 20:36:39.515 : -169--> terrace_111_00.jpg | 34.67dB
25-05-17 20:36:39.700 : -170--> terrace_111_01.jpg | 35.57dB
25-05-17 20:36:39.881 : -171--> terrace_111_10.jpg | 34.80dB
25-05-17 20:36:40.065 : -172--> terrace_111_11.jpg | 34.79dB
25-05-17 20:36:40.249 : -173--> thermal_power_station_111_00.jpg | 32.88dB
25-05-17 20:36:40.428 : -174--> thermal_power_station_111_01.jpg | 34.38dB
25-05-17 20:36:40.607 : -175--> thermal_power_station_111_10.jpg | 32.73dB
25-05-17 20:36:40.785 : -176--> thermal_power_station_111_11.jpg | 33.20dB
25-05-17 20:36:40.964 : -177--> wetland_111_00.jpg | 33.69dB
25-05-17 20:36:41.143 : -178--> wetland_111_01.jpg | 33.73dB
25-05-17 20:36:41.322 : -179--> wetland_111_10.jpg | 33.97dB
25-05-17 20:36:41.500 : -180--> wetland_111_11.jpg | 33.40dB
25-05-17 20:36:41.511 : <epoch:  0, iter:  10,000, Average PSNR : 34.59dB

25-05-17 21:57:22.592 : <epoch:  0, iter:  15,000, lr:1.000e-04> G_loss: 4.300e-05 
25-05-17 21:57:22.594 : Saving the model.
25-05-17 21:57:23.361 : ---1--> airplane_111_00.jpg | 33.20dB
25-05-17 21:57:23.544 : ---2--> airplane_111_01.jpg | 37.45dB
25-05-17 21:57:23.724 : ---3--> airplane_111_10.jpg | 35.29dB
25-05-17 21:57:23.905 : ---4--> airplane_111_11.jpg | 35.17dB
25-05-17 21:57:24.089 : ---5--> airport_111_00.jpg | 36.54dB
25-05-17 21:57:24.266 : ---6--> airport_111_01.jpg | 34.67dB
25-05-17 21:57:24.453 : ---7--> airport_111_10.jpg | 34.42dB
25-05-17 21:57:24.638 : ---8--> airport_111_11.jpg | 35.22dB
25-05-17 21:57:24.816 : ---9--> baseball_diamond_111_00.jpg | 35.12dB
25-05-17 21:57:24.995 : --10--> baseball_diamond_111_01.jpg | 36.44dB
25-05-17 21:57:25.174 : --11--> baseball_diamond_111_10.jpg | 34.83dB
25-05-17 21:57:25.355 : --12--> baseball_diamond_111_11.jpg | 37.42dB
25-05-17 21:57:25.532 : --13--> basketball_court_111_00.jpg | 33.29dB
25-05-17 21:57:25.716 : --14--> basketball_court_111_01.jpg | 32.90dB
25-05-17 21:57:25.894 : --15--> basketball_court_111_10.jpg | 35.75dB
25-05-17 21:57:26.069 : --16--> basketball_court_111_11.jpg | 34.34dB
25-05-17 21:57:26.253 : --17--> beach_111_00.jpg | 31.43dB
25-05-17 21:57:26.442 : --18--> beach_111_01.jpg | 34.34dB
25-05-17 21:57:26.623 : --19--> beach_111_10.jpg | 32.54dB
25-05-17 21:57:26.805 : --20--> beach_111_11.jpg | 36.58dB
25-05-17 21:57:26.981 : --21--> bridge_111_00.jpg | 42.48dB
25-05-17 21:57:27.161 : --22--> bridge_111_01.jpg | 36.52dB
25-05-17 21:57:27.338 : --23--> bridge_111_10.jpg | 35.60dB
25-05-17 21:57:27.525 : --24--> bridge_111_11.jpg | 38.78dB
25-05-17 21:57:27.708 : --25--> chaparral_111_00.jpg | 32.97dB
25-05-17 21:57:27.888 : --26--> chaparral_111_01.jpg | 33.28dB
25-05-17 21:57:28.070 : --27--> chaparral_111_10.jpg | 33.42dB
25-05-17 21:57:28.254 : --28--> chaparral_111_11.jpg | 31.69dB
25-05-17 21:57:28.429 : --29--> church_111_00.jpg | 34.10dB
25-05-17 21:57:28.614 : --30--> church_111_01.jpg | 33.21dB
25-05-17 21:57:28.795 : --31--> church_111_10.jpg | 36.54dB
25-05-17 21:57:28.975 : --32--> church_111_11.jpg | 33.02dB
25-05-17 21:57:29.155 : --33--> circular_farmland_111_00.jpg | 35.35dB
25-05-17 21:57:29.334 : --34--> circular_farmland_111_01.jpg | 36.09dB
25-05-17 21:57:29.522 : --35--> circular_farmland_111_10.jpg | 36.44dB
25-05-17 21:57:29.705 : --36--> circular_farmland_111_11.jpg | 36.38dB
25-05-17 21:57:29.884 : --37--> cloud_111_00.jpg | 43.07dB
25-05-17 21:57:30.063 : --38--> cloud_111_01.jpg | 38.99dB
25-05-17 21:57:30.242 : --39--> cloud_111_10.jpg | 38.58dB
25-05-17 21:57:30.420 : --40--> cloud_111_11.jpg | 38.95dB
25-05-17 21:57:30.601 : --41--> commercial_area_111_00.jpg | 35.80dB
25-05-17 21:57:30.779 : --42--> commercial_area_111_01.jpg | 34.99dB
25-05-17 21:57:30.958 : --43--> commercial_area_111_10.jpg | 35.68dB
25-05-17 21:57:31.142 : --44--> commercial_area_111_11.jpg | 35.56dB
25-05-17 21:57:31.316 : --45--> dense_residential_111_00.jpg | 32.75dB
25-05-17 21:57:31.497 : --46--> dense_residential_111_01.jpg | 32.04dB
25-05-17 21:57:31.674 : --47--> dense_residential_111_10.jpg | 32.37dB
25-05-17 21:57:31.851 : --48--> dense_residential_111_11.jpg | 32.21dB
25-05-17 21:57:32.025 : --49--> desert_111_00.jpg | 38.66dB
25-05-17 21:57:32.203 : --50--> desert_111_01.jpg | 38.72dB
25-05-17 21:57:32.378 : --51--> desert_111_10.jpg | 38.92dB
25-05-17 21:57:32.561 : --52--> desert_111_11.jpg | 39.06dB
25-05-17 21:57:32.739 : --53--> forest_111_00.jpg | 35.28dB
25-05-17 21:57:32.919 : --54--> forest_111_01.jpg | 34.42dB
25-05-17 21:57:33.095 : --55--> forest_111_10.jpg | 34.18dB
25-05-17 21:57:33.276 : --56--> forest_111_11.jpg | 34.96dB
25-05-17 21:57:33.454 : --57--> freeway_111_00.jpg | 36.04dB
25-05-17 21:57:33.630 : --58--> freeway_111_01.jpg | 36.60dB
25-05-17 21:57:33.806 : --59--> freeway_111_10.jpg | 36.42dB
25-05-17 21:57:33.988 : --60--> freeway_111_11.jpg | 36.64dB
25-05-17 21:57:34.173 : --61--> golf_course_111_00.jpg | 35.09dB
25-05-17 21:57:34.359 : --62--> golf_course_111_01.jpg | 34.68dB
25-05-17 21:57:34.538 : --63--> golf_course_111_10.jpg | 35.78dB
25-05-17 21:57:34.714 : --64--> golf_course_111_11.jpg | 36.25dB
25-05-17 21:57:34.892 : --65--> ground_track_field_111_00.jpg | 35.65dB
25-05-17 21:57:35.070 : --66--> ground_track_field_111_01.jpg | 32.17dB
25-05-17 21:57:35.252 : --67--> ground_track_field_111_10.jpg | 33.34dB
25-05-17 21:57:35.431 : --68--> ground_track_field_111_11.jpg | 32.68dB
25-05-17 21:57:35.615 : --69--> harbor_111_00.jpg | 34.79dB
25-05-17 21:57:35.800 : --70--> harbor_111_01.jpg | 33.59dB
25-05-17 21:57:35.988 : --71--> harbor_111_10.jpg | 33.38dB
25-05-17 21:57:36.163 : --72--> harbor_111_11.jpg | 34.90dB
25-05-17 21:57:36.341 : --73--> industrial_area_111_00.jpg | 33.89dB
25-05-17 21:57:36.523 : --74--> industrial_area_111_01.jpg | 34.23dB
25-05-17 21:57:36.702 : --75--> industrial_area_111_10.jpg | 34.24dB
25-05-17 21:57:36.878 : --76--> industrial_area_111_11.jpg | 33.82dB
25-05-17 21:57:37.054 : --77--> intersection_111_00.jpg | 33.20dB
25-05-17 21:57:37.238 : --78--> intersection_111_01.jpg | 33.33dB
25-05-17 21:57:37.414 : --79--> intersection_111_10.jpg | 33.08dB
25-05-17 21:57:37.591 : --80--> intersection_111_11.jpg | 32.87dB
25-05-17 21:57:37.769 : --81--> island_111_00.jpg | 34.11dB
25-05-17 21:57:37.944 : --82--> island_111_01.jpg | 36.34dB
25-05-17 21:57:38.128 : --83--> island_111_10.jpg | 34.98dB
25-05-17 21:57:38.310 : --84--> island_111_11.jpg | 34.51dB
25-05-17 21:57:38.498 : --85--> lake_111_00.jpg | 34.72dB
25-05-17 21:57:38.675 : --86--> lake_111_01.jpg | 34.60dB
25-05-17 21:57:38.851 : --87--> lake_111_10.jpg | 34.16dB
25-05-17 21:57:39.038 : --88--> lake_111_11.jpg | 33.49dB
25-05-17 21:57:39.218 : --89--> meadow_111_00.jpg | 32.68dB
25-05-17 21:57:39.402 : --90--> meadow_111_01.jpg | 32.82dB
25-05-17 21:57:39.579 : --91--> meadow_111_10.jpg | 32.76dB
25-05-17 21:57:39.759 : --92--> meadow_111_11.jpg | 32.95dB
25-05-17 21:57:39.938 : --93--> medium_residential_111_00.jpg | 31.60dB
25-05-17 21:57:40.119 : --94--> medium_residential_111_01.jpg | 31.15dB
25-05-17 21:57:40.303 : --95--> medium_residential_111_10.jpg | 31.45dB
25-05-17 21:57:40.485 : --96--> medium_residential_111_11.jpg | 31.88dB
25-05-17 21:57:40.673 : --97--> mobile_home_park_111_00.jpg | 33.62dB
25-05-17 21:57:40.854 : --98--> mobile_home_park_111_01.jpg | 34.04dB
25-05-17 21:57:41.031 : --99--> mobile_home_park_111_10.jpg | 34.31dB
25-05-17 21:57:41.210 : -100--> mobile_home_park_111_11.jpg | 34.45dB
25-05-17 21:57:41.396 : -101--> mountain_111_00.jpg | 31.75dB
25-05-17 21:57:41.574 : -102--> mountain_111_01.jpg | 32.23dB
25-05-17 21:57:41.757 : -103--> mountain_111_10.jpg | 32.09dB
25-05-17 21:57:41.942 : -104--> mountain_111_11.jpg | 32.34dB
25-05-17 21:57:42.117 : -105--> overpass_111_00.jpg | 32.66dB
25-05-17 21:57:42.300 : -106--> overpass_111_01.jpg | 32.65dB
25-05-17 21:57:42.478 : -107--> overpass_111_10.jpg | 32.99dB
25-05-17 21:57:42.664 : -108--> overpass_111_11.jpg | 33.92dB
25-05-17 21:57:42.845 : -109--> palace_111_00.jpg | 32.69dB
25-05-17 21:57:43.024 : -110--> palace_111_01.jpg | 32.56dB
25-05-17 21:57:43.202 : -111--> palace_111_10.jpg | 33.60dB
25-05-17 21:57:43.379 : -112--> palace_111_11.jpg | 32.17dB
25-05-17 21:57:43.557 : -113--> parking_lot_111_00.jpg | 32.29dB
25-05-17 21:57:43.736 : -114--> parking_lot_111_01.jpg | 32.50dB
25-05-17 21:57:43.913 : -115--> parking_lot_111_10.jpg | 33.68dB
25-05-17 21:57:44.091 : -116--> parking_lot_111_11.jpg | 32.70dB
25-05-17 21:57:44.272 : -117--> railway_111_00.jpg | 32.79dB
25-05-17 21:57:44.450 : -118--> railway_111_01.jpg | 32.25dB
25-05-17 21:57:44.633 : -119--> railway_111_10.jpg | 34.70dB
25-05-17 21:57:44.814 : -120--> railway_111_11.jpg | 31.88dB
25-05-17 21:57:44.992 : -121--> railway_station_111_00.jpg | 33.40dB
25-05-17 21:57:45.174 : -122--> railway_station_111_01.jpg | 33.67dB
25-05-17 21:57:45.351 : -123--> railway_station_111_10.jpg | 33.52dB
25-05-17 21:57:45.539 : -124--> railway_station_111_11.jpg | 33.78dB
25-05-17 21:57:45.714 : -125--> rectangular_farmland_111_00.jpg | 35.79dB
25-05-17 21:57:45.894 : -126--> rectangular_farmland_111_01.jpg | 34.44dB
25-05-17 21:57:46.075 : -127--> rectangular_farmland_111_10.jpg | 36.09dB
25-05-17 21:57:46.258 : -128--> rectangular_farmland_111_11.jpg | 36.43dB
25-05-17 21:57:46.445 : -129--> river_111_00.jpg | 32.84dB
25-05-17 21:57:46.627 : -130--> river_111_01.jpg | 32.66dB
25-05-17 21:57:46.813 : -131--> river_111_10.jpg | 32.22dB
25-05-17 21:57:46.998 : -132--> river_111_11.jpg | 33.82dB
25-05-17 21:57:47.182 : -133--> roundabout_111_00.jpg | 32.98dB
25-05-17 21:57:47.361 : -134--> roundabout_111_01.jpg | 34.36dB
25-05-17 21:57:47.544 : -135--> roundabout_111_10.jpg | 32.93dB
25-05-17 21:57:47.722 : -136--> roundabout_111_11.jpg | 33.25dB
25-05-17 21:57:47.904 : -137--> runway_111_00.jpg | 38.18dB
25-05-17 21:57:48.079 : -138--> runway_111_01.jpg | 37.74dB
25-05-17 21:57:48.264 : -139--> runway_111_10.jpg | 38.48dB
25-05-17 21:57:48.438 : -140--> runway_111_11.jpg | 39.39dB
25-05-17 21:57:48.615 : -141--> sea_ice_111_00.jpg | 35.79dB
25-05-17 21:57:48.796 : -142--> sea_ice_111_01.jpg | 36.80dB
25-05-17 21:57:48.972 : -143--> sea_ice_111_10.jpg | 35.76dB
25-05-17 21:57:49.155 : -144--> sea_ice_111_11.jpg | 36.82dB
25-05-17 21:57:49.335 : -145--> ship_111_00.jpg | 40.75dB
25-05-17 21:57:49.515 : -146--> ship_111_01.jpg | 36.91dB
25-05-17 21:57:49.694 : -147--> ship_111_10.jpg | 43.86dB
25-05-17 21:57:49.871 : -148--> ship_111_11.jpg | 42.27dB
25-05-17 21:57:50.052 : -149--> snowberg_111_00.jpg | 36.89dB
25-05-17 21:57:50.232 : -150--> snowberg_111_01.jpg | 35.23dB
25-05-17 21:57:50.412 : -151--> snowberg_111_10.jpg | 34.61dB
25-05-17 21:57:50.595 : -152--> snowberg_111_11.jpg | 34.51dB
25-05-17 21:57:50.775 : -153--> sparse_residential_111_00.jpg | 33.00dB
25-05-17 21:57:50.955 : -154--> sparse_residential_111_01.jpg | 33.27dB
25-05-17 21:57:51.133 : -155--> sparse_residential_111_10.jpg | 32.52dB
25-05-17 21:57:51.310 : -156--> sparse_residential_111_11.jpg | 32.75dB
25-05-17 21:57:51.492 : -157--> stadium_111_00.jpg | 32.87dB
25-05-17 21:57:51.671 : -158--> stadium_111_01.jpg | 32.81dB
25-05-17 21:57:51.846 : -159--> stadium_111_10.jpg | 33.88dB
25-05-17 21:57:52.025 : -160--> stadium_111_11.jpg | 32.86dB
25-05-17 21:57:52.201 : -161--> storage_tank_111_00.jpg | 34.34dB
25-05-17 21:57:52.382 : -162--> storage_tank_111_01.jpg | 34.54dB
25-05-17 21:57:52.561 : -163--> storage_tank_111_10.jpg | 33.37dB
25-05-17 21:57:52.742 : -164--> storage_tank_111_11.jpg | 33.82dB
25-05-17 21:57:52.924 : -165--> tennis_court_111_00.jpg | 34.17dB
25-05-17 21:57:53.100 : -166--> tennis_court_111_01.jpg | 33.98dB
25-05-17 21:57:53.281 : -167--> tennis_court_111_10.jpg | 33.92dB
25-05-17 21:57:53.462 : -168--> tennis_court_111_11.jpg | 32.36dB
25-05-17 21:57:53.640 : -169--> terrace_111_00.jpg | 34.67dB
25-05-17 21:57:53.822 : -170--> terrace_111_01.jpg | 35.59dB
25-05-17 21:57:54.007 : -171--> terrace_111_10.jpg | 34.80dB
25-05-17 21:57:54.185 : -172--> terrace_111_11.jpg | 34.78dB
25-05-17 21:57:54.365 : -173--> thermal_power_station_111_00.jpg | 32.92dB
25-05-17 21:57:54.553 : -174--> thermal_power_station_111_01.jpg | 34.38dB
25-05-17 21:57:54.733 : -175--> thermal_power_station_111_10.jpg | 32.76dB
25-05-17 21:57:54.921 : -176--> thermal_power_station_111_11.jpg | 33.21dB
25-05-17 21:57:55.098 : -177--> wetland_111_00.jpg | 33.71dB
25-05-17 21:57:55.272 : -178--> wetland_111_01.jpg | 33.73dB
25-05-17 21:57:55.451 : -179--> wetland_111_10.jpg | 33.97dB
25-05-17 21:57:55.631 : -180--> wetland_111_11.jpg | 33.41dB
25-05-17 21:57:55.643 : <epoch:  0, iter:  15,000, Average PSNR : 34.60dB

25-05-17 23:18:18.550 : <epoch:  0, iter:  20,000, lr:1.000e-04> G_loss: 5.966e-05 
25-05-17 23:18:18.552 : Saving the model.
25-05-17 23:18:19.214 : ---1--> airplane_111_00.jpg | 33.24dB
25-05-17 23:18:19.393 : ---2--> airplane_111_01.jpg | 37.49dB
25-05-17 23:18:19.572 : ---3--> airplane_111_10.jpg | 35.35dB
25-05-17 23:18:19.754 : ---4--> airplane_111_11.jpg | 35.18dB
25-05-17 23:18:19.929 : ---5--> airport_111_00.jpg | 36.56dB
25-05-17 23:18:20.108 : ---6--> airport_111_01.jpg | 34.70dB
25-05-17 23:18:20.286 : ---7--> airport_111_10.jpg | 34.44dB
25-05-17 23:18:20.470 : ---8--> airport_111_11.jpg | 35.26dB
25-05-17 23:18:20.647 : ---9--> baseball_diamond_111_00.jpg | 35.13dB
25-05-17 23:18:20.822 : --10--> baseball_diamond_111_01.jpg | 36.50dB
25-05-17 23:18:21.006 : --11--> baseball_diamond_111_10.jpg | 34.86dB
25-05-17 23:18:21.184 : --12--> baseball_diamond_111_11.jpg | 37.41dB
25-05-17 23:18:21.362 : --13--> basketball_court_111_00.jpg | 33.33dB
25-05-17 23:18:21.542 : --14--> basketball_court_111_01.jpg | 32.93dB
25-05-17 23:18:21.724 : --15--> basketball_court_111_10.jpg | 35.77dB
25-05-17 23:18:21.900 : --16--> basketball_court_111_11.jpg | 34.38dB
25-05-17 23:18:22.081 : --17--> beach_111_00.jpg | 31.47dB
25-05-17 23:18:22.263 : --18--> beach_111_01.jpg | 34.37dB
25-05-17 23:18:22.439 : --19--> beach_111_10.jpg | 32.58dB
25-05-17 23:18:22.617 : --20--> beach_111_11.jpg | 36.61dB
25-05-17 23:18:22.791 : --21--> bridge_111_00.jpg | 42.52dB
25-05-17 23:18:22.974 : --22--> bridge_111_01.jpg | 36.54dB
25-05-17 23:18:23.152 : --23--> bridge_111_10.jpg | 35.63dB
25-05-17 23:18:23.329 : --24--> bridge_111_11.jpg | 38.85dB
25-05-17 23:18:23.506 : --25--> chaparral_111_00.jpg | 33.01dB
25-05-17 23:18:23.693 : --26--> chaparral_111_01.jpg | 33.32dB
25-05-17 23:18:23.878 : --27--> chaparral_111_10.jpg | 33.46dB
25-05-17 23:18:24.063 : --28--> chaparral_111_11.jpg | 31.74dB
25-05-17 23:18:24.249 : --29--> church_111_00.jpg | 34.16dB
25-05-17 23:18:24.425 : --30--> church_111_01.jpg | 33.25dB
25-05-17 23:18:24.603 : --31--> church_111_10.jpg | 36.61dB
25-05-17 23:18:24.779 : --32--> church_111_11.jpg | 33.08dB
25-05-17 23:18:24.956 : --33--> circular_farmland_111_00.jpg | 35.41dB
25-05-17 23:18:25.135 : --34--> circular_farmland_111_01.jpg | 36.12dB
25-05-17 23:18:25.313 : --35--> circular_farmland_111_10.jpg | 36.44dB
25-05-17 23:18:25.491 : --36--> circular_farmland_111_11.jpg | 36.40dB
25-05-17 23:18:25.669 : --37--> cloud_111_00.jpg | 43.17dB
25-05-17 23:18:25.855 : --38--> cloud_111_01.jpg | 39.03dB
25-05-17 23:18:26.030 : --39--> cloud_111_10.jpg | 38.65dB
25-05-17 23:18:26.213 : --40--> cloud_111_11.jpg | 38.96dB
25-05-17 23:18:26.389 : --41--> commercial_area_111_00.jpg | 35.85dB
25-05-17 23:18:26.566 : --42--> commercial_area_111_01.jpg | 35.03dB
25-05-17 23:18:26.745 : --43--> commercial_area_111_10.jpg | 35.71dB
25-05-17 23:18:26.924 : --44--> commercial_area_111_11.jpg | 35.61dB
25-05-17 23:18:27.103 : --45--> dense_residential_111_00.jpg | 32.80dB
25-05-17 23:18:27.277 : --46--> dense_residential_111_01.jpg | 32.08dB
25-05-17 23:18:27.458 : --47--> dense_residential_111_10.jpg | 32.40dB
25-05-17 23:18:27.636 : --48--> dense_residential_111_11.jpg | 32.25dB
25-05-17 23:18:27.814 : --49--> desert_111_00.jpg | 38.68dB
25-05-17 23:18:27.995 : --50--> desert_111_01.jpg | 38.74dB
25-05-17 23:18:28.176 : --51--> desert_111_10.jpg | 38.92dB
25-05-17 23:18:28.355 : --52--> desert_111_11.jpg | 39.07dB
25-05-17 23:18:28.534 : --53--> forest_111_00.jpg | 35.31dB
25-05-17 23:18:28.711 : --54--> forest_111_01.jpg | 34.45dB
25-05-17 23:18:28.892 : --55--> forest_111_10.jpg | 34.22dB
25-05-17 23:18:29.074 : --56--> forest_111_11.jpg | 34.98dB
25-05-17 23:18:29.253 : --57--> freeway_111_00.jpg | 36.06dB
25-05-17 23:18:29.429 : --58--> freeway_111_01.jpg | 36.65dB
25-05-17 23:18:29.612 : --59--> freeway_111_10.jpg | 36.43dB
25-05-17 23:18:29.788 : --60--> freeway_111_11.jpg | 36.68dB
25-05-17 23:18:29.968 : --61--> golf_course_111_00.jpg | 35.12dB
25-05-17 23:18:30.148 : --62--> golf_course_111_01.jpg | 34.72dB
25-05-17 23:18:30.326 : --63--> golf_course_111_10.jpg | 35.79dB
25-05-17 23:18:30.506 : --64--> golf_course_111_11.jpg | 36.28dB
25-05-17 23:18:30.684 : --65--> ground_track_field_111_00.jpg | 35.70dB
25-05-17 23:18:30.863 : --66--> ground_track_field_111_01.jpg | 32.21dB
25-05-17 23:18:31.039 : --67--> ground_track_field_111_10.jpg | 33.38dB
25-05-17 23:18:31.224 : --68--> ground_track_field_111_11.jpg | 32.73dB
25-05-17 23:18:31.404 : --69--> harbor_111_00.jpg | 34.82dB
25-05-17 23:18:31.584 : --70--> harbor_111_01.jpg | 33.62dB
25-05-17 23:18:31.761 : --71--> harbor_111_10.jpg | 33.41dB
25-05-17 23:18:31.941 : --72--> harbor_111_11.jpg | 34.91dB
25-05-17 23:18:32.122 : --73--> industrial_area_111_00.jpg | 33.97dB
25-05-17 23:18:32.303 : --74--> industrial_area_111_01.jpg | 34.28dB
25-05-17 23:18:32.484 : --75--> industrial_area_111_10.jpg | 34.29dB
25-05-17 23:18:32.664 : --76--> industrial_area_111_11.jpg | 33.86dB
25-05-17 23:18:32.844 : --77--> intersection_111_00.jpg | 33.27dB
25-05-17 23:18:33.021 : --78--> intersection_111_01.jpg | 33.37dB
25-05-17 23:18:33.195 : --79--> intersection_111_10.jpg | 33.11dB
25-05-17 23:18:33.375 : --80--> intersection_111_11.jpg | 32.92dB
25-05-17 23:18:33.556 : --81--> island_111_00.jpg | 34.14dB
25-05-17 23:18:33.735 : --82--> island_111_01.jpg | 36.38dB
25-05-17 23:18:33.912 : --83--> island_111_10.jpg | 35.03dB
25-05-17 23:18:34.088 : --84--> island_111_11.jpg | 34.54dB
25-05-17 23:18:34.265 : --85--> lake_111_00.jpg | 34.77dB
25-05-17 23:18:34.447 : --86--> lake_111_01.jpg | 34.63dB
25-05-17 23:18:34.625 : --87--> lake_111_10.jpg | 34.19dB
25-05-17 23:18:34.802 : --88--> lake_111_11.jpg | 33.53dB
25-05-17 23:18:34.980 : --89--> meadow_111_00.jpg | 32.73dB
25-05-17 23:18:35.160 : --90--> meadow_111_01.jpg | 32.86dB
25-05-17 23:18:35.349 : --91--> meadow_111_10.jpg | 32.81dB
25-05-17 23:18:35.525 : --92--> meadow_111_11.jpg | 32.99dB
25-05-17 23:18:35.703 : --93--> medium_residential_111_00.jpg | 31.64dB
25-05-17 23:18:35.880 : --94--> medium_residential_111_01.jpg | 31.18dB
25-05-17 23:18:36.058 : --95--> medium_residential_111_10.jpg | 31.48dB
25-05-17 23:18:36.236 : --96--> medium_residential_111_11.jpg | 31.93dB
25-05-17 23:18:36.419 : --97--> mobile_home_park_111_00.jpg | 33.68dB
25-05-17 23:18:36.603 : --98--> mobile_home_park_111_01.jpg | 34.08dB
25-05-17 23:18:36.784 : --99--> mobile_home_park_111_10.jpg | 34.35dB
25-05-17 23:18:36.962 : -100--> mobile_home_park_111_11.jpg | 34.48dB
25-05-17 23:18:37.138 : -101--> mountain_111_00.jpg | 31.77dB
25-05-17 23:18:37.316 : -102--> mountain_111_01.jpg | 32.26dB
25-05-17 23:18:37.498 : -103--> mountain_111_10.jpg | 32.12dB
25-05-17 23:18:37.681 : -104--> mountain_111_11.jpg | 32.38dB
25-05-17 23:18:37.857 : -105--> overpass_111_00.jpg | 32.70dB
25-05-17 23:18:38.040 : -106--> overpass_111_01.jpg | 32.69dB
25-05-17 23:18:38.218 : -107--> overpass_111_10.jpg | 33.06dB
25-05-17 23:18:38.401 : -108--> overpass_111_11.jpg | 33.96dB
25-05-17 23:18:38.577 : -109--> palace_111_00.jpg | 32.74dB
25-05-17 23:18:38.759 : -110--> palace_111_01.jpg | 32.59dB
25-05-17 23:18:38.933 : -111--> palace_111_10.jpg | 33.62dB
25-05-17 23:18:39.115 : -112--> palace_111_11.jpg | 32.20dB
25-05-17 23:18:39.293 : -113--> parking_lot_111_00.jpg | 32.31dB
25-05-17 23:18:39.476 : -114--> parking_lot_111_01.jpg | 32.55dB
25-05-17 23:18:39.651 : -115--> parking_lot_111_10.jpg | 33.72dB
25-05-17 23:18:39.831 : -116--> parking_lot_111_11.jpg | 32.73dB
25-05-17 23:18:40.013 : -117--> railway_111_00.jpg | 32.82dB
25-05-17 23:18:40.199 : -118--> railway_111_01.jpg | 32.29dB
25-05-17 23:18:40.382 : -119--> railway_111_10.jpg | 34.73dB
25-05-17 23:18:40.568 : -120--> railway_111_11.jpg | 31.93dB
25-05-17 23:18:40.747 : -121--> railway_station_111_00.jpg | 33.44dB
25-05-17 23:18:40.927 : -122--> railway_station_111_01.jpg | 33.72dB
25-05-17 23:18:41.103 : -123--> railway_station_111_10.jpg | 33.56dB
25-05-17 23:18:41.286 : -124--> railway_station_111_11.jpg | 33.80dB
25-05-17 23:18:41.466 : -125--> rectangular_farmland_111_00.jpg | 35.81dB
25-05-17 23:18:41.646 : -126--> rectangular_farmland_111_01.jpg | 34.46dB
25-05-17 23:18:41.822 : -127--> rectangular_farmland_111_10.jpg | 36.13dB
25-05-17 23:18:42.003 : -128--> rectangular_farmland_111_11.jpg | 36.45dB
25-05-17 23:18:42.182 : -129--> river_111_00.jpg | 32.89dB
25-05-17 23:18:42.360 : -130--> river_111_01.jpg | 32.70dB
25-05-17 23:18:42.540 : -131--> river_111_10.jpg | 32.28dB
25-05-17 23:18:42.727 : -132--> river_111_11.jpg | 33.84dB
25-05-17 23:18:42.905 : -133--> roundabout_111_00.jpg | 33.03dB
25-05-17 23:18:43.085 : -134--> roundabout_111_01.jpg | 34.38dB
25-05-17 23:18:43.261 : -135--> roundabout_111_10.jpg | 32.96dB
25-05-17 23:18:43.444 : -136--> roundabout_111_11.jpg | 33.28dB
25-05-17 23:18:43.622 : -137--> runway_111_00.jpg | 38.22dB
25-05-17 23:18:43.800 : -138--> runway_111_01.jpg | 37.76dB
25-05-17 23:18:43.977 : -139--> runway_111_10.jpg | 38.52dB
25-05-17 23:18:44.160 : -140--> runway_111_11.jpg | 39.41dB
25-05-17 23:18:44.333 : -141--> sea_ice_111_00.jpg | 35.82dB
25-05-17 23:18:44.511 : -142--> sea_ice_111_01.jpg | 36.83dB
25-05-17 23:18:44.686 : -143--> sea_ice_111_10.jpg | 35.77dB
25-05-17 23:18:44.866 : -144--> sea_ice_111_11.jpg | 36.87dB
25-05-17 23:18:45.051 : -145--> ship_111_00.jpg | 40.78dB
25-05-17 23:18:45.229 : -146--> ship_111_01.jpg | 36.97dB
25-05-17 23:18:45.404 : -147--> ship_111_10.jpg | 43.96dB
25-05-17 23:18:45.583 : -148--> ship_111_11.jpg | 42.41dB
25-05-17 23:18:45.765 : -149--> snowberg_111_00.jpg | 36.96dB
25-05-17 23:18:45.950 : -150--> snowberg_111_01.jpg | 35.28dB
25-05-17 23:18:46.129 : -151--> snowberg_111_10.jpg | 34.66dB
25-05-17 23:18:46.308 : -152--> snowberg_111_11.jpg | 34.57dB
25-05-17 23:18:46.488 : -153--> sparse_residential_111_00.jpg | 33.03dB
25-05-17 23:18:46.670 : -154--> sparse_residential_111_01.jpg | 33.30dB
25-05-17 23:18:46.849 : -155--> sparse_residential_111_10.jpg | 32.56dB
25-05-17 23:18:47.032 : -156--> sparse_residential_111_11.jpg | 32.78dB
25-05-17 23:18:47.208 : -157--> stadium_111_00.jpg | 32.92dB
25-05-17 23:18:47.390 : -158--> stadium_111_01.jpg | 32.87dB
25-05-17 23:18:47.568 : -159--> stadium_111_10.jpg | 33.91dB
25-05-17 23:18:47.749 : -160--> stadium_111_11.jpg | 32.90dB
25-05-17 23:18:47.927 : -161--> storage_tank_111_00.jpg | 34.38dB
25-05-17 23:18:48.105 : -162--> storage_tank_111_01.jpg | 34.57dB
25-05-17 23:18:48.285 : -163--> storage_tank_111_10.jpg | 33.38dB
25-05-17 23:18:48.465 : -164--> storage_tank_111_11.jpg | 33.84dB
25-05-17 23:18:48.646 : -165--> tennis_court_111_00.jpg | 34.21dB
25-05-17 23:18:48.833 : -166--> tennis_court_111_01.jpg | 34.02dB
25-05-17 23:18:49.013 : -167--> tennis_court_111_10.jpg | 33.95dB
25-05-17 23:18:49.189 : -168--> tennis_court_111_11.jpg | 32.40dB
25-05-17 23:18:49.367 : -169--> terrace_111_00.jpg | 34.70dB
25-05-17 23:18:49.542 : -170--> terrace_111_01.jpg | 35.62dB
25-05-17 23:18:49.722 : -171--> terrace_111_10.jpg | 34.82dB
25-05-17 23:18:49.902 : -172--> terrace_111_11.jpg | 34.81dB
25-05-17 23:18:50.087 : -173--> thermal_power_station_111_00.jpg | 32.94dB
25-05-17 23:18:50.273 : -174--> thermal_power_station_111_01.jpg | 34.43dB
25-05-17 23:18:50.459 : -175--> thermal_power_station_111_10.jpg | 32.82dB
25-05-17 23:18:50.647 : -176--> thermal_power_station_111_11.jpg | 33.28dB
25-05-17 23:18:50.824 : -177--> wetland_111_00.jpg | 33.75dB
25-05-17 23:18:51.004 : -178--> wetland_111_01.jpg | 33.77dB
25-05-17 23:18:51.179 : -179--> wetland_111_10.jpg | 34.01dB
25-05-17 23:18:51.360 : -180--> wetland_111_11.jpg | 33.45dB
25-05-17 23:18:51.369 : <epoch:  0, iter:  20,000, Average PSNR : 34.64dB

25-05-18 00:39:09.826 : <epoch:  0, iter:  25,000, lr:1.000e-04> G_loss: 6.362e-05 
25-05-18 00:39:09.827 : Saving the model.
25-05-18 00:39:10.428 : ---1--> airplane_111_00.jpg | 33.24dB
25-05-18 00:39:10.605 : ---2--> airplane_111_01.jpg | 37.49dB
25-05-18 00:39:10.786 : ---3--> airplane_111_10.jpg | 35.36dB
25-05-18 00:39:10.965 : ---4--> airplane_111_11.jpg | 35.20dB
25-05-18 00:39:11.144 : ---5--> airport_111_00.jpg | 36.56dB
25-05-18 00:39:11.325 : ---6--> airport_111_01.jpg | 34.72dB
25-05-18 00:39:11.504 : ---7--> airport_111_10.jpg | 34.45dB
25-05-18 00:39:11.680 : ---8--> airport_111_11.jpg | 35.28dB
25-05-18 00:39:11.862 : ---9--> baseball_diamond_111_00.jpg | 35.14dB
25-05-18 00:39:12.048 : --10--> baseball_diamond_111_01.jpg | 36.49dB
25-05-18 00:39:12.227 : --11--> baseball_diamond_111_10.jpg | 34.86dB
25-05-18 00:39:12.404 : --12--> baseball_diamond_111_11.jpg | 37.43dB
25-05-18 00:39:12.578 : --13--> basketball_court_111_00.jpg | 33.36dB
25-05-18 00:39:12.757 : --14--> basketball_court_111_01.jpg | 32.95dB
25-05-18 00:39:12.937 : --15--> basketball_court_111_10.jpg | 35.76dB
25-05-18 00:39:13.117 : --16--> basketball_court_111_11.jpg | 34.39dB
25-05-18 00:39:13.296 : --17--> beach_111_00.jpg | 31.48dB
25-05-18 00:39:13.481 : --18--> beach_111_01.jpg | 34.38dB
25-05-18 00:39:13.661 : --19--> beach_111_10.jpg | 32.59dB
25-05-18 00:39:13.837 : --20--> beach_111_11.jpg | 36.62dB
25-05-18 00:39:14.015 : --21--> bridge_111_00.jpg | 42.53dB
25-05-18 00:39:14.190 : --22--> bridge_111_01.jpg | 36.55dB
25-05-18 00:39:14.367 : --23--> bridge_111_10.jpg | 35.64dB
25-05-18 00:39:14.550 : --24--> bridge_111_11.jpg | 38.84dB
25-05-18 00:39:14.734 : --25--> chaparral_111_00.jpg | 33.02dB
25-05-18 00:39:14.913 : --26--> chaparral_111_01.jpg | 33.32dB
25-05-18 00:39:15.093 : --27--> chaparral_111_10.jpg | 33.47dB
25-05-18 00:39:15.271 : --28--> chaparral_111_11.jpg | 31.74dB
25-05-18 00:39:15.448 : --29--> church_111_00.jpg | 34.16dB
25-05-18 00:39:15.622 : --30--> church_111_01.jpg | 33.27dB
25-05-18 00:39:15.796 : --31--> church_111_10.jpg | 36.62dB
25-05-18 00:39:15.972 : --32--> church_111_11.jpg | 33.09dB
25-05-18 00:39:16.152 : --33--> circular_farmland_111_00.jpg | 35.38dB
25-05-18 00:39:16.328 : --34--> circular_farmland_111_01.jpg | 36.15dB
25-05-18 00:39:16.507 : --35--> circular_farmland_111_10.jpg | 36.45dB
25-05-18 00:39:16.685 : --36--> circular_farmland_111_11.jpg | 36.40dB
25-05-18 00:39:16.865 : --37--> cloud_111_00.jpg | 43.09dB
25-05-18 00:39:17.044 : --38--> cloud_111_01.jpg | 39.01dB
25-05-18 00:39:17.226 : --39--> cloud_111_10.jpg | 38.63dB
25-05-18 00:39:17.404 : --40--> cloud_111_11.jpg | 38.98dB
25-05-18 00:39:17.584 : --41--> commercial_area_111_00.jpg | 35.84dB
25-05-18 00:39:17.761 : --42--> commercial_area_111_01.jpg | 35.03dB
25-05-18 00:39:17.941 : --43--> commercial_area_111_10.jpg | 35.70dB
25-05-18 00:39:18.119 : --44--> commercial_area_111_11.jpg | 35.63dB
25-05-18 00:39:18.304 : --45--> dense_residential_111_00.jpg | 32.82dB
25-05-18 00:39:18.483 : --46--> dense_residential_111_01.jpg | 32.09dB
25-05-18 00:39:18.662 : --47--> dense_residential_111_10.jpg | 32.43dB
25-05-18 00:39:18.840 : --48--> dense_residential_111_11.jpg | 32.26dB
25-05-18 00:39:19.017 : --49--> desert_111_00.jpg | 38.67dB
25-05-18 00:39:19.199 : --50--> desert_111_01.jpg | 38.72dB
25-05-18 00:39:19.374 : --51--> desert_111_10.jpg | 38.93dB
25-05-18 00:39:19.552 : --52--> desert_111_11.jpg | 39.04dB
25-05-18 00:39:19.728 : --53--> forest_111_00.jpg | 35.31dB
25-05-18 00:39:19.904 : --54--> forest_111_01.jpg | 34.45dB
25-05-18 00:39:20.079 : --55--> forest_111_10.jpg | 34.22dB
25-05-18 00:39:20.259 : --56--> forest_111_11.jpg | 34.99dB
25-05-18 00:39:20.439 : --57--> freeway_111_00.jpg | 36.06dB
25-05-18 00:39:20.617 : --58--> freeway_111_01.jpg | 36.67dB
25-05-18 00:39:20.798 : --59--> freeway_111_10.jpg | 36.46dB
25-05-18 00:39:20.979 : --60--> freeway_111_11.jpg | 36.68dB
25-05-18 00:39:21.158 : --61--> golf_course_111_00.jpg | 35.13dB
25-05-18 00:39:21.336 : --62--> golf_course_111_01.jpg | 34.73dB
25-05-18 00:39:21.521 : --63--> golf_course_111_10.jpg | 35.78dB
25-05-18 00:39:21.696 : --64--> golf_course_111_11.jpg | 36.28dB
25-05-18 00:39:21.876 : --65--> ground_track_field_111_00.jpg | 35.71dB
25-05-18 00:39:22.057 : --66--> ground_track_field_111_01.jpg | 32.24dB
25-05-18 00:39:22.235 : --67--> ground_track_field_111_10.jpg | 33.39dB
25-05-18 00:39:22.412 : --68--> ground_track_field_111_11.jpg | 32.74dB
25-05-18 00:39:22.595 : --69--> harbor_111_00.jpg | 34.82dB
25-05-18 00:39:22.772 : --70--> harbor_111_01.jpg | 33.63dB
25-05-18 00:39:22.948 : --71--> harbor_111_10.jpg | 33.42dB
25-05-18 00:39:23.125 : --72--> harbor_111_11.jpg | 34.92dB
25-05-18 00:39:23.303 : --73--> industrial_area_111_00.jpg | 33.99dB
25-05-18 00:39:23.482 : --74--> industrial_area_111_01.jpg | 34.28dB
25-05-18 00:39:23.660 : --75--> industrial_area_111_10.jpg | 34.30dB
25-05-18 00:39:23.836 : --76--> industrial_area_111_11.jpg | 33.87dB
25-05-18 00:39:24.018 : --77--> intersection_111_00.jpg | 33.26dB
25-05-18 00:39:24.198 : --78--> intersection_111_01.jpg | 33.38dB
25-05-18 00:39:24.384 : --79--> intersection_111_10.jpg | 33.14dB
25-05-18 00:39:24.560 : --80--> intersection_111_11.jpg | 32.94dB
25-05-18 00:39:24.744 : --81--> island_111_00.jpg | 34.16dB
25-05-18 00:39:24.924 : --82--> island_111_01.jpg | 36.39dB
25-05-18 00:39:25.102 : --83--> island_111_10.jpg | 35.05dB
25-05-18 00:39:25.279 : --84--> island_111_11.jpg | 34.57dB
25-05-18 00:39:25.459 : --85--> lake_111_00.jpg | 34.76dB
25-05-18 00:39:25.644 : --86--> lake_111_01.jpg | 34.63dB
25-05-18 00:39:25.825 : --87--> lake_111_10.jpg | 34.20dB
25-05-18 00:39:26.006 : --88--> lake_111_11.jpg | 33.54dB
25-05-18 00:39:26.188 : --89--> meadow_111_00.jpg | 32.76dB
25-05-18 00:39:26.366 : --90--> meadow_111_01.jpg | 32.89dB
25-05-18 00:39:26.543 : --91--> meadow_111_10.jpg | 32.84dB
25-05-18 00:39:26.724 : --92--> meadow_111_11.jpg | 33.02dB
25-05-18 00:39:26.906 : --93--> medium_residential_111_00.jpg | 31.66dB
25-05-18 00:39:27.084 : --94--> medium_residential_111_01.jpg | 31.20dB
25-05-18 00:39:27.258 : --95--> medium_residential_111_10.jpg | 31.48dB
25-05-18 00:39:27.445 : --96--> medium_residential_111_11.jpg | 31.93dB
25-05-18 00:39:27.632 : --97--> mobile_home_park_111_00.jpg | 33.69dB
25-05-18 00:39:27.805 : --98--> mobile_home_park_111_01.jpg | 34.09dB
25-05-18 00:39:27.989 : --99--> mobile_home_park_111_10.jpg | 34.36dB
25-05-18 00:39:28.171 : -100--> mobile_home_park_111_11.jpg | 34.49dB
25-05-18 00:39:28.350 : -101--> mountain_111_00.jpg | 31.78dB
25-05-18 00:39:28.529 : -102--> mountain_111_01.jpg | 32.27dB
25-05-18 00:39:28.709 : -103--> mountain_111_10.jpg | 32.14dB
25-05-18 00:39:28.895 : -104--> mountain_111_11.jpg | 32.39dB
25-05-18 00:39:29.074 : -105--> overpass_111_00.jpg | 32.71dB
25-05-18 00:39:29.248 : -106--> overpass_111_01.jpg | 32.71dB
25-05-18 00:39:29.425 : -107--> overpass_111_10.jpg | 33.08dB
25-05-18 00:39:29.606 : -108--> overpass_111_11.jpg | 33.97dB
25-05-18 00:39:29.791 : -109--> palace_111_00.jpg | 32.75dB
25-05-18 00:39:29.967 : -110--> palace_111_01.jpg | 32.61dB
25-05-18 00:39:30.146 : -111--> palace_111_10.jpg | 33.64dB
25-05-18 00:39:30.327 : -112--> palace_111_11.jpg | 32.23dB
25-05-18 00:39:30.510 : -113--> parking_lot_111_00.jpg | 32.29dB
25-05-18 00:39:30.689 : -114--> parking_lot_111_01.jpg | 32.54dB
25-05-18 00:39:30.863 : -115--> parking_lot_111_10.jpg | 33.72dB
25-05-18 00:39:31.043 : -116--> parking_lot_111_11.jpg | 32.75dB
25-05-18 00:39:31.232 : -117--> railway_111_00.jpg | 32.83dB
25-05-18 00:39:31.415 : -118--> railway_111_01.jpg | 32.31dB
25-05-18 00:39:31.592 : -119--> railway_111_10.jpg | 34.74dB
25-05-18 00:39:31.777 : -120--> railway_111_11.jpg | 31.94dB
25-05-18 00:39:31.957 : -121--> railway_station_111_00.jpg | 33.46dB
25-05-18 00:39:32.135 : -122--> railway_station_111_01.jpg | 33.71dB
25-05-18 00:39:32.311 : -123--> railway_station_111_10.jpg | 33.58dB
25-05-18 00:39:32.490 : -124--> railway_station_111_11.jpg | 33.82dB
25-05-18 00:39:32.673 : -125--> rectangular_farmland_111_00.jpg | 35.81dB
25-05-18 00:39:32.858 : -126--> rectangular_farmland_111_01.jpg | 34.47dB
25-05-18 00:39:33.050 : -127--> rectangular_farmland_111_10.jpg | 36.13dB
25-05-18 00:39:33.234 : -128--> rectangular_farmland_111_11.jpg | 36.44dB
25-05-18 00:39:33.415 : -129--> river_111_00.jpg | 32.91dB
25-05-18 00:39:33.594 : -130--> river_111_01.jpg | 32.71dB
25-05-18 00:39:33.773 : -131--> river_111_10.jpg | 32.30dB
25-05-18 00:39:33.951 : -132--> river_111_11.jpg | 33.87dB
25-05-18 00:39:34.132 : -133--> roundabout_111_00.jpg | 33.03dB
25-05-18 00:39:34.311 : -134--> roundabout_111_01.jpg | 34.40dB
25-05-18 00:39:34.492 : -135--> roundabout_111_10.jpg | 32.95dB
25-05-18 00:39:34.667 : -136--> roundabout_111_11.jpg | 33.29dB
25-05-18 00:39:34.849 : -137--> runway_111_00.jpg | 38.20dB
25-05-18 00:39:35.025 : -138--> runway_111_01.jpg | 37.78dB
25-05-18 00:39:35.205 : -139--> runway_111_10.jpg | 38.50dB
25-05-18 00:39:35.386 : -140--> runway_111_11.jpg | 39.40dB
25-05-18 00:39:35.565 : -141--> sea_ice_111_00.jpg | 35.84dB
25-05-18 00:39:35.743 : -142--> sea_ice_111_01.jpg | 36.83dB
25-05-18 00:39:35.918 : -143--> sea_ice_111_10.jpg | 35.79dB
25-05-18 00:39:36.095 : -144--> sea_ice_111_11.jpg | 36.87dB
25-05-18 00:39:36.271 : -145--> ship_111_00.jpg | 40.75dB
25-05-18 00:39:36.457 : -146--> ship_111_01.jpg | 36.94dB
25-05-18 00:39:36.634 : -147--> ship_111_10.jpg | 43.87dB
25-05-18 00:39:36.815 : -148--> ship_111_11.jpg | 42.33dB
25-05-18 00:39:37.000 : -149--> snowberg_111_00.jpg | 36.92dB
25-05-18 00:39:37.175 : -150--> snowberg_111_01.jpg | 35.29dB
25-05-18 00:39:37.351 : -151--> snowberg_111_10.jpg | 34.65dB
25-05-18 00:39:37.526 : -152--> snowberg_111_11.jpg | 34.59dB
25-05-18 00:39:37.710 : -153--> sparse_residential_111_00.jpg | 33.04dB
25-05-18 00:39:37.894 : -154--> sparse_residential_111_01.jpg | 33.31dB
25-05-18 00:39:38.074 : -155--> sparse_residential_111_10.jpg | 32.58dB
25-05-18 00:39:38.254 : -156--> sparse_residential_111_11.jpg | 32.80dB
25-05-18 00:39:38.434 : -157--> stadium_111_00.jpg | 32.94dB
25-05-18 00:39:38.615 : -158--> stadium_111_01.jpg | 32.89dB
25-05-18 00:39:38.794 : -159--> stadium_111_10.jpg | 33.93dB
25-05-18 00:39:38.977 : -160--> stadium_111_11.jpg | 32.91dB
25-05-18 00:39:39.160 : -161--> storage_tank_111_00.jpg | 34.39dB
25-05-18 00:39:39.337 : -162--> storage_tank_111_01.jpg | 34.56dB
25-05-18 00:39:39.515 : -163--> storage_tank_111_10.jpg | 33.38dB
25-05-18 00:39:39.692 : -164--> storage_tank_111_11.jpg | 33.86dB
25-05-18 00:39:39.875 : -165--> tennis_court_111_00.jpg | 34.23dB
25-05-18 00:39:40.054 : -166--> tennis_court_111_01.jpg | 34.04dB
25-05-18 00:39:40.233 : -167--> tennis_court_111_10.jpg | 33.97dB
25-05-18 00:39:40.410 : -168--> tennis_court_111_11.jpg | 32.41dB
25-05-18 00:39:40.588 : -169--> terrace_111_00.jpg | 34.73dB
25-05-18 00:39:40.764 : -170--> terrace_111_01.jpg | 35.63dB
25-05-18 00:39:40.942 : -171--> terrace_111_10.jpg | 34.83dB
25-05-18 00:39:41.118 : -172--> terrace_111_11.jpg | 34.84dB
25-05-18 00:39:41.299 : -173--> thermal_power_station_111_00.jpg | 32.97dB
25-05-18 00:39:41.476 : -174--> thermal_power_station_111_01.jpg | 34.44dB
25-05-18 00:39:41.651 : -175--> thermal_power_station_111_10.jpg | 32.84dB
25-05-18 00:39:41.834 : -176--> thermal_power_station_111_11.jpg | 33.29dB
25-05-18 00:39:42.016 : -177--> wetland_111_00.jpg | 33.76dB
25-05-18 00:39:42.197 : -178--> wetland_111_01.jpg | 33.78dB
25-05-18 00:39:42.374 : -179--> wetland_111_10.jpg | 34.01dB
25-05-18 00:39:42.555 : -180--> wetland_111_11.jpg | 33.46dB
25-05-18 00:39:42.564 : <epoch:  0, iter:  25,000, Average PSNR : 34.65dB

25-05-18 01:59:59.618 : <epoch:  0, iter:  30,000, lr:2.500e-05> G_loss: 2.746e-05 
25-05-18 01:59:59.619 : Saving the model.
25-05-18 02:00:00.178 : ---1--> airplane_111_00.jpg | 33.25dB
25-05-18 02:00:00.353 : ---2--> airplane_111_01.jpg | 37.47dB
25-05-18 02:00:00.533 : ---3--> airplane_111_10.jpg | 35.36dB
25-05-18 02:00:00.711 : ---4--> airplane_111_11.jpg | 35.20dB
25-05-18 02:00:00.887 : ---5--> airport_111_00.jpg | 36.55dB
25-05-18 02:00:01.063 : ---6--> airport_111_01.jpg | 34.72dB
25-05-18 02:00:01.240 : ---7--> airport_111_10.jpg | 34.45dB
25-05-18 02:00:01.422 : ---8--> airport_111_11.jpg | 35.27dB
25-05-18 02:00:01.603 : ---9--> baseball_diamond_111_00.jpg | 35.14dB
25-05-18 02:00:01.781 : --10--> baseball_diamond_111_01.jpg | 36.49dB
25-05-18 02:00:01.962 : --11--> baseball_diamond_111_10.jpg | 34.86dB
25-05-18 02:00:02.143 : --12--> baseball_diamond_111_11.jpg | 37.42dB
25-05-18 02:00:02.320 : --13--> basketball_court_111_00.jpg | 33.35dB
25-05-18 02:00:02.497 : --14--> basketball_court_111_01.jpg | 32.95dB
25-05-18 02:00:02.674 : --15--> basketball_court_111_10.jpg | 35.77dB
25-05-18 02:00:02.854 : --16--> basketball_court_111_11.jpg | 34.39dB
25-05-18 02:00:03.033 : --17--> beach_111_00.jpg | 31.49dB
25-05-18 02:00:03.217 : --18--> beach_111_01.jpg | 34.39dB
25-05-18 02:00:03.394 : --19--> beach_111_10.jpg | 32.61dB
25-05-18 02:00:03.568 : --20--> beach_111_11.jpg | 36.62dB
25-05-18 02:00:03.745 : --21--> bridge_111_00.jpg | 42.48dB
25-05-18 02:00:03.921 : --22--> bridge_111_01.jpg | 36.55dB
25-05-18 02:00:04.095 : --23--> bridge_111_10.jpg | 35.62dB
25-05-18 02:00:04.283 : --24--> bridge_111_11.jpg | 38.86dB
25-05-18 02:00:04.463 : --25--> chaparral_111_00.jpg | 33.02dB
25-05-18 02:00:04.640 : --26--> chaparral_111_01.jpg | 33.32dB
25-05-18 02:00:04.812 : --27--> chaparral_111_10.jpg | 33.49dB
25-05-18 02:00:04.987 : --28--> chaparral_111_11.jpg | 31.75dB
25-05-18 02:00:05.167 : --29--> church_111_00.jpg | 34.15dB
25-05-18 02:00:05.346 : --30--> church_111_01.jpg | 33.27dB
25-05-18 02:00:05.525 : --31--> church_111_10.jpg | 36.63dB
25-05-18 02:00:05.702 : --32--> church_111_11.jpg | 33.08dB
25-05-18 02:00:05.884 : --33--> circular_farmland_111_00.jpg | 35.39dB
25-05-18 02:00:06.065 : --34--> circular_farmland_111_01.jpg | 36.15dB
25-05-18 02:00:06.245 : --35--> circular_farmland_111_10.jpg | 36.44dB
25-05-18 02:00:06.429 : --36--> circular_farmland_111_11.jpg | 36.39dB
25-05-18 02:00:06.609 : --37--> cloud_111_00.jpg | 43.13dB
25-05-18 02:00:06.783 : --38--> cloud_111_01.jpg | 39.00dB
25-05-18 02:00:06.963 : --39--> cloud_111_10.jpg | 38.63dB
25-05-18 02:00:07.138 : --40--> cloud_111_11.jpg | 38.98dB
25-05-18 02:00:07.315 : --41--> commercial_area_111_00.jpg | 35.82dB
25-05-18 02:00:07.499 : --42--> commercial_area_111_01.jpg | 35.03dB
25-05-18 02:00:07.675 : --43--> commercial_area_111_10.jpg | 35.70dB
25-05-18 02:00:07.855 : --44--> commercial_area_111_11.jpg | 35.63dB
25-05-18 02:00:08.032 : --45--> dense_residential_111_00.jpg | 32.81dB
25-05-18 02:00:08.209 : --46--> dense_residential_111_01.jpg | 32.10dB
25-05-18 02:00:08.389 : --47--> dense_residential_111_10.jpg | 32.42dB
25-05-18 02:00:08.566 : --48--> dense_residential_111_11.jpg | 32.27dB
25-05-18 02:00:08.748 : --49--> desert_111_00.jpg | 38.70dB
25-05-18 02:00:08.925 : --50--> desert_111_01.jpg | 38.75dB
25-05-18 02:00:09.106 : --51--> desert_111_10.jpg | 38.91dB
25-05-18 02:00:09.282 : --52--> desert_111_11.jpg | 39.05dB
25-05-18 02:00:09.461 : --53--> forest_111_00.jpg | 35.31dB
25-05-18 02:00:09.643 : --54--> forest_111_01.jpg | 34.44dB
25-05-18 02:00:09.824 : --55--> forest_111_10.jpg | 34.21dB
25-05-18 02:00:10.001 : --56--> forest_111_11.jpg | 34.99dB
25-05-18 02:00:10.176 : --57--> freeway_111_00.jpg | 36.07dB
25-05-18 02:00:10.356 : --58--> freeway_111_01.jpg | 36.64dB
25-05-18 02:00:10.535 : --59--> freeway_111_10.jpg | 36.46dB
25-05-18 02:00:10.719 : --60--> freeway_111_11.jpg | 36.68dB
25-05-18 02:00:10.893 : --61--> golf_course_111_00.jpg | 35.12dB
25-05-18 02:00:11.077 : --62--> golf_course_111_01.jpg | 34.72dB
25-05-18 02:00:11.257 : --63--> golf_course_111_10.jpg | 35.80dB
25-05-18 02:00:11.439 : --64--> golf_course_111_11.jpg | 36.29dB
25-05-18 02:00:11.616 : --65--> ground_track_field_111_00.jpg | 35.70dB
25-05-18 02:00:11.795 : --66--> ground_track_field_111_01.jpg | 32.23dB
25-05-18 02:00:11.969 : --67--> ground_track_field_111_10.jpg | 33.39dB
25-05-18 02:00:12.144 : --68--> ground_track_field_111_11.jpg | 32.75dB
25-05-18 02:00:12.325 : --69--> harbor_111_00.jpg | 34.83dB
25-05-18 02:00:12.509 : --70--> harbor_111_01.jpg | 33.63dB
25-05-18 02:00:12.696 : --71--> harbor_111_10.jpg | 33.44dB
25-05-18 02:00:12.874 : --72--> harbor_111_11.jpg | 34.92dB
25-05-18 02:00:13.054 : --73--> industrial_area_111_00.jpg | 33.98dB
25-05-18 02:00:13.229 : --74--> industrial_area_111_01.jpg | 34.29dB
25-05-18 02:00:13.411 : --75--> industrial_area_111_10.jpg | 34.28dB
25-05-18 02:00:13.589 : --76--> industrial_area_111_11.jpg | 33.87dB
25-05-18 02:00:13.769 : --77--> intersection_111_00.jpg | 33.27dB
25-05-18 02:00:13.946 : --78--> intersection_111_01.jpg | 33.38dB
25-05-18 02:00:14.125 : --79--> intersection_111_10.jpg | 33.13dB
25-05-18 02:00:14.302 : --80--> intersection_111_11.jpg | 32.94dB
25-05-18 02:00:14.482 : --81--> island_111_00.jpg | 34.18dB
25-05-18 02:00:14.662 : --82--> island_111_01.jpg | 36.40dB
25-05-18 02:00:14.841 : --83--> island_111_10.jpg | 35.05dB
25-05-18 02:00:15.015 : --84--> island_111_11.jpg | 34.55dB
25-05-18 02:00:15.195 : --85--> lake_111_00.jpg | 34.76dB
25-05-18 02:00:15.373 : --86--> lake_111_01.jpg | 34.63dB
25-05-18 02:00:15.547 : --87--> lake_111_10.jpg | 34.19dB
25-05-18 02:00:15.725 : --88--> lake_111_11.jpg | 33.53dB
25-05-18 02:00:15.904 : --89--> meadow_111_00.jpg | 32.76dB
25-05-18 02:00:16.083 : --90--> meadow_111_01.jpg | 32.89dB
25-05-18 02:00:16.263 : --91--> meadow_111_10.jpg | 32.84dB
25-05-18 02:00:16.441 : --92--> meadow_111_11.jpg | 33.01dB
25-05-18 02:00:16.625 : --93--> medium_residential_111_00.jpg | 31.66dB
25-05-18 02:00:16.805 : --94--> medium_residential_111_01.jpg | 31.20dB
25-05-18 02:00:16.981 : --95--> medium_residential_111_10.jpg | 31.48dB
25-05-18 02:00:17.164 : --96--> medium_residential_111_11.jpg | 31.94dB
25-05-18 02:00:17.340 : --97--> mobile_home_park_111_00.jpg | 33.69dB
25-05-18 02:00:17.525 : --98--> mobile_home_park_111_01.jpg | 34.09dB
25-05-18 02:00:17.703 : --99--> mobile_home_park_111_10.jpg | 34.36dB
25-05-18 02:00:17.883 : -100--> mobile_home_park_111_11.jpg | 34.49dB
25-05-18 02:00:18.062 : -101--> mountain_111_00.jpg | 31.80dB
25-05-18 02:00:18.242 : -102--> mountain_111_01.jpg | 32.27dB
25-05-18 02:00:18.421 : -103--> mountain_111_10.jpg | 32.14dB
25-05-18 02:00:18.601 : -104--> mountain_111_11.jpg | 32.38dB
25-05-18 02:00:18.783 : -105--> overpass_111_00.jpg | 32.73dB
25-05-18 02:00:18.963 : -106--> overpass_111_01.jpg | 32.74dB
25-05-18 02:00:19.142 : -107--> overpass_111_10.jpg | 33.08dB
25-05-18 02:00:19.325 : -108--> overpass_111_11.jpg | 33.97dB
25-05-18 02:00:19.502 : -109--> palace_111_00.jpg | 32.75dB
25-05-18 02:00:19.682 : -110--> palace_111_01.jpg | 32.62dB
25-05-18 02:00:19.860 : -111--> palace_111_10.jpg | 33.64dB
25-05-18 02:00:20.042 : -112--> palace_111_11.jpg | 32.23dB
25-05-18 02:00:20.224 : -113--> parking_lot_111_00.jpg | 32.30dB
25-05-18 02:00:20.401 : -114--> parking_lot_111_01.jpg | 32.57dB
25-05-18 02:00:20.585 : -115--> parking_lot_111_10.jpg | 33.74dB
25-05-18 02:00:20.767 : -116--> parking_lot_111_11.jpg | 32.76dB
25-05-18 02:00:20.952 : -117--> railway_111_00.jpg | 32.83dB
25-05-18 02:00:21.125 : -118--> railway_111_01.jpg | 32.31dB
25-05-18 02:00:21.299 : -119--> railway_111_10.jpg | 34.72dB
25-05-18 02:00:21.482 : -120--> railway_111_11.jpg | 31.95dB
25-05-18 02:00:21.658 : -121--> railway_station_111_00.jpg | 33.45dB
25-05-18 02:00:21.833 : -122--> railway_station_111_01.jpg | 33.71dB
25-05-18 02:00:22.012 : -123--> railway_station_111_10.jpg | 33.59dB
25-05-18 02:00:22.186 : -124--> railway_station_111_11.jpg | 33.82dB
25-05-18 02:00:22.363 : -125--> rectangular_farmland_111_00.jpg | 35.80dB
25-05-18 02:00:22.542 : -126--> rectangular_farmland_111_01.jpg | 34.48dB
25-05-18 02:00:22.721 : -127--> rectangular_farmland_111_10.jpg | 36.11dB
25-05-18 02:00:22.904 : -128--> rectangular_farmland_111_11.jpg | 36.44dB
25-05-18 02:00:23.081 : -129--> river_111_00.jpg | 32.91dB
25-05-18 02:00:23.267 : -130--> river_111_01.jpg | 32.71dB
25-05-18 02:00:23.441 : -131--> river_111_10.jpg | 32.30dB
25-05-18 02:00:23.619 : -132--> river_111_11.jpg | 33.87dB
25-05-18 02:00:23.802 : -133--> roundabout_111_00.jpg | 33.03dB
25-05-18 02:00:23.982 : -134--> roundabout_111_01.jpg | 34.40dB
25-05-18 02:00:24.167 : -135--> roundabout_111_10.jpg | 32.96dB
25-05-18 02:00:24.347 : -136--> roundabout_111_11.jpg | 33.30dB
25-05-18 02:00:24.531 : -137--> runway_111_00.jpg | 38.20dB
25-05-18 02:00:24.705 : -138--> runway_111_01.jpg | 37.76dB
25-05-18 02:00:24.883 : -139--> runway_111_10.jpg | 38.52dB
25-05-18 02:00:25.065 : -140--> runway_111_11.jpg | 39.41dB
25-05-18 02:00:25.250 : -141--> sea_ice_111_00.jpg | 35.83dB
25-05-18 02:00:25.424 : -142--> sea_ice_111_01.jpg | 36.83dB
25-05-18 02:00:25.607 : -143--> sea_ice_111_10.jpg | 35.78dB
25-05-18 02:00:25.783 : -144--> sea_ice_111_11.jpg | 36.87dB
25-05-18 02:00:25.964 : -145--> ship_111_00.jpg | 40.75dB
25-05-18 02:00:26.142 : -146--> ship_111_01.jpg | 36.93dB
25-05-18 02:00:26.322 : -147--> ship_111_10.jpg | 43.85dB
25-05-18 02:00:26.504 : -148--> ship_111_11.jpg | 42.34dB
25-05-18 02:00:26.681 : -149--> snowberg_111_00.jpg | 36.95dB
25-05-18 02:00:26.861 : -150--> snowberg_111_01.jpg | 35.28dB
25-05-18 02:00:27.043 : -151--> snowberg_111_10.jpg | 34.67dB
25-05-18 02:00:27.221 : -152--> snowberg_111_11.jpg | 34.59dB
25-05-18 02:00:27.405 : -153--> sparse_residential_111_00.jpg | 33.06dB
25-05-18 02:00:27.582 : -154--> sparse_residential_111_01.jpg | 33.32dB
25-05-18 02:00:27.764 : -155--> sparse_residential_111_10.jpg | 32.59dB
25-05-18 02:00:27.941 : -156--> sparse_residential_111_11.jpg | 32.81dB
25-05-18 02:00:28.122 : -157--> stadium_111_00.jpg | 32.95dB
25-05-18 02:00:28.300 : -158--> stadium_111_01.jpg | 32.89dB
25-05-18 02:00:28.480 : -159--> stadium_111_10.jpg | 33.93dB
25-05-18 02:00:28.657 : -160--> stadium_111_11.jpg | 32.92dB
25-05-18 02:00:28.833 : -161--> storage_tank_111_00.jpg | 34.38dB
25-05-18 02:00:29.014 : -162--> storage_tank_111_01.jpg | 34.56dB
25-05-18 02:00:29.192 : -163--> storage_tank_111_10.jpg | 33.38dB
25-05-18 02:00:29.373 : -164--> storage_tank_111_11.jpg | 33.86dB
25-05-18 02:00:29.552 : -165--> tennis_court_111_00.jpg | 34.23dB
25-05-18 02:00:29.732 : -166--> tennis_court_111_01.jpg | 34.04dB
25-05-18 02:00:29.912 : -167--> tennis_court_111_10.jpg | 33.98dB
25-05-18 02:00:30.092 : -168--> tennis_court_111_11.jpg | 32.43dB
25-05-18 02:00:30.270 : -169--> terrace_111_00.jpg | 34.69dB
25-05-18 02:00:30.452 : -170--> terrace_111_01.jpg | 35.62dB
25-05-18 02:00:30.629 : -171--> terrace_111_10.jpg | 34.82dB
25-05-18 02:00:30.810 : -172--> terrace_111_11.jpg | 34.82dB
25-05-18 02:00:30.987 : -173--> thermal_power_station_111_00.jpg | 32.97dB
25-05-18 02:00:31.166 : -174--> thermal_power_station_111_01.jpg | 34.44dB
25-05-18 02:00:31.346 : -175--> thermal_power_station_111_10.jpg | 32.85dB
25-05-18 02:00:31.525 : -176--> thermal_power_station_111_11.jpg | 33.28dB
25-05-18 02:00:31.706 : -177--> wetland_111_00.jpg | 33.76dB
25-05-18 02:00:31.882 : -178--> wetland_111_01.jpg | 33.78dB
25-05-18 02:00:32.061 : -179--> wetland_111_10.jpg | 34.01dB
25-05-18 02:00:32.243 : -180--> wetland_111_11.jpg | 33.45dB
25-05-18 02:00:32.251 : <epoch:  0, iter:  30,000, Average PSNR : 34.65dB

25-05-18 03:20:52.896 : <epoch:  1, iter:  35,000, lr:5.000e-05> G_loss: 4.672e-05 
25-05-18 03:20:52.897 : Saving the model.
25-05-18 03:20:53.603 : ---1--> airplane_111_00.jpg | 33.26dB
25-05-18 03:20:53.785 : ---2--> airplane_111_01.jpg | 37.49dB
25-05-18 03:20:53.964 : ---3--> airplane_111_10.jpg | 35.36dB
25-05-18 03:20:54.142 : ---4--> airplane_111_11.jpg | 35.20dB
25-05-18 03:20:54.323 : ---5--> airport_111_00.jpg | 36.56dB
25-05-18 03:20:54.501 : ---6--> airport_111_01.jpg | 34.73dB
25-05-18 03:20:54.683 : ---7--> airport_111_10.jpg | 34.45dB
25-05-18 03:20:54.862 : ---8--> airport_111_11.jpg | 35.26dB
25-05-18 03:20:55.041 : ---9--> baseball_diamond_111_00.jpg | 35.15dB
25-05-18 03:20:55.224 : --10--> baseball_diamond_111_01.jpg | 36.52dB
25-05-18 03:20:55.402 : --11--> baseball_diamond_111_10.jpg | 34.87dB
25-05-18 03:20:55.581 : --12--> baseball_diamond_111_11.jpg | 37.43dB
25-05-18 03:20:55.762 : --13--> basketball_court_111_00.jpg | 33.36dB
25-05-18 03:20:55.941 : --14--> basketball_court_111_01.jpg | 32.97dB
25-05-18 03:20:56.119 : --15--> basketball_court_111_10.jpg | 35.77dB
25-05-18 03:20:56.293 : --16--> basketball_court_111_11.jpg | 34.40dB
25-05-18 03:20:56.473 : --17--> beach_111_00.jpg | 31.50dB
25-05-18 03:20:56.653 : --18--> beach_111_01.jpg | 34.39dB
25-05-18 03:20:56.832 : --19--> beach_111_10.jpg | 32.60dB
25-05-18 03:20:57.010 : --20--> beach_111_11.jpg | 36.63dB
25-05-18 03:20:57.191 : --21--> bridge_111_00.jpg | 42.52dB
25-05-18 03:20:57.365 : --22--> bridge_111_01.jpg | 36.55dB
25-05-18 03:20:57.545 : --23--> bridge_111_10.jpg | 35.64dB
25-05-18 03:20:57.722 : --24--> bridge_111_11.jpg | 38.87dB
25-05-18 03:20:57.896 : --25--> chaparral_111_00.jpg | 33.02dB
25-05-18 03:20:58.078 : --26--> chaparral_111_01.jpg | 33.32dB
25-05-18 03:20:58.254 : --27--> chaparral_111_10.jpg | 33.49dB
25-05-18 03:20:58.431 : --28--> chaparral_111_11.jpg | 31.76dB
25-05-18 03:20:58.613 : --29--> church_111_00.jpg | 34.17dB
25-05-18 03:20:58.790 : --30--> church_111_01.jpg | 33.29dB
25-05-18 03:20:58.969 : --31--> church_111_10.jpg | 36.63dB
25-05-18 03:20:59.145 : --32--> church_111_11.jpg | 33.10dB
25-05-18 03:20:59.324 : --33--> circular_farmland_111_00.jpg | 35.42dB
25-05-18 03:20:59.502 : --34--> circular_farmland_111_01.jpg | 36.15dB
25-05-18 03:20:59.681 : --35--> circular_farmland_111_10.jpg | 36.45dB
25-05-18 03:20:59.858 : --36--> circular_farmland_111_11.jpg | 36.39dB
25-05-18 03:21:00.035 : --37--> cloud_111_00.jpg | 43.16dB
25-05-18 03:21:00.211 : --38--> cloud_111_01.jpg | 39.02dB
25-05-18 03:21:00.383 : --39--> cloud_111_10.jpg | 38.63dB
25-05-18 03:21:00.567 : --40--> cloud_111_11.jpg | 38.98dB
25-05-18 03:21:00.750 : --41--> commercial_area_111_00.jpg | 35.84dB
25-05-18 03:21:00.937 : --42--> commercial_area_111_01.jpg | 35.05dB
25-05-18 03:21:01.124 : --43--> commercial_area_111_10.jpg | 35.71dB
25-05-18 03:21:01.304 : --44--> commercial_area_111_11.jpg | 35.63dB
25-05-18 03:21:01.478 : --45--> dense_residential_111_00.jpg | 32.83dB
25-05-18 03:21:01.661 : --46--> dense_residential_111_01.jpg | 32.09dB
25-05-18 03:21:01.850 : --47--> dense_residential_111_10.jpg | 32.43dB
25-05-18 03:21:02.034 : --48--> dense_residential_111_11.jpg | 32.28dB
25-05-18 03:21:02.215 : --49--> desert_111_00.jpg | 38.71dB
25-05-18 03:21:02.393 : --50--> desert_111_01.jpg | 38.74dB
25-05-18 03:21:02.575 : --51--> desert_111_10.jpg | 38.90dB
25-05-18 03:21:02.759 : --52--> desert_111_11.jpg | 39.05dB
25-05-18 03:21:02.936 : --53--> forest_111_00.jpg | 35.31dB
25-05-18 03:21:03.115 : --54--> forest_111_01.jpg | 34.46dB
25-05-18 03:21:03.293 : --55--> forest_111_10.jpg | 34.22dB
25-05-18 03:21:03.474 : --56--> forest_111_11.jpg | 34.99dB
25-05-18 03:21:03.649 : --57--> freeway_111_00.jpg | 36.06dB
25-05-18 03:21:03.826 : --58--> freeway_111_01.jpg | 36.65dB
25-05-18 03:21:04.005 : --59--> freeway_111_10.jpg | 36.45dB
25-05-18 03:21:04.188 : --60--> freeway_111_11.jpg | 36.70dB
25-05-18 03:21:04.374 : --61--> golf_course_111_00.jpg | 35.13dB
25-05-18 03:21:04.552 : --62--> golf_course_111_01.jpg | 34.73dB
25-05-18 03:21:04.730 : --63--> golf_course_111_10.jpg | 35.79dB
25-05-18 03:21:04.910 : --64--> golf_course_111_11.jpg | 36.31dB
25-05-18 03:21:05.087 : --65--> ground_track_field_111_00.jpg | 35.73dB
25-05-18 03:21:05.276 : --66--> ground_track_field_111_01.jpg | 32.24dB
25-05-18 03:21:05.456 : --67--> ground_track_field_111_10.jpg | 33.41dB
25-05-18 03:21:05.636 : --68--> ground_track_field_111_11.jpg | 32.75dB
25-05-18 03:21:05.816 : --69--> harbor_111_00.jpg | 34.84dB
25-05-18 03:21:05.994 : --70--> harbor_111_01.jpg | 33.64dB
25-05-18 03:21:06.177 : --71--> harbor_111_10.jpg | 33.44dB
25-05-18 03:21:06.357 : --72--> harbor_111_11.jpg | 34.92dB
25-05-18 03:21:06.545 : --73--> industrial_area_111_00.jpg | 34.00dB
25-05-18 03:21:06.733 : --74--> industrial_area_111_01.jpg | 34.29dB
25-05-18 03:21:06.914 : --75--> industrial_area_111_10.jpg | 34.30dB
25-05-18 03:21:07.102 : --76--> industrial_area_111_11.jpg | 33.88dB
25-05-18 03:21:07.282 : --77--> intersection_111_00.jpg | 33.29dB
25-05-18 03:21:07.461 : --78--> intersection_111_01.jpg | 33.39dB
25-05-18 03:21:07.639 : --79--> intersection_111_10.jpg | 33.14dB
25-05-18 03:21:07.818 : --80--> intersection_111_11.jpg | 32.95dB
25-05-18 03:21:07.996 : --81--> island_111_00.jpg | 34.19dB
25-05-18 03:21:08.180 : --82--> island_111_01.jpg | 36.41dB
25-05-18 03:21:08.358 : --83--> island_111_10.jpg | 35.06dB
25-05-18 03:21:08.534 : --84--> island_111_11.jpg | 34.59dB
25-05-18 03:21:08.717 : --85--> lake_111_00.jpg | 34.77dB
25-05-18 03:21:08.894 : --86--> lake_111_01.jpg | 34.63dB
25-05-18 03:21:09.072 : --87--> lake_111_10.jpg | 34.21dB
25-05-18 03:21:09.252 : --88--> lake_111_11.jpg | 33.55dB
25-05-18 03:21:09.428 : --89--> meadow_111_00.jpg | 32.77dB
25-05-18 03:21:09.607 : --90--> meadow_111_01.jpg | 32.90dB
25-05-18 03:21:09.781 : --91--> meadow_111_10.jpg | 32.85dB
25-05-18 03:21:09.965 : --92--> meadow_111_11.jpg | 33.01dB
25-05-18 03:21:10.141 : --93--> medium_residential_111_00.jpg | 31.68dB
25-05-18 03:21:10.319 : --94--> medium_residential_111_01.jpg | 31.22dB
25-05-18 03:21:10.498 : --95--> medium_residential_111_10.jpg | 31.49dB
25-05-18 03:21:10.675 : --96--> medium_residential_111_11.jpg | 31.94dB
25-05-18 03:21:10.853 : --97--> mobile_home_park_111_00.jpg | 33.69dB
25-05-18 03:21:11.033 : --98--> mobile_home_park_111_01.jpg | 34.10dB
25-05-18 03:21:11.214 : --99--> mobile_home_park_111_10.jpg | 34.37dB
25-05-18 03:21:11.391 : -100--> mobile_home_park_111_11.jpg | 34.51dB
25-05-18 03:21:11.573 : -101--> mountain_111_00.jpg | 31.80dB
25-05-18 03:21:11.759 : -102--> mountain_111_01.jpg | 32.28dB
25-05-18 03:21:11.938 : -103--> mountain_111_10.jpg | 32.14dB
25-05-18 03:21:12.116 : -104--> mountain_111_11.jpg | 32.39dB
25-05-18 03:21:12.292 : -105--> overpass_111_00.jpg | 32.74dB
25-05-18 03:21:12.475 : -106--> overpass_111_01.jpg | 32.74dB
25-05-18 03:21:12.653 : -107--> overpass_111_10.jpg | 33.10dB
25-05-18 03:21:12.835 : -108--> overpass_111_11.jpg | 33.99dB
25-05-18 03:21:13.015 : -109--> palace_111_00.jpg | 32.75dB
25-05-18 03:21:13.194 : -110--> palace_111_01.jpg | 32.61dB
25-05-18 03:21:13.374 : -111--> palace_111_10.jpg | 33.64dB
25-05-18 03:21:13.556 : -112--> palace_111_11.jpg | 32.25dB
25-05-18 03:21:13.733 : -113--> parking_lot_111_00.jpg | 32.30dB
25-05-18 03:21:13.911 : -114--> parking_lot_111_01.jpg | 32.56dB
25-05-18 03:21:14.091 : -115--> parking_lot_111_10.jpg | 33.75dB
25-05-18 03:21:14.277 : -116--> parking_lot_111_11.jpg | 32.77dB
25-05-18 03:21:14.457 : -117--> railway_111_00.jpg | 32.82dB
25-05-18 03:21:14.636 : -118--> railway_111_01.jpg | 32.31dB
25-05-18 03:21:14.816 : -119--> railway_111_10.jpg | 34.74dB
25-05-18 03:21:14.995 : -120--> railway_111_11.jpg | 31.95dB
25-05-18 03:21:15.175 : -121--> railway_station_111_00.jpg | 33.46dB
25-05-18 03:21:15.356 : -122--> railway_station_111_01.jpg | 33.72dB
25-05-18 03:21:15.542 : -123--> railway_station_111_10.jpg | 33.56dB
25-05-18 03:21:15.722 : -124--> railway_station_111_11.jpg | 33.81dB
25-05-18 03:21:15.905 : -125--> rectangular_farmland_111_00.jpg | 35.82dB
25-05-18 03:21:16.085 : -126--> rectangular_farmland_111_01.jpg | 34.48dB
25-05-18 03:21:16.262 : -127--> rectangular_farmland_111_10.jpg | 36.14dB
25-05-18 03:21:16.442 : -128--> rectangular_farmland_111_11.jpg | 36.45dB
25-05-18 03:21:16.624 : -129--> river_111_00.jpg | 32.92dB
25-05-18 03:21:16.801 : -130--> river_111_01.jpg | 32.72dB
25-05-18 03:21:16.988 : -131--> river_111_10.jpg | 32.32dB
25-05-18 03:21:17.169 : -132--> river_111_11.jpg | 33.87dB
25-05-18 03:21:17.344 : -133--> roundabout_111_00.jpg | 33.03dB
25-05-18 03:21:17.522 : -134--> roundabout_111_01.jpg | 34.40dB
25-05-18 03:21:17.701 : -135--> roundabout_111_10.jpg | 32.96dB
25-05-18 03:21:17.882 : -136--> roundabout_111_11.jpg | 33.29dB
25-05-18 03:21:18.059 : -137--> runway_111_00.jpg | 38.21dB
25-05-18 03:21:18.235 : -138--> runway_111_01.jpg | 37.76dB
25-05-18 03:21:18.411 : -139--> runway_111_10.jpg | 38.54dB
25-05-18 03:21:18.595 : -140--> runway_111_11.jpg | 39.43dB
25-05-18 03:21:18.773 : -141--> sea_ice_111_00.jpg | 35.85dB
25-05-18 03:21:18.953 : -142--> sea_ice_111_01.jpg | 36.84dB
25-05-18 03:21:19.130 : -143--> sea_ice_111_10.jpg | 35.80dB
25-05-18 03:21:19.312 : -144--> sea_ice_111_11.jpg | 36.89dB
25-05-18 03:21:19.489 : -145--> ship_111_00.jpg | 40.77dB
25-05-18 03:21:19.669 : -146--> ship_111_01.jpg | 36.97dB
25-05-18 03:21:19.847 : -147--> ship_111_10.jpg | 43.94dB
25-05-18 03:21:20.028 : -148--> ship_111_11.jpg | 42.40dB
25-05-18 03:21:20.207 : -149--> snowberg_111_00.jpg | 36.95dB
25-05-18 03:21:20.396 : -150--> snowberg_111_01.jpg | 35.31dB
25-05-18 03:21:20.582 : -151--> snowberg_111_10.jpg | 34.68dB
25-05-18 03:21:20.765 : -152--> snowberg_111_11.jpg | 34.61dB
25-05-18 03:21:20.941 : -153--> sparse_residential_111_00.jpg | 33.05dB
25-05-18 03:21:21.122 : -154--> sparse_residential_111_01.jpg | 33.32dB
25-05-18 03:21:21.300 : -155--> sparse_residential_111_10.jpg | 32.59dB
25-05-18 03:21:21.482 : -156--> sparse_residential_111_11.jpg | 32.81dB
25-05-18 03:21:21.660 : -157--> stadium_111_00.jpg | 32.97dB
25-05-18 03:21:21.836 : -158--> stadium_111_01.jpg | 32.90dB
25-05-18 03:21:22.019 : -159--> stadium_111_10.jpg | 33.94dB
25-05-18 03:21:22.192 : -160--> stadium_111_11.jpg | 32.93dB
25-05-18 03:21:22.374 : -161--> storage_tank_111_00.jpg | 34.39dB
25-05-18 03:21:22.549 : -162--> storage_tank_111_01.jpg | 34.57dB
25-05-18 03:21:22.729 : -163--> storage_tank_111_10.jpg | 33.37dB
25-05-18 03:21:22.908 : -164--> storage_tank_111_11.jpg | 33.87dB
25-05-18 03:21:23.089 : -165--> tennis_court_111_00.jpg | 34.25dB
25-05-18 03:21:23.269 : -166--> tennis_court_111_01.jpg | 34.03dB
25-05-18 03:21:23.453 : -167--> tennis_court_111_10.jpg | 34.00dB
25-05-18 03:21:23.635 : -168--> tennis_court_111_11.jpg | 32.43dB
25-05-18 03:21:23.814 : -169--> terrace_111_00.jpg | 34.71dB
25-05-18 03:21:23.999 : -170--> terrace_111_01.jpg | 35.63dB
25-05-18 03:21:24.173 : -171--> terrace_111_10.jpg | 34.82dB
25-05-18 03:21:24.358 : -172--> terrace_111_11.jpg | 34.84dB
25-05-18 03:21:24.535 : -173--> thermal_power_station_111_00.jpg | 32.98dB
25-05-18 03:21:24.718 : -174--> thermal_power_station_111_01.jpg | 34.45dB
25-05-18 03:21:24.904 : -175--> thermal_power_station_111_10.jpg | 32.86dB
25-05-18 03:21:25.082 : -176--> thermal_power_station_111_11.jpg | 33.29dB
25-05-18 03:21:25.259 : -177--> wetland_111_00.jpg | 33.76dB
25-05-18 03:21:25.437 : -178--> wetland_111_01.jpg | 33.79dB
25-05-18 03:21:25.616 : -179--> wetland_111_10.jpg | 34.01dB
25-05-18 03:21:25.802 : -180--> wetland_111_11.jpg | 33.47dB
25-05-18 03:21:25.814 : <epoch:  1, iter:  35,000, Average PSNR : 34.66dB

25-05-18 04:41:45.018 : <epoch:  1, iter:  40,000, lr:5.000e-05> G_loss: 1.616e-05 
25-05-18 04:41:45.018 : Saving the model.
25-05-18 04:41:45.610 : ---1--> airplane_111_00.jpg | 33.27dB
25-05-18 04:41:45.788 : ---2--> airplane_111_01.jpg | 37.50dB
25-05-18 04:41:45.968 : ---3--> airplane_111_10.jpg | 35.37dB
25-05-18 04:41:46.144 : ---4--> airplane_111_11.jpg | 35.22dB
25-05-18 04:41:46.320 : ---5--> airport_111_00.jpg | 36.56dB
25-05-18 04:41:46.505 : ---6--> airport_111_01.jpg | 34.73dB
25-05-18 04:41:46.683 : ---7--> airport_111_10.jpg | 34.47dB
25-05-18 04:41:46.865 : ---8--> airport_111_11.jpg | 35.28dB
25-05-18 04:41:47.043 : ---9--> baseball_diamond_111_00.jpg | 35.15dB
25-05-18 04:41:47.226 : --10--> baseball_diamond_111_01.jpg | 36.53dB
25-05-18 04:41:47.398 : --11--> baseball_diamond_111_10.jpg | 34.88dB
25-05-18 04:41:47.583 : --12--> baseball_diamond_111_11.jpg | 37.42dB
25-05-18 04:41:47.760 : --13--> basketball_court_111_00.jpg | 33.38dB
25-05-18 04:41:47.940 : --14--> basketball_court_111_01.jpg | 32.98dB
25-05-18 04:41:48.123 : --15--> basketball_court_111_10.jpg | 35.78dB
25-05-18 04:41:48.296 : --16--> basketball_court_111_11.jpg | 34.40dB
25-05-18 04:41:48.475 : --17--> beach_111_00.jpg | 31.51dB
25-05-18 04:41:48.652 : --18--> beach_111_01.jpg | 34.41dB
25-05-18 04:41:48.835 : --19--> beach_111_10.jpg | 32.61dB
25-05-18 04:41:49.017 : --20--> beach_111_11.jpg | 36.62dB
25-05-18 04:41:49.197 : --21--> bridge_111_00.jpg | 42.52dB
25-05-18 04:41:49.378 : --22--> bridge_111_01.jpg | 36.56dB
25-05-18 04:41:49.551 : --23--> bridge_111_10.jpg | 35.65dB
25-05-18 04:41:49.728 : --24--> bridge_111_11.jpg | 38.87dB
25-05-18 04:41:49.910 : --25--> chaparral_111_00.jpg | 33.05dB
25-05-18 04:41:50.087 : --26--> chaparral_111_01.jpg | 33.35dB
25-05-18 04:41:50.265 : --27--> chaparral_111_10.jpg | 33.51dB
25-05-18 04:41:50.444 : --28--> chaparral_111_11.jpg | 31.78dB
25-05-18 04:41:50.629 : --29--> church_111_00.jpg | 34.18dB
25-05-18 04:41:50.805 : --30--> church_111_01.jpg | 33.30dB
25-05-18 04:41:50.984 : --31--> church_111_10.jpg | 36.66dB
25-05-18 04:41:51.165 : --32--> church_111_11.jpg | 33.11dB
25-05-18 04:41:51.344 : --33--> circular_farmland_111_00.jpg | 35.42dB
25-05-18 04:41:51.523 : --34--> circular_farmland_111_01.jpg | 36.15dB
25-05-18 04:41:51.702 : --35--> circular_farmland_111_10.jpg | 36.45dB
25-05-18 04:41:51.882 : --36--> circular_farmland_111_11.jpg | 36.40dB
25-05-18 04:41:52.057 : --37--> cloud_111_00.jpg | 43.18dB
25-05-18 04:41:52.233 : --38--> cloud_111_01.jpg | 39.01dB
25-05-18 04:41:52.411 : --39--> cloud_111_10.jpg | 38.66dB
25-05-18 04:41:52.591 : --40--> cloud_111_11.jpg | 38.98dB
25-05-18 04:41:52.768 : --41--> commercial_area_111_00.jpg | 35.86dB
25-05-18 04:41:52.952 : --42--> commercial_area_111_01.jpg | 35.05dB
25-05-18 04:41:53.130 : --43--> commercial_area_111_10.jpg | 35.70dB
25-05-18 04:41:53.305 : --44--> commercial_area_111_11.jpg | 35.64dB
25-05-18 04:41:53.489 : --45--> dense_residential_111_00.jpg | 32.87dB
25-05-18 04:41:53.663 : --46--> dense_residential_111_01.jpg | 32.13dB
25-05-18 04:41:53.846 : --47--> dense_residential_111_10.jpg | 32.45dB
25-05-18 04:41:54.021 : --48--> dense_residential_111_11.jpg | 32.30dB
25-05-18 04:41:54.199 : --49--> desert_111_00.jpg | 38.71dB
25-05-18 04:41:54.377 : --50--> desert_111_01.jpg | 38.76dB
25-05-18 04:41:54.558 : --51--> desert_111_10.jpg | 38.94dB
25-05-18 04:41:54.738 : --52--> desert_111_11.jpg | 39.09dB
25-05-18 04:41:54.924 : --53--> forest_111_00.jpg | 35.32dB
25-05-18 04:41:55.106 : --54--> forest_111_01.jpg | 34.45dB
25-05-18 04:41:55.281 : --55--> forest_111_10.jpg | 34.23dB
25-05-18 04:41:55.457 : --56--> forest_111_11.jpg | 34.99dB
25-05-18 04:41:55.631 : --57--> freeway_111_00.jpg | 36.06dB
25-05-18 04:41:55.817 : --58--> freeway_111_01.jpg | 36.66dB
25-05-18 04:41:55.996 : --59--> freeway_111_10.jpg | 36.47dB
25-05-18 04:41:56.179 : --60--> freeway_111_11.jpg | 36.71dB
25-05-18 04:41:56.357 : --61--> golf_course_111_00.jpg | 35.14dB
25-05-18 04:41:56.539 : --62--> golf_course_111_01.jpg | 34.74dB
25-05-18 04:41:56.723 : --63--> golf_course_111_10.jpg | 35.80dB
25-05-18 04:41:56.899 : --64--> golf_course_111_11.jpg | 36.30dB
25-05-18 04:41:57.075 : --65--> ground_track_field_111_00.jpg | 35.75dB
25-05-18 04:41:57.254 : --66--> ground_track_field_111_01.jpg | 32.26dB
25-05-18 04:41:57.433 : --67--> ground_track_field_111_10.jpg | 33.42dB
25-05-18 04:41:57.611 : --68--> ground_track_field_111_11.jpg | 32.77dB
25-05-18 04:41:57.794 : --69--> harbor_111_00.jpg | 34.84dB
25-05-18 04:41:57.984 : --70--> harbor_111_01.jpg | 33.65dB
25-05-18 04:41:58.163 : --71--> harbor_111_10.jpg | 33.45dB
25-05-18 04:41:58.341 : --72--> harbor_111_11.jpg | 34.93dB
25-05-18 04:41:58.521 : --73--> industrial_area_111_00.jpg | 34.02dB
25-05-18 04:41:58.708 : --74--> industrial_area_111_01.jpg | 34.30dB
25-05-18 04:41:58.884 : --75--> industrial_area_111_10.jpg | 34.30dB
25-05-18 04:41:59.061 : --76--> industrial_area_111_11.jpg | 33.90dB
25-05-18 04:41:59.239 : --77--> intersection_111_00.jpg | 33.29dB
25-05-18 04:41:59.418 : --78--> intersection_111_01.jpg | 33.41dB
25-05-18 04:41:59.598 : --79--> intersection_111_10.jpg | 33.15dB
25-05-18 04:41:59.773 : --80--> intersection_111_11.jpg | 32.96dB
25-05-18 04:41:59.951 : --81--> island_111_00.jpg | 34.20dB
25-05-18 04:42:00.129 : --82--> island_111_01.jpg | 36.41dB
25-05-18 04:42:00.309 : --83--> island_111_10.jpg | 35.07dB
25-05-18 04:42:00.481 : --84--> island_111_11.jpg | 34.59dB
25-05-18 04:42:00.658 : --85--> lake_111_00.jpg | 34.78dB
25-05-18 04:42:00.835 : --86--> lake_111_01.jpg | 34.65dB
25-05-18 04:42:01.014 : --87--> lake_111_10.jpg | 34.23dB
25-05-18 04:42:01.192 : --88--> lake_111_11.jpg | 33.57dB
25-05-18 04:42:01.373 : --89--> meadow_111_00.jpg | 32.79dB
25-05-18 04:42:01.553 : --90--> meadow_111_01.jpg | 32.92dB
25-05-18 04:42:01.732 : --91--> meadow_111_10.jpg | 32.87dB
25-05-18 04:42:01.912 : --92--> meadow_111_11.jpg | 33.03dB
25-05-18 04:42:02.091 : --93--> medium_residential_111_00.jpg | 31.69dB
25-05-18 04:42:02.274 : --94--> medium_residential_111_01.jpg | 31.23dB
25-05-18 04:42:02.453 : --95--> medium_residential_111_10.jpg | 31.50dB
25-05-18 04:42:02.635 : --96--> medium_residential_111_11.jpg | 31.96dB
25-05-18 04:42:02.814 : --97--> mobile_home_park_111_00.jpg | 33.71dB
25-05-18 04:42:02.993 : --98--> mobile_home_park_111_01.jpg | 34.12dB
25-05-18 04:42:03.172 : --99--> mobile_home_park_111_10.jpg | 34.38dB
25-05-18 04:42:03.353 : -100--> mobile_home_park_111_11.jpg | 34.52dB
25-05-18 04:42:03.527 : -101--> mountain_111_00.jpg | 31.82dB
25-05-18 04:42:03.713 : -102--> mountain_111_01.jpg | 32.30dB
25-05-18 04:42:03.888 : -103--> mountain_111_10.jpg | 32.16dB
25-05-18 04:42:04.064 : -104--> mountain_111_11.jpg | 32.41dB
25-05-18 04:42:04.240 : -105--> overpass_111_00.jpg | 32.76dB
25-05-18 04:42:04.416 : -106--> overpass_111_01.jpg | 32.75dB
25-05-18 04:42:04.601 : -107--> overpass_111_10.jpg | 33.12dB
25-05-18 04:42:04.783 : -108--> overpass_111_11.jpg | 33.98dB
25-05-18 04:42:04.958 : -109--> palace_111_00.jpg | 32.77dB
25-05-18 04:42:05.136 : -110--> palace_111_01.jpg | 32.64dB
25-05-18 04:42:05.310 : -111--> palace_111_10.jpg | 33.65dB
25-05-18 04:42:05.489 : -112--> palace_111_11.jpg | 32.26dB
25-05-18 04:42:05.666 : -113--> parking_lot_111_00.jpg | 32.32dB
25-05-18 04:42:05.843 : -114--> parking_lot_111_01.jpg | 32.58dB
25-05-18 04:42:06.022 : -115--> parking_lot_111_10.jpg | 33.77dB
25-05-18 04:42:06.201 : -116--> parking_lot_111_11.jpg | 32.79dB
25-05-18 04:42:06.384 : -117--> railway_111_00.jpg | 32.85dB
25-05-18 04:42:06.562 : -118--> railway_111_01.jpg | 32.33dB
25-05-18 04:42:06.744 : -119--> railway_111_10.jpg | 34.74dB
25-05-18 04:42:06.925 : -120--> railway_111_11.jpg | 31.97dB
25-05-18 04:42:07.108 : -121--> railway_station_111_00.jpg | 33.47dB
25-05-18 04:42:07.288 : -122--> railway_station_111_01.jpg | 33.73dB
25-05-18 04:42:07.464 : -123--> railway_station_111_10.jpg | 33.59dB
25-05-18 04:42:07.639 : -124--> railway_station_111_11.jpg | 33.82dB
25-05-18 04:42:07.821 : -125--> rectangular_farmland_111_00.jpg | 35.81dB
25-05-18 04:42:08.001 : -126--> rectangular_farmland_111_01.jpg | 34.49dB
25-05-18 04:42:08.190 : -127--> rectangular_farmland_111_10.jpg | 36.14dB
25-05-18 04:42:08.368 : -128--> rectangular_farmland_111_11.jpg | 36.46dB
25-05-18 04:42:08.547 : -129--> river_111_00.jpg | 32.93dB
25-05-18 04:42:08.723 : -130--> river_111_01.jpg | 32.74dB
25-05-18 04:42:08.902 : -131--> river_111_10.jpg | 32.34dB
25-05-18 04:42:09.089 : -132--> river_111_11.jpg | 33.88dB
25-05-18 04:42:09.271 : -133--> roundabout_111_00.jpg | 33.06dB
25-05-18 04:42:09.450 : -134--> roundabout_111_01.jpg | 34.41dB
25-05-18 04:42:09.630 : -135--> roundabout_111_10.jpg | 32.98dB
25-05-18 04:42:09.811 : -136--> roundabout_111_11.jpg | 33.31dB
25-05-18 04:42:09.987 : -137--> runway_111_00.jpg | 38.21dB
25-05-18 04:42:10.164 : -138--> runway_111_01.jpg | 37.76dB
25-05-18 04:42:10.342 : -139--> runway_111_10.jpg | 38.53dB
25-05-18 04:42:10.524 : -140--> runway_111_11.jpg | 39.41dB
25-05-18 04:42:10.703 : -141--> sea_ice_111_00.jpg | 35.86dB
25-05-18 04:42:10.880 : -142--> sea_ice_111_01.jpg | 36.85dB
25-05-18 04:42:11.054 : -143--> sea_ice_111_10.jpg | 35.79dB
25-05-18 04:42:11.232 : -144--> sea_ice_111_11.jpg | 36.89dB
25-05-18 04:42:11.407 : -145--> ship_111_00.jpg | 40.76dB
25-05-18 04:42:11.584 : -146--> ship_111_01.jpg | 36.95dB
25-05-18 04:42:11.765 : -147--> ship_111_10.jpg | 43.94dB
25-05-18 04:42:11.951 : -148--> ship_111_11.jpg | 42.37dB
25-05-18 04:42:12.129 : -149--> snowberg_111_00.jpg | 36.96dB
25-05-18 04:42:12.307 : -150--> snowberg_111_01.jpg | 35.33dB
25-05-18 04:42:12.482 : -151--> snowberg_111_10.jpg | 34.70dB
25-05-18 04:42:12.664 : -152--> snowberg_111_11.jpg | 34.62dB
25-05-18 04:42:12.840 : -153--> sparse_residential_111_00.jpg | 33.07dB
25-05-18 04:42:13.018 : -154--> sparse_residential_111_01.jpg | 33.33dB
25-05-18 04:42:13.199 : -155--> sparse_residential_111_10.jpg | 32.61dB
25-05-18 04:42:13.381 : -156--> sparse_residential_111_11.jpg | 32.82dB
25-05-18 04:42:13.562 : -157--> stadium_111_00.jpg | 32.98dB
25-05-18 04:42:13.741 : -158--> stadium_111_01.jpg | 32.91dB
25-05-18 04:42:13.922 : -159--> stadium_111_10.jpg | 33.95dB
25-05-18 04:42:14.103 : -160--> stadium_111_11.jpg | 32.94dB
25-05-18 04:42:14.277 : -161--> storage_tank_111_00.jpg | 34.41dB
25-05-18 04:42:14.461 : -162--> storage_tank_111_01.jpg | 34.58dB
25-05-18 04:42:14.641 : -163--> storage_tank_111_10.jpg | 33.38dB
25-05-18 04:42:14.819 : -164--> storage_tank_111_11.jpg | 33.87dB
25-05-18 04:42:14.998 : -165--> tennis_court_111_00.jpg | 34.26dB
25-05-18 04:42:15.174 : -166--> tennis_court_111_01.jpg | 34.05dB
25-05-18 04:42:15.353 : -167--> tennis_court_111_10.jpg | 34.02dB
25-05-18 04:42:15.531 : -168--> tennis_court_111_11.jpg | 32.45dB
25-05-18 04:42:15.707 : -169--> terrace_111_00.jpg | 34.72dB
25-05-18 04:42:15.884 : -170--> terrace_111_01.jpg | 35.63dB
25-05-18 04:42:16.064 : -171--> terrace_111_10.jpg | 34.83dB
25-05-18 04:42:16.242 : -172--> terrace_111_11.jpg | 34.84dB
25-05-18 04:42:16.420 : -173--> thermal_power_station_111_00.jpg | 32.99dB
25-05-18 04:42:16.601 : -174--> thermal_power_station_111_01.jpg | 34.47dB
25-05-18 04:42:16.784 : -175--> thermal_power_station_111_10.jpg | 32.88dB
25-05-18 04:42:16.967 : -176--> thermal_power_station_111_11.jpg | 33.31dB
25-05-18 04:42:17.142 : -177--> wetland_111_00.jpg | 33.77dB
25-05-18 04:42:17.321 : -178--> wetland_111_01.jpg | 33.79dB
25-05-18 04:42:17.505 : -179--> wetland_111_10.jpg | 34.02dB
25-05-18 04:42:17.684 : -180--> wetland_111_11.jpg | 33.48dB
25-05-18 04:42:17.694 : <epoch:  1, iter:  40,000, Average PSNR : 34.67dB

25-05-18 06:02:37.800 : <epoch:  1, iter:  45,000, lr:5.000e-05> G_loss: 3.524e-05 
25-05-18 06:02:37.801 : Saving the model.
25-05-18 06:02:38.370 : ---1--> airplane_111_00.jpg | 33.32dB
25-05-18 06:02:38.547 : ---2--> airplane_111_01.jpg | 37.54dB
25-05-18 06:02:38.726 : ---3--> airplane_111_10.jpg | 35.41dB
25-05-18 06:02:38.905 : ---4--> airplane_111_11.jpg | 35.27dB
25-05-18 06:02:39.089 : ---5--> airport_111_00.jpg | 36.60dB
25-05-18 06:02:39.266 : ---6--> airport_111_01.jpg | 34.79dB
25-05-18 06:02:39.446 : ---7--> airport_111_10.jpg | 34.52dB
25-05-18 06:02:39.621 : ---8--> airport_111_11.jpg | 35.34dB
25-05-18 06:02:39.802 : ---9--> baseball_diamond_111_00.jpg | 35.19dB
25-05-18 06:02:39.984 : --10--> baseball_diamond_111_01.jpg | 36.54dB
25-05-18 06:02:40.166 : --11--> baseball_diamond_111_10.jpg | 34.91dB
25-05-18 06:02:40.346 : --12--> baseball_diamond_111_11.jpg | 37.45dB
25-05-18 06:02:40.530 : --13--> basketball_court_111_00.jpg | 33.42dB
25-05-18 06:02:40.703 : --14--> basketball_court_111_01.jpg | 33.02dB
25-05-18 06:02:40.881 : --15--> basketball_court_111_10.jpg | 35.80dB
25-05-18 06:02:41.056 : --16--> basketball_court_111_11.jpg | 34.47dB
25-05-18 06:02:41.240 : --17--> beach_111_00.jpg | 31.56dB
25-05-18 06:02:41.417 : --18--> beach_111_01.jpg | 34.45dB
25-05-18 06:02:41.604 : --19--> beach_111_10.jpg | 32.67dB
25-05-18 06:02:41.784 : --20--> beach_111_11.jpg | 36.67dB
25-05-18 06:02:41.965 : --21--> bridge_111_00.jpg | 42.52dB
25-05-18 06:02:42.145 : --22--> bridge_111_01.jpg | 36.62dB
25-05-18 06:02:42.324 : --23--> bridge_111_10.jpg | 35.71dB
25-05-18 06:02:42.509 : --24--> bridge_111_11.jpg | 38.90dB
25-05-18 06:02:42.690 : --25--> chaparral_111_00.jpg | 33.12dB
25-05-18 06:02:42.866 : --26--> chaparral_111_01.jpg | 33.38dB
25-05-18 06:02:43.047 : --27--> chaparral_111_10.jpg | 33.58dB
25-05-18 06:02:43.226 : --28--> chaparral_111_11.jpg | 31.82dB
25-05-18 06:02:43.408 : --29--> church_111_00.jpg | 34.21dB
25-05-18 06:02:43.582 : --30--> church_111_01.jpg | 33.35dB
25-05-18 06:02:43.763 : --31--> church_111_10.jpg | 36.68dB
25-05-18 06:02:43.942 : --32--> church_111_11.jpg | 33.16dB
25-05-18 06:02:44.120 : --33--> circular_farmland_111_00.jpg | 35.45dB
25-05-18 06:02:44.299 : --34--> circular_farmland_111_01.jpg | 36.19dB
25-05-18 06:02:44.474 : --35--> circular_farmland_111_10.jpg | 36.51dB
25-05-18 06:02:44.653 : --36--> circular_farmland_111_11.jpg | 36.45dB
25-05-18 06:02:44.833 : --37--> cloud_111_00.jpg | 43.16dB
25-05-18 06:02:45.006 : --38--> cloud_111_01.jpg | 39.02dB
25-05-18 06:02:45.187 : --39--> cloud_111_10.jpg | 38.64dB
25-05-18 06:02:45.369 : --40--> cloud_111_11.jpg | 39.02dB
25-05-18 06:02:45.545 : --41--> commercial_area_111_00.jpg | 35.86dB
25-05-18 06:02:45.721 : --42--> commercial_area_111_01.jpg | 35.10dB
25-05-18 06:02:45.903 : --43--> commercial_area_111_10.jpg | 35.74dB
25-05-18 06:02:46.081 : --44--> commercial_area_111_11.jpg | 35.69dB
25-05-18 06:02:46.260 : --45--> dense_residential_111_00.jpg | 32.92dB
25-05-18 06:02:46.446 : --46--> dense_residential_111_01.jpg | 32.16dB
25-05-18 06:02:46.626 : --47--> dense_residential_111_10.jpg | 32.51dB
25-05-18 06:02:46.802 : --48--> dense_residential_111_11.jpg | 32.34dB
25-05-18 06:02:46.986 : --49--> desert_111_00.jpg | 38.75dB
25-05-18 06:02:47.159 : --50--> desert_111_01.jpg | 38.77dB
25-05-18 06:02:47.338 : --51--> desert_111_10.jpg | 38.95dB
25-05-18 06:02:47.514 : --52--> desert_111_11.jpg | 39.09dB
25-05-18 06:02:47.693 : --53--> forest_111_00.jpg | 35.34dB
25-05-18 06:02:47.872 : --54--> forest_111_01.jpg | 34.50dB
25-05-18 06:02:48.050 : --55--> forest_111_10.jpg | 34.28dB
25-05-18 06:02:48.229 : --56--> forest_111_11.jpg | 35.06dB
25-05-18 06:02:48.405 : --57--> freeway_111_00.jpg | 36.10dB
25-05-18 06:02:48.589 : --58--> freeway_111_01.jpg | 36.72dB
25-05-18 06:02:48.765 : --59--> freeway_111_10.jpg | 36.56dB
25-05-18 06:02:48.946 : --60--> freeway_111_11.jpg | 36.76dB
25-05-18 06:02:49.120 : --61--> golf_course_111_00.jpg | 35.18dB
25-05-18 06:02:49.295 : --62--> golf_course_111_01.jpg | 34.77dB
25-05-18 06:02:49.471 : --63--> golf_course_111_10.jpg | 35.85dB
25-05-18 06:02:49.648 : --64--> golf_course_111_11.jpg | 36.33dB
25-05-18 06:02:49.836 : --65--> ground_track_field_111_00.jpg | 35.81dB
25-05-18 06:02:50.019 : --66--> ground_track_field_111_01.jpg | 32.32dB
25-05-18 06:02:50.196 : --67--> ground_track_field_111_10.jpg | 33.47dB
25-05-18 06:02:50.378 : --68--> ground_track_field_111_11.jpg | 32.81dB
25-05-18 06:02:50.558 : --69--> harbor_111_00.jpg | 34.90dB
25-05-18 06:02:50.738 : --70--> harbor_111_01.jpg | 33.71dB
25-05-18 06:02:50.915 : --71--> harbor_111_10.jpg | 33.49dB
25-05-18 06:02:51.090 : --72--> harbor_111_11.jpg | 34.97dB
25-05-18 06:02:51.266 : --73--> industrial_area_111_00.jpg | 34.10dB
25-05-18 06:02:51.442 : --74--> industrial_area_111_01.jpg | 34.36dB
25-05-18 06:02:51.619 : --75--> industrial_area_111_10.jpg | 34.38dB
25-05-18 06:02:51.802 : --76--> industrial_area_111_11.jpg | 33.97dB
25-05-18 06:02:51.980 : --77--> intersection_111_00.jpg | 33.35dB
25-05-18 06:02:52.157 : --78--> intersection_111_01.jpg | 33.46dB
25-05-18 06:02:52.333 : --79--> intersection_111_10.jpg | 33.21dB
25-05-18 06:02:52.517 : --80--> intersection_111_11.jpg | 33.03dB
25-05-18 06:02:52.699 : --81--> island_111_00.jpg | 34.27dB
25-05-18 06:02:52.880 : --82--> island_111_01.jpg | 36.46dB
25-05-18 06:02:53.060 : --83--> island_111_10.jpg | 35.13dB
25-05-18 06:02:53.237 : --84--> island_111_11.jpg | 34.64dB
25-05-18 06:02:53.417 : --85--> lake_111_00.jpg | 34.83dB
25-05-18 06:02:53.596 : --86--> lake_111_01.jpg | 34.71dB
25-05-18 06:02:53.776 : --87--> lake_111_10.jpg | 34.29dB
25-05-18 06:02:53.953 : --88--> lake_111_11.jpg | 33.62dB
25-05-18 06:02:54.132 : --89--> meadow_111_00.jpg | 32.84dB
25-05-18 06:02:54.310 : --90--> meadow_111_01.jpg | 32.98dB
25-05-18 06:02:54.485 : --91--> meadow_111_10.jpg | 32.94dB
25-05-18 06:02:54.661 : --92--> meadow_111_11.jpg | 33.10dB
25-05-18 06:02:54.837 : --93--> medium_residential_111_00.jpg | 31.74dB
25-05-18 06:02:55.021 : --94--> medium_residential_111_01.jpg | 31.27dB
25-05-18 06:02:55.197 : --95--> medium_residential_111_10.jpg | 31.56dB
25-05-18 06:02:55.381 : --96--> medium_residential_111_11.jpg | 32.00dB
25-05-18 06:02:55.557 : --97--> mobile_home_park_111_00.jpg | 33.75dB
25-05-18 06:02:55.734 : --98--> mobile_home_park_111_01.jpg | 34.16dB
25-05-18 06:02:55.916 : --99--> mobile_home_park_111_10.jpg | 34.42dB
25-05-18 06:02:56.095 : -100--> mobile_home_park_111_11.jpg | 34.56dB
25-05-18 06:02:56.276 : -101--> mountain_111_00.jpg | 31.85dB
25-05-18 06:02:56.455 : -102--> mountain_111_01.jpg | 32.35dB
25-05-18 06:02:56.635 : -103--> mountain_111_10.jpg | 32.22dB
25-05-18 06:02:56.820 : -104--> mountain_111_11.jpg | 32.47dB
25-05-18 06:02:56.994 : -105--> overpass_111_00.jpg | 32.80dB
25-05-18 06:02:57.177 : -106--> overpass_111_01.jpg | 32.81dB
25-05-18 06:02:57.352 : -107--> overpass_111_10.jpg | 33.19dB
25-05-18 06:02:57.530 : -108--> overpass_111_11.jpg | 34.05dB
25-05-18 06:02:57.710 : -109--> palace_111_00.jpg | 32.80dB
25-05-18 06:02:57.898 : -110--> palace_111_01.jpg | 32.68dB
25-05-18 06:02:58.073 : -111--> palace_111_10.jpg | 33.70dB
25-05-18 06:02:58.250 : -112--> palace_111_11.jpg | 32.32dB
25-05-18 06:02:58.429 : -113--> parking_lot_111_00.jpg | 32.36dB
25-05-18 06:02:58.603 : -114--> parking_lot_111_01.jpg | 32.62dB
25-05-18 06:02:58.786 : -115--> parking_lot_111_10.jpg | 33.81dB
25-05-18 06:02:58.964 : -116--> parking_lot_111_11.jpg | 32.84dB
25-05-18 06:02:59.144 : -117--> railway_111_00.jpg | 32.89dB
25-05-18 06:02:59.323 : -118--> railway_111_01.jpg | 32.39dB
25-05-18 06:02:59.501 : -119--> railway_111_10.jpg | 34.81dB
25-05-18 06:02:59.680 : -120--> railway_111_11.jpg | 32.03dB
25-05-18 06:02:59.864 : -121--> railway_station_111_00.jpg | 33.52dB
25-05-18 06:03:00.047 : -122--> railway_station_111_01.jpg | 33.80dB
25-05-18 06:03:00.227 : -123--> railway_station_111_10.jpg | 33.64dB
25-05-18 06:03:00.403 : -124--> railway_station_111_11.jpg | 33.90dB
25-05-18 06:03:00.583 : -125--> rectangular_farmland_111_00.jpg | 35.87dB
25-05-18 06:03:00.759 : -126--> rectangular_farmland_111_01.jpg | 34.54dB
25-05-18 06:03:00.938 : -127--> rectangular_farmland_111_10.jpg | 36.15dB
25-05-18 06:03:01.115 : -128--> rectangular_farmland_111_11.jpg | 36.49dB
25-05-18 06:03:01.291 : -129--> river_111_00.jpg | 32.98dB
25-05-18 06:03:01.468 : -130--> river_111_01.jpg | 32.80dB
25-05-18 06:03:01.649 : -131--> river_111_10.jpg | 32.39dB
25-05-18 06:03:01.825 : -132--> river_111_11.jpg | 33.93dB
25-05-18 06:03:02.003 : -133--> roundabout_111_00.jpg | 33.11dB
25-05-18 06:03:02.180 : -134--> roundabout_111_01.jpg | 34.46dB
25-05-18 06:03:02.365 : -135--> roundabout_111_10.jpg | 33.03dB
25-05-18 06:03:02.547 : -136--> roundabout_111_11.jpg | 33.36dB
25-05-18 06:03:02.728 : -137--> runway_111_00.jpg | 38.26dB
25-05-18 06:03:02.905 : -138--> runway_111_01.jpg | 37.81dB
25-05-18 06:03:03.086 : -139--> runway_111_10.jpg | 38.53dB
25-05-18 06:03:03.265 : -140--> runway_111_11.jpg | 39.43dB
25-05-18 06:03:03.446 : -141--> sea_ice_111_00.jpg | 35.92dB
25-05-18 06:03:03.622 : -142--> sea_ice_111_01.jpg | 36.89dB
25-05-18 06:03:03.800 : -143--> sea_ice_111_10.jpg | 35.88dB
25-05-18 06:03:03.976 : -144--> sea_ice_111_11.jpg | 36.93dB
25-05-18 06:03:04.157 : -145--> ship_111_00.jpg | 40.79dB
25-05-18 06:03:04.335 : -146--> ship_111_01.jpg | 36.97dB
25-05-18 06:03:04.516 : -147--> ship_111_10.jpg | 43.94dB
25-05-18 06:03:04.693 : -148--> ship_111_11.jpg | 42.36dB
25-05-18 06:03:04.881 : -149--> snowberg_111_00.jpg | 37.04dB
25-05-18 06:03:05.056 : -150--> snowberg_111_01.jpg | 35.39dB
25-05-18 06:03:05.238 : -151--> snowberg_111_10.jpg | 34.77dB
25-05-18 06:03:05.422 : -152--> snowberg_111_11.jpg | 34.69dB
25-05-18 06:03:05.599 : -153--> sparse_residential_111_00.jpg | 33.14dB
25-05-18 06:03:05.778 : -154--> sparse_residential_111_01.jpg | 33.38dB
25-05-18 06:03:05.955 : -155--> sparse_residential_111_10.jpg | 32.66dB
25-05-18 06:03:06.133 : -156--> sparse_residential_111_11.jpg | 32.88dB
25-05-18 06:03:06.315 : -157--> stadium_111_00.jpg | 33.02dB
25-05-18 06:03:06.494 : -158--> stadium_111_01.jpg | 32.97dB
25-05-18 06:03:06.675 : -159--> stadium_111_10.jpg | 34.01dB
25-05-18 06:03:06.851 : -160--> stadium_111_11.jpg | 33.00dB
25-05-18 06:03:07.030 : -161--> storage_tank_111_00.jpg | 34.44dB
25-05-18 06:03:07.212 : -162--> storage_tank_111_01.jpg | 34.61dB
25-05-18 06:03:07.394 : -163--> storage_tank_111_10.jpg | 33.44dB
25-05-18 06:03:07.574 : -164--> storage_tank_111_11.jpg | 33.92dB
25-05-18 06:03:07.760 : -165--> tennis_court_111_00.jpg | 34.33dB
25-05-18 06:03:07.941 : -166--> tennis_court_111_01.jpg | 34.10dB
25-05-18 06:03:08.118 : -167--> tennis_court_111_10.jpg | 34.08dB
25-05-18 06:03:08.296 : -168--> tennis_court_111_11.jpg | 32.50dB
25-05-18 06:03:08.480 : -169--> terrace_111_00.jpg | 34.79dB
25-05-18 06:03:08.660 : -170--> terrace_111_01.jpg | 35.68dB
25-05-18 06:03:08.840 : -171--> terrace_111_10.jpg | 34.87dB
25-05-18 06:03:09.022 : -172--> terrace_111_11.jpg | 34.90dB
25-05-18 06:03:09.199 : -173--> thermal_power_station_111_00.jpg | 33.03dB
25-05-18 06:03:09.376 : -174--> thermal_power_station_111_01.jpg | 34.52dB
25-05-18 06:03:09.553 : -175--> thermal_power_station_111_10.jpg | 32.93dB
25-05-18 06:03:09.737 : -176--> thermal_power_station_111_11.jpg | 33.37dB
25-05-18 06:03:09.911 : -177--> wetland_111_00.jpg | 33.83dB
25-05-18 06:03:10.093 : -178--> wetland_111_01.jpg | 33.86dB
25-05-18 06:03:10.270 : -179--> wetland_111_10.jpg | 34.08dB
25-05-18 06:03:10.452 : -180--> wetland_111_11.jpg | 33.55dB
25-05-18 06:03:10.460 : <epoch:  1, iter:  45,000, Average PSNR : 34.72dB

25-05-18 07:23:29.967 : <epoch:  1, iter:  50,000, lr:1.250e-05> G_loss: 2.062e-05 
25-05-18 07:23:29.968 : Saving the model.
25-05-18 07:23:30.548 : ---1--> airplane_111_00.jpg | 33.34dB
25-05-18 07:23:30.722 : ---2--> airplane_111_01.jpg | 37.57dB
25-05-18 07:23:30.909 : ---3--> airplane_111_10.jpg | 35.44dB
25-05-18 07:23:31.083 : ---4--> airplane_111_11.jpg | 35.30dB
25-05-18 07:23:31.267 : ---5--> airport_111_00.jpg | 36.61dB
25-05-18 07:23:31.446 : ---6--> airport_111_01.jpg | 34.83dB
25-05-18 07:23:31.626 : ---7--> airport_111_10.jpg | 34.55dB
25-05-18 07:23:31.804 : ---8--> airport_111_11.jpg | 35.36dB
25-05-18 07:23:31.983 : ---9--> baseball_diamond_111_00.jpg | 35.20dB
25-05-18 07:23:32.164 : --10--> baseball_diamond_111_01.jpg | 36.56dB
25-05-18 07:23:32.338 : --11--> baseball_diamond_111_10.jpg | 34.93dB
25-05-18 07:23:32.514 : --12--> baseball_diamond_111_11.jpg | 37.48dB
25-05-18 07:23:32.690 : --13--> basketball_court_111_00.jpg | 33.44dB
25-05-18 07:23:32.871 : --14--> basketball_court_111_01.jpg | 33.05dB
25-05-18 07:23:33.050 : --15--> basketball_court_111_10.jpg | 35.82dB
25-05-18 07:23:33.233 : --16--> basketball_court_111_11.jpg | 34.48dB
25-05-18 07:23:33.414 : --17--> beach_111_00.jpg | 31.60dB
25-05-18 07:23:33.590 : --18--> beach_111_01.jpg | 34.50dB
25-05-18 07:23:33.770 : --19--> beach_111_10.jpg | 32.70dB
25-05-18 07:23:33.947 : --20--> beach_111_11.jpg | 36.69dB
25-05-18 07:23:34.128 : --21--> bridge_111_00.jpg | 42.54dB
25-05-18 07:23:34.307 : --22--> bridge_111_01.jpg | 36.65dB
25-05-18 07:23:34.482 : --23--> bridge_111_10.jpg | 35.75dB
25-05-18 07:23:34.659 : --24--> bridge_111_11.jpg | 38.94dB
25-05-18 07:23:34.842 : --25--> chaparral_111_00.jpg | 33.16dB
25-05-18 07:23:35.024 : --26--> chaparral_111_01.jpg | 33.40dB
25-05-18 07:23:35.203 : --27--> chaparral_111_10.jpg | 33.59dB
25-05-18 07:23:35.376 : --28--> chaparral_111_11.jpg | 31.85dB
25-05-18 07:23:35.560 : --29--> church_111_00.jpg | 34.25dB
25-05-18 07:23:35.736 : --30--> church_111_01.jpg | 33.38dB
25-05-18 07:23:35.917 : --31--> church_111_10.jpg | 36.72dB
25-05-18 07:23:36.103 : --32--> church_111_11.jpg | 33.19dB
25-05-18 07:23:36.282 : --33--> circular_farmland_111_00.jpg | 35.49dB
25-05-18 07:23:36.458 : --34--> circular_farmland_111_01.jpg | 36.19dB
25-05-18 07:23:36.638 : --35--> circular_farmland_111_10.jpg | 36.52dB
25-05-18 07:23:36.821 : --36--> circular_farmland_111_11.jpg | 36.46dB
25-05-18 07:23:37.000 : --37--> cloud_111_00.jpg | 43.18dB
25-05-18 07:23:37.182 : --38--> cloud_111_01.jpg | 39.01dB
25-05-18 07:23:37.366 : --39--> cloud_111_10.jpg | 38.64dB
25-05-18 07:23:37.545 : --40--> cloud_111_11.jpg | 39.02dB
25-05-18 07:23:37.719 : --41--> commercial_area_111_00.jpg | 35.87dB
25-05-18 07:23:37.899 : --42--> commercial_area_111_01.jpg | 35.11dB
25-05-18 07:23:38.079 : --43--> commercial_area_111_10.jpg | 35.77dB
25-05-18 07:23:38.256 : --44--> commercial_area_111_11.jpg | 35.72dB
25-05-18 07:23:38.439 : --45--> dense_residential_111_00.jpg | 32.95dB
25-05-18 07:23:38.617 : --46--> dense_residential_111_01.jpg | 32.20dB
25-05-18 07:23:38.797 : --47--> dense_residential_111_10.jpg | 32.55dB
25-05-18 07:23:38.981 : --48--> dense_residential_111_11.jpg | 32.38dB
25-05-18 07:23:39.159 : --49--> desert_111_00.jpg | 38.74dB
25-05-18 07:23:39.338 : --50--> desert_111_01.jpg | 38.77dB
25-05-18 07:23:39.518 : --51--> desert_111_10.jpg | 38.96dB
25-05-18 07:23:39.699 : --52--> desert_111_11.jpg | 39.10dB
25-05-18 07:23:39.878 : --53--> forest_111_00.jpg | 35.37dB
25-05-18 07:23:40.059 : --54--> forest_111_01.jpg | 34.52dB
25-05-18 07:23:40.242 : --55--> forest_111_10.jpg | 34.30dB
25-05-18 07:23:40.423 : --56--> forest_111_11.jpg | 35.09dB
25-05-18 07:23:40.598 : --57--> freeway_111_00.jpg | 36.12dB
25-05-18 07:23:40.775 : --58--> freeway_111_01.jpg | 36.78dB
25-05-18 07:23:40.953 : --59--> freeway_111_10.jpg | 36.60dB
25-05-18 07:23:41.127 : --60--> freeway_111_11.jpg | 36.78dB
25-05-18 07:23:41.309 : --61--> golf_course_111_00.jpg | 35.20dB
25-05-18 07:23:41.485 : --62--> golf_course_111_01.jpg | 34.81dB
25-05-18 07:23:41.660 : --63--> golf_course_111_10.jpg | 35.86dB
25-05-18 07:23:41.841 : --64--> golf_course_111_11.jpg | 36.35dB
25-05-18 07:23:42.019 : --65--> ground_track_field_111_00.jpg | 35.85dB
25-05-18 07:23:42.206 : --66--> ground_track_field_111_01.jpg | 32.34dB
25-05-18 07:23:42.387 : --67--> ground_track_field_111_10.jpg | 33.49dB
25-05-18 07:23:42.565 : --68--> ground_track_field_111_11.jpg | 32.83dB
25-05-18 07:23:42.750 : --69--> harbor_111_00.jpg | 34.93dB
25-05-18 07:23:42.932 : --70--> harbor_111_01.jpg | 33.74dB
25-05-18 07:23:43.109 : --71--> harbor_111_10.jpg | 33.51dB
25-05-18 07:23:43.295 : --72--> harbor_111_11.jpg | 35.00dB
25-05-18 07:23:43.477 : --73--> industrial_area_111_00.jpg | 34.11dB
25-05-18 07:23:43.653 : --74--> industrial_area_111_01.jpg | 34.39dB
25-05-18 07:23:43.827 : --75--> industrial_area_111_10.jpg | 34.42dB
25-05-18 07:23:44.006 : --76--> industrial_area_111_11.jpg | 33.98dB
25-05-18 07:23:44.184 : --77--> intersection_111_00.jpg | 33.38dB
25-05-18 07:23:44.362 : --78--> intersection_111_01.jpg | 33.48dB
25-05-18 07:23:44.541 : --79--> intersection_111_10.jpg | 33.25dB
25-05-18 07:23:44.715 : --80--> intersection_111_11.jpg | 33.07dB
25-05-18 07:23:44.899 : --81--> island_111_00.jpg | 34.30dB
25-05-18 07:23:45.083 : --82--> island_111_01.jpg | 36.49dB
25-05-18 07:23:45.263 : --83--> island_111_10.jpg | 35.16dB
25-05-18 07:23:45.440 : --84--> island_111_11.jpg | 34.65dB
25-05-18 07:23:45.619 : --85--> lake_111_00.jpg | 34.86dB
25-05-18 07:23:45.803 : --86--> lake_111_01.jpg | 34.74dB
25-05-18 07:23:45.978 : --87--> lake_111_10.jpg | 34.32dB
25-05-18 07:23:46.155 : --88--> lake_111_11.jpg | 33.64dB
25-05-18 07:23:46.330 : --89--> meadow_111_00.jpg | 32.86dB
25-05-18 07:23:46.508 : --90--> meadow_111_01.jpg | 32.99dB
25-05-18 07:23:46.690 : --91--> meadow_111_10.jpg | 32.95dB
25-05-18 07:23:46.867 : --92--> meadow_111_11.jpg | 33.12dB
25-05-18 07:23:47.042 : --93--> medium_residential_111_00.jpg | 31.76dB
25-05-18 07:23:47.217 : --94--> medium_residential_111_01.jpg | 31.30dB
25-05-18 07:23:47.395 : --95--> medium_residential_111_10.jpg | 31.58dB
25-05-18 07:23:47.576 : --96--> medium_residential_111_11.jpg | 32.03dB
25-05-18 07:23:47.751 : --97--> mobile_home_park_111_00.jpg | 33.77dB
25-05-18 07:23:47.932 : --98--> mobile_home_park_111_01.jpg | 34.19dB
25-05-18 07:23:48.110 : --99--> mobile_home_park_111_10.jpg | 34.44dB
25-05-18 07:23:48.301 : -100--> mobile_home_park_111_11.jpg | 34.58dB
25-05-18 07:23:48.477 : -101--> mountain_111_00.jpg | 31.89dB
25-05-18 07:23:48.654 : -102--> mountain_111_01.jpg | 32.37dB
25-05-18 07:23:48.834 : -103--> mountain_111_10.jpg | 32.24dB
25-05-18 07:23:49.014 : -104--> mountain_111_11.jpg | 32.49dB
25-05-18 07:23:49.192 : -105--> overpass_111_00.jpg | 32.83dB
25-05-18 07:23:49.374 : -106--> overpass_111_01.jpg | 32.82dB
25-05-18 07:23:49.554 : -107--> overpass_111_10.jpg | 33.19dB
25-05-18 07:23:49.732 : -108--> overpass_111_11.jpg | 34.08dB
25-05-18 07:23:49.908 : -109--> palace_111_00.jpg | 32.82dB
25-05-18 07:23:50.087 : -110--> palace_111_01.jpg | 32.71dB
25-05-18 07:23:50.264 : -111--> palace_111_10.jpg | 33.73dB
25-05-18 07:23:50.439 : -112--> palace_111_11.jpg | 32.36dB
25-05-18 07:23:50.615 : -113--> parking_lot_111_00.jpg | 32.40dB
25-05-18 07:23:50.795 : -114--> parking_lot_111_01.jpg | 32.68dB
25-05-18 07:23:50.974 : -115--> parking_lot_111_10.jpg | 33.83dB
25-05-18 07:23:51.164 : -116--> parking_lot_111_11.jpg | 32.87dB
25-05-18 07:23:51.341 : -117--> railway_111_00.jpg | 32.92dB
25-05-18 07:23:51.517 : -118--> railway_111_01.jpg | 32.42dB
25-05-18 07:23:51.701 : -119--> railway_111_10.jpg | 34.83dB
25-05-18 07:23:51.883 : -120--> railway_111_11.jpg | 32.07dB
25-05-18 07:23:52.073 : -121--> railway_station_111_00.jpg | 33.54dB
25-05-18 07:23:52.253 : -122--> railway_station_111_01.jpg | 33.85dB
25-05-18 07:23:52.432 : -123--> railway_station_111_10.jpg | 33.66dB
25-05-18 07:23:52.612 : -124--> railway_station_111_11.jpg | 33.92dB
25-05-18 07:23:52.793 : -125--> rectangular_farmland_111_00.jpg | 35.87dB
25-05-18 07:23:52.974 : -126--> rectangular_farmland_111_01.jpg | 34.59dB
25-05-18 07:23:53.155 : -127--> rectangular_farmland_111_10.jpg | 36.18dB
25-05-18 07:23:53.334 : -128--> rectangular_farmland_111_11.jpg | 36.49dB
25-05-18 07:23:53.510 : -129--> river_111_00.jpg | 33.00dB
25-05-18 07:23:53.691 : -130--> river_111_01.jpg | 32.81dB
25-05-18 07:23:53.881 : -131--> river_111_10.jpg | 32.42dB
25-05-18 07:23:54.059 : -132--> river_111_11.jpg | 33.96dB
25-05-18 07:23:54.241 : -133--> roundabout_111_00.jpg | 33.13dB
25-05-18 07:23:54.418 : -134--> roundabout_111_01.jpg | 34.50dB
25-05-18 07:23:54.601 : -135--> roundabout_111_10.jpg | 33.06dB
25-05-18 07:23:54.789 : -136--> roundabout_111_11.jpg | 33.37dB
25-05-18 07:23:54.969 : -137--> runway_111_00.jpg | 38.27dB
25-05-18 07:23:55.157 : -138--> runway_111_01.jpg | 37.80dB
25-05-18 07:23:55.335 : -139--> runway_111_10.jpg | 38.54dB
25-05-18 07:23:55.516 : -140--> runway_111_11.jpg | 39.45dB
25-05-18 07:23:55.695 : -141--> sea_ice_111_00.jpg | 35.94dB
25-05-18 07:23:55.877 : -142--> sea_ice_111_01.jpg | 36.91dB
25-05-18 07:23:56.050 : -143--> sea_ice_111_10.jpg | 35.90dB
25-05-18 07:23:56.225 : -144--> sea_ice_111_11.jpg | 36.97dB
25-05-18 07:23:56.404 : -145--> ship_111_00.jpg | 40.80dB
25-05-18 07:23:56.583 : -146--> ship_111_01.jpg | 36.97dB
25-05-18 07:23:56.763 : -147--> ship_111_10.jpg | 43.94dB
25-05-18 07:23:56.941 : -148--> ship_111_11.jpg | 42.39dB
25-05-18 07:23:57.124 : -149--> snowberg_111_00.jpg | 37.09dB
25-05-18 07:23:57.300 : -150--> snowberg_111_01.jpg | 35.42dB
25-05-18 07:23:57.481 : -151--> snowberg_111_10.jpg | 34.81dB
25-05-18 07:23:57.657 : -152--> snowberg_111_11.jpg | 34.73dB
25-05-18 07:23:57.832 : -153--> sparse_residential_111_00.jpg | 33.17dB
25-05-18 07:23:58.016 : -154--> sparse_residential_111_01.jpg | 33.40dB
25-05-18 07:23:58.194 : -155--> sparse_residential_111_10.jpg | 32.69dB
25-05-18 07:23:58.374 : -156--> sparse_residential_111_11.jpg | 32.90dB
25-05-18 07:23:58.551 : -157--> stadium_111_00.jpg | 33.06dB
25-05-18 07:23:58.732 : -158--> stadium_111_01.jpg | 32.99dB
25-05-18 07:23:58.906 : -159--> stadium_111_10.jpg | 34.04dB
25-05-18 07:23:59.093 : -160--> stadium_111_11.jpg | 33.03dB
25-05-18 07:23:59.275 : -161--> storage_tank_111_00.jpg | 34.48dB
25-05-18 07:23:59.457 : -162--> storage_tank_111_01.jpg | 34.64dB
25-05-18 07:23:59.638 : -163--> storage_tank_111_10.jpg | 33.49dB
25-05-18 07:23:59.814 : -164--> storage_tank_111_11.jpg | 33.95dB
25-05-18 07:23:59.997 : -165--> tennis_court_111_00.jpg | 34.37dB
25-05-18 07:24:00.177 : -166--> tennis_court_111_01.jpg | 34.12dB
25-05-18 07:24:00.354 : -167--> tennis_court_111_10.jpg | 34.12dB
25-05-18 07:24:00.533 : -168--> tennis_court_111_11.jpg | 32.53dB
25-05-18 07:24:00.717 : -169--> terrace_111_00.jpg | 34.83dB
25-05-18 07:24:00.898 : -170--> terrace_111_01.jpg | 35.71dB
25-05-18 07:24:01.075 : -171--> terrace_111_10.jpg | 34.88dB
25-05-18 07:24:01.255 : -172--> terrace_111_11.jpg | 34.92dB
25-05-18 07:24:01.435 : -173--> thermal_power_station_111_00.jpg | 33.06dB
25-05-18 07:24:01.611 : -174--> thermal_power_station_111_01.jpg | 34.55dB
25-05-18 07:24:01.798 : -175--> thermal_power_station_111_10.jpg | 32.95dB
25-05-18 07:24:01.974 : -176--> thermal_power_station_111_11.jpg | 33.39dB
25-05-18 07:24:02.156 : -177--> wetland_111_00.jpg | 33.86dB
25-05-18 07:24:02.334 : -178--> wetland_111_01.jpg | 33.88dB
25-05-18 07:24:02.512 : -179--> wetland_111_10.jpg | 34.10dB
25-05-18 07:24:02.691 : -180--> wetland_111_11.jpg | 33.58dB
25-05-18 07:24:02.699 : <epoch:  1, iter:  50,000, Average PSNR : 34.74dB

25-05-18 08:44:22.853 : <epoch:  1, iter:  55,000, lr:2.500e-05> G_loss: 8.482e-06 
25-05-18 08:44:22.854 : Saving the model.
25-05-18 08:44:23.439 : ---1--> airplane_111_00.jpg | 33.35dB
25-05-18 08:44:23.616 : ---2--> airplane_111_01.jpg | 37.58dB
25-05-18 08:44:23.793 : ---3--> airplane_111_10.jpg | 35.46dB
25-05-18 08:44:23.976 : ---4--> airplane_111_11.jpg | 35.30dB
25-05-18 08:44:24.154 : ---5--> airport_111_00.jpg | 36.61dB
25-05-18 08:44:24.333 : ---6--> airport_111_01.jpg | 34.84dB
25-05-18 08:44:24.510 : ---7--> airport_111_10.jpg | 34.56dB
25-05-18 08:44:24.688 : ---8--> airport_111_11.jpg | 35.37dB
25-05-18 08:44:24.866 : ---9--> baseball_diamond_111_00.jpg | 35.20dB
25-05-18 08:44:25.042 : --10--> baseball_diamond_111_01.jpg | 36.58dB
25-05-18 08:44:25.224 : --11--> baseball_diamond_111_10.jpg | 34.94dB
25-05-18 08:44:25.400 : --12--> baseball_diamond_111_11.jpg | 37.48dB
25-05-18 08:44:25.587 : --13--> basketball_court_111_00.jpg | 33.45dB
25-05-18 08:44:25.764 : --14--> basketball_court_111_01.jpg | 33.06dB
25-05-18 08:44:25.942 : --15--> basketball_court_111_10.jpg | 35.83dB
25-05-18 08:44:26.119 : --16--> basketball_court_111_11.jpg | 34.49dB
25-05-18 08:44:26.303 : --17--> beach_111_00.jpg | 31.61dB
25-05-18 08:44:26.480 : --18--> beach_111_01.jpg | 34.49dB
25-05-18 08:44:26.658 : --19--> beach_111_10.jpg | 32.71dB
25-05-18 08:44:26.835 : --20--> beach_111_11.jpg | 36.70dB
25-05-18 08:44:27.015 : --21--> bridge_111_00.jpg | 42.59dB
25-05-18 08:44:27.192 : --22--> bridge_111_01.jpg | 36.67dB
25-05-18 08:44:27.370 : --23--> bridge_111_10.jpg | 35.77dB
25-05-18 08:44:27.548 : --24--> bridge_111_11.jpg | 38.96dB
25-05-18 08:44:27.728 : --25--> chaparral_111_00.jpg | 33.16dB
25-05-18 08:44:27.908 : --26--> chaparral_111_01.jpg | 33.40dB
25-05-18 08:44:28.084 : --27--> chaparral_111_10.jpg | 33.61dB
25-05-18 08:44:28.263 : --28--> chaparral_111_11.jpg | 31.86dB
25-05-18 08:44:28.442 : --29--> church_111_00.jpg | 34.26dB
25-05-18 08:44:28.621 : --30--> church_111_01.jpg | 33.40dB
25-05-18 08:44:28.799 : --31--> church_111_10.jpg | 36.74dB
25-05-18 08:44:28.977 : --32--> church_111_11.jpg | 33.21dB
25-05-18 08:44:29.155 : --33--> circular_farmland_111_00.jpg | 35.51dB
25-05-18 08:44:29.334 : --34--> circular_farmland_111_01.jpg | 36.21dB
25-05-18 08:44:29.512 : --35--> circular_farmland_111_10.jpg | 36.54dB
25-05-18 08:44:29.691 : --36--> circular_farmland_111_11.jpg | 36.46dB
25-05-18 08:44:29.869 : --37--> cloud_111_00.jpg | 43.19dB
25-05-18 08:44:30.044 : --38--> cloud_111_01.jpg | 39.06dB
25-05-18 08:44:30.221 : --39--> cloud_111_10.jpg | 38.66dB
25-05-18 08:44:30.398 : --40--> cloud_111_11.jpg | 39.02dB
25-05-18 08:44:30.578 : --41--> commercial_area_111_00.jpg | 35.89dB
25-05-18 08:44:30.754 : --42--> commercial_area_111_01.jpg | 35.12dB
25-05-18 08:44:30.939 : --43--> commercial_area_111_10.jpg | 35.77dB
25-05-18 08:44:31.113 : --44--> commercial_area_111_11.jpg | 35.71dB
25-05-18 08:44:31.294 : --45--> dense_residential_111_00.jpg | 32.96dB
25-05-18 08:44:31.473 : --46--> dense_residential_111_01.jpg | 32.21dB
25-05-18 08:44:31.653 : --47--> dense_residential_111_10.jpg | 32.55dB
25-05-18 08:44:31.830 : --48--> dense_residential_111_11.jpg | 32.40dB
25-05-18 08:44:32.009 : --49--> desert_111_00.jpg | 38.75dB
25-05-18 08:44:32.193 : --50--> desert_111_01.jpg | 38.79dB
25-05-18 08:44:32.369 : --51--> desert_111_10.jpg | 38.97dB
25-05-18 08:44:32.546 : --52--> desert_111_11.jpg | 39.12dB
25-05-18 08:44:32.727 : --53--> forest_111_00.jpg | 35.37dB
25-05-18 08:44:32.907 : --54--> forest_111_01.jpg | 34.53dB
25-05-18 08:44:33.085 : --55--> forest_111_10.jpg | 34.31dB
25-05-18 08:44:33.265 : --56--> forest_111_11.jpg | 35.08dB
25-05-18 08:44:33.440 : --57--> freeway_111_00.jpg | 36.11dB
25-05-18 08:44:33.622 : --58--> freeway_111_01.jpg | 36.79dB
25-05-18 08:44:33.809 : --59--> freeway_111_10.jpg | 36.60dB
25-05-18 08:44:33.986 : --60--> freeway_111_11.jpg | 36.80dB
25-05-18 08:44:34.165 : --61--> golf_course_111_00.jpg | 35.21dB
25-05-18 08:44:34.343 : --62--> golf_course_111_01.jpg | 34.81dB
25-05-18 08:44:34.522 : --63--> golf_course_111_10.jpg | 35.87dB
25-05-18 08:44:34.703 : --64--> golf_course_111_11.jpg | 36.35dB
25-05-18 08:44:34.882 : --65--> ground_track_field_111_00.jpg | 35.85dB
25-05-18 08:44:35.063 : --66--> ground_track_field_111_01.jpg | 32.35dB
25-05-18 08:44:35.242 : --67--> ground_track_field_111_10.jpg | 33.49dB
25-05-18 08:44:35.427 : --68--> ground_track_field_111_11.jpg | 32.85dB
25-05-18 08:44:35.609 : --69--> harbor_111_00.jpg | 34.93dB
25-05-18 08:44:35.796 : --70--> harbor_111_01.jpg | 33.75dB
25-05-18 08:44:35.976 : --71--> harbor_111_10.jpg | 33.53dB
25-05-18 08:44:36.163 : --72--> harbor_111_11.jpg | 35.00dB
25-05-18 08:44:36.340 : --73--> industrial_area_111_00.jpg | 34.13dB
25-05-18 08:44:36.523 : --74--> industrial_area_111_01.jpg | 34.41dB
25-05-18 08:44:36.710 : --75--> industrial_area_111_10.jpg | 34.43dB
25-05-18 08:44:36.887 : --76--> industrial_area_111_11.jpg | 34.01dB
25-05-18 08:44:37.066 : --77--> intersection_111_00.jpg | 33.39dB
25-05-18 08:44:37.246 : --78--> intersection_111_01.jpg | 33.49dB
25-05-18 08:44:37.419 : --79--> intersection_111_10.jpg | 33.26dB
25-05-18 08:44:37.600 : --80--> intersection_111_11.jpg | 33.08dB
25-05-18 08:44:37.779 : --81--> island_111_00.jpg | 34.31dB
25-05-18 08:44:37.959 : --82--> island_111_01.jpg | 36.48dB
25-05-18 08:44:38.139 : --83--> island_111_10.jpg | 35.18dB
25-05-18 08:44:38.321 : --84--> island_111_11.jpg | 34.67dB
25-05-18 08:44:38.499 : --85--> lake_111_00.jpg | 34.86dB
25-05-18 08:44:38.683 : --86--> lake_111_01.jpg | 34.74dB
25-05-18 08:44:38.864 : --87--> lake_111_10.jpg | 34.32dB
25-05-18 08:44:39.053 : --88--> lake_111_11.jpg | 33.64dB
25-05-18 08:44:39.233 : --89--> meadow_111_00.jpg | 32.86dB
25-05-18 08:44:39.416 : --90--> meadow_111_01.jpg | 33.01dB
25-05-18 08:44:39.593 : --91--> meadow_111_10.jpg | 32.96dB
25-05-18 08:44:39.768 : --92--> meadow_111_11.jpg | 33.13dB
25-05-18 08:44:39.947 : --93--> medium_residential_111_00.jpg | 31.77dB
25-05-18 08:44:40.125 : --94--> medium_residential_111_01.jpg | 31.31dB
25-05-18 08:44:40.304 : --95--> medium_residential_111_10.jpg | 31.57dB
25-05-18 08:44:40.484 : --96--> medium_residential_111_11.jpg | 32.04dB
25-05-18 08:44:40.659 : --97--> mobile_home_park_111_00.jpg | 33.79dB
25-05-18 08:44:40.835 : --98--> mobile_home_park_111_01.jpg | 34.21dB
25-05-18 08:44:41.014 : --99--> mobile_home_park_111_10.jpg | 34.46dB
25-05-18 08:44:41.192 : -100--> mobile_home_park_111_11.jpg | 34.59dB
25-05-18 08:44:41.370 : -101--> mountain_111_00.jpg | 31.88dB
25-05-18 08:44:41.549 : -102--> mountain_111_01.jpg | 32.37dB
25-05-18 08:44:41.723 : -103--> mountain_111_10.jpg | 32.25dB
25-05-18 08:44:41.907 : -104--> mountain_111_11.jpg | 32.49dB
25-05-18 08:44:42.088 : -105--> overpass_111_00.jpg | 32.84dB
25-05-18 08:44:42.268 : -106--> overpass_111_01.jpg | 32.85dB
25-05-18 08:44:42.449 : -107--> overpass_111_10.jpg | 33.24dB
25-05-18 08:44:42.629 : -108--> overpass_111_11.jpg | 34.08dB
25-05-18 08:44:42.812 : -109--> palace_111_00.jpg | 32.83dB
25-05-18 08:44:42.988 : -110--> palace_111_01.jpg | 32.73dB
25-05-18 08:44:43.174 : -111--> palace_111_10.jpg | 33.74dB
25-05-18 08:44:43.353 : -112--> palace_111_11.jpg | 32.37dB
25-05-18 08:44:43.531 : -113--> parking_lot_111_00.jpg | 32.40dB
25-05-18 08:44:43.709 : -114--> parking_lot_111_01.jpg | 32.67dB
25-05-18 08:44:43.888 : -115--> parking_lot_111_10.jpg | 33.84dB
25-05-18 08:44:44.066 : -116--> parking_lot_111_11.jpg | 32.88dB
25-05-18 08:44:44.243 : -117--> railway_111_00.jpg | 32.91dB
25-05-18 08:44:44.421 : -118--> railway_111_01.jpg | 32.43dB
25-05-18 08:44:44.597 : -119--> railway_111_10.jpg | 34.85dB
25-05-18 08:44:44.780 : -120--> railway_111_11.jpg | 32.07dB
25-05-18 08:44:44.954 : -121--> railway_station_111_00.jpg | 33.56dB
25-05-18 08:44:45.131 : -122--> railway_station_111_01.jpg | 33.85dB
25-05-18 08:44:45.306 : -123--> railway_station_111_10.jpg | 33.66dB
25-05-18 08:44:45.481 : -124--> railway_station_111_11.jpg | 33.91dB
25-05-18 08:44:45.661 : -125--> rectangular_farmland_111_00.jpg | 35.89dB
25-05-18 08:44:45.837 : -126--> rectangular_farmland_111_01.jpg | 34.59dB
25-05-18 08:44:46.019 : -127--> rectangular_farmland_111_10.jpg | 36.17dB
25-05-18 08:44:46.203 : -128--> rectangular_farmland_111_11.jpg | 36.51dB
25-05-18 08:44:46.387 : -129--> river_111_00.jpg | 33.02dB
25-05-18 08:44:46.567 : -130--> river_111_01.jpg | 32.83dB
25-05-18 08:44:46.750 : -131--> river_111_10.jpg | 32.43dB
25-05-18 08:44:46.926 : -132--> river_111_11.jpg | 33.96dB
25-05-18 08:44:47.107 : -133--> roundabout_111_00.jpg | 33.14dB
25-05-18 08:44:47.282 : -134--> roundabout_111_01.jpg | 34.51dB
25-05-18 08:44:47.463 : -135--> roundabout_111_10.jpg | 33.06dB
25-05-18 08:44:47.642 : -136--> roundabout_111_11.jpg | 33.38dB
25-05-18 08:44:47.818 : -137--> runway_111_00.jpg | 38.28dB
25-05-18 08:44:47.995 : -138--> runway_111_01.jpg | 37.80dB
25-05-18 08:44:48.172 : -139--> runway_111_10.jpg | 38.57dB
25-05-18 08:44:48.358 : -140--> runway_111_11.jpg | 39.47dB
25-05-18 08:44:48.542 : -141--> sea_ice_111_00.jpg | 35.98dB
25-05-18 08:44:48.719 : -142--> sea_ice_111_01.jpg | 36.93dB
25-05-18 08:44:48.896 : -143--> sea_ice_111_10.jpg | 35.93dB
25-05-18 08:44:49.079 : -144--> sea_ice_111_11.jpg | 36.98dB
25-05-18 08:44:49.258 : -145--> ship_111_00.jpg | 40.82dB
25-05-18 08:44:49.437 : -146--> ship_111_01.jpg | 36.99dB
25-05-18 08:44:49.612 : -147--> ship_111_10.jpg | 44.00dB
25-05-18 08:44:49.795 : -148--> ship_111_11.jpg | 42.42dB
25-05-18 08:44:49.971 : -149--> snowberg_111_00.jpg | 37.09dB
25-05-18 08:44:50.147 : -150--> snowberg_111_01.jpg | 35.44dB
25-05-18 08:44:50.329 : -151--> snowberg_111_10.jpg | 34.83dB
25-05-18 08:44:50.507 : -152--> snowberg_111_11.jpg | 34.73dB
25-05-18 08:44:50.692 : -153--> sparse_residential_111_00.jpg | 33.18dB
25-05-18 08:44:50.874 : -154--> sparse_residential_111_01.jpg | 33.40dB
25-05-18 08:44:51.052 : -155--> sparse_residential_111_10.jpg | 32.70dB
25-05-18 08:44:51.228 : -156--> sparse_residential_111_11.jpg | 32.90dB
25-05-18 08:44:51.408 : -157--> stadium_111_00.jpg | 33.06dB
25-05-18 08:44:51.583 : -158--> stadium_111_01.jpg | 32.99dB
25-05-18 08:44:51.759 : -159--> stadium_111_10.jpg | 34.05dB
25-05-18 08:44:51.945 : -160--> stadium_111_11.jpg | 33.03dB
25-05-18 08:44:52.121 : -161--> storage_tank_111_00.jpg | 34.48dB
25-05-18 08:44:52.304 : -162--> storage_tank_111_01.jpg | 34.64dB
25-05-18 08:44:52.488 : -163--> storage_tank_111_10.jpg | 33.49dB
25-05-18 08:44:52.667 : -164--> storage_tank_111_11.jpg | 33.96dB
25-05-18 08:44:52.848 : -165--> tennis_court_111_00.jpg | 34.39dB
25-05-18 08:44:53.028 : -166--> tennis_court_111_01.jpg | 34.12dB
25-05-18 08:44:53.207 : -167--> tennis_court_111_10.jpg | 34.14dB
25-05-18 08:44:53.383 : -168--> tennis_court_111_11.jpg | 32.53dB
25-05-18 08:44:53.564 : -169--> terrace_111_00.jpg | 34.83dB
25-05-18 08:44:53.745 : -170--> terrace_111_01.jpg | 35.73dB
25-05-18 08:44:53.932 : -171--> terrace_111_10.jpg | 34.89dB
25-05-18 08:44:54.109 : -172--> terrace_111_11.jpg | 34.94dB
25-05-18 08:44:54.287 : -173--> thermal_power_station_111_00.jpg | 33.06dB
25-05-18 08:44:54.465 : -174--> thermal_power_station_111_01.jpg | 34.56dB
25-05-18 08:44:54.650 : -175--> thermal_power_station_111_10.jpg | 32.96dB
25-05-18 08:44:54.825 : -176--> thermal_power_station_111_11.jpg | 33.40dB
25-05-18 08:44:55.003 : -177--> wetland_111_00.jpg | 33.86dB
25-05-18 08:44:55.184 : -178--> wetland_111_01.jpg | 33.89dB
25-05-18 08:44:55.363 : -179--> wetland_111_10.jpg | 34.10dB
25-05-18 08:44:55.545 : -180--> wetland_111_11.jpg | 33.59dB
25-05-18 08:44:55.554 : <epoch:  1, iter:  55,000, Average PSNR : 34.75dB

25-05-18 10:05:28.162 : <epoch:  1, iter:  60,000, lr:2.500e-05> G_loss: 2.123e-05 
25-05-18 10:05:28.164 : Saving the model.
25-05-18 10:05:28.748 : ---1--> airplane_111_00.jpg | 33.36dB
25-05-18 10:05:28.924 : ---2--> airplane_111_01.jpg | 37.59dB
25-05-18 10:05:29.106 : ---3--> airplane_111_10.jpg | 35.47dB
25-05-18 10:05:29.285 : ---4--> airplane_111_11.jpg | 35.32dB
25-05-18 10:05:29.462 : ---5--> airport_111_00.jpg | 36.62dB
25-05-18 10:05:29.638 : ---6--> airport_111_01.jpg | 34.86dB
25-05-18 10:05:29.815 : ---7--> airport_111_10.jpg | 34.56dB
25-05-18 10:05:29.992 : ---8--> airport_111_11.jpg | 35.38dB
25-05-18 10:05:30.169 : ---9--> baseball_diamond_111_00.jpg | 35.23dB
25-05-18 10:05:30.349 : --10--> baseball_diamond_111_01.jpg | 36.58dB
25-05-18 10:05:30.525 : --11--> baseball_diamond_111_10.jpg | 34.97dB
25-05-18 10:05:30.705 : --12--> baseball_diamond_111_11.jpg | 37.49dB
25-05-18 10:05:30.885 : --13--> basketball_court_111_00.jpg | 33.46dB
25-05-18 10:05:31.059 : --14--> basketball_court_111_01.jpg | 33.07dB
25-05-18 10:05:31.240 : --15--> basketball_court_111_10.jpg | 35.84dB
25-05-18 10:05:31.418 : --16--> basketball_court_111_11.jpg | 34.50dB
25-05-18 10:05:31.602 : --17--> beach_111_00.jpg | 31.64dB
25-05-18 10:05:31.779 : --18--> beach_111_01.jpg | 34.49dB
25-05-18 10:05:31.958 : --19--> beach_111_10.jpg | 32.74dB
25-05-18 10:05:32.137 : --20--> beach_111_11.jpg | 36.71dB
25-05-18 10:05:32.316 : --21--> bridge_111_00.jpg | 42.54dB
25-05-18 10:05:32.497 : --22--> bridge_111_01.jpg | 36.66dB
25-05-18 10:05:32.673 : --23--> bridge_111_10.jpg | 35.77dB
25-05-18 10:05:32.855 : --24--> bridge_111_11.jpg | 38.95dB
25-05-18 10:05:33.034 : --25--> chaparral_111_00.jpg | 33.18dB
25-05-18 10:05:33.216 : --26--> chaparral_111_01.jpg | 33.40dB
25-05-18 10:05:33.394 : --27--> chaparral_111_10.jpg | 33.62dB
25-05-18 10:05:33.570 : --28--> chaparral_111_11.jpg | 31.87dB
25-05-18 10:05:33.745 : --29--> church_111_00.jpg | 34.28dB
25-05-18 10:05:33.923 : --30--> church_111_01.jpg | 33.41dB
25-05-18 10:05:34.099 : --31--> church_111_10.jpg | 36.75dB
25-05-18 10:05:34.280 : --32--> church_111_11.jpg | 33.22dB
25-05-18 10:05:34.460 : --33--> circular_farmland_111_00.jpg | 35.51dB
25-05-18 10:05:34.640 : --34--> circular_farmland_111_01.jpg | 36.21dB
25-05-18 10:05:34.819 : --35--> circular_farmland_111_10.jpg | 36.55dB
25-05-18 10:05:34.996 : --36--> circular_farmland_111_11.jpg | 36.49dB
25-05-18 10:05:35.177 : --37--> cloud_111_00.jpg | 43.23dB
25-05-18 10:05:35.356 : --38--> cloud_111_01.jpg | 39.05dB
25-05-18 10:05:35.536 : --39--> cloud_111_10.jpg | 38.66dB
25-05-18 10:05:35.716 : --40--> cloud_111_11.jpg | 39.04dB
25-05-18 10:05:35.893 : --41--> commercial_area_111_00.jpg | 35.88dB
25-05-18 10:05:36.070 : --42--> commercial_area_111_01.jpg | 35.13dB
25-05-18 10:05:36.249 : --43--> commercial_area_111_10.jpg | 35.78dB
25-05-18 10:05:36.430 : --44--> commercial_area_111_11.jpg | 35.73dB
25-05-18 10:05:36.606 : --45--> dense_residential_111_00.jpg | 32.97dB
25-05-18 10:05:36.785 : --46--> dense_residential_111_01.jpg | 32.23dB
25-05-18 10:05:36.963 : --47--> dense_residential_111_10.jpg | 32.57dB
25-05-18 10:05:37.140 : --48--> dense_residential_111_11.jpg | 32.42dB
25-05-18 10:05:37.319 : --49--> desert_111_00.jpg | 38.73dB
25-05-18 10:05:37.498 : --50--> desert_111_01.jpg | 38.77dB
25-05-18 10:05:37.681 : --51--> desert_111_10.jpg | 38.95dB
25-05-18 10:05:37.856 : --52--> desert_111_11.jpg | 39.10dB
25-05-18 10:05:38.035 : --53--> forest_111_00.jpg | 35.38dB
25-05-18 10:05:38.210 : --54--> forest_111_01.jpg | 34.53dB
25-05-18 10:05:38.390 : --55--> forest_111_10.jpg | 34.32dB
25-05-18 10:05:38.567 : --56--> forest_111_11.jpg | 35.10dB
25-05-18 10:05:38.746 : --57--> freeway_111_00.jpg | 36.11dB
25-05-18 10:05:38.934 : --58--> freeway_111_01.jpg | 36.81dB
25-05-18 10:05:39.116 : --59--> freeway_111_10.jpg | 36.61dB
25-05-18 10:05:39.300 : --60--> freeway_111_11.jpg | 36.81dB
25-05-18 10:05:39.484 : --61--> golf_course_111_00.jpg | 35.22dB
25-05-18 10:05:39.659 : --62--> golf_course_111_01.jpg | 34.82dB
25-05-18 10:05:39.840 : --63--> golf_course_111_10.jpg | 35.88dB
25-05-18 10:05:40.024 : --64--> golf_course_111_11.jpg | 36.37dB
25-05-18 10:05:40.207 : --65--> ground_track_field_111_00.jpg | 35.86dB
25-05-18 10:05:40.385 : --66--> ground_track_field_111_01.jpg | 32.36dB
25-05-18 10:05:40.562 : --67--> ground_track_field_111_10.jpg | 33.50dB
25-05-18 10:05:40.737 : --68--> ground_track_field_111_11.jpg | 32.86dB
25-05-18 10:05:40.920 : --69--> harbor_111_00.jpg | 34.94dB
25-05-18 10:05:41.103 : --70--> harbor_111_01.jpg | 33.76dB
25-05-18 10:05:41.283 : --71--> harbor_111_10.jpg | 33.54dB
25-05-18 10:05:41.462 : --72--> harbor_111_11.jpg | 35.01dB
25-05-18 10:05:41.644 : --73--> industrial_area_111_00.jpg | 34.13dB
25-05-18 10:05:41.818 : --74--> industrial_area_111_01.jpg | 34.41dB
25-05-18 10:05:42.005 : --75--> industrial_area_111_10.jpg | 34.44dB
25-05-18 10:05:42.187 : --76--> industrial_area_111_11.jpg | 34.02dB
25-05-18 10:05:42.365 : --77--> intersection_111_00.jpg | 33.41dB
25-05-18 10:05:42.545 : --78--> intersection_111_01.jpg | 33.50dB
25-05-18 10:05:42.726 : --79--> intersection_111_10.jpg | 33.27dB
25-05-18 10:05:42.903 : --80--> intersection_111_11.jpg | 33.09dB
25-05-18 10:05:43.084 : --81--> island_111_00.jpg | 34.34dB
25-05-18 10:05:43.258 : --82--> island_111_01.jpg | 36.51dB
25-05-18 10:05:43.440 : --83--> island_111_10.jpg | 35.19dB
25-05-18 10:05:43.617 : --84--> island_111_11.jpg | 34.68dB
25-05-18 10:05:43.796 : --85--> lake_111_00.jpg | 34.87dB
25-05-18 10:05:43.977 : --86--> lake_111_01.jpg | 34.75dB
25-05-18 10:05:44.151 : --87--> lake_111_10.jpg | 34.32dB
25-05-18 10:05:44.333 : --88--> lake_111_11.jpg | 33.65dB
25-05-18 10:05:44.507 : --89--> meadow_111_00.jpg | 32.89dB
25-05-18 10:05:44.685 : --90--> meadow_111_01.jpg | 33.02dB
25-05-18 10:05:44.865 : --91--> meadow_111_10.jpg | 32.98dB
25-05-18 10:05:45.046 : --92--> meadow_111_11.jpg | 33.16dB
25-05-18 10:05:45.221 : --93--> medium_residential_111_00.jpg | 31.79dB
25-05-18 10:05:45.404 : --94--> medium_residential_111_01.jpg | 31.32dB
25-05-18 10:05:45.582 : --95--> medium_residential_111_10.jpg | 31.60dB
25-05-18 10:05:45.770 : --96--> medium_residential_111_11.jpg | 32.05dB
25-05-18 10:05:45.954 : --97--> mobile_home_park_111_00.jpg | 33.80dB
25-05-18 10:05:46.135 : --98--> mobile_home_park_111_01.jpg | 34.20dB
25-05-18 10:05:46.312 : --99--> mobile_home_park_111_10.jpg | 34.46dB
25-05-18 10:05:46.494 : -100--> mobile_home_park_111_11.jpg | 34.60dB
25-05-18 10:05:46.676 : -101--> mountain_111_00.jpg | 31.90dB
25-05-18 10:05:46.854 : -102--> mountain_111_01.jpg | 32.39dB
25-05-18 10:05:47.035 : -103--> mountain_111_10.jpg | 32.27dB
25-05-18 10:05:47.213 : -104--> mountain_111_11.jpg | 32.51dB
25-05-18 10:05:47.393 : -105--> overpass_111_00.jpg | 32.86dB
25-05-18 10:05:47.576 : -106--> overpass_111_01.jpg | 32.84dB
25-05-18 10:05:47.762 : -107--> overpass_111_10.jpg | 33.24dB
25-05-18 10:05:47.942 : -108--> overpass_111_11.jpg | 34.09dB
25-05-18 10:05:48.123 : -109--> palace_111_00.jpg | 32.85dB
25-05-18 10:05:48.303 : -110--> palace_111_01.jpg | 32.73dB
25-05-18 10:05:48.484 : -111--> palace_111_10.jpg | 33.76dB
25-05-18 10:05:48.664 : -112--> palace_111_11.jpg | 32.37dB
25-05-18 10:05:48.843 : -113--> parking_lot_111_00.jpg | 32.42dB
25-05-18 10:05:49.020 : -114--> parking_lot_111_01.jpg | 32.70dB
25-05-18 10:05:49.196 : -115--> parking_lot_111_10.jpg | 33.87dB
25-05-18 10:05:49.375 : -116--> parking_lot_111_11.jpg | 32.90dB
25-05-18 10:05:49.555 : -117--> railway_111_00.jpg | 32.93dB
25-05-18 10:05:49.736 : -118--> railway_111_01.jpg | 32.45dB
25-05-18 10:05:49.914 : -119--> railway_111_10.jpg | 34.85dB
25-05-18 10:05:50.092 : -120--> railway_111_11.jpg | 32.09dB
25-05-18 10:05:50.271 : -121--> railway_station_111_00.jpg | 33.56dB
25-05-18 10:05:50.444 : -122--> railway_station_111_01.jpg | 33.86dB
25-05-18 10:05:50.621 : -123--> railway_station_111_10.jpg | 33.68dB
25-05-18 10:05:50.804 : -124--> railway_station_111_11.jpg | 33.93dB
25-05-18 10:05:50.984 : -125--> rectangular_farmland_111_00.jpg | 35.90dB
25-05-18 10:05:51.164 : -126--> rectangular_farmland_111_01.jpg | 34.59dB
25-05-18 10:05:51.341 : -127--> rectangular_farmland_111_10.jpg | 36.19dB
25-05-18 10:05:51.522 : -128--> rectangular_farmland_111_11.jpg | 36.52dB
25-05-18 10:05:51.700 : -129--> river_111_00.jpg | 33.03dB
25-05-18 10:05:51.880 : -130--> river_111_01.jpg | 32.84dB
25-05-18 10:05:52.058 : -131--> river_111_10.jpg | 32.44dB
25-05-18 10:05:52.236 : -132--> river_111_11.jpg | 33.98dB
25-05-18 10:05:52.414 : -133--> roundabout_111_00.jpg | 33.15dB
25-05-18 10:05:52.590 : -134--> roundabout_111_01.jpg | 34.54dB
25-05-18 10:05:52.777 : -135--> roundabout_111_10.jpg | 33.08dB
25-05-18 10:05:52.963 : -136--> roundabout_111_11.jpg | 33.39dB
25-05-18 10:05:53.143 : -137--> runway_111_00.jpg | 38.28dB
25-05-18 10:05:53.325 : -138--> runway_111_01.jpg | 37.81dB
25-05-18 10:05:53.506 : -139--> runway_111_10.jpg | 38.56dB
25-05-18 10:05:53.694 : -140--> runway_111_11.jpg | 39.45dB
25-05-18 10:05:53.873 : -141--> sea_ice_111_00.jpg | 35.99dB
25-05-18 10:05:54.051 : -142--> sea_ice_111_01.jpg | 36.95dB
25-05-18 10:05:54.229 : -143--> sea_ice_111_10.jpg | 35.95dB
25-05-18 10:05:54.405 : -144--> sea_ice_111_11.jpg | 36.98dB
25-05-18 10:05:54.587 : -145--> ship_111_00.jpg | 40.79dB
25-05-18 10:05:54.764 : -146--> ship_111_01.jpg | 36.97dB
25-05-18 10:05:54.947 : -147--> ship_111_10.jpg | 43.97dB
25-05-18 10:05:55.125 : -148--> ship_111_11.jpg | 42.38dB
25-05-18 10:05:55.304 : -149--> snowberg_111_00.jpg | 37.12dB
25-05-18 10:05:55.481 : -150--> snowberg_111_01.jpg | 35.44dB
25-05-18 10:05:55.659 : -151--> snowberg_111_10.jpg | 34.85dB
25-05-18 10:05:55.842 : -152--> snowberg_111_11.jpg | 34.74dB
25-05-18 10:05:56.021 : -153--> sparse_residential_111_00.jpg | 33.19dB
25-05-18 10:05:56.202 : -154--> sparse_residential_111_01.jpg | 33.42dB
25-05-18 10:05:56.384 : -155--> sparse_residential_111_10.jpg | 32.72dB
25-05-18 10:05:56.571 : -156--> sparse_residential_111_11.jpg | 32.92dB
25-05-18 10:05:56.750 : -157--> stadium_111_00.jpg | 33.07dB
25-05-18 10:05:56.924 : -158--> stadium_111_01.jpg | 33.00dB
25-05-18 10:05:57.105 : -159--> stadium_111_10.jpg | 34.06dB
25-05-18 10:05:57.285 : -160--> stadium_111_11.jpg | 33.05dB
25-05-18 10:05:57.464 : -161--> storage_tank_111_00.jpg | 34.48dB
25-05-18 10:05:57.641 : -162--> storage_tank_111_01.jpg | 34.64dB
25-05-18 10:05:57.820 : -163--> storage_tank_111_10.jpg | 33.49dB
25-05-18 10:05:58.003 : -164--> storage_tank_111_11.jpg | 33.96dB
25-05-18 10:05:58.182 : -165--> tennis_court_111_00.jpg | 34.40dB
25-05-18 10:05:58.361 : -166--> tennis_court_111_01.jpg | 34.13dB
25-05-18 10:05:58.540 : -167--> tennis_court_111_10.jpg | 34.15dB
25-05-18 10:05:58.719 : -168--> tennis_court_111_11.jpg | 32.55dB
25-05-18 10:05:58.901 : -169--> terrace_111_00.jpg | 34.84dB
25-05-18 10:05:59.084 : -170--> terrace_111_01.jpg | 35.73dB
25-05-18 10:05:59.263 : -171--> terrace_111_10.jpg | 34.90dB
25-05-18 10:05:59.440 : -172--> terrace_111_11.jpg | 34.93dB
25-05-18 10:05:59.622 : -173--> thermal_power_station_111_00.jpg | 33.09dB
25-05-18 10:05:59.799 : -174--> thermal_power_station_111_01.jpg | 34.57dB
25-05-18 10:05:59.976 : -175--> thermal_power_station_111_10.jpg | 32.97dB
25-05-18 10:06:00.156 : -176--> thermal_power_station_111_11.jpg | 33.41dB
25-05-18 10:06:00.335 : -177--> wetland_111_00.jpg | 33.87dB
25-05-18 10:06:00.522 : -178--> wetland_111_01.jpg | 33.91dB
25-05-18 10:06:00.702 : -179--> wetland_111_10.jpg | 34.12dB
25-05-18 10:06:00.881 : -180--> wetland_111_11.jpg | 33.60dB
25-05-18 10:06:00.893 : <epoch:  1, iter:  60,000, Average PSNR : 34.76dB

25-05-18 11:39:24.806 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/10_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 25
      sigma_test: 25
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test_4fen
      dataroot_L: None
      sigma: 25
      sigma_test: 25
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [30000, 50000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-18 11:39:24.807 : Random seed: 1972
25-05-18 11:39:24.954 : Number of train images: 31,005, iters: 31,005
25-05-18 11:39:26.127 : 
Networks name: DRNet
Params number: 17746115
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-18 11:39:26.728 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.002 | -0.482 |  0.572 |  0.192 | torch.Size([64, 3, 3, 3]) || head1.weight
 | -0.002 | -0.335 |  0.276 |  0.182 | torch.Size([64]) || head1.bias
 |  0.000 | -0.511 |  0.500 |  0.101 | torch.Size([64, 64, 3, 3]) || head1_1.body.0.weight
 |  0.081 | -0.074 |  0.237 |  0.075 | torch.Size([64]) || head1_1.body.0.bias
 | -0.000 | -0.524 |  0.608 |  0.089 | torch.Size([64, 64, 3, 3]) || head1_1.body.2.weight
 |  0.010 | -0.105 |  0.129 |  0.056 | torch.Size([64]) || head1_1.body.2.bias
 |  0.000 | -0.310 |  0.321 |  0.059 | torch.Size([768, 256]) || head1_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.001 | -0.330 |  0.309 |  0.066 | torch.Size([256, 256]) || head1_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.297 |  0.295 |  0.058 | torch.Size([1024, 256]) || head1_3.encoder.layers.0.linear1.weight
 | -0.022 | -0.170 |  0.098 |  0.042 | torch.Size([1024]) || head1_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.440 |  0.381 |  0.049 | torch.Size([256, 1024]) || head1_3.encoder.layers.0.linear2.weight
 | -0.000 | -0.078 |  0.078 |  0.030 | torch.Size([256]) || head1_3.encoder.layers.0.linear2.bias
 |  1.014 |  0.747 |  1.199 |  0.067 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.weight
 |  0.005 | -0.194 |  0.325 |  0.061 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.bias
 |  1.107 |  0.976 |  1.282 |  0.059 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.weight
 |  0.003 | -0.079 |  0.083 |  0.033 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || head1_3.position_encoding.position_ids
 |  0.000 | -5.337 |  4.745 |  0.991 | torch.Size([4096, 256]) || head1_3.position_encoding.pe.weight
 |  0.000 | -0.958 |  1.005 |  0.034 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.0.weight
 |  0.027 | -0.102 |  0.114 |  0.044 | torch.Size([64]) || body1_1.0.body.0.bias
 | -0.001 | -0.381 |  0.392 |  0.037 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.2.weight
 | -0.014 | -0.139 |  0.114 |  0.063 | torch.Size([64]) || body1_1.0.body.2.bias
 | -0.001 | -0.493 |  0.465 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.1.weight
 |  0.048 | -0.052 |  0.155 |  0.047 | torch.Size([64]) || body1_1.1.bias
 |  0.000 | -0.175 |  0.185 |  0.042 | torch.Size([768, 256]) || body1_2.0.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.156 |  0.148 |  0.037 | torch.Size([256, 256]) || body1_2.0.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.294 |  0.246 |  0.043 | torch.Size([1024, 256]) || body1_2.0.encoder.layers.0.linear1.weight
 |  0.003 | -0.073 |  0.100 |  0.038 | torch.Size([1024]) || body1_2.0.encoder.layers.0.linear1.bias
 | -0.003 | -0.259 |  0.206 |  0.028 | torch.Size([256, 1024]) || body1_2.0.encoder.layers.0.linear2.weight
 | -0.007 | -0.057 |  0.042 |  0.021 | torch.Size([256]) || body1_2.0.encoder.layers.0.linear2.bias
 |  0.994 |  0.803 |  1.138 |  0.068 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.weight
 |  0.008 | -0.141 |  0.151 |  0.067 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.bias
 |  0.998 |  0.798 |  1.202 |  0.059 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.weight
 |  0.011 | -0.232 |  0.251 |  0.086 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body1_2.0.position_encoding.position_ids
 |  0.001 | -4.538 |  4.876 |  0.995 | torch.Size([4096, 256]) || body1_2.0.position_encoding.pe.weight
 | -0.001 | -0.290 |  0.227 |  0.038 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.0.weight
 |  0.002 | -0.101 |  0.085 |  0.033 | torch.Size([64]) || body1_2.1.body.0.bias
 | -0.005 | -0.260 |  0.284 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.2.weight
 | -0.016 | -0.104 |  0.048 |  0.033 | torch.Size([64]) || body1_2.1.body.2.bias
 |  0.000 | -0.280 |  0.243 |  0.050 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.0.weight
 |  0.014 | -0.116 |  0.117 |  0.046 | torch.Size([64]) || body2_1.0.body.0.bias
 |  0.000 | -0.325 |  0.504 |  0.049 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.2.weight
 | -0.005 | -0.140 |  0.157 |  0.075 | torch.Size([64]) || body2_1.0.body.2.bias
 |  0.000 | -0.329 |  0.370 |  0.061 | torch.Size([768, 256]) || body2_1.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.320 |  0.349 |  0.070 | torch.Size([256, 256]) || body2_1.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.293 |  0.302 |  0.060 | torch.Size([1024, 256]) || body2_1.1.encoder.layers.0.linear1.weight
 |  0.010 | -0.127 |  0.131 |  0.042 | torch.Size([1024]) || body2_1.1.encoder.layers.0.linear1.bias
 | -0.000 | -0.270 |  0.278 |  0.049 | torch.Size([256, 1024]) || body2_1.1.encoder.layers.0.linear2.weight
 | -0.001 | -0.069 |  0.074 |  0.031 | torch.Size([256]) || body2_1.1.encoder.layers.0.linear2.bias
 |  1.079 |  0.947 |  1.207 |  0.049 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.weight
 |  0.003 | -0.150 |  0.166 |  0.072 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.bias
 |  1.196 |  1.024 |  1.391 |  0.072 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.115 |  0.110 |  0.033 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_1.1.position_encoding.position_ids
 | -0.001 | -4.994 |  4.878 |  0.999 | torch.Size([4096, 256]) || body2_1.1.position_encoding.pe.weight
 | -0.003 | -0.345 |  0.344 |  0.110 | torch.Size([128, 1, 5, 5]) || fusion2_1.0.weight
 |  0.015 | -0.266 |  0.257 |  0.121 | torch.Size([128]) || fusion2_1.0.bias
 |  0.000 | -0.211 |  0.240 |  0.055 | torch.Size([64, 128, 1, 1]) || fusion2_1.1.weight
 | -0.005 | -0.177 |  0.160 |  0.089 | torch.Size([64]) || fusion2_1.1.bias
 |  0.002 | -0.194 |  0.221 |  0.044 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.0.weight
 |  0.002 | -0.144 |  0.227 |  0.084 | torch.Size([64]) || body2_2.0.body.0.bias
 |  0.000 | -0.214 |  0.226 |  0.043 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.2.weight
 | -0.004 | -0.232 |  0.212 |  0.106 | torch.Size([64]) || body2_2.0.body.2.bias
 | -0.000 | -0.420 |  0.336 |  0.066 | torch.Size([768, 256]) || body2_2.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.343 |  0.382 |  0.081 | torch.Size([256, 256]) || body2_2.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.248 |  0.265 |  0.060 | torch.Size([1024, 256]) || body2_2.1.encoder.layers.0.linear1.weight
 | -0.001 | -0.156 |  0.139 |  0.052 | torch.Size([1024]) || body2_2.1.encoder.layers.0.linear1.bias
 |  0.000 | -0.249 |  0.289 |  0.050 | torch.Size([256, 1024]) || body2_2.1.encoder.layers.0.linear2.weight
 |  0.002 | -0.052 |  0.056 |  0.025 | torch.Size([256]) || body2_2.1.encoder.layers.0.linear2.bias
 |  1.107 |  0.948 |  1.263 |  0.052 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.weight
 |  0.001 | -0.181 |  0.212 |  0.079 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.bias
 |  1.154 |  0.954 |  1.331 |  0.056 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.weight
 |  0.000 | -0.115 |  0.103 |  0.036 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_2.1.position_encoding.position_ids
 | -0.001 | -4.834 |  4.669 |  0.998 | torch.Size([4096, 256]) || body2_2.1.position_encoding.pe.weight
 | -0.000 | -0.303 |  0.380 |  0.105 | torch.Size([128, 1, 5, 5]) || fusion2_2.0.weight
 | -0.015 | -0.210 |  0.214 |  0.117 | torch.Size([128]) || fusion2_2.0.bias
 | -0.001 | -0.240 |  0.243 |  0.059 | torch.Size([64, 128, 1, 1]) || fusion2_2.1.weight
 | -0.019 | -0.152 |  0.154 |  0.066 | torch.Size([64]) || fusion2_2.1.bias
 | -0.000 | -0.238 |  0.236 |  0.053 | torch.Size([768, 256]) || body2_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.247 |  0.248 |  0.057 | torch.Size([256, 256]) || body2_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.228 |  0.229 |  0.051 | torch.Size([1024, 256]) || body2_3.encoder.layers.0.linear1.weight
 | -0.029 | -0.150 |  0.091 |  0.042 | torch.Size([1024]) || body2_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.201 |  0.201 |  0.039 | torch.Size([256, 1024]) || body2_3.encoder.layers.0.linear2.weight
 |  0.002 | -0.052 |  0.075 |  0.022 | torch.Size([256]) || body2_3.encoder.layers.0.linear2.bias
 |  1.060 |  0.953 |  1.190 |  0.041 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.132 |  0.175 |  0.051 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.bias
 |  1.018 |  0.890 |  1.163 |  0.045 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.096 |  0.073 |  0.030 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_3.position_encoding.position_ids
 | -0.000 | -4.715 |  5.524 |  0.998 | torch.Size([4096, 256]) || body2_3.position_encoding.pe.weight
 |  0.000 | -0.240 |  0.271 |  0.039 | torch.Size([64, 64, 3, 3]) || body3_1.0.weight
 |  0.018 | -0.058 |  0.069 |  0.031 | torch.Size([64]) || body3_1.0.bias
 |  0.000 | -0.178 |  0.180 |  0.039 | torch.Size([768, 256]) || body3_1.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.158 |  0.168 |  0.040 | torch.Size([256, 256]) || body3_1.2.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.287 |  0.237 |  0.047 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.0.linear1.weight
 | -0.010 | -0.107 |  0.098 |  0.038 | torch.Size([1024]) || body3_1.2.encoder.layers.0.linear1.bias
 | -0.003 | -0.279 |  0.293 |  0.033 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.0.linear2.weight
 | -0.006 | -0.066 |  0.074 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.linear2.bias
 |  1.002 |  0.916 |  1.085 |  0.027 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.090 |  0.083 |  0.031 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.bias
 |  1.115 |  0.989 |  1.258 |  0.051 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.weight
 |  0.002 | -0.086 |  0.097 |  0.036 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.153 |  0.162 |  0.038 | torch.Size([768, 256]) || body3_1.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.130 |  0.138 |  0.038 | torch.Size([256, 256]) || body3_1.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.322 |  0.282 |  0.047 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.1.linear1.weight
 | -0.006 | -0.094 |  0.096 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.1.linear1.bias
 | -0.003 | -0.359 |  0.419 |  0.033 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.1.linear2.weight
 | -0.007 | -0.066 |  0.049 |  0.023 | torch.Size([256]) || body3_1.2.encoder.layers.1.linear2.bias
 |  0.996 |  0.951 |  1.115 |  0.024 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.weight
 | -0.001 | -0.064 |  0.068 |  0.027 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.bias
 |  1.134 |  1.002 |  1.289 |  0.051 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.weight
 |  0.000 | -0.053 |  0.050 |  0.021 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_1.2.position_encoding.position_ids
 |  0.002 | -4.658 |  4.616 |  1.000 | torch.Size([4096, 256]) || body3_1.2.position_encoding.pe.weight
 |  0.001 | -0.331 |  0.379 |  0.071 | torch.Size([128, 1, 5, 5]) || fusion3_1.0.weight
 |  0.006 | -0.233 |  0.243 |  0.123 | torch.Size([128]) || fusion3_1.0.bias
 | -0.000 | -0.133 |  0.146 |  0.029 | torch.Size([64, 128, 1, 1]) || fusion3_1.1.weight
 | -0.010 | -0.193 |  0.185 |  0.095 | torch.Size([64]) || fusion3_1.1.bias
 | -0.000 | -0.156 |  0.144 |  0.026 | torch.Size([64, 64, 3, 3]) || body3_2.0.weight
 |  0.061 | -0.118 |  0.120 |  0.038 | torch.Size([64]) || body3_2.0.bias
 |  0.000 | -0.143 |  0.128 |  0.040 | torch.Size([768, 256]) || body3_2.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.111 |  0.110 |  0.037 | torch.Size([256, 256]) || body3_2.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.203 |  0.200 |  0.051 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.0.linear1.weight
 | -0.043 | -0.138 |  0.065 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.167 |  0.150 |  0.037 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.0.linear2.weight
 | -0.008 | -0.063 |  0.038 |  0.023 | torch.Size([256]) || body3_2.2.encoder.layers.0.linear2.bias
 |  0.997 |  0.836 |  1.076 |  0.031 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.123 |  0.177 |  0.044 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.bias
 |  1.058 |  0.938 |  1.193 |  0.048 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.weight
 | -0.001 | -0.147 |  0.103 |  0.043 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.109 |  0.115 |  0.038 | torch.Size([768, 256]) || body3_2.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.117 |  0.103 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.198 |  0.189 |  0.049 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.1.linear1.weight
 | -0.025 | -0.108 |  0.091 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.1.linear1.bias
 | -0.001 | -0.154 |  0.155 |  0.036 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.1.linear2.weight
 | -0.009 | -0.067 |  0.048 |  0.025 | torch.Size([256]) || body3_2.2.encoder.layers.1.linear2.bias
 |  0.987 |  0.918 |  1.033 |  0.020 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.weight
 | -0.000 | -0.105 |  0.116 |  0.045 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.bias
 |  1.066 |  0.951 |  1.158 |  0.037 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.weight
 |  0.000 | -0.048 |  0.049 |  0.019 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_2.2.position_encoding.position_ids
 |  0.001 | -5.085 |  5.020 |  1.000 | torch.Size([4096, 256]) || body3_2.2.position_encoding.pe.weight
 |  0.002 | -0.233 |  0.259 |  0.086 | torch.Size([128, 1, 5, 5]) || fusion3_2.0.weight
 |  0.003 | -0.200 |  0.226 |  0.105 | torch.Size([128]) || fusion3_2.0.bias
 |  0.000 | -0.153 |  0.163 |  0.046 | torch.Size([64, 128, 1, 1]) || fusion3_2.1.weight
 |  0.005 | -0.100 |  0.129 |  0.050 | torch.Size([64]) || fusion3_2.1.bias
 | -0.001 | -0.232 |  0.202 |  0.050 | torch.Size([256, 256]) || body3_3.linear_encoding.weight
 | -0.005 | -0.143 |  0.156 |  0.065 | torch.Size([256]) || body3_3.linear_encoding.bias
 | -0.000 | -0.230 |  0.209 |  0.045 | torch.Size([1024, 256]) || body3_3.mlp_head.0.weight
 | -0.027 | -0.122 |  0.077 |  0.039 | torch.Size([1024]) || body3_3.mlp_head.0.bias
 | -0.000 | -0.215 |  0.183 |  0.032 | torch.Size([256, 1024]) || body3_3.mlp_head.3.weight
 |  0.002 | -0.089 |  0.078 |  0.029 | torch.Size([256]) || body3_3.mlp_head.3.bias
 |  0.000 | -0.141 |  0.140 |  0.040 | torch.Size([768, 256]) || body3_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.149 |  0.146 |  0.038 | torch.Size([256, 256]) || body3_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.197 |  0.212 |  0.044 | torch.Size([1024, 256]) || body3_3.encoder.layers.0.linear1.weight
 | -0.036 | -0.134 |  0.054 |  0.037 | torch.Size([1024]) || body3_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.188 |  0.228 |  0.031 | torch.Size([256, 1024]) || body3_3.encoder.layers.0.linear2.weight
 | -0.000 | -0.082 |  0.072 |  0.026 | torch.Size([256]) || body3_3.encoder.layers.0.linear2.bias
 |  0.939 |  0.846 |  1.018 |  0.029 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.086 |  0.115 |  0.035 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.bias
 |  0.863 |  0.776 |  1.020 |  0.040 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.weight
 | -0.000 | -0.186 |  0.188 |  0.063 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.bias
 | -0.000 | -0.134 |  0.150 |  0.037 | torch.Size([192, 1, 5, 5]) || fusion3_3.0.weight
 |  0.004 | -0.185 |  0.223 |  0.077 | torch.Size([192]) || fusion3_3.0.bias
 |  0.000 | -0.129 |  0.111 |  0.021 | torch.Size([64, 192, 1, 1]) || fusion3_3.1.weight
 | -0.003 | -0.041 |  0.029 |  0.018 | torch.Size([64]) || fusion3_3.1.bias
 | -0.001 | -0.496 |  0.134 |  0.037 | torch.Size([256, 256]) || body3_4.linear_encoding.weight
 |  0.004 | -0.059 |  0.099 |  0.024 | torch.Size([256]) || body3_4.linear_encoding.bias
 | -0.001 | -0.262 |  0.263 |  0.046 | torch.Size([1024, 256]) || body3_4.mlp_head.0.weight
 | -0.048 | -0.178 |  0.064 |  0.037 | torch.Size([1024]) || body3_4.mlp_head.0.bias
 | -0.000 | -0.251 |  0.278 |  0.029 | torch.Size([256, 1024]) || body3_4.mlp_head.3.weight
 | -0.004 | -0.129 |  0.091 |  0.033 | torch.Size([256]) || body3_4.mlp_head.3.bias
 | -0.000 | -0.211 |  0.214 |  0.043 | torch.Size([768, 256]) || body3_4.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.140 |  0.137 |  0.033 | torch.Size([256, 256]) || body3_4.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.214 |  0.210 |  0.039 | torch.Size([1024, 256]) || body3_4.encoder.layers.0.linear1.weight
 | -0.040 | -0.151 |  0.061 |  0.037 | torch.Size([1024]) || body3_4.encoder.layers.0.linear1.bias
 |  0.000 | -0.195 |  0.173 |  0.021 | torch.Size([256, 1024]) || body3_4.encoder.layers.0.linear2.weight
 |  0.001 | -0.062 |  0.058 |  0.023 | torch.Size([256]) || body3_4.encoder.layers.0.linear2.bias
 |  0.771 |  0.603 |  0.935 |  0.069 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.weight
 |  0.000 | -0.221 |  0.170 |  0.070 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.bias
 |  0.759 |  0.451 |  1.032 |  0.104 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.weight
 |  0.000 | -0.214 |  0.199 |  0.088 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.bias
 |  0.000 | -0.040 |  0.040 |  0.008 | torch.Size([3, 64, 3, 3]) || tail.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([3]) || tail.bias

25-05-18 12:53:45.297 : <epoch:  0, iter:   5,000, lr:1.000e-04> G_loss: 3.259e-05 
25-05-18 12:53:45.299 : Saving the model.
25-05-18 12:53:46.049 : ---1--> airplane_111_00.jpg | 30.36dB
25-05-18 12:53:46.235 : ---2--> airplane_111_01.jpg | 35.26dB
25-05-18 12:53:46.413 : ---3--> airplane_111_10.jpg | 32.80dB
25-05-18 12:53:46.589 : ---4--> airplane_111_11.jpg | 32.83dB
25-05-18 12:53:46.764 : ---5--> airport_111_00.jpg | 34.40dB
25-05-18 12:53:46.942 : ---6--> airport_111_01.jpg | 32.29dB
25-05-18 12:53:47.122 : ---7--> airport_111_10.jpg | 31.86dB
25-05-18 12:53:47.303 : ---8--> airport_111_11.jpg | 32.82dB
25-05-18 12:53:47.479 : ---9--> baseball_diamond_111_00.jpg | 32.63dB
25-05-18 12:53:47.657 : --10--> baseball_diamond_111_01.jpg | 34.24dB
25-05-18 12:53:47.836 : --11--> baseball_diamond_111_10.jpg | 32.48dB
25-05-18 12:53:48.021 : --12--> baseball_diamond_111_11.jpg | 35.32dB
25-05-18 12:53:48.201 : --13--> basketball_court_111_00.jpg | 30.49dB
25-05-18 12:53:48.381 : --14--> basketball_court_111_01.jpg | 30.04dB
25-05-18 12:53:48.566 : --15--> basketball_court_111_10.jpg | 33.29dB
25-05-18 12:53:48.747 : --16--> basketball_court_111_11.jpg | 31.58dB
25-05-18 12:53:48.926 : --17--> beach_111_00.jpg | 28.52dB
25-05-18 12:53:49.105 : --18--> beach_111_01.jpg | 31.69dB
25-05-18 12:53:49.284 : --19--> beach_111_10.jpg | 29.70dB
25-05-18 12:53:49.470 : --20--> beach_111_11.jpg | 34.31dB
25-05-18 12:53:49.650 : --21--> bridge_111_00.jpg | 40.70dB
25-05-18 12:53:49.825 : --22--> bridge_111_01.jpg | 34.24dB
25-05-18 12:53:50.004 : --23--> bridge_111_10.jpg | 33.15dB
25-05-18 12:53:50.182 : --24--> bridge_111_11.jpg | 36.55dB
25-05-18 12:53:50.362 : --25--> chaparral_111_00.jpg | 30.25dB
25-05-18 12:53:50.547 : --26--> chaparral_111_01.jpg | 30.53dB
25-05-18 12:53:50.722 : --27--> chaparral_111_10.jpg | 30.84dB
25-05-18 12:53:50.904 : --28--> chaparral_111_11.jpg | 28.62dB
25-05-18 12:53:51.085 : --29--> church_111_00.jpg | 31.52dB
25-05-18 12:53:51.266 : --30--> church_111_01.jpg | 30.53dB
25-05-18 12:53:51.445 : --31--> church_111_10.jpg | 34.31dB
25-05-18 12:53:51.632 : --32--> church_111_11.jpg | 30.31dB
25-05-18 12:53:51.818 : --33--> circular_farmland_111_00.jpg | 32.71dB
25-05-18 12:53:51.995 : --34--> circular_farmland_111_01.jpg | 33.77dB
25-05-18 12:53:52.174 : --35--> circular_farmland_111_10.jpg | 33.92dB
25-05-18 12:53:52.362 : --36--> circular_farmland_111_11.jpg | 34.10dB
25-05-18 12:53:52.540 : --37--> cloud_111_00.jpg | 40.99dB
25-05-18 12:53:52.722 : --38--> cloud_111_01.jpg | 36.77dB
25-05-18 12:53:52.905 : --39--> cloud_111_10.jpg | 36.31dB
25-05-18 12:53:53.083 : --40--> cloud_111_11.jpg | 36.77dB
25-05-18 12:53:53.260 : --41--> commercial_area_111_00.jpg | 33.31dB
25-05-18 12:53:53.438 : --42--> commercial_area_111_01.jpg | 32.30dB
25-05-18 12:53:53.620 : --43--> commercial_area_111_10.jpg | 33.09dB
25-05-18 12:53:53.802 : --44--> commercial_area_111_11.jpg | 32.96dB
25-05-18 12:53:53.981 : --45--> dense_residential_111_00.jpg | 30.06dB
25-05-18 12:53:54.158 : --46--> dense_residential_111_01.jpg | 29.16dB
25-05-18 12:53:54.338 : --47--> dense_residential_111_10.jpg | 29.54dB
25-05-18 12:53:54.517 : --48--> dense_residential_111_11.jpg | 29.43dB
25-05-18 12:53:54.697 : --49--> desert_111_00.jpg | 36.84dB
25-05-18 12:53:54.879 : --50--> desert_111_01.jpg | 36.71dB
25-05-18 12:53:55.056 : --51--> desert_111_10.jpg | 36.85dB
25-05-18 12:53:55.232 : --52--> desert_111_11.jpg | 36.98dB
25-05-18 12:53:55.410 : --53--> forest_111_00.jpg | 32.96dB
25-05-18 12:53:55.594 : --54--> forest_111_01.jpg | 32.04dB
25-05-18 12:53:55.774 : --55--> forest_111_10.jpg | 31.67dB
25-05-18 12:53:55.952 : --56--> forest_111_11.jpg | 32.57dB
25-05-18 12:53:56.127 : --57--> freeway_111_00.jpg | 33.77dB
25-05-18 12:53:56.304 : --58--> freeway_111_01.jpg | 34.79dB
25-05-18 12:53:56.487 : --59--> freeway_111_10.jpg | 34.66dB
25-05-18 12:53:56.664 : --60--> freeway_111_11.jpg | 34.72dB
25-05-18 12:53:56.843 : --61--> golf_course_111_00.jpg | 32.65dB
25-05-18 12:53:57.022 : --62--> golf_course_111_01.jpg | 32.05dB
25-05-18 12:53:57.201 : --63--> golf_course_111_10.jpg | 33.44dB
25-05-18 12:53:57.378 : --64--> golf_course_111_11.jpg | 33.81dB
25-05-18 12:53:57.560 : --65--> ground_track_field_111_00.jpg | 33.21dB
25-05-18 12:53:57.744 : --66--> ground_track_field_111_01.jpg | 29.33dB
25-05-18 12:53:57.920 : --67--> ground_track_field_111_10.jpg | 30.69dB
25-05-18 12:53:58.105 : --68--> ground_track_field_111_11.jpg | 29.92dB
25-05-18 12:53:58.280 : --69--> harbor_111_00.jpg | 32.77dB
25-05-18 12:53:58.459 : --70--> harbor_111_01.jpg | 31.08dB
25-05-18 12:53:58.635 : --71--> harbor_111_10.jpg | 30.65dB
25-05-18 12:53:58.823 : --72--> harbor_111_11.jpg | 32.36dB
25-05-18 12:53:59.003 : --73--> industrial_area_111_00.jpg | 31.48dB
25-05-18 12:53:59.182 : --74--> industrial_area_111_01.jpg | 31.72dB
25-05-18 12:53:59.357 : --75--> industrial_area_111_10.jpg | 31.83dB
25-05-18 12:53:59.538 : --76--> industrial_area_111_11.jpg | 31.24dB
25-05-18 12:53:59.718 : --77--> intersection_111_00.jpg | 30.52dB
25-05-18 12:53:59.903 : --78--> intersection_111_01.jpg | 30.64dB
25-05-18 12:54:00.082 : --79--> intersection_111_10.jpg | 30.37dB
25-05-18 12:54:00.260 : --80--> intersection_111_11.jpg | 30.16dB
25-05-18 12:54:00.437 : --81--> island_111_00.jpg | 31.32dB
25-05-18 12:54:00.621 : --82--> island_111_01.jpg | 33.75dB
25-05-18 12:54:00.800 : --83--> island_111_10.jpg | 32.39dB
25-05-18 12:54:00.986 : --84--> island_111_11.jpg | 31.96dB
25-05-18 12:54:01.165 : --85--> lake_111_00.jpg | 32.44dB
25-05-18 12:54:01.344 : --86--> lake_111_01.jpg | 32.24dB
25-05-18 12:54:01.522 : --87--> lake_111_10.jpg | 31.57dB
25-05-18 12:54:01.712 : --88--> lake_111_11.jpg | 31.01dB
25-05-18 12:54:01.890 : --89--> meadow_111_00.jpg | 29.98dB
25-05-18 12:54:02.068 : --90--> meadow_111_01.jpg | 30.09dB
25-05-18 12:54:02.251 : --91--> meadow_111_10.jpg | 30.13dB
25-05-18 12:54:02.433 : --92--> meadow_111_11.jpg | 30.28dB
25-05-18 12:54:02.610 : --93--> medium_residential_111_00.jpg | 28.64dB
25-05-18 12:54:02.792 : --94--> medium_residential_111_01.jpg | 28.08dB
25-05-18 12:54:02.971 : --95--> medium_residential_111_10.jpg | 28.42dB
25-05-18 12:54:03.155 : --96--> medium_residential_111_11.jpg | 28.96dB
25-05-18 12:54:03.331 : --97--> mobile_home_park_111_00.jpg | 30.89dB
25-05-18 12:54:03.517 : --98--> mobile_home_park_111_01.jpg | 31.34dB
25-05-18 12:54:03.695 : --99--> mobile_home_park_111_10.jpg | 31.70dB
25-05-18 12:54:03.874 : -100--> mobile_home_park_111_11.jpg | 31.75dB
25-05-18 12:54:04.052 : -101--> mountain_111_00.jpg | 28.81dB
25-05-18 12:54:04.230 : -102--> mountain_111_01.jpg | 29.49dB
25-05-18 12:54:04.408 : -103--> mountain_111_10.jpg | 29.27dB
25-05-18 12:54:04.594 : -104--> mountain_111_11.jpg | 29.60dB
25-05-18 12:54:04.775 : -105--> overpass_111_00.jpg | 29.99dB
25-05-18 12:54:04.954 : -106--> overpass_111_01.jpg | 29.93dB
25-05-18 12:54:05.142 : -107--> overpass_111_10.jpg | 30.50dB
25-05-18 12:54:05.319 : -108--> overpass_111_11.jpg | 31.25dB
25-05-18 12:54:05.495 : -109--> palace_111_00.jpg | 29.93dB
25-05-18 12:54:05.674 : -110--> palace_111_01.jpg | 29.72dB
25-05-18 12:54:05.855 : -111--> palace_111_10.jpg | 30.97dB
25-05-18 12:54:06.033 : -112--> palace_111_11.jpg | 29.33dB
25-05-18 12:54:06.215 : -113--> parking_lot_111_00.jpg | 29.21dB
25-05-18 12:54:06.395 : -114--> parking_lot_111_01.jpg | 29.50dB
25-05-18 12:54:06.574 : -115--> parking_lot_111_10.jpg | 31.04dB
25-05-18 12:54:06.755 : -116--> parking_lot_111_11.jpg | 29.89dB
25-05-18 12:54:06.933 : -117--> railway_111_00.jpg | 30.06dB
25-05-18 12:54:07.113 : -118--> railway_111_01.jpg | 29.58dB
25-05-18 12:54:07.296 : -119--> railway_111_10.jpg | 32.34dB
25-05-18 12:54:07.478 : -120--> railway_111_11.jpg | 28.96dB
25-05-18 12:54:07.655 : -121--> railway_station_111_00.jpg | 30.77dB
25-05-18 12:54:07.837 : -122--> railway_station_111_01.jpg | 31.27dB
25-05-18 12:54:08.016 : -123--> railway_station_111_10.jpg | 30.96dB
25-05-18 12:54:08.202 : -124--> railway_station_111_11.jpg | 31.48dB
25-05-18 12:54:08.382 : -125--> rectangular_farmland_111_00.jpg | 33.32dB
25-05-18 12:54:08.559 : -126--> rectangular_farmland_111_01.jpg | 31.80dB
25-05-18 12:54:08.737 : -127--> rectangular_farmland_111_10.jpg | 33.68dB
25-05-18 12:54:08.915 : -128--> rectangular_farmland_111_11.jpg | 34.00dB
25-05-18 12:54:09.096 : -129--> river_111_00.jpg | 30.08dB
25-05-18 12:54:09.275 : -130--> river_111_01.jpg | 29.94dB
25-05-18 12:54:09.454 : -131--> river_111_10.jpg | 29.39dB
25-05-18 12:54:09.634 : -132--> river_111_11.jpg | 31.24dB
25-05-18 12:54:09.814 : -133--> roundabout_111_00.jpg | 30.34dB
25-05-18 12:54:09.991 : -134--> roundabout_111_01.jpg | 31.95dB
25-05-18 12:54:10.172 : -135--> roundabout_111_10.jpg | 30.31dB
25-05-18 12:54:10.353 : -136--> roundabout_111_11.jpg | 30.66dB
25-05-18 12:54:10.535 : -137--> runway_111_00.jpg | 36.32dB
25-05-18 12:54:10.717 : -138--> runway_111_01.jpg | 35.68dB
25-05-18 12:54:10.903 : -139--> runway_111_10.jpg | 36.43dB
25-05-18 12:54:11.079 : -140--> runway_111_11.jpg | 37.31dB
25-05-18 12:54:11.260 : -141--> sea_ice_111_00.jpg | 33.49dB
25-05-18 12:54:11.441 : -142--> sea_ice_111_01.jpg | 34.53dB
25-05-18 12:54:11.617 : -143--> sea_ice_111_10.jpg | 33.48dB
25-05-18 12:54:11.801 : -144--> sea_ice_111_11.jpg | 34.57dB
25-05-18 12:54:11.983 : -145--> ship_111_00.jpg | 38.47dB
25-05-18 12:54:12.160 : -146--> ship_111_01.jpg | 34.49dB
25-05-18 12:54:12.338 : -147--> ship_111_10.jpg | 42.62dB
25-05-18 12:54:12.518 : -148--> ship_111_11.jpg | 39.94dB
25-05-18 12:54:12.696 : -149--> snowberg_111_00.jpg | 34.10dB
25-05-18 12:54:12.874 : -150--> snowberg_111_01.jpg | 32.67dB
25-05-18 12:54:13.053 : -151--> snowberg_111_10.jpg | 31.88dB
25-05-18 12:54:13.231 : -152--> snowberg_111_11.jpg | 31.89dB
25-05-18 12:54:13.410 : -153--> sparse_residential_111_00.jpg | 30.36dB
25-05-18 12:54:13.589 : -154--> sparse_residential_111_01.jpg | 30.63dB
25-05-18 12:54:13.765 : -155--> sparse_residential_111_10.jpg | 29.66dB
25-05-18 12:54:13.952 : -156--> sparse_residential_111_11.jpg | 29.96dB
25-05-18 12:54:14.132 : -157--> stadium_111_00.jpg | 30.18dB
25-05-18 12:54:14.311 : -158--> stadium_111_01.jpg | 30.00dB
25-05-18 12:54:14.492 : -159--> stadium_111_10.jpg | 31.32dB
25-05-18 12:54:14.671 : -160--> stadium_111_11.jpg | 30.10dB
25-05-18 12:54:14.849 : -161--> storage_tank_111_00.jpg | 31.80dB
25-05-18 12:54:15.028 : -162--> storage_tank_111_01.jpg | 31.94dB
25-05-18 12:54:15.209 : -163--> storage_tank_111_10.jpg | 30.73dB
25-05-18 12:54:15.386 : -164--> storage_tank_111_11.jpg | 31.20dB
25-05-18 12:54:15.569 : -165--> tennis_court_111_00.jpg | 31.87dB
25-05-18 12:54:15.746 : -166--> tennis_court_111_01.jpg | 31.45dB
25-05-18 12:54:15.926 : -167--> tennis_court_111_10.jpg | 31.62dB
25-05-18 12:54:16.106 : -168--> tennis_court_111_11.jpg | 29.57dB
25-05-18 12:54:16.286 : -169--> terrace_111_00.jpg | 32.19dB
25-05-18 12:54:16.463 : -170--> terrace_111_01.jpg | 33.26dB
25-05-18 12:54:16.645 : -171--> terrace_111_10.jpg | 32.23dB
25-05-18 12:54:16.822 : -172--> terrace_111_11.jpg | 32.25dB
25-05-18 12:54:16.996 : -173--> thermal_power_station_111_00.jpg | 30.05dB
25-05-18 12:54:17.176 : -174--> thermal_power_station_111_01.jpg | 31.58dB
25-05-18 12:54:17.355 : -175--> thermal_power_station_111_10.jpg | 29.81dB
25-05-18 12:54:17.535 : -176--> thermal_power_station_111_11.jpg | 30.38dB
25-05-18 12:54:17.715 : -177--> wetland_111_00.jpg | 31.32dB
25-05-18 12:54:17.896 : -178--> wetland_111_01.jpg | 31.36dB
25-05-18 12:54:18.080 : -179--> wetland_111_10.jpg | 31.59dB
25-05-18 12:54:18.256 : -180--> wetland_111_11.jpg | 30.89dB
25-05-18 12:54:18.275 : <epoch:  0, iter:   5,000, Average PSNR : 32.07dB

25-05-18 14:08:37.796 : <epoch:  0, iter:  10,000, lr:1.000e-04> G_loss: 2.947e-05 
25-05-18 14:08:37.797 : Saving the model.
25-05-18 14:08:38.461 : ---1--> airplane_111_00.jpg | 30.36dB
25-05-18 14:08:38.636 : ---2--> airplane_111_01.jpg | 35.27dB
25-05-18 14:08:38.813 : ---3--> airplane_111_10.jpg | 32.79dB
25-05-18 14:08:38.996 : ---4--> airplane_111_11.jpg | 32.83dB
25-05-18 14:08:39.173 : ---5--> airport_111_00.jpg | 34.42dB
25-05-18 14:08:39.348 : ---6--> airport_111_01.jpg | 32.32dB
25-05-18 14:08:39.530 : ---7--> airport_111_10.jpg | 31.88dB
25-05-18 14:08:39.714 : ---8--> airport_111_11.jpg | 32.82dB
25-05-18 14:08:39.891 : ---9--> baseball_diamond_111_00.jpg | 32.68dB
25-05-18 14:08:40.069 : --10--> baseball_diamond_111_01.jpg | 34.29dB
25-05-18 14:08:40.249 : --11--> baseball_diamond_111_10.jpg | 32.50dB
25-05-18 14:08:40.427 : --12--> baseball_diamond_111_11.jpg | 35.33dB
25-05-18 14:08:40.604 : --13--> basketball_court_111_00.jpg | 30.50dB
25-05-18 14:08:40.792 : --14--> basketball_court_111_01.jpg | 30.07dB
25-05-18 14:08:40.971 : --15--> basketball_court_111_10.jpg | 33.34dB
25-05-18 14:08:41.157 : --16--> basketball_court_111_11.jpg | 31.59dB
25-05-18 14:08:41.339 : --17--> beach_111_00.jpg | 28.55dB
25-05-18 14:08:41.517 : --18--> beach_111_01.jpg | 31.71dB
25-05-18 14:08:41.700 : --19--> beach_111_10.jpg | 29.72dB
25-05-18 14:08:41.879 : --20--> beach_111_11.jpg | 34.36dB
25-05-18 14:08:42.059 : --21--> bridge_111_00.jpg | 40.74dB
25-05-18 14:08:42.235 : --22--> bridge_111_01.jpg | 34.28dB
25-05-18 14:08:42.414 : --23--> bridge_111_10.jpg | 33.17dB
25-05-18 14:08:42.597 : --24--> bridge_111_11.jpg | 36.59dB
25-05-18 14:08:42.775 : --25--> chaparral_111_00.jpg | 30.26dB
25-05-18 14:08:42.956 : --26--> chaparral_111_01.jpg | 30.51dB
25-05-18 14:08:43.132 : --27--> chaparral_111_10.jpg | 30.84dB
25-05-18 14:08:43.315 : --28--> chaparral_111_11.jpg | 28.63dB
25-05-18 14:08:43.492 : --29--> church_111_00.jpg | 31.55dB
25-05-18 14:08:43.670 : --30--> church_111_01.jpg | 30.56dB
25-05-18 14:08:43.850 : --31--> church_111_10.jpg | 34.39dB
25-05-18 14:08:44.028 : --32--> church_111_11.jpg | 30.34dB
25-05-18 14:08:44.209 : --33--> circular_farmland_111_00.jpg | 32.73dB
25-05-18 14:08:44.394 : --34--> circular_farmland_111_01.jpg | 33.78dB
25-05-18 14:08:44.569 : --35--> circular_farmland_111_10.jpg | 33.94dB
25-05-18 14:08:44.749 : --36--> circular_farmland_111_11.jpg | 34.12dB
25-05-18 14:08:44.926 : --37--> cloud_111_00.jpg | 40.88dB
25-05-18 14:08:45.104 : --38--> cloud_111_01.jpg | 36.75dB
25-05-18 14:08:45.284 : --39--> cloud_111_10.jpg | 36.30dB
25-05-18 14:08:45.460 : --40--> cloud_111_11.jpg | 36.80dB
25-05-18 14:08:45.644 : --41--> commercial_area_111_00.jpg | 33.29dB
25-05-18 14:08:45.819 : --42--> commercial_area_111_01.jpg | 32.32dB
25-05-18 14:08:46.000 : --43--> commercial_area_111_10.jpg | 33.10dB
25-05-18 14:08:46.178 : --44--> commercial_area_111_11.jpg | 32.99dB
25-05-18 14:08:46.359 : --45--> dense_residential_111_00.jpg | 30.11dB
25-05-18 14:08:46.536 : --46--> dense_residential_111_01.jpg | 29.19dB
25-05-18 14:08:46.722 : --47--> dense_residential_111_10.jpg | 29.59dB
25-05-18 14:08:46.911 : --48--> dense_residential_111_11.jpg | 29.47dB
25-05-18 14:08:47.093 : --49--> desert_111_00.jpg | 36.82dB
25-05-18 14:08:47.273 : --50--> desert_111_01.jpg | 36.72dB
25-05-18 14:08:47.455 : --51--> desert_111_10.jpg | 36.91dB
25-05-18 14:08:47.630 : --52--> desert_111_11.jpg | 37.05dB
25-05-18 14:08:47.815 : --53--> forest_111_00.jpg | 32.97dB
25-05-18 14:08:47.989 : --54--> forest_111_01.jpg | 32.05dB
25-05-18 14:08:48.170 : --55--> forest_111_10.jpg | 31.68dB
25-05-18 14:08:48.345 : --56--> forest_111_11.jpg | 32.61dB
25-05-18 14:08:48.525 : --57--> freeway_111_00.jpg | 33.80dB
25-05-18 14:08:48.703 : --58--> freeway_111_01.jpg | 34.81dB
25-05-18 14:08:48.878 : --59--> freeway_111_10.jpg | 34.61dB
25-05-18 14:08:49.055 : --60--> freeway_111_11.jpg | 34.73dB
25-05-18 14:08:49.237 : --61--> golf_course_111_00.jpg | 32.68dB
25-05-18 14:08:49.414 : --62--> golf_course_111_01.jpg | 32.09dB
25-05-18 14:08:49.598 : --63--> golf_course_111_10.jpg | 33.48dB
25-05-18 14:08:49.778 : --64--> golf_course_111_11.jpg | 33.81dB
25-05-18 14:08:49.955 : --65--> ground_track_field_111_00.jpg | 33.26dB
25-05-18 14:08:50.134 : --66--> ground_track_field_111_01.jpg | 29.35dB
25-05-18 14:08:50.313 : --67--> ground_track_field_111_10.jpg | 30.71dB
25-05-18 14:08:50.492 : --68--> ground_track_field_111_11.jpg | 29.95dB
25-05-18 14:08:50.670 : --69--> harbor_111_00.jpg | 32.76dB
25-05-18 14:08:50.847 : --70--> harbor_111_01.jpg | 31.13dB
25-05-18 14:08:51.025 : --71--> harbor_111_10.jpg | 30.67dB
25-05-18 14:08:51.205 : --72--> harbor_111_11.jpg | 32.38dB
25-05-18 14:08:51.388 : --73--> industrial_area_111_00.jpg | 31.52dB
25-05-18 14:08:51.569 : --74--> industrial_area_111_01.jpg | 31.72dB
25-05-18 14:08:51.745 : --75--> industrial_area_111_10.jpg | 31.88dB
25-05-18 14:08:51.923 : --76--> industrial_area_111_11.jpg | 31.28dB
25-05-18 14:08:52.104 : --77--> intersection_111_00.jpg | 30.58dB
25-05-18 14:08:52.282 : --78--> intersection_111_01.jpg | 30.66dB
25-05-18 14:08:52.461 : --79--> intersection_111_10.jpg | 30.38dB
25-05-18 14:08:52.641 : --80--> intersection_111_11.jpg | 30.19dB
25-05-18 14:08:52.818 : --81--> island_111_00.jpg | 31.35dB
25-05-18 14:08:53.000 : --82--> island_111_01.jpg | 33.80dB
25-05-18 14:08:53.178 : --83--> island_111_10.jpg | 32.41dB
25-05-18 14:08:53.356 : --84--> island_111_11.jpg | 31.99dB
25-05-18 14:08:53.532 : --85--> lake_111_00.jpg | 32.47dB
25-05-18 14:08:53.713 : --86--> lake_111_01.jpg | 32.26dB
25-05-18 14:08:53.892 : --87--> lake_111_10.jpg | 31.58dB
25-05-18 14:08:54.069 : --88--> lake_111_11.jpg | 31.01dB
25-05-18 14:08:54.248 : --89--> meadow_111_00.jpg | 30.01dB
25-05-18 14:08:54.433 : --90--> meadow_111_01.jpg | 30.12dB
25-05-18 14:08:54.608 : --91--> meadow_111_10.jpg | 30.16dB
25-05-18 14:08:54.785 : --92--> meadow_111_11.jpg | 30.31dB
25-05-18 14:08:54.967 : --93--> medium_residential_111_00.jpg | 28.65dB
25-05-18 14:08:55.144 : --94--> medium_residential_111_01.jpg | 28.12dB
25-05-18 14:08:55.331 : --95--> medium_residential_111_10.jpg | 28.43dB
25-05-18 14:08:55.509 : --96--> medium_residential_111_11.jpg | 28.98dB
25-05-18 14:08:55.687 : --97--> mobile_home_park_111_00.jpg | 30.89dB
25-05-18 14:08:55.868 : --98--> mobile_home_park_111_01.jpg | 31.38dB
25-05-18 14:08:56.050 : --99--> mobile_home_park_111_10.jpg | 31.72dB
25-05-18 14:08:56.227 : -100--> mobile_home_park_111_11.jpg | 31.75dB
25-05-18 14:08:56.403 : -101--> mountain_111_00.jpg | 28.85dB
25-05-18 14:08:56.580 : -102--> mountain_111_01.jpg | 29.50dB
25-05-18 14:08:56.760 : -103--> mountain_111_10.jpg | 29.29dB
25-05-18 14:08:56.942 : -104--> mountain_111_11.jpg | 29.63dB
25-05-18 14:08:57.120 : -105--> overpass_111_00.jpg | 30.04dB
25-05-18 14:08:57.301 : -106--> overpass_111_01.jpg | 29.94dB
25-05-18 14:08:57.480 : -107--> overpass_111_10.jpg | 30.52dB
25-05-18 14:08:57.655 : -108--> overpass_111_11.jpg | 31.26dB
25-05-18 14:08:57.836 : -109--> palace_111_00.jpg | 29.96dB
25-05-18 14:08:58.015 : -110--> palace_111_01.jpg | 29.74dB
25-05-18 14:08:58.196 : -111--> palace_111_10.jpg | 30.98dB
25-05-18 14:08:58.370 : -112--> palace_111_11.jpg | 29.33dB
25-05-18 14:08:58.554 : -113--> parking_lot_111_00.jpg | 29.24dB
25-05-18 14:08:58.731 : -114--> parking_lot_111_01.jpg | 29.53dB
25-05-18 14:08:58.909 : -115--> parking_lot_111_10.jpg | 31.05dB
25-05-18 14:08:59.086 : -116--> parking_lot_111_11.jpg | 29.94dB
25-05-18 14:08:59.265 : -117--> railway_111_00.jpg | 30.08dB
25-05-18 14:08:59.445 : -118--> railway_111_01.jpg | 29.58dB
25-05-18 14:08:59.622 : -119--> railway_111_10.jpg | 32.39dB
25-05-18 14:08:59.802 : -120--> railway_111_11.jpg | 29.00dB
25-05-18 14:08:59.977 : -121--> railway_station_111_00.jpg | 30.80dB
25-05-18 14:09:00.154 : -122--> railway_station_111_01.jpg | 31.29dB
25-05-18 14:09:00.335 : -123--> railway_station_111_10.jpg | 30.97dB
25-05-18 14:09:00.522 : -124--> railway_station_111_11.jpg | 31.46dB
25-05-18 14:09:00.703 : -125--> rectangular_farmland_111_00.jpg | 33.36dB
25-05-18 14:09:00.883 : -126--> rectangular_farmland_111_01.jpg | 31.83dB
25-05-18 14:09:01.062 : -127--> rectangular_farmland_111_10.jpg | 33.71dB
25-05-18 14:09:01.239 : -128--> rectangular_farmland_111_11.jpg | 34.01dB
25-05-18 14:09:01.427 : -129--> river_111_00.jpg | 30.11dB
25-05-18 14:09:01.600 : -130--> river_111_01.jpg | 29.95dB
25-05-18 14:09:01.776 : -131--> river_111_10.jpg | 29.41dB
25-05-18 14:09:01.954 : -132--> river_111_11.jpg | 31.27dB
25-05-18 14:09:02.134 : -133--> roundabout_111_00.jpg | 30.37dB
25-05-18 14:09:02.311 : -134--> roundabout_111_01.jpg | 31.97dB
25-05-18 14:09:02.489 : -135--> roundabout_111_10.jpg | 30.32dB
25-05-18 14:09:02.666 : -136--> roundabout_111_11.jpg | 30.67dB
25-05-18 14:09:02.844 : -137--> runway_111_00.jpg | 36.34dB
25-05-18 14:09:03.021 : -138--> runway_111_01.jpg | 35.71dB
25-05-18 14:09:03.200 : -139--> runway_111_10.jpg | 36.43dB
25-05-18 14:09:03.382 : -140--> runway_111_11.jpg | 37.36dB
25-05-18 14:09:03.560 : -141--> sea_ice_111_00.jpg | 33.53dB
25-05-18 14:09:03.745 : -142--> sea_ice_111_01.jpg | 34.56dB
25-05-18 14:09:03.925 : -143--> sea_ice_111_10.jpg | 33.53dB
25-05-18 14:09:04.105 : -144--> sea_ice_111_11.jpg | 34.59dB
25-05-18 14:09:04.283 : -145--> ship_111_00.jpg | 38.51dB
25-05-18 14:09:04.460 : -146--> ship_111_01.jpg | 34.49dB
25-05-18 14:09:04.639 : -147--> ship_111_10.jpg | 42.56dB
25-05-18 14:09:04.819 : -148--> ship_111_11.jpg | 39.95dB
25-05-18 14:09:04.993 : -149--> snowberg_111_00.jpg | 34.13dB
25-05-18 14:09:05.174 : -150--> snowberg_111_01.jpg | 32.68dB
25-05-18 14:09:05.353 : -151--> snowberg_111_10.jpg | 31.89dB
25-05-18 14:09:05.532 : -152--> snowberg_111_11.jpg | 31.94dB
25-05-18 14:09:05.710 : -153--> sparse_residential_111_00.jpg | 30.39dB
25-05-18 14:09:05.889 : -154--> sparse_residential_111_01.jpg | 30.65dB
25-05-18 14:09:06.068 : -155--> sparse_residential_111_10.jpg | 29.68dB
25-05-18 14:09:06.246 : -156--> sparse_residential_111_11.jpg | 29.97dB
25-05-18 14:09:06.428 : -157--> stadium_111_00.jpg | 30.17dB
25-05-18 14:09:06.608 : -158--> stadium_111_01.jpg | 30.01dB
25-05-18 14:09:06.787 : -159--> stadium_111_10.jpg | 31.32dB
25-05-18 14:09:06.965 : -160--> stadium_111_11.jpg | 30.11dB
25-05-18 14:09:07.145 : -161--> storage_tank_111_00.jpg | 31.81dB
25-05-18 14:09:07.320 : -162--> storage_tank_111_01.jpg | 31.97dB
25-05-18 14:09:07.501 : -163--> storage_tank_111_10.jpg | 30.75dB
25-05-18 14:09:07.679 : -164--> storage_tank_111_11.jpg | 31.23dB
25-05-18 14:09:07.860 : -165--> tennis_court_111_00.jpg | 31.89dB
25-05-18 14:09:08.041 : -166--> tennis_court_111_01.jpg | 31.47dB
25-05-18 14:09:08.224 : -167--> tennis_court_111_10.jpg | 31.66dB
25-05-18 14:09:08.400 : -168--> tennis_court_111_11.jpg | 29.59dB
25-05-18 14:09:08.582 : -169--> terrace_111_00.jpg | 32.21dB
25-05-18 14:09:08.759 : -170--> terrace_111_01.jpg | 33.28dB
25-05-18 14:09:08.938 : -171--> terrace_111_10.jpg | 32.25dB
25-05-18 14:09:09.116 : -172--> terrace_111_11.jpg | 32.29dB
25-05-18 14:09:09.293 : -173--> thermal_power_station_111_00.jpg | 30.08dB
25-05-18 14:09:09.471 : -174--> thermal_power_station_111_01.jpg | 31.62dB
25-05-18 14:09:09.649 : -175--> thermal_power_station_111_10.jpg | 29.82dB
25-05-18 14:09:09.826 : -176--> thermal_power_station_111_11.jpg | 30.40dB
25-05-18 14:09:10.005 : -177--> wetland_111_00.jpg | 31.34dB
25-05-18 14:09:10.185 : -178--> wetland_111_01.jpg | 31.38dB
25-05-18 14:09:10.375 : -179--> wetland_111_10.jpg | 31.61dB
25-05-18 14:09:10.554 : -180--> wetland_111_11.jpg | 30.95dB
25-05-18 14:09:10.564 : <epoch:  0, iter:  10,000, Average PSNR : 32.09dB

25-05-18 15:29:09.202 : <epoch:  0, iter:  15,000, lr:1.000e-04> G_loss: 1.251e-04 
25-05-18 15:29:09.204 : Saving the model.
25-05-18 15:29:09.855 : ---1--> airplane_111_00.jpg | 30.37dB
25-05-18 15:29:10.028 : ---2--> airplane_111_01.jpg | 35.25dB
25-05-18 15:29:10.208 : ---3--> airplane_111_10.jpg | 32.80dB
25-05-18 15:29:10.388 : ---4--> airplane_111_11.jpg | 32.86dB
25-05-18 15:29:10.576 : ---5--> airport_111_00.jpg | 34.42dB
25-05-18 15:29:10.762 : ---6--> airport_111_01.jpg | 32.30dB
25-05-18 15:29:10.948 : ---7--> airport_111_10.jpg | 31.86dB
25-05-18 15:29:11.130 : ---8--> airport_111_11.jpg | 32.84dB
25-05-18 15:29:11.306 : ---9--> baseball_diamond_111_00.jpg | 32.66dB
25-05-18 15:29:11.484 : --10--> baseball_diamond_111_01.jpg | 34.26dB
25-05-18 15:29:11.664 : --11--> baseball_diamond_111_10.jpg | 32.51dB
25-05-18 15:29:11.843 : --12--> baseball_diamond_111_11.jpg | 35.28dB
25-05-18 15:29:12.023 : --13--> basketball_court_111_00.jpg | 30.52dB
25-05-18 15:29:12.210 : --14--> basketball_court_111_01.jpg | 30.08dB
25-05-18 15:29:12.384 : --15--> basketball_court_111_10.jpg | 33.34dB
25-05-18 15:29:12.558 : --16--> basketball_court_111_11.jpg | 31.61dB
25-05-18 15:29:12.742 : --17--> beach_111_00.jpg | 28.54dB
25-05-18 15:29:12.927 : --18--> beach_111_01.jpg | 31.75dB
25-05-18 15:29:13.112 : --19--> beach_111_10.jpg | 29.72dB
25-05-18 15:29:13.296 : --20--> beach_111_11.jpg | 34.38dB
25-05-18 15:29:13.474 : --21--> bridge_111_00.jpg | 40.68dB
25-05-18 15:29:13.653 : --22--> bridge_111_01.jpg | 34.29dB
25-05-18 15:29:13.832 : --23--> bridge_111_10.jpg | 33.17dB
25-05-18 15:29:14.017 : --24--> bridge_111_11.jpg | 36.53dB
25-05-18 15:29:14.198 : --25--> chaparral_111_00.jpg | 30.25dB
25-05-18 15:29:14.382 : --26--> chaparral_111_01.jpg | 30.52dB
25-05-18 15:29:14.563 : --27--> chaparral_111_10.jpg | 30.83dB
25-05-18 15:29:14.744 : --28--> chaparral_111_11.jpg | 28.65dB
25-05-18 15:29:14.929 : --29--> church_111_00.jpg | 31.57dB
25-05-18 15:29:15.111 : --30--> church_111_01.jpg | 30.55dB
25-05-18 15:29:15.290 : --31--> church_111_10.jpg | 34.29dB
25-05-18 15:29:15.472 : --32--> church_111_11.jpg | 30.38dB
25-05-18 15:29:15.654 : --33--> circular_farmland_111_00.jpg | 32.71dB
25-05-18 15:29:15.832 : --34--> circular_farmland_111_01.jpg | 33.76dB
25-05-18 15:29:16.017 : --35--> circular_farmland_111_10.jpg | 33.91dB
25-05-18 15:29:16.198 : --36--> circular_farmland_111_11.jpg | 34.09dB
25-05-18 15:29:16.377 : --37--> cloud_111_00.jpg | 40.93dB
25-05-18 15:29:16.562 : --38--> cloud_111_01.jpg | 36.79dB
25-05-18 15:29:16.737 : --39--> cloud_111_10.jpg | 36.34dB
25-05-18 15:29:16.913 : --40--> cloud_111_11.jpg | 36.79dB
25-05-18 15:29:17.096 : --41--> commercial_area_111_00.jpg | 33.30dB
25-05-18 15:29:17.274 : --42--> commercial_area_111_01.jpg | 32.32dB
25-05-18 15:29:17.458 : --43--> commercial_area_111_10.jpg | 33.10dB
25-05-18 15:29:17.643 : --44--> commercial_area_111_11.jpg | 32.97dB
25-05-18 15:29:17.816 : --45--> dense_residential_111_00.jpg | 30.11dB
25-05-18 15:29:18.000 : --46--> dense_residential_111_01.jpg | 29.19dB
25-05-18 15:29:18.189 : --47--> dense_residential_111_10.jpg | 29.59dB
25-05-18 15:29:18.366 : --48--> dense_residential_111_11.jpg | 29.46dB
25-05-18 15:29:18.545 : --49--> desert_111_00.jpg | 36.83dB
25-05-18 15:29:18.724 : --50--> desert_111_01.jpg | 36.71dB
25-05-18 15:29:18.902 : --51--> desert_111_10.jpg | 36.88dB
25-05-18 15:29:19.092 : --52--> desert_111_11.jpg | 36.99dB
25-05-18 15:29:19.278 : --53--> forest_111_00.jpg | 32.98dB
25-05-18 15:29:19.459 : --54--> forest_111_01.jpg | 32.06dB
25-05-18 15:29:19.635 : --55--> forest_111_10.jpg | 31.70dB
25-05-18 15:29:19.815 : --56--> forest_111_11.jpg | 32.62dB
25-05-18 15:29:19.993 : --57--> freeway_111_00.jpg | 33.80dB
25-05-18 15:29:20.173 : --58--> freeway_111_01.jpg | 34.76dB
25-05-18 15:29:20.352 : --59--> freeway_111_10.jpg | 34.67dB
25-05-18 15:29:20.533 : --60--> freeway_111_11.jpg | 34.73dB
25-05-18 15:29:20.711 : --61--> golf_course_111_00.jpg | 32.69dB
25-05-18 15:29:20.890 : --62--> golf_course_111_01.jpg | 32.07dB
25-05-18 15:29:21.067 : --63--> golf_course_111_10.jpg | 33.47dB
25-05-18 15:29:21.246 : --64--> golf_course_111_11.jpg | 33.84dB
25-05-18 15:29:21.434 : --65--> ground_track_field_111_00.jpg | 33.24dB
25-05-18 15:29:21.615 : --66--> ground_track_field_111_01.jpg | 29.36dB
25-05-18 15:29:21.794 : --67--> ground_track_field_111_10.jpg | 30.71dB
25-05-18 15:29:21.980 : --68--> ground_track_field_111_11.jpg | 29.94dB
25-05-18 15:29:22.153 : --69--> harbor_111_00.jpg | 32.76dB
25-05-18 15:29:22.334 : --70--> harbor_111_01.jpg | 31.14dB
25-05-18 15:29:22.522 : --71--> harbor_111_10.jpg | 30.68dB
25-05-18 15:29:22.705 : --72--> harbor_111_11.jpg | 32.37dB
25-05-18 15:29:22.881 : --73--> industrial_area_111_00.jpg | 31.53dB
25-05-18 15:29:23.058 : --74--> industrial_area_111_01.jpg | 31.74dB
25-05-18 15:29:23.237 : --75--> industrial_area_111_10.jpg | 31.88dB
25-05-18 15:29:23.417 : --76--> industrial_area_111_11.jpg | 31.27dB
25-05-18 15:29:23.600 : --77--> intersection_111_00.jpg | 30.56dB
25-05-18 15:29:23.777 : --78--> intersection_111_01.jpg | 30.67dB
25-05-18 15:29:23.958 : --79--> intersection_111_10.jpg | 30.40dB
25-05-18 15:29:24.135 : --80--> intersection_111_11.jpg | 30.16dB
25-05-18 15:29:24.319 : --81--> island_111_00.jpg | 31.36dB
25-05-18 15:29:24.498 : --82--> island_111_01.jpg | 33.77dB
25-05-18 15:29:24.672 : --83--> island_111_10.jpg | 32.41dB
25-05-18 15:29:24.850 : --84--> island_111_11.jpg | 31.99dB
25-05-18 15:29:25.031 : --85--> lake_111_00.jpg | 32.45dB
25-05-18 15:29:25.208 : --86--> lake_111_01.jpg | 32.25dB
25-05-18 15:29:25.393 : --87--> lake_111_10.jpg | 31.57dB
25-05-18 15:29:25.569 : --88--> lake_111_11.jpg | 31.00dB
25-05-18 15:29:25.752 : --89--> meadow_111_00.jpg | 30.01dB
25-05-18 15:29:25.942 : --90--> meadow_111_01.jpg | 30.13dB
25-05-18 15:29:26.122 : --91--> meadow_111_10.jpg | 30.16dB
25-05-18 15:29:26.303 : --92--> meadow_111_11.jpg | 30.32dB
25-05-18 15:29:26.490 : --93--> medium_residential_111_00.jpg | 28.64dB
25-05-18 15:29:26.668 : --94--> medium_residential_111_01.jpg | 28.10dB
25-05-18 15:29:26.845 : --95--> medium_residential_111_10.jpg | 28.44dB
25-05-18 15:29:27.034 : --96--> medium_residential_111_11.jpg | 28.99dB
25-05-18 15:29:27.221 : --97--> mobile_home_park_111_00.jpg | 30.90dB
25-05-18 15:29:27.395 : --98--> mobile_home_park_111_01.jpg | 31.37dB
25-05-18 15:29:27.583 : --99--> mobile_home_park_111_10.jpg | 31.72dB
25-05-18 15:29:27.770 : -100--> mobile_home_park_111_11.jpg | 31.77dB
25-05-18 15:29:27.953 : -101--> mountain_111_00.jpg | 28.82dB
25-05-18 15:29:28.140 : -102--> mountain_111_01.jpg | 29.49dB
25-05-18 15:29:28.318 : -103--> mountain_111_10.jpg | 29.25dB
25-05-18 15:29:28.504 : -104--> mountain_111_11.jpg | 29.61dB
25-05-18 15:29:28.684 : -105--> overpass_111_00.jpg | 30.04dB
25-05-18 15:29:28.865 : -106--> overpass_111_01.jpg | 29.95dB
25-05-18 15:29:29.045 : -107--> overpass_111_10.jpg | 30.49dB
25-05-18 15:29:29.234 : -108--> overpass_111_11.jpg | 31.29dB
25-05-18 15:29:29.411 : -109--> palace_111_00.jpg | 29.99dB
25-05-18 15:29:29.597 : -110--> palace_111_01.jpg | 29.77dB
25-05-18 15:29:29.784 : -111--> palace_111_10.jpg | 30.99dB
25-05-18 15:29:29.965 : -112--> palace_111_11.jpg | 29.35dB
25-05-18 15:29:30.142 : -113--> parking_lot_111_00.jpg | 29.24dB
25-05-18 15:29:30.324 : -114--> parking_lot_111_01.jpg | 29.53dB
25-05-18 15:29:30.505 : -115--> parking_lot_111_10.jpg | 31.06dB
25-05-18 15:29:30.685 : -116--> parking_lot_111_11.jpg | 29.94dB
25-05-18 15:29:30.868 : -117--> railway_111_00.jpg | 30.07dB
25-05-18 15:29:31.052 : -118--> railway_111_01.jpg | 29.58dB
25-05-18 15:29:31.231 : -119--> railway_111_10.jpg | 32.39dB
25-05-18 15:29:31.412 : -120--> railway_111_11.jpg | 29.02dB
25-05-18 15:29:31.597 : -121--> railway_station_111_00.jpg | 30.79dB
25-05-18 15:29:31.772 : -122--> railway_station_111_01.jpg | 31.26dB
25-05-18 15:29:31.955 : -123--> railway_station_111_10.jpg | 30.97dB
25-05-18 15:29:32.133 : -124--> railway_station_111_11.jpg | 31.50dB
25-05-18 15:29:32.312 : -125--> rectangular_farmland_111_00.jpg | 33.34dB
25-05-18 15:29:32.506 : -126--> rectangular_farmland_111_01.jpg | 31.81dB
25-05-18 15:29:32.687 : -127--> rectangular_farmland_111_10.jpg | 33.68dB
25-05-18 15:29:32.862 : -128--> rectangular_farmland_111_11.jpg | 33.99dB
25-05-18 15:29:33.052 : -129--> river_111_00.jpg | 30.10dB
25-05-18 15:29:33.235 : -130--> river_111_01.jpg | 29.94dB
25-05-18 15:29:33.416 : -131--> river_111_10.jpg | 29.42dB
25-05-18 15:29:33.594 : -132--> river_111_11.jpg | 31.25dB
25-05-18 15:29:33.777 : -133--> roundabout_111_00.jpg | 30.39dB
25-05-18 15:29:33.953 : -134--> roundabout_111_01.jpg | 31.98dB
25-05-18 15:29:34.144 : -135--> roundabout_111_10.jpg | 30.30dB
25-05-18 15:29:34.318 : -136--> roundabout_111_11.jpg | 30.65dB
25-05-18 15:29:34.493 : -137--> runway_111_00.jpg | 36.39dB
25-05-18 15:29:34.675 : -138--> runway_111_01.jpg | 35.71dB
25-05-18 15:29:34.852 : -139--> runway_111_10.jpg | 36.43dB
25-05-18 15:29:35.038 : -140--> runway_111_11.jpg | 37.36dB
25-05-18 15:29:35.217 : -141--> sea_ice_111_00.jpg | 33.55dB
25-05-18 15:29:35.400 : -142--> sea_ice_111_01.jpg | 34.56dB
25-05-18 15:29:35.584 : -143--> sea_ice_111_10.jpg | 33.54dB
25-05-18 15:29:35.770 : -144--> sea_ice_111_11.jpg | 34.59dB
25-05-18 15:29:35.955 : -145--> ship_111_00.jpg | 38.50dB
25-05-18 15:29:36.134 : -146--> ship_111_01.jpg | 34.49dB
25-05-18 15:29:36.313 : -147--> ship_111_10.jpg | 42.57dB
25-05-18 15:29:36.492 : -148--> ship_111_11.jpg | 39.91dB
25-05-18 15:29:36.670 : -149--> snowberg_111_00.jpg | 34.07dB
25-05-18 15:29:36.856 : -150--> snowberg_111_01.jpg | 32.70dB
25-05-18 15:29:37.039 : -151--> snowberg_111_10.jpg | 31.92dB
25-05-18 15:29:37.219 : -152--> snowberg_111_11.jpg | 31.94dB
25-05-18 15:29:37.400 : -153--> sparse_residential_111_00.jpg | 30.39dB
25-05-18 15:29:37.588 : -154--> sparse_residential_111_01.jpg | 30.66dB
25-05-18 15:29:37.762 : -155--> sparse_residential_111_10.jpg | 29.69dB
25-05-18 15:29:37.944 : -156--> sparse_residential_111_11.jpg | 29.98dB
25-05-18 15:29:38.125 : -157--> stadium_111_00.jpg | 30.20dB
25-05-18 15:29:38.305 : -158--> stadium_111_01.jpg | 30.02dB
25-05-18 15:29:38.492 : -159--> stadium_111_10.jpg | 31.35dB
25-05-18 15:29:38.670 : -160--> stadium_111_11.jpg | 30.13dB
25-05-18 15:29:38.846 : -161--> storage_tank_111_00.jpg | 31.81dB
25-05-18 15:29:39.027 : -162--> storage_tank_111_01.jpg | 31.97dB
25-05-18 15:29:39.207 : -163--> storage_tank_111_10.jpg | 30.75dB
25-05-18 15:29:39.387 : -164--> storage_tank_111_11.jpg | 31.23dB
25-05-18 15:29:39.567 : -165--> tennis_court_111_00.jpg | 31.91dB
25-05-18 15:29:39.744 : -166--> tennis_court_111_01.jpg | 31.45dB
25-05-18 15:29:39.926 : -167--> tennis_court_111_10.jpg | 31.65dB
25-05-18 15:29:40.116 : -168--> tennis_court_111_11.jpg | 29.60dB
25-05-18 15:29:40.292 : -169--> terrace_111_00.jpg | 32.19dB
25-05-18 15:29:40.474 : -170--> terrace_111_01.jpg | 33.25dB
25-05-18 15:29:40.654 : -171--> terrace_111_10.jpg | 32.27dB
25-05-18 15:29:40.837 : -172--> terrace_111_11.jpg | 32.27dB
25-05-18 15:29:41.011 : -173--> thermal_power_station_111_00.jpg | 30.06dB
25-05-18 15:29:41.194 : -174--> thermal_power_station_111_01.jpg | 31.60dB
25-05-18 15:29:41.374 : -175--> thermal_power_station_111_10.jpg | 29.84dB
25-05-18 15:29:41.555 : -176--> thermal_power_station_111_11.jpg | 30.40dB
25-05-18 15:29:41.741 : -177--> wetland_111_00.jpg | 31.33dB
25-05-18 15:29:41.916 : -178--> wetland_111_01.jpg | 31.38dB
25-05-18 15:29:42.100 : -179--> wetland_111_10.jpg | 31.60dB
25-05-18 15:29:42.287 : -180--> wetland_111_11.jpg | 30.93dB
25-05-18 15:29:42.295 : <epoch:  0, iter:  15,000, Average PSNR : 32.09dB

25-05-18 17:51:09.045 : <epoch:  0, iter:  20,000, lr:1.000e-04> G_loss: 3.506e-05 
25-05-18 17:51:09.046 : Saving the model.
25-05-18 17:51:09.666 : ---1--> airplane_111_00.jpg | 30.38dB
25-05-18 17:51:09.873 : ---2--> airplane_111_01.jpg | 35.28dB
25-05-18 17:51:10.052 : ---3--> airplane_111_10.jpg | 32.80dB
25-05-18 17:51:10.234 : ---4--> airplane_111_11.jpg | 32.85dB
25-05-18 17:51:10.431 : ---5--> airport_111_00.jpg | 34.45dB
25-05-18 17:51:10.612 : ---6--> airport_111_01.jpg | 32.32dB
25-05-18 17:51:10.790 : ---7--> airport_111_10.jpg | 31.85dB
25-05-18 17:51:10.988 : ---8--> airport_111_11.jpg | 32.84dB
25-05-18 17:51:11.168 : ---9--> baseball_diamond_111_00.jpg | 32.66dB
25-05-18 17:51:11.350 : --10--> baseball_diamond_111_01.jpg | 34.25dB
25-05-18 17:51:11.543 : --11--> baseball_diamond_111_10.jpg | 32.51dB
25-05-18 17:51:11.724 : --12--> baseball_diamond_111_11.jpg | 35.31dB
25-05-18 17:51:11.905 : --13--> basketball_court_111_00.jpg | 30.51dB
25-05-18 17:51:12.115 : --14--> basketball_court_111_01.jpg | 30.07dB
25-05-18 17:51:12.294 : --15--> basketball_court_111_10.jpg | 33.34dB
25-05-18 17:51:12.477 : --16--> basketball_court_111_11.jpg | 31.60dB
25-05-18 17:51:12.668 : --17--> beach_111_00.jpg | 28.56dB
25-05-18 17:51:12.851 : --18--> beach_111_01.jpg | 31.74dB
25-05-18 17:51:13.031 : --19--> beach_111_10.jpg | 29.72dB
25-05-18 17:51:13.229 : --20--> beach_111_11.jpg | 34.32dB
25-05-18 17:51:13.422 : --21--> bridge_111_00.jpg | 40.69dB
25-05-18 17:51:13.624 : --22--> bridge_111_01.jpg | 34.27dB
25-05-18 17:51:13.816 : --23--> bridge_111_10.jpg | 33.17dB
25-05-18 17:51:13.999 : --24--> bridge_111_11.jpg | 36.56dB
25-05-18 17:51:14.178 : --25--> chaparral_111_00.jpg | 30.24dB
25-05-18 17:51:14.375 : --26--> chaparral_111_01.jpg | 30.51dB
25-05-18 17:51:14.552 : --27--> chaparral_111_10.jpg | 30.82dB
25-05-18 17:51:14.735 : --28--> chaparral_111_11.jpg | 28.64dB
25-05-18 17:51:14.931 : --29--> church_111_00.jpg | 31.59dB
25-05-18 17:51:15.122 : --30--> church_111_01.jpg | 30.56dB
25-05-18 17:51:15.321 : --31--> church_111_10.jpg | 34.30dB
25-05-18 17:51:15.520 : --32--> church_111_11.jpg | 30.38dB
25-05-18 17:51:15.698 : --33--> circular_farmland_111_00.jpg | 32.75dB
25-05-18 17:51:15.885 : --34--> circular_farmland_111_01.jpg | 33.79dB
25-05-18 17:51:16.075 : --35--> circular_farmland_111_10.jpg | 33.95dB
25-05-18 17:51:16.273 : --36--> circular_farmland_111_11.jpg | 34.10dB
25-05-18 17:51:16.466 : --37--> cloud_111_00.jpg | 41.02dB
25-05-18 17:51:16.652 : --38--> cloud_111_01.jpg | 36.81dB
25-05-18 17:51:16.829 : --39--> cloud_111_10.jpg | 36.33dB
25-05-18 17:51:17.027 : --40--> cloud_111_11.jpg | 36.82dB
25-05-18 17:51:17.224 : --41--> commercial_area_111_00.jpg | 33.30dB
25-05-18 17:51:17.409 : --42--> commercial_area_111_01.jpg | 32.33dB
25-05-18 17:51:17.599 : --43--> commercial_area_111_10.jpg | 33.10dB
25-05-18 17:51:17.786 : --44--> commercial_area_111_11.jpg | 32.96dB
25-05-18 17:51:17.979 : --45--> dense_residential_111_00.jpg | 30.11dB
25-05-18 17:51:18.177 : --46--> dense_residential_111_01.jpg | 29.22dB
25-05-18 17:51:18.354 : --47--> dense_residential_111_10.jpg | 29.62dB
25-05-18 17:51:18.547 : --48--> dense_residential_111_11.jpg | 29.49dB
25-05-18 17:51:18.737 : --49--> desert_111_00.jpg | 36.81dB
25-05-18 17:51:18.923 : --50--> desert_111_01.jpg | 36.66dB
25-05-18 17:51:19.107 : --51--> desert_111_10.jpg | 36.83dB
25-05-18 17:51:19.319 : --52--> desert_111_11.jpg | 36.98dB
25-05-18 17:51:19.514 : --53--> forest_111_00.jpg | 32.98dB
25-05-18 17:51:19.711 : --54--> forest_111_01.jpg | 32.08dB
25-05-18 17:51:19.904 : --55--> forest_111_10.jpg | 31.70dB
25-05-18 17:51:20.093 : --56--> forest_111_11.jpg | 32.62dB
25-05-18 17:51:20.275 : --57--> freeway_111_00.jpg | 33.78dB
25-05-18 17:51:20.477 : --58--> freeway_111_01.jpg | 34.81dB
25-05-18 17:51:20.656 : --59--> freeway_111_10.jpg | 34.71dB
25-05-18 17:51:20.840 : --60--> freeway_111_11.jpg | 34.75dB
25-05-18 17:51:21.038 : --61--> golf_course_111_00.jpg | 32.67dB
25-05-18 17:51:21.232 : --62--> golf_course_111_01.jpg | 32.06dB
25-05-18 17:51:21.415 : --63--> golf_course_111_10.jpg | 33.47dB
25-05-18 17:51:21.616 : --64--> golf_course_111_11.jpg | 33.85dB
25-05-18 17:51:21.801 : --65--> ground_track_field_111_00.jpg | 33.24dB
25-05-18 17:51:22.014 : --66--> ground_track_field_111_01.jpg | 29.34dB
25-05-18 17:51:22.196 : --67--> ground_track_field_111_10.jpg | 30.72dB
25-05-18 17:51:22.391 : --68--> ground_track_field_111_11.jpg | 29.94dB
25-05-18 17:51:22.584 : --69--> harbor_111_00.jpg | 32.81dB
25-05-18 17:51:22.767 : --70--> harbor_111_01.jpg | 31.15dB
25-05-18 17:51:22.946 : --71--> harbor_111_10.jpg | 30.69dB
25-05-18 17:51:23.143 : --72--> harbor_111_11.jpg | 32.38dB
25-05-18 17:51:23.325 : --73--> industrial_area_111_00.jpg | 31.52dB
25-05-18 17:51:23.523 : --74--> industrial_area_111_01.jpg | 31.74dB
25-05-18 17:51:23.715 : --75--> industrial_area_111_10.jpg | 31.86dB
25-05-18 17:51:23.899 : --76--> industrial_area_111_11.jpg | 31.28dB
25-05-18 17:51:24.100 : --77--> intersection_111_00.jpg | 30.57dB
25-05-18 17:51:24.311 : --78--> intersection_111_01.jpg | 30.71dB
25-05-18 17:51:24.488 : --79--> intersection_111_10.jpg | 30.41dB
25-05-18 17:51:24.674 : --80--> intersection_111_11.jpg | 30.19dB
25-05-18 17:51:24.872 : --81--> island_111_00.jpg | 31.38dB
25-05-18 17:51:25.055 : --82--> island_111_01.jpg | 33.81dB
25-05-18 17:51:25.233 : --83--> island_111_10.jpg | 32.43dB
25-05-18 17:51:25.450 : --84--> island_111_11.jpg | 32.01dB
25-05-18 17:51:25.631 : --85--> lake_111_00.jpg | 32.45dB
25-05-18 17:51:25.814 : --86--> lake_111_01.jpg | 32.29dB
25-05-18 17:51:26.028 : --87--> lake_111_10.jpg | 31.60dB
25-05-18 17:51:26.210 : --88--> lake_111_11.jpg | 31.01dB
25-05-18 17:51:26.404 : --89--> meadow_111_00.jpg | 30.02dB
25-05-18 17:51:26.589 : --90--> meadow_111_01.jpg | 30.13dB
25-05-18 17:51:26.773 : --91--> meadow_111_10.jpg | 30.16dB
25-05-18 17:51:26.971 : --92--> meadow_111_11.jpg | 30.33dB
25-05-18 17:51:27.149 : --93--> medium_residential_111_00.jpg | 28.66dB
25-05-18 17:51:27.350 : --94--> medium_residential_111_01.jpg | 28.12dB
25-05-18 17:51:27.538 : --95--> medium_residential_111_10.jpg | 28.47dB
25-05-18 17:51:27.721 : --96--> medium_residential_111_11.jpg | 29.01dB
25-05-18 17:51:27.905 : --97--> mobile_home_park_111_00.jpg | 30.93dB
25-05-18 17:51:28.104 : --98--> mobile_home_park_111_01.jpg | 31.37dB
25-05-18 17:51:28.283 : --99--> mobile_home_park_111_10.jpg | 31.72dB
25-05-18 17:51:28.484 : -100--> mobile_home_park_111_11.jpg | 31.79dB
25-05-18 17:51:28.693 : -101--> mountain_111_00.jpg | 28.84dB
25-05-18 17:51:28.876 : -102--> mountain_111_01.jpg | 29.50dB
25-05-18 17:51:29.068 : -103--> mountain_111_10.jpg | 29.28dB
25-05-18 17:51:29.262 : -104--> mountain_111_11.jpg | 29.64dB
25-05-18 17:51:29.442 : -105--> overpass_111_00.jpg | 30.06dB
25-05-18 17:51:29.629 : -106--> overpass_111_01.jpg | 29.95dB
25-05-18 17:51:29.830 : -107--> overpass_111_10.jpg | 30.53dB
25-05-18 17:51:30.031 : -108--> overpass_111_11.jpg | 31.29dB
25-05-18 17:51:30.229 : -109--> palace_111_00.jpg | 29.96dB
25-05-18 17:51:30.425 : -110--> palace_111_01.jpg | 29.80dB
25-05-18 17:51:30.618 : -111--> palace_111_10.jpg | 31.01dB
25-05-18 17:51:30.814 : -112--> palace_111_11.jpg | 29.35dB
25-05-18 17:51:30.996 : -113--> parking_lot_111_00.jpg | 29.25dB
25-05-18 17:51:31.198 : -114--> parking_lot_111_01.jpg | 29.53dB
25-05-18 17:51:31.391 : -115--> parking_lot_111_10.jpg | 31.09dB
25-05-18 17:51:31.580 : -116--> parking_lot_111_11.jpg | 29.94dB
25-05-18 17:51:31.762 : -117--> railway_111_00.jpg | 30.09dB
25-05-18 17:51:31.970 : -118--> railway_111_01.jpg | 29.62dB
25-05-18 17:51:32.154 : -119--> railway_111_10.jpg | 32.42dB
25-05-18 17:51:32.341 : -120--> railway_111_11.jpg | 29.01dB
25-05-18 17:51:32.549 : -121--> railway_station_111_00.jpg | 30.78dB
25-05-18 17:51:32.736 : -122--> railway_station_111_01.jpg | 31.29dB
25-05-18 17:51:32.921 : -123--> railway_station_111_10.jpg | 30.99dB
25-05-18 17:51:33.116 : -124--> railway_station_111_11.jpg | 31.51dB
25-05-18 17:51:33.301 : -125--> rectangular_farmland_111_00.jpg | 33.36dB
25-05-18 17:51:33.503 : -126--> rectangular_farmland_111_01.jpg | 31.81dB
25-05-18 17:51:33.703 : -127--> rectangular_farmland_111_10.jpg | 33.73dB
25-05-18 17:51:33.885 : -128--> rectangular_farmland_111_11.jpg | 33.98dB
25-05-18 17:51:34.067 : -129--> river_111_00.jpg | 30.12dB
25-05-18 17:51:34.259 : -130--> river_111_01.jpg | 29.94dB
25-05-18 17:51:34.442 : -131--> river_111_10.jpg | 29.43dB
25-05-18 17:51:34.627 : -132--> river_111_11.jpg | 31.29dB
25-05-18 17:51:34.824 : -133--> roundabout_111_00.jpg | 30.40dB
25-05-18 17:51:35.029 : -134--> roundabout_111_01.jpg | 32.02dB
25-05-18 17:51:35.238 : -135--> roundabout_111_10.jpg | 30.33dB
25-05-18 17:51:35.422 : -136--> roundabout_111_11.jpg | 30.67dB
25-05-18 17:51:35.606 : -137--> runway_111_00.jpg | 36.36dB
25-05-18 17:51:35.798 : -138--> runway_111_01.jpg | 35.71dB
25-05-18 17:51:35.995 : -139--> runway_111_10.jpg | 36.43dB
25-05-18 17:51:36.175 : -140--> runway_111_11.jpg | 37.33dB
25-05-18 17:51:36.369 : -141--> sea_ice_111_00.jpg | 33.57dB
25-05-18 17:51:36.556 : -142--> sea_ice_111_01.jpg | 34.59dB
25-05-18 17:51:36.734 : -143--> sea_ice_111_10.jpg | 33.57dB
25-05-18 17:51:36.935 : -144--> sea_ice_111_11.jpg | 34.59dB
25-05-18 17:51:37.112 : -145--> ship_111_00.jpg | 38.45dB
25-05-18 17:51:37.296 : -146--> ship_111_01.jpg | 34.47dB
25-05-18 17:51:37.492 : -147--> ship_111_10.jpg | 42.61dB
25-05-18 17:51:37.674 : -148--> ship_111_11.jpg | 39.92dB
25-05-18 17:51:37.857 : -149--> snowberg_111_00.jpg | 34.11dB
25-05-18 17:51:38.051 : -150--> snowberg_111_01.jpg | 32.69dB
25-05-18 17:51:38.232 : -151--> snowberg_111_10.jpg | 31.91dB
25-05-18 17:51:38.415 : -152--> snowberg_111_11.jpg | 31.93dB
25-05-18 17:51:38.604 : -153--> sparse_residential_111_00.jpg | 30.39dB
25-05-18 17:51:38.788 : -154--> sparse_residential_111_01.jpg | 30.67dB
25-05-18 17:51:38.969 : -155--> sparse_residential_111_10.jpg | 29.69dB
25-05-18 17:51:39.165 : -156--> sparse_residential_111_11.jpg | 30.00dB
25-05-18 17:51:39.344 : -157--> stadium_111_00.jpg | 30.17dB
25-05-18 17:51:39.532 : -158--> stadium_111_01.jpg | 30.05dB
25-05-18 17:51:39.737 : -159--> stadium_111_10.jpg | 31.35dB
25-05-18 17:51:39.926 : -160--> stadium_111_11.jpg | 30.14dB
25-05-18 17:51:40.114 : -161--> storage_tank_111_00.jpg | 31.81dB
25-05-18 17:51:40.308 : -162--> storage_tank_111_01.jpg | 31.98dB
25-05-18 17:51:40.491 : -163--> storage_tank_111_10.jpg | 30.76dB
25-05-18 17:51:40.675 : -164--> storage_tank_111_11.jpg | 31.22dB
25-05-18 17:51:40.865 : -165--> tennis_court_111_00.jpg | 31.93dB
25-05-18 17:51:41.054 : -166--> tennis_court_111_01.jpg | 31.47dB
25-05-18 17:51:41.244 : -167--> tennis_court_111_10.jpg | 31.66dB
25-05-18 17:51:41.459 : -168--> tennis_court_111_11.jpg | 29.59dB
25-05-18 17:51:41.635 : -169--> terrace_111_00.jpg | 32.21dB
25-05-18 17:51:41.820 : -170--> terrace_111_01.jpg | 33.29dB
25-05-18 17:51:42.014 : -171--> terrace_111_10.jpg | 32.25dB
25-05-18 17:51:42.194 : -172--> terrace_111_11.jpg | 32.29dB
25-05-18 17:51:42.375 : -173--> thermal_power_station_111_00.jpg | 30.09dB
25-05-18 17:51:42.569 : -174--> thermal_power_station_111_01.jpg | 31.62dB
25-05-18 17:51:42.754 : -175--> thermal_power_station_111_10.jpg | 29.82dB
25-05-18 17:51:42.966 : -176--> thermal_power_station_111_11.jpg | 30.44dB
25-05-18 17:51:43.144 : -177--> wetland_111_00.jpg | 31.35dB
25-05-18 17:51:43.325 : -178--> wetland_111_01.jpg | 31.38dB
25-05-18 17:51:43.524 : -179--> wetland_111_10.jpg | 31.62dB
25-05-18 17:51:43.723 : -180--> wetland_111_11.jpg | 30.94dB
25-05-18 17:51:43.732 : <epoch:  0, iter:  20,000, Average PSNR : 32.10dB

25-05-18 21:37:32.953 : <epoch:  0, iter:  25,000, lr:1.000e-04> G_loss: 1.157e-04 
25-05-18 21:37:32.956 : Saving the model.
25-05-18 21:37:33.763 : ---1--> airplane_111_00.jpg | 30.39dB
25-05-18 21:37:33.939 : ---2--> airplane_111_01.jpg | 35.28dB
25-05-18 21:37:34.114 : ---3--> airplane_111_10.jpg | 32.84dB
25-05-18 21:37:34.295 : ---4--> airplane_111_11.jpg | 32.90dB
25-05-18 21:37:34.472 : ---5--> airport_111_00.jpg | 34.46dB
25-05-18 21:37:34.645 : ---6--> airport_111_01.jpg | 32.33dB
25-05-18 21:37:34.825 : ---7--> airport_111_10.jpg | 31.87dB
25-05-18 21:37:35.002 : ---8--> airport_111_11.jpg | 32.86dB
25-05-18 21:37:35.188 : ---9--> baseball_diamond_111_00.jpg | 32.66dB
25-05-18 21:37:35.364 : --10--> baseball_diamond_111_01.jpg | 34.26dB
25-05-18 21:37:35.544 : --11--> baseball_diamond_111_10.jpg | 32.52dB
25-05-18 21:37:35.720 : --12--> baseball_diamond_111_11.jpg | 35.35dB
25-05-18 21:37:35.900 : --13--> basketball_court_111_00.jpg | 30.51dB
25-05-18 21:37:36.074 : --14--> basketball_court_111_01.jpg | 30.09dB
25-05-18 21:37:36.251 : --15--> basketball_court_111_10.jpg | 33.33dB
25-05-18 21:37:36.431 : --16--> basketball_court_111_11.jpg | 31.59dB
25-05-18 21:37:36.615 : --17--> beach_111_00.jpg | 28.58dB
25-05-18 21:37:36.794 : --18--> beach_111_01.jpg | 31.73dB
25-05-18 21:37:36.975 : --19--> beach_111_10.jpg | 29.73dB
25-05-18 21:37:37.152 : --20--> beach_111_11.jpg | 34.36dB
25-05-18 21:37:37.331 : --21--> bridge_111_00.jpg | 40.74dB
25-05-18 21:37:37.508 : --22--> bridge_111_01.jpg | 34.29dB
25-05-18 21:37:37.685 : --23--> bridge_111_10.jpg | 33.16dB
25-05-18 21:37:37.867 : --24--> bridge_111_11.jpg | 36.58dB
25-05-18 21:37:38.045 : --25--> chaparral_111_00.jpg | 30.27dB
25-05-18 21:37:38.224 : --26--> chaparral_111_01.jpg | 30.55dB
25-05-18 21:37:38.405 : --27--> chaparral_111_10.jpg | 30.82dB
25-05-18 21:37:38.580 : --28--> chaparral_111_11.jpg | 28.66dB
25-05-18 21:37:38.763 : --29--> church_111_00.jpg | 31.58dB
25-05-18 21:37:38.939 : --30--> church_111_01.jpg | 30.57dB
25-05-18 21:37:39.122 : --31--> church_111_10.jpg | 34.38dB
25-05-18 21:37:39.297 : --32--> church_111_11.jpg | 30.39dB
25-05-18 21:37:39.478 : --33--> circular_farmland_111_00.jpg | 32.75dB
25-05-18 21:37:39.654 : --34--> circular_farmland_111_01.jpg | 33.82dB
25-05-18 21:37:39.834 : --35--> circular_farmland_111_10.jpg | 33.97dB
25-05-18 21:37:40.012 : --36--> circular_farmland_111_11.jpg | 34.11dB
25-05-18 21:37:40.194 : --37--> cloud_111_00.jpg | 40.95dB
25-05-18 21:37:40.374 : --38--> cloud_111_01.jpg | 36.72dB
25-05-18 21:37:40.557 : --39--> cloud_111_10.jpg | 36.30dB
25-05-18 21:37:40.734 : --40--> cloud_111_11.jpg | 36.78dB
25-05-18 21:37:40.913 : --41--> commercial_area_111_00.jpg | 33.29dB
25-05-18 21:37:41.090 : --42--> commercial_area_111_01.jpg | 32.33dB
25-05-18 21:37:41.275 : --43--> commercial_area_111_10.jpg | 33.09dB
25-05-18 21:37:41.449 : --44--> commercial_area_111_11.jpg | 32.97dB
25-05-18 21:37:41.633 : --45--> dense_residential_111_00.jpg | 30.11dB
25-05-18 21:37:41.809 : --46--> dense_residential_111_01.jpg | 29.21dB
25-05-18 21:37:41.994 : --47--> dense_residential_111_10.jpg | 29.62dB
25-05-18 21:37:42.170 : --48--> dense_residential_111_11.jpg | 29.49dB
25-05-18 21:37:42.352 : --49--> desert_111_00.jpg | 36.84dB
25-05-18 21:37:42.527 : --50--> desert_111_01.jpg | 36.73dB
25-05-18 21:37:42.709 : --51--> desert_111_10.jpg | 36.88dB
25-05-18 21:37:42.884 : --52--> desert_111_11.jpg | 37.02dB
25-05-18 21:37:43.065 : --53--> forest_111_00.jpg | 32.98dB
25-05-18 21:37:43.244 : --54--> forest_111_01.jpg | 32.07dB
25-05-18 21:37:43.424 : --55--> forest_111_10.jpg | 31.70dB
25-05-18 21:37:43.603 : --56--> forest_111_11.jpg | 32.63dB
25-05-18 21:37:43.785 : --57--> freeway_111_00.jpg | 33.81dB
25-05-18 21:37:43.962 : --58--> freeway_111_01.jpg | 34.86dB
25-05-18 21:37:44.137 : --59--> freeway_111_10.jpg | 34.69dB
25-05-18 21:37:44.319 : --60--> freeway_111_11.jpg | 34.74dB
25-05-18 21:37:44.494 : --61--> golf_course_111_00.jpg | 32.70dB
25-05-18 21:37:44.675 : --62--> golf_course_111_01.jpg | 32.05dB
25-05-18 21:37:44.852 : --63--> golf_course_111_10.jpg | 33.48dB
25-05-18 21:37:45.032 : --64--> golf_course_111_11.jpg | 33.87dB
25-05-18 21:37:45.211 : --65--> ground_track_field_111_00.jpg | 33.26dB
25-05-18 21:37:45.390 : --66--> ground_track_field_111_01.jpg | 29.35dB
25-05-18 21:37:45.564 : --67--> ground_track_field_111_10.jpg | 30.73dB
25-05-18 21:37:45.743 : --68--> ground_track_field_111_11.jpg | 29.95dB
25-05-18 21:37:45.923 : --69--> harbor_111_00.jpg | 32.82dB
25-05-18 21:37:46.101 : --70--> harbor_111_01.jpg | 31.13dB
25-05-18 21:37:46.281 : --71--> harbor_111_10.jpg | 30.72dB
25-05-18 21:37:46.457 : --72--> harbor_111_11.jpg | 32.38dB
25-05-18 21:37:46.633 : --73--> industrial_area_111_00.jpg | 31.52dB
25-05-18 21:37:46.812 : --74--> industrial_area_111_01.jpg | 31.75dB
25-05-18 21:37:46.989 : --75--> industrial_area_111_10.jpg | 31.86dB
25-05-18 21:37:47.167 : --76--> industrial_area_111_11.jpg | 31.30dB
25-05-18 21:37:47.347 : --77--> intersection_111_00.jpg | 30.56dB
25-05-18 21:37:47.524 : --78--> intersection_111_01.jpg | 30.69dB
25-05-18 21:37:47.703 : --79--> intersection_111_10.jpg | 30.43dB
25-05-18 21:37:47.880 : --80--> intersection_111_11.jpg | 30.19dB
25-05-18 21:37:48.058 : --81--> island_111_00.jpg | 31.38dB
25-05-18 21:37:48.237 : --82--> island_111_01.jpg | 33.78dB
25-05-18 21:37:48.414 : --83--> island_111_10.jpg | 32.42dB
25-05-18 21:37:48.596 : --84--> island_111_11.jpg | 32.01dB
25-05-18 21:37:48.773 : --85--> lake_111_00.jpg | 32.45dB
25-05-18 21:37:48.951 : --86--> lake_111_01.jpg | 32.28dB
25-05-18 21:37:49.128 : --87--> lake_111_10.jpg | 31.59dB
25-05-18 21:37:49.311 : --88--> lake_111_11.jpg | 31.02dB
25-05-18 21:37:49.488 : --89--> meadow_111_00.jpg | 30.02dB
25-05-18 21:37:49.672 : --90--> meadow_111_01.jpg | 30.13dB
25-05-18 21:37:49.846 : --91--> meadow_111_10.jpg | 30.17dB
25-05-18 21:37:50.022 : --92--> meadow_111_11.jpg | 30.32dB
25-05-18 21:37:50.205 : --93--> medium_residential_111_00.jpg | 28.68dB
25-05-18 21:37:50.383 : --94--> medium_residential_111_01.jpg | 28.15dB
25-05-18 21:37:50.560 : --95--> medium_residential_111_10.jpg | 28.49dB
25-05-18 21:37:50.736 : --96--> medium_residential_111_11.jpg | 29.02dB
25-05-18 21:37:50.913 : --97--> mobile_home_park_111_00.jpg | 30.93dB
25-05-18 21:37:51.091 : --98--> mobile_home_park_111_01.jpg | 31.36dB
25-05-18 21:37:51.267 : --99--> mobile_home_park_111_10.jpg | 31.70dB
25-05-18 21:37:51.444 : -100--> mobile_home_park_111_11.jpg | 31.76dB
25-05-18 21:37:51.620 : -101--> mountain_111_00.jpg | 28.86dB
25-05-18 21:37:51.799 : -102--> mountain_111_01.jpg | 29.52dB
25-05-18 21:37:51.976 : -103--> mountain_111_10.jpg | 29.31dB
25-05-18 21:37:52.157 : -104--> mountain_111_11.jpg | 29.64dB
25-05-18 21:37:52.338 : -105--> overpass_111_00.jpg | 30.07dB
25-05-18 21:37:52.514 : -106--> overpass_111_01.jpg | 29.96dB
25-05-18 21:37:52.691 : -107--> overpass_111_10.jpg | 30.54dB
25-05-18 21:37:52.867 : -108--> overpass_111_11.jpg | 31.33dB
25-05-18 21:37:53.050 : -109--> palace_111_00.jpg | 29.97dB
25-05-18 21:37:53.231 : -110--> palace_111_01.jpg | 29.78dB
25-05-18 21:37:53.409 : -111--> palace_111_10.jpg | 31.00dB
25-05-18 21:37:53.590 : -112--> palace_111_11.jpg | 29.35dB
25-05-18 21:37:53.767 : -113--> parking_lot_111_00.jpg | 29.28dB
25-05-18 21:37:53.945 : -114--> parking_lot_111_01.jpg | 29.55dB
25-05-18 21:37:54.126 : -115--> parking_lot_111_10.jpg | 31.09dB
25-05-18 21:37:54.302 : -116--> parking_lot_111_11.jpg | 29.97dB
25-05-18 21:37:54.485 : -117--> railway_111_00.jpg | 30.10dB
25-05-18 21:37:54.663 : -118--> railway_111_01.jpg | 29.65dB
25-05-18 21:37:54.845 : -119--> railway_111_10.jpg | 32.42dB
25-05-18 21:37:55.027 : -120--> railway_111_11.jpg | 29.01dB
25-05-18 21:37:55.203 : -121--> railway_station_111_00.jpg | 30.79dB
25-05-18 21:37:55.386 : -122--> railway_station_111_01.jpg | 31.30dB
25-05-18 21:37:55.563 : -123--> railway_station_111_10.jpg | 30.98dB
25-05-18 21:37:55.743 : -124--> railway_station_111_11.jpg | 31.48dB
25-05-18 21:37:55.922 : -125--> rectangular_farmland_111_00.jpg | 33.33dB
25-05-18 21:37:56.106 : -126--> rectangular_farmland_111_01.jpg | 31.80dB
25-05-18 21:37:56.282 : -127--> rectangular_farmland_111_10.jpg | 33.73dB
25-05-18 21:37:56.460 : -128--> rectangular_farmland_111_11.jpg | 34.00dB
25-05-18 21:37:56.640 : -129--> river_111_00.jpg | 30.10dB
25-05-18 21:37:56.816 : -130--> river_111_01.jpg | 29.96dB
25-05-18 21:37:56.994 : -131--> river_111_10.jpg | 29.44dB
25-05-18 21:37:57.171 : -132--> river_111_11.jpg | 31.27dB
25-05-18 21:37:57.353 : -133--> roundabout_111_00.jpg | 30.41dB
25-05-18 21:37:57.530 : -134--> roundabout_111_01.jpg | 32.04dB
25-05-18 21:37:57.708 : -135--> roundabout_111_10.jpg | 30.34dB
25-05-18 21:37:57.885 : -136--> roundabout_111_11.jpg | 30.67dB
25-05-18 21:37:58.065 : -137--> runway_111_00.jpg | 36.36dB
25-05-18 21:37:58.242 : -138--> runway_111_01.jpg | 35.70dB
25-05-18 21:37:58.422 : -139--> runway_111_10.jpg | 36.41dB
25-05-18 21:37:58.599 : -140--> runway_111_11.jpg | 37.28dB
25-05-18 21:37:58.779 : -141--> sea_ice_111_00.jpg | 33.56dB
25-05-18 21:37:58.959 : -142--> sea_ice_111_01.jpg | 34.57dB
25-05-18 21:37:59.136 : -143--> sea_ice_111_10.jpg | 33.52dB
25-05-18 21:37:59.314 : -144--> sea_ice_111_11.jpg | 34.61dB
25-05-18 21:37:59.493 : -145--> ship_111_00.jpg | 38.48dB
25-05-18 21:37:59.669 : -146--> ship_111_01.jpg | 34.45dB
25-05-18 21:37:59.845 : -147--> ship_111_10.jpg | 42.56dB
25-05-18 21:38:00.024 : -148--> ship_111_11.jpg | 39.95dB
25-05-18 21:38:00.205 : -149--> snowberg_111_00.jpg | 34.14dB
25-05-18 21:38:00.384 : -150--> snowberg_111_01.jpg | 32.72dB
25-05-18 21:38:00.563 : -151--> snowberg_111_10.jpg | 31.92dB
25-05-18 21:38:00.743 : -152--> snowberg_111_11.jpg | 31.94dB
25-05-18 21:38:00.922 : -153--> sparse_residential_111_00.jpg | 30.42dB
25-05-18 21:38:01.099 : -154--> sparse_residential_111_01.jpg | 30.66dB
25-05-18 21:38:01.279 : -155--> sparse_residential_111_10.jpg | 29.70dB
25-05-18 21:38:01.458 : -156--> sparse_residential_111_11.jpg | 30.01dB
25-05-18 21:38:01.638 : -157--> stadium_111_00.jpg | 30.17dB
25-05-18 21:38:01.815 : -158--> stadium_111_01.jpg | 30.04dB
25-05-18 21:38:01.994 : -159--> stadium_111_10.jpg | 31.34dB
25-05-18 21:38:02.175 : -160--> stadium_111_11.jpg | 30.14dB
25-05-18 21:38:02.357 : -161--> storage_tank_111_00.jpg | 31.84dB
25-05-18 21:38:02.535 : -162--> storage_tank_111_01.jpg | 31.98dB
25-05-18 21:38:02.712 : -163--> storage_tank_111_10.jpg | 30.78dB
25-05-18 21:38:02.891 : -164--> storage_tank_111_11.jpg | 31.24dB
25-05-18 21:38:03.068 : -165--> tennis_court_111_00.jpg | 31.94dB
25-05-18 21:38:03.249 : -166--> tennis_court_111_01.jpg | 31.48dB
25-05-18 21:38:03.426 : -167--> tennis_court_111_10.jpg | 31.65dB
25-05-18 21:38:03.604 : -168--> tennis_court_111_11.jpg | 29.61dB
25-05-18 21:38:03.782 : -169--> terrace_111_00.jpg | 32.23dB
25-05-18 21:38:03.957 : -170--> terrace_111_01.jpg | 33.28dB
25-05-18 21:38:04.133 : -171--> terrace_111_10.jpg | 32.24dB
25-05-18 21:38:04.311 : -172--> terrace_111_11.jpg | 32.29dB
25-05-18 21:38:04.487 : -173--> thermal_power_station_111_00.jpg | 30.09dB
25-05-18 21:38:04.666 : -174--> thermal_power_station_111_01.jpg | 31.64dB
25-05-18 21:38:04.843 : -175--> thermal_power_station_111_10.jpg | 29.86dB
25-05-18 21:38:05.023 : -176--> thermal_power_station_111_11.jpg | 30.41dB
25-05-18 21:38:05.203 : -177--> wetland_111_00.jpg | 31.35dB
25-05-18 21:38:05.385 : -178--> wetland_111_01.jpg | 31.38dB
25-05-18 21:38:05.565 : -179--> wetland_111_10.jpg | 31.62dB
25-05-18 21:38:05.744 : -180--> wetland_111_11.jpg | 30.97dB
25-05-18 21:38:05.757 : <epoch:  0, iter:  25,000, Average PSNR : 32.11dB

25-05-19 01:24:05.685 : <epoch:  0, iter:  30,000, lr:2.500e-05> G_loss: 7.432e-05 
25-05-19 01:24:05.687 : Saving the model.
25-05-19 01:24:06.512 : ---1--> airplane_111_00.jpg | 30.39dB
25-05-19 01:24:06.695 : ---2--> airplane_111_01.jpg | 35.27dB
25-05-19 01:24:06.874 : ---3--> airplane_111_10.jpg | 32.81dB
25-05-19 01:24:07.057 : ---4--> airplane_111_11.jpg | 32.86dB
25-05-19 01:24:07.246 : ---5--> airport_111_00.jpg | 34.44dB
25-05-19 01:24:07.423 : ---6--> airport_111_01.jpg | 32.32dB
25-05-19 01:24:07.602 : ---7--> airport_111_10.jpg | 31.88dB
25-05-19 01:24:07.798 : ---8--> airport_111_11.jpg | 32.87dB
25-05-19 01:24:07.982 : ---9--> baseball_diamond_111_00.jpg | 32.66dB
25-05-19 01:24:08.177 : --10--> baseball_diamond_111_01.jpg | 34.29dB
25-05-19 01:24:08.352 : --11--> baseball_diamond_111_10.jpg | 32.51dB
25-05-19 01:24:08.531 : --12--> baseball_diamond_111_11.jpg | 35.33dB
25-05-19 01:24:08.707 : --13--> basketball_court_111_00.jpg | 30.54dB
25-05-19 01:24:08.889 : --14--> basketball_court_111_01.jpg | 30.10dB
25-05-19 01:24:09.078 : --15--> basketball_court_111_10.jpg | 33.34dB
25-05-19 01:24:09.263 : --16--> basketball_court_111_11.jpg | 31.61dB
25-05-19 01:24:09.449 : --17--> beach_111_00.jpg | 28.57dB
25-05-19 01:24:09.634 : --18--> beach_111_01.jpg | 31.72dB
25-05-19 01:24:09.831 : --19--> beach_111_10.jpg | 29.74dB
25-05-19 01:24:10.017 : --20--> beach_111_11.jpg | 34.37dB
25-05-19 01:24:10.198 : --21--> bridge_111_00.jpg | 40.70dB
25-05-19 01:24:10.392 : --22--> bridge_111_01.jpg | 34.30dB
25-05-19 01:24:10.577 : --23--> bridge_111_10.jpg | 33.19dB
25-05-19 01:24:10.762 : --24--> bridge_111_11.jpg | 36.60dB
25-05-19 01:24:10.956 : --25--> chaparral_111_00.jpg | 30.28dB
25-05-19 01:24:11.138 : --26--> chaparral_111_01.jpg | 30.52dB
25-05-19 01:24:11.316 : --27--> chaparral_111_10.jpg | 30.85dB
25-05-19 01:24:11.515 : --28--> chaparral_111_11.jpg | 28.66dB
25-05-19 01:24:11.697 : --29--> church_111_00.jpg | 31.59dB
25-05-19 01:24:11.875 : --30--> church_111_01.jpg | 30.57dB
25-05-19 01:24:12.071 : --31--> church_111_10.jpg | 34.33dB
25-05-19 01:24:12.253 : --32--> church_111_11.jpg | 30.38dB
25-05-19 01:24:12.437 : --33--> circular_farmland_111_00.jpg | 32.76dB
25-05-19 01:24:12.640 : --34--> circular_farmland_111_01.jpg | 33.78dB
25-05-19 01:24:12.825 : --35--> circular_farmland_111_10.jpg | 33.92dB
25-05-19 01:24:13.013 : --36--> circular_farmland_111_11.jpg | 34.08dB
25-05-19 01:24:13.210 : --37--> cloud_111_00.jpg | 40.93dB
25-05-19 01:24:13.398 : --38--> cloud_111_01.jpg | 36.77dB
25-05-19 01:24:13.582 : --39--> cloud_111_10.jpg | 36.29dB
25-05-19 01:24:13.775 : --40--> cloud_111_11.jpg | 36.79dB
25-05-19 01:24:13.964 : --41--> commercial_area_111_00.jpg | 33.31dB
25-05-19 01:24:14.150 : --42--> commercial_area_111_01.jpg | 32.34dB
25-05-19 01:24:14.350 : --43--> commercial_area_111_10.jpg | 33.09dB
25-05-19 01:24:14.532 : --44--> commercial_area_111_11.jpg | 32.98dB
25-05-19 01:24:14.714 : --45--> dense_residential_111_00.jpg | 30.12dB
25-05-19 01:24:14.912 : --46--> dense_residential_111_01.jpg | 29.22dB
25-05-19 01:24:15.094 : --47--> dense_residential_111_10.jpg | 29.63dB
25-05-19 01:24:15.277 : --48--> dense_residential_111_11.jpg | 29.50dB
25-05-19 01:24:15.475 : --49--> desert_111_00.jpg | 36.83dB
25-05-19 01:24:15.660 : --50--> desert_111_01.jpg | 36.64dB
25-05-19 01:24:15.847 : --51--> desert_111_10.jpg | 36.83dB
25-05-19 01:24:16.040 : --52--> desert_111_11.jpg | 36.92dB
25-05-19 01:24:16.224 : --53--> forest_111_00.jpg | 32.97dB
25-05-19 01:24:16.403 : --54--> forest_111_01.jpg | 32.09dB
25-05-19 01:24:16.596 : --55--> forest_111_10.jpg | 31.72dB
25-05-19 01:24:16.778 : --56--> forest_111_11.jpg | 32.64dB
25-05-19 01:24:16.965 : --57--> freeway_111_00.jpg | 33.79dB
25-05-19 01:24:17.165 : --58--> freeway_111_01.jpg | 34.86dB
25-05-19 01:24:17.354 : --59--> freeway_111_10.jpg | 34.70dB
25-05-19 01:24:17.536 : --60--> freeway_111_11.jpg | 34.75dB
25-05-19 01:24:17.731 : --61--> golf_course_111_00.jpg | 32.70dB
25-05-19 01:24:17.914 : --62--> golf_course_111_01.jpg | 32.08dB
25-05-19 01:24:18.098 : --63--> golf_course_111_10.jpg | 33.49dB
25-05-19 01:24:18.291 : --64--> golf_course_111_11.jpg | 33.85dB
25-05-19 01:24:18.473 : --65--> ground_track_field_111_00.jpg | 33.26dB
25-05-19 01:24:18.670 : --66--> ground_track_field_111_01.jpg | 29.36dB
25-05-19 01:24:18.854 : --67--> ground_track_field_111_10.jpg | 30.72dB
25-05-19 01:24:19.035 : --68--> ground_track_field_111_11.jpg | 29.95dB
25-05-19 01:24:19.227 : --69--> harbor_111_00.jpg | 32.83dB
25-05-19 01:24:19.412 : --70--> harbor_111_01.jpg | 31.13dB
25-05-19 01:24:19.595 : --71--> harbor_111_10.jpg | 30.71dB
25-05-19 01:24:19.796 : --72--> harbor_111_11.jpg | 32.39dB
25-05-19 01:24:19.983 : --73--> industrial_area_111_00.jpg | 31.53dB
25-05-19 01:24:20.160 : --74--> industrial_area_111_01.jpg | 31.75dB
25-05-19 01:24:20.360 : --75--> industrial_area_111_10.jpg | 31.88dB
25-05-19 01:24:20.544 : --76--> industrial_area_111_11.jpg | 31.30dB
25-05-19 01:24:20.726 : --77--> intersection_111_00.jpg | 30.57dB
25-05-19 01:24:20.916 : --78--> intersection_111_01.jpg | 30.72dB
25-05-19 01:24:21.104 : --79--> intersection_111_10.jpg | 30.41dB
25-05-19 01:24:21.285 : --80--> intersection_111_11.jpg | 30.19dB
25-05-19 01:24:21.486 : --81--> island_111_00.jpg | 31.35dB
25-05-19 01:24:21.670 : --82--> island_111_01.jpg | 33.80dB
25-05-19 01:24:21.857 : --83--> island_111_10.jpg | 32.43dB
25-05-19 01:24:22.051 : --84--> island_111_11.jpg | 32.01dB
25-05-19 01:24:22.235 : --85--> lake_111_00.jpg | 32.47dB
25-05-19 01:24:22.423 : --86--> lake_111_01.jpg | 32.26dB
25-05-19 01:24:22.624 : --87--> lake_111_10.jpg | 31.58dB
25-05-19 01:24:22.805 : --88--> lake_111_11.jpg | 31.01dB
25-05-19 01:24:22.982 : --89--> meadow_111_00.jpg | 30.02dB
25-05-19 01:24:23.164 : --90--> meadow_111_01.jpg | 30.15dB
25-05-19 01:24:23.350 : --91--> meadow_111_10.jpg | 30.17dB
25-05-19 01:24:23.537 : --92--> meadow_111_11.jpg | 30.33dB
25-05-19 01:24:23.732 : --93--> medium_residential_111_00.jpg | 28.68dB
25-05-19 01:24:23.915 : --94--> medium_residential_111_01.jpg | 28.13dB
25-05-19 01:24:24.102 : --95--> medium_residential_111_10.jpg | 28.46dB
25-05-19 01:24:24.283 : --96--> medium_residential_111_11.jpg | 29.02dB
25-05-19 01:24:24.464 : --97--> mobile_home_park_111_00.jpg | 30.92dB
25-05-19 01:24:24.647 : --98--> mobile_home_park_111_01.jpg | 31.40dB
25-05-19 01:24:24.841 : --99--> mobile_home_park_111_10.jpg | 31.72dB
25-05-19 01:24:25.025 : -100--> mobile_home_park_111_11.jpg | 31.78dB
25-05-19 01:24:25.200 : -101--> mountain_111_00.jpg | 28.84dB
25-05-19 01:24:25.395 : -102--> mountain_111_01.jpg | 29.52dB
25-05-19 01:24:25.584 : -103--> mountain_111_10.jpg | 29.29dB
25-05-19 01:24:25.774 : -104--> mountain_111_11.jpg | 29.62dB
25-05-19 01:24:25.974 : -105--> overpass_111_00.jpg | 30.07dB
25-05-19 01:24:26.156 : -106--> overpass_111_01.jpg | 29.96dB
25-05-19 01:24:26.335 : -107--> overpass_111_10.jpg | 30.54dB
25-05-19 01:24:26.520 : -108--> overpass_111_11.jpg | 31.32dB
25-05-19 01:24:26.711 : -109--> palace_111_00.jpg | 29.98dB
25-05-19 01:24:26.894 : -110--> palace_111_01.jpg | 29.79dB
25-05-19 01:24:27.083 : -111--> palace_111_10.jpg | 31.00dB
25-05-19 01:24:27.266 : -112--> palace_111_11.jpg | 29.36dB
25-05-19 01:24:27.460 : -113--> parking_lot_111_00.jpg | 29.24dB
25-05-19 01:24:27.647 : -114--> parking_lot_111_01.jpg | 29.55dB
25-05-19 01:24:27.834 : -115--> parking_lot_111_10.jpg | 31.10dB
25-05-19 01:24:28.027 : -116--> parking_lot_111_11.jpg | 29.95dB
25-05-19 01:24:28.207 : -117--> railway_111_00.jpg | 30.11dB
25-05-19 01:24:28.391 : -118--> railway_111_01.jpg | 29.64dB
25-05-19 01:24:28.585 : -119--> railway_111_10.jpg | 32.42dB
25-05-19 01:24:28.767 : -120--> railway_111_11.jpg | 29.03dB
25-05-19 01:24:28.946 : -121--> railway_station_111_00.jpg | 30.80dB
25-05-19 01:24:29.145 : -122--> railway_station_111_01.jpg | 31.30dB
25-05-19 01:24:29.334 : -123--> railway_station_111_10.jpg | 30.99dB
25-05-19 01:24:29.518 : -124--> railway_station_111_11.jpg | 31.51dB
25-05-19 01:24:29.711 : -125--> rectangular_farmland_111_00.jpg | 33.36dB
25-05-19 01:24:29.895 : -126--> rectangular_farmland_111_01.jpg | 31.82dB
25-05-19 01:24:30.082 : -127--> rectangular_farmland_111_10.jpg | 33.73dB
25-05-19 01:24:30.276 : -128--> rectangular_farmland_111_11.jpg | 34.00dB
25-05-19 01:24:30.455 : -129--> river_111_00.jpg | 30.11dB
25-05-19 01:24:30.639 : -130--> river_111_01.jpg | 29.96dB
25-05-19 01:24:30.834 : -131--> river_111_10.jpg | 29.44dB
25-05-19 01:24:31.011 : -132--> river_111_11.jpg | 31.31dB
25-05-19 01:24:31.191 : -133--> roundabout_111_00.jpg | 30.40dB
25-05-19 01:24:31.388 : -134--> roundabout_111_01.jpg | 31.99dB
25-05-19 01:24:31.571 : -135--> roundabout_111_10.jpg | 30.33dB
25-05-19 01:24:31.751 : -136--> roundabout_111_11.jpg | 30.68dB
25-05-19 01:24:31.945 : -137--> runway_111_00.jpg | 36.37dB
25-05-19 01:24:32.129 : -138--> runway_111_01.jpg | 35.74dB
25-05-19 01:24:32.307 : -139--> runway_111_10.jpg | 36.41dB
25-05-19 01:24:32.504 : -140--> runway_111_11.jpg | 37.37dB
25-05-19 01:24:32.685 : -141--> sea_ice_111_00.jpg | 33.57dB
25-05-19 01:24:32.864 : -142--> sea_ice_111_01.jpg | 34.60dB
25-05-19 01:24:33.066 : -143--> sea_ice_111_10.jpg | 33.54dB
25-05-19 01:24:33.249 : -144--> sea_ice_111_11.jpg | 34.62dB
25-05-19 01:24:33.430 : -145--> ship_111_00.jpg | 38.51dB
25-05-19 01:24:33.625 : -146--> ship_111_01.jpg | 34.48dB
25-05-19 01:24:33.804 : -147--> ship_111_10.jpg | 42.61dB
25-05-19 01:24:33.984 : -148--> ship_111_11.jpg | 39.93dB
25-05-19 01:24:34.179 : -149--> snowberg_111_00.jpg | 34.08dB
25-05-19 01:24:34.362 : -150--> snowberg_111_01.jpg | 32.72dB
25-05-19 01:24:34.546 : -151--> snowberg_111_10.jpg | 31.94dB
25-05-19 01:24:34.738 : -152--> snowberg_111_11.jpg | 31.96dB
25-05-19 01:24:34.923 : -153--> sparse_residential_111_00.jpg | 30.41dB
25-05-19 01:24:35.106 : -154--> sparse_residential_111_01.jpg | 30.68dB
25-05-19 01:24:35.294 : -155--> sparse_residential_111_10.jpg | 29.71dB
25-05-19 01:24:35.474 : -156--> sparse_residential_111_11.jpg | 30.01dB
25-05-19 01:24:35.655 : -157--> stadium_111_00.jpg | 30.20dB
25-05-19 01:24:35.858 : -158--> stadium_111_01.jpg | 30.06dB
25-05-19 01:24:36.035 : -159--> stadium_111_10.jpg | 31.37dB
25-05-19 01:24:36.220 : -160--> stadium_111_11.jpg | 30.15dB
25-05-19 01:24:36.407 : -161--> storage_tank_111_00.jpg | 31.81dB
25-05-19 01:24:36.593 : -162--> storage_tank_111_01.jpg | 31.99dB
25-05-19 01:24:36.773 : -163--> storage_tank_111_10.jpg | 30.76dB
25-05-19 01:24:36.961 : -164--> storage_tank_111_11.jpg | 31.24dB
25-05-19 01:24:37.148 : -165--> tennis_court_111_00.jpg | 31.94dB
25-05-19 01:24:37.344 : -166--> tennis_court_111_01.jpg | 31.48dB
25-05-19 01:24:37.523 : -167--> tennis_court_111_10.jpg | 31.66dB
25-05-19 01:24:37.704 : -168--> tennis_court_111_11.jpg | 29.63dB
25-05-19 01:24:37.891 : -169--> terrace_111_00.jpg | 32.20dB
25-05-19 01:24:38.070 : -170--> terrace_111_01.jpg | 33.26dB
25-05-19 01:24:38.261 : -171--> terrace_111_10.jpg | 32.26dB
25-05-19 01:24:38.454 : -172--> terrace_111_11.jpg | 32.27dB
25-05-19 01:24:38.636 : -173--> thermal_power_station_111_00.jpg | 30.08dB
25-05-19 01:24:38.819 : -174--> thermal_power_station_111_01.jpg | 31.63dB
25-05-19 01:24:39.014 : -175--> thermal_power_station_111_10.jpg | 29.86dB
25-05-19 01:24:39.196 : -176--> thermal_power_station_111_11.jpg | 30.43dB
25-05-19 01:24:39.380 : -177--> wetland_111_00.jpg | 31.35dB
25-05-19 01:24:39.584 : -178--> wetland_111_01.jpg | 31.39dB
25-05-19 01:24:39.769 : -179--> wetland_111_10.jpg | 31.61dB
25-05-19 01:24:39.958 : -180--> wetland_111_11.jpg | 30.96dB
25-05-19 01:24:39.970 : <epoch:  0, iter:  30,000, Average PSNR : 32.11dB

25-05-19 05:12:58.078 : <epoch:  1, iter:  35,000, lr:5.000e-05> G_loss: 5.007e-05 
25-05-19 05:12:58.079 : Saving the model.
25-05-19 05:12:58.852 : ---1--> airplane_111_00.jpg | 30.40dB
25-05-19 05:12:59.036 : ---2--> airplane_111_01.jpg | 35.31dB
25-05-19 05:12:59.221 : ---3--> airplane_111_10.jpg | 32.81dB
25-05-19 05:12:59.423 : ---4--> airplane_111_11.jpg | 32.88dB
25-05-19 05:12:59.609 : ---5--> airport_111_00.jpg | 34.44dB
25-05-19 05:12:59.805 : ---6--> airport_111_01.jpg | 32.36dB
25-05-19 05:12:59.985 : ---7--> airport_111_10.jpg | 31.88dB
25-05-19 05:13:00.168 : ---8--> airport_111_11.jpg | 32.87dB
25-05-19 05:13:00.361 : ---9--> baseball_diamond_111_00.jpg | 32.69dB
25-05-19 05:13:00.551 : --10--> baseball_diamond_111_01.jpg | 34.29dB
25-05-19 05:13:00.728 : --11--> baseball_diamond_111_10.jpg | 32.53dB
25-05-19 05:13:00.920 : --12--> baseball_diamond_111_11.jpg | 35.33dB
25-05-19 05:13:01.099 : --13--> basketball_court_111_00.jpg | 30.54dB
25-05-19 05:13:01.280 : --14--> basketball_court_111_01.jpg | 30.11dB
25-05-19 05:13:01.479 : --15--> basketball_court_111_10.jpg | 33.35dB
25-05-19 05:13:01.667 : --16--> basketball_court_111_11.jpg | 31.62dB
25-05-19 05:13:01.846 : --17--> beach_111_00.jpg | 28.59dB
25-05-19 05:13:02.056 : --18--> beach_111_01.jpg | 31.75dB
25-05-19 05:13:02.242 : --19--> beach_111_10.jpg | 29.75dB
25-05-19 05:13:02.430 : --20--> beach_111_11.jpg | 34.37dB
25-05-19 05:13:02.630 : --21--> bridge_111_00.jpg | 40.75dB
25-05-19 05:13:02.813 : --22--> bridge_111_01.jpg | 34.32dB
25-05-19 05:13:02.993 : --23--> bridge_111_10.jpg | 33.20dB
25-05-19 05:13:03.192 : --24--> bridge_111_11.jpg | 36.62dB
25-05-19 05:13:03.373 : --25--> chaparral_111_00.jpg | 30.31dB
25-05-19 05:13:03.557 : --26--> chaparral_111_01.jpg | 30.50dB
25-05-19 05:13:03.758 : --27--> chaparral_111_10.jpg | 30.88dB
25-05-19 05:13:03.945 : --28--> chaparral_111_11.jpg | 28.67dB
25-05-19 05:13:04.131 : --29--> church_111_00.jpg | 31.59dB
25-05-19 05:13:04.328 : --30--> church_111_01.jpg | 30.60dB
25-05-19 05:13:04.519 : --31--> church_111_10.jpg | 34.38dB
25-05-19 05:13:04.704 : --32--> church_111_11.jpg | 30.42dB
25-05-19 05:13:04.904 : --33--> circular_farmland_111_00.jpg | 32.76dB
25-05-19 05:13:05.091 : --34--> circular_farmland_111_01.jpg | 33.77dB
25-05-19 05:13:05.273 : --35--> circular_farmland_111_10.jpg | 33.96dB
25-05-19 05:13:05.473 : --36--> circular_farmland_111_11.jpg | 34.07dB
25-05-19 05:13:05.654 : --37--> cloud_111_00.jpg | 40.98dB
25-05-19 05:13:05.836 : --38--> cloud_111_01.jpg | 36.80dB
25-05-19 05:13:06.015 : --39--> cloud_111_10.jpg | 36.34dB
25-05-19 05:13:06.204 : --40--> cloud_111_11.jpg | 36.80dB
25-05-19 05:13:06.389 : --41--> commercial_area_111_00.jpg | 33.31dB
25-05-19 05:13:06.589 : --42--> commercial_area_111_01.jpg | 32.33dB
25-05-19 05:13:06.770 : --43--> commercial_area_111_10.jpg | 33.09dB
25-05-19 05:13:06.971 : --44--> commercial_area_111_11.jpg | 33.00dB
25-05-19 05:13:07.154 : --45--> dense_residential_111_00.jpg | 30.14dB
25-05-19 05:13:07.342 : --46--> dense_residential_111_01.jpg | 29.24dB
25-05-19 05:13:07.541 : --47--> dense_residential_111_10.jpg | 29.64dB
25-05-19 05:13:07.720 : --48--> dense_residential_111_11.jpg | 29.51dB
25-05-19 05:13:07.903 : --49--> desert_111_00.jpg | 36.86dB
25-05-19 05:13:08.100 : --50--> desert_111_01.jpg | 36.72dB
25-05-19 05:13:08.284 : --51--> desert_111_10.jpg | 36.90dB
25-05-19 05:13:08.475 : --52--> desert_111_11.jpg | 37.02dB
25-05-19 05:13:08.666 : --53--> forest_111_00.jpg | 32.97dB
25-05-19 05:13:08.856 : --54--> forest_111_01.jpg | 32.07dB
25-05-19 05:13:09.041 : --55--> forest_111_10.jpg | 31.71dB
25-05-19 05:13:09.243 : --56--> forest_111_11.jpg | 32.63dB
25-05-19 05:13:09.424 : --57--> freeway_111_00.jpg | 33.81dB
25-05-19 05:13:09.617 : --58--> freeway_111_01.jpg | 34.88dB
25-05-19 05:13:09.806 : --59--> freeway_111_10.jpg | 34.73dB
25-05-19 05:13:09.993 : --60--> freeway_111_11.jpg | 34.74dB
25-05-19 05:13:10.179 : --61--> golf_course_111_00.jpg | 32.71dB
25-05-19 05:13:10.378 : --62--> golf_course_111_01.jpg | 32.10dB
25-05-19 05:13:10.560 : --63--> golf_course_111_10.jpg | 33.49dB
25-05-19 05:13:10.747 : --64--> golf_course_111_11.jpg | 33.86dB
25-05-19 05:13:10.943 : --65--> ground_track_field_111_00.jpg | 33.32dB
25-05-19 05:13:11.126 : --66--> ground_track_field_111_01.jpg | 29.37dB
25-05-19 05:13:11.317 : --67--> ground_track_field_111_10.jpg | 30.74dB
25-05-19 05:13:11.522 : --68--> ground_track_field_111_11.jpg | 29.95dB
25-05-19 05:13:11.703 : --69--> harbor_111_00.jpg | 32.83dB
25-05-19 05:13:11.887 : --70--> harbor_111_01.jpg | 31.15dB
25-05-19 05:13:12.082 : --71--> harbor_111_10.jpg | 30.72dB
25-05-19 05:13:12.265 : --72--> harbor_111_11.jpg | 32.42dB
25-05-19 05:13:12.449 : --73--> industrial_area_111_00.jpg | 31.55dB
25-05-19 05:13:12.633 : --74--> industrial_area_111_01.jpg | 31.77dB
25-05-19 05:13:12.828 : --75--> industrial_area_111_10.jpg | 31.92dB
25-05-19 05:13:13.024 : --76--> industrial_area_111_11.jpg | 31.33dB
25-05-19 05:13:13.213 : --77--> intersection_111_00.jpg | 30.59dB
25-05-19 05:13:13.411 : --78--> intersection_111_01.jpg | 30.72dB
25-05-19 05:13:13.614 : --79--> intersection_111_10.jpg | 30.39dB
25-05-19 05:13:13.797 : --80--> intersection_111_11.jpg | 30.22dB
25-05-19 05:13:13.982 : --81--> island_111_00.jpg | 31.35dB
25-05-19 05:13:14.180 : --82--> island_111_01.jpg | 33.84dB
25-05-19 05:13:14.368 : --83--> island_111_10.jpg | 32.46dB
25-05-19 05:13:14.552 : --84--> island_111_11.jpg | 32.02dB
25-05-19 05:13:14.746 : --85--> lake_111_00.jpg | 32.48dB
25-05-19 05:13:14.929 : --86--> lake_111_01.jpg | 32.28dB
25-05-19 05:13:15.116 : --87--> lake_111_10.jpg | 31.58dB
25-05-19 05:13:15.315 : --88--> lake_111_11.jpg | 31.01dB
25-05-19 05:13:15.496 : --89--> meadow_111_00.jpg | 30.04dB
25-05-19 05:13:15.681 : --90--> meadow_111_01.jpg | 30.14dB
25-05-19 05:13:15.871 : --91--> meadow_111_10.jpg | 30.17dB
25-05-19 05:13:16.055 : --92--> meadow_111_11.jpg | 30.34dB
25-05-19 05:13:16.241 : --93--> medium_residential_111_00.jpg | 28.68dB
25-05-19 05:13:16.445 : --94--> medium_residential_111_01.jpg | 28.14dB
25-05-19 05:13:16.627 : --95--> medium_residential_111_10.jpg | 28.47dB
25-05-19 05:13:16.811 : --96--> medium_residential_111_11.jpg | 29.03dB
25-05-19 05:13:17.008 : --97--> mobile_home_park_111_00.jpg | 30.98dB
25-05-19 05:13:17.194 : --98--> mobile_home_park_111_01.jpg | 31.42dB
25-05-19 05:13:17.380 : --99--> mobile_home_park_111_10.jpg | 31.75dB
25-05-19 05:13:17.583 : -100--> mobile_home_park_111_11.jpg | 31.78dB
25-05-19 05:13:17.758 : -101--> mountain_111_00.jpg | 28.87dB
25-05-19 05:13:17.944 : -102--> mountain_111_01.jpg | 29.52dB
25-05-19 05:13:18.128 : -103--> mountain_111_10.jpg | 29.29dB
25-05-19 05:13:18.316 : -104--> mountain_111_11.jpg | 29.63dB
25-05-19 05:13:18.495 : -105--> overpass_111_00.jpg | 30.10dB
25-05-19 05:13:18.700 : -106--> overpass_111_01.jpg | 29.96dB
25-05-19 05:13:18.884 : -107--> overpass_111_10.jpg | 30.54dB
25-05-19 05:13:19.078 : -108--> overpass_111_11.jpg | 31.31dB
25-05-19 05:13:19.258 : -109--> palace_111_00.jpg | 30.01dB
25-05-19 05:13:19.452 : -110--> palace_111_01.jpg | 29.80dB
25-05-19 05:13:19.632 : -111--> palace_111_10.jpg | 30.99dB
25-05-19 05:13:19.823 : -112--> palace_111_11.jpg | 29.36dB
25-05-19 05:13:20.009 : -113--> parking_lot_111_00.jpg | 29.31dB
25-05-19 05:13:20.214 : -114--> parking_lot_111_01.jpg | 29.55dB
25-05-19 05:13:20.392 : -115--> parking_lot_111_10.jpg | 31.13dB
25-05-19 05:13:20.575 : -116--> parking_lot_111_11.jpg | 29.98dB
25-05-19 05:13:20.766 : -117--> railway_111_00.jpg | 30.11dB
25-05-19 05:13:20.947 : -118--> railway_111_01.jpg | 29.64dB
25-05-19 05:13:21.128 : -119--> railway_111_10.jpg | 32.44dB
25-05-19 05:13:21.327 : -120--> railway_111_11.jpg | 29.04dB
25-05-19 05:13:21.509 : -121--> railway_station_111_00.jpg | 30.83dB
25-05-19 05:13:21.694 : -122--> railway_station_111_01.jpg | 31.33dB
25-05-19 05:13:21.895 : -123--> railway_station_111_10.jpg | 31.00dB
25-05-19 05:13:22.084 : -124--> railway_station_111_11.jpg | 31.51dB
25-05-19 05:13:22.267 : -125--> rectangular_farmland_111_00.jpg | 33.36dB
25-05-19 05:13:22.461 : -126--> rectangular_farmland_111_01.jpg | 31.87dB
25-05-19 05:13:22.651 : -127--> rectangular_farmland_111_10.jpg | 33.75dB
25-05-19 05:13:22.839 : -128--> rectangular_farmland_111_11.jpg | 34.00dB
25-05-19 05:13:23.032 : -129--> river_111_00.jpg | 30.15dB
25-05-19 05:13:23.221 : -130--> river_111_01.jpg | 29.97dB
25-05-19 05:13:23.407 : -131--> river_111_10.jpg | 29.44dB
25-05-19 05:13:23.609 : -132--> river_111_11.jpg | 31.29dB
25-05-19 05:13:23.792 : -133--> roundabout_111_00.jpg | 30.42dB
25-05-19 05:13:23.978 : -134--> roundabout_111_01.jpg | 32.01dB
25-05-19 05:13:24.171 : -135--> roundabout_111_10.jpg | 30.33dB
25-05-19 05:13:24.369 : -136--> roundabout_111_11.jpg | 30.69dB
25-05-19 05:13:24.551 : -137--> runway_111_00.jpg | 36.36dB
25-05-19 05:13:24.754 : -138--> runway_111_01.jpg | 35.77dB
25-05-19 05:13:24.944 : -139--> runway_111_10.jpg | 36.44dB
25-05-19 05:13:25.146 : -140--> runway_111_11.jpg | 37.39dB
25-05-19 05:13:25.329 : -141--> sea_ice_111_00.jpg | 33.56dB
25-05-19 05:13:25.518 : -142--> sea_ice_111_01.jpg | 34.63dB
25-05-19 05:13:25.707 : -143--> sea_ice_111_10.jpg | 33.58dB
25-05-19 05:13:25.897 : -144--> sea_ice_111_11.jpg | 34.64dB
25-05-19 05:13:26.081 : -145--> ship_111_00.jpg | 38.51dB
25-05-19 05:13:26.292 : -146--> ship_111_01.jpg | 34.51dB
25-05-19 05:13:26.474 : -147--> ship_111_10.jpg | 42.62dB
25-05-19 05:13:26.665 : -148--> ship_111_11.jpg | 39.98dB
25-05-19 05:13:26.854 : -149--> snowberg_111_00.jpg | 34.10dB
25-05-19 05:13:27.037 : -150--> snowberg_111_01.jpg | 32.73dB
25-05-19 05:13:27.216 : -151--> snowberg_111_10.jpg | 31.95dB
25-05-19 05:13:27.415 : -152--> snowberg_111_11.jpg | 31.96dB
25-05-19 05:13:27.598 : -153--> sparse_residential_111_00.jpg | 30.42dB
25-05-19 05:13:27.788 : -154--> sparse_residential_111_01.jpg | 30.69dB
25-05-19 05:13:27.985 : -155--> sparse_residential_111_10.jpg | 29.72dB
25-05-19 05:13:28.174 : -156--> sparse_residential_111_11.jpg | 30.02dB
25-05-19 05:13:28.355 : -157--> stadium_111_00.jpg | 30.22dB
25-05-19 05:13:28.552 : -158--> stadium_111_01.jpg | 30.06dB
25-05-19 05:13:28.738 : -159--> stadium_111_10.jpg | 31.38dB
25-05-19 05:13:28.927 : -160--> stadium_111_11.jpg | 30.16dB
25-05-19 05:13:29.120 : -161--> storage_tank_111_00.jpg | 31.81dB
25-05-19 05:13:29.311 : -162--> storage_tank_111_01.jpg | 31.99dB
25-05-19 05:13:29.491 : -163--> storage_tank_111_10.jpg | 30.76dB
25-05-19 05:13:29.677 : -164--> storage_tank_111_11.jpg | 31.23dB
25-05-19 05:13:29.861 : -165--> tennis_court_111_00.jpg | 31.98dB
25-05-19 05:13:30.046 : -166--> tennis_court_111_01.jpg | 31.50dB
25-05-19 05:13:30.239 : -167--> tennis_court_111_10.jpg | 31.69dB
25-05-19 05:13:30.431 : -168--> tennis_court_111_11.jpg | 29.62dB
25-05-19 05:13:30.612 : -169--> terrace_111_00.jpg | 32.22dB
25-05-19 05:13:30.810 : -170--> terrace_111_01.jpg | 33.29dB
25-05-19 05:13:30.990 : -171--> terrace_111_10.jpg | 32.28dB
25-05-19 05:13:31.192 : -172--> terrace_111_11.jpg | 32.30dB
25-05-19 05:13:31.375 : -173--> thermal_power_station_111_00.jpg | 30.09dB
25-05-19 05:13:31.561 : -174--> thermal_power_station_111_01.jpg | 31.65dB
25-05-19 05:13:31.760 : -175--> thermal_power_station_111_10.jpg | 29.86dB
25-05-19 05:13:31.945 : -176--> thermal_power_station_111_11.jpg | 30.44dB
25-05-19 05:13:32.134 : -177--> wetland_111_00.jpg | 31.33dB
25-05-19 05:13:32.335 : -178--> wetland_111_01.jpg | 31.40dB
25-05-19 05:13:32.518 : -179--> wetland_111_10.jpg | 31.63dB
25-05-19 05:13:32.713 : -180--> wetland_111_11.jpg | 30.97dB
25-05-19 05:13:32.728 : <epoch:  1, iter:  35,000, Average PSNR : 32.12dB

25-05-19 09:52:28.473 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/35000_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 25
      sigma_test: 25
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test_4fen
      dataroot_L: None
      sigma: 25
      sigma_test: 25
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [30000, 50000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-19 09:52:28.474 : Random seed: 1310
25-05-19 09:52:28.623 : Number of train images: 31,005, iters: 31,005
25-05-19 09:52:29.779 : 
Networks name: DRNet
Params number: 17746115
Net structure:
DRNet(
  (head1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (head1_1): ResBlock(
    (body): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (head1_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body1_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): ReLU(inplace=True)
  )
  (body1_2): Sequential(
    (0): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
    (1): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (body2_1): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_2): Sequential(
    (0): ResBlock(
      (body): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion2_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body2_3): VisionEncoder(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (position_encoding): LearnedPositionalEncoding(
      (pe): Embedding(4096, 256)
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (body3_1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): VisionEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0, inplace=False)
            (dropout2): Dropout(p=0, inplace=False)
          )
        )
      )
      (position_encoding): LearnedPositionalEncoding(
        (pe): Embedding(4096, 256)
      )
      (dropout_layer1): Dropout(p=0, inplace=False)
    )
  )
  (fusion3_2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
    (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_3): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (fusion3_3): Sequential(
    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
    (1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (body3_4): VisionEncoder(
    (linear_encoding): Linear(in_features=256, out_features=256, bias=True)
    (mlp_head): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
      (4): Dropout(p=0, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
    (dropout_layer1): Dropout(p=0, inplace=False)
  )
  (tail): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

25-05-19 09:52:30.484 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.002 | -0.477 |  0.564 |  0.190 | torch.Size([64, 3, 3, 3]) || head1.weight
 | -0.002 | -0.346 |  0.285 |  0.187 | torch.Size([64]) || head1.bias
 |  0.000 | -0.520 |  0.499 |  0.101 | torch.Size([64, 64, 3, 3]) || head1_1.body.0.weight
 |  0.084 | -0.083 |  0.246 |  0.078 | torch.Size([64]) || head1_1.body.0.bias
 | -0.000 | -0.538 |  0.635 |  0.090 | torch.Size([64, 64, 3, 3]) || head1_1.body.2.weight
 |  0.010 | -0.109 |  0.130 |  0.057 | torch.Size([64]) || head1_1.body.2.bias
 |  0.000 | -0.311 |  0.328 |  0.060 | torch.Size([768, 256]) || head1_3.encoder.layers.0.self_attn.in_proj_weight
 | -0.001 | -0.345 |  0.309 |  0.067 | torch.Size([256, 256]) || head1_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.301 |  0.311 |  0.058 | torch.Size([1024, 256]) || head1_3.encoder.layers.0.linear1.weight
 | -0.022 | -0.171 |  0.099 |  0.042 | torch.Size([1024]) || head1_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.453 |  0.379 |  0.049 | torch.Size([256, 1024]) || head1_3.encoder.layers.0.linear2.weight
 |  0.000 | -0.080 |  0.079 |  0.031 | torch.Size([256]) || head1_3.encoder.layers.0.linear2.bias
 |  1.016 |  0.743 |  1.214 |  0.069 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.weight
 |  0.005 | -0.195 |  0.335 |  0.063 | torch.Size([256]) || head1_3.encoder.layers.0.norm1.bias
 |  1.125 |  0.986 |  1.308 |  0.062 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.weight
 |  0.003 | -0.084 |  0.082 |  0.033 | torch.Size([256]) || head1_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || head1_3.position_encoding.position_ids
 |  0.000 | -5.337 |  4.744 |  0.991 | torch.Size([4096, 256]) || head1_3.position_encoding.pe.weight
 |  0.000 | -0.958 |  1.005 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.0.weight
 |  0.026 | -0.107 |  0.115 |  0.045 | torch.Size([64]) || body1_1.0.body.0.bias
 | -0.001 | -0.380 |  0.407 |  0.037 | torch.Size([64, 64, 3, 3]) || body1_1.0.body.2.weight
 | -0.015 | -0.140 |  0.115 |  0.064 | torch.Size([64]) || body1_1.0.body.2.bias
 | -0.001 | -0.500 |  0.471 |  0.036 | torch.Size([64, 64, 3, 3]) || body1_1.1.weight
 |  0.049 | -0.053 |  0.157 |  0.048 | torch.Size([64]) || body1_1.1.bias
 |  0.000 | -0.177 |  0.188 |  0.042 | torch.Size([768, 256]) || body1_2.0.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.157 |  0.150 |  0.037 | torch.Size([256, 256]) || body1_2.0.encoder.layers.0.self_attn.out_proj.weight
 |  0.001 | -0.301 |  0.250 |  0.043 | torch.Size([1024, 256]) || body1_2.0.encoder.layers.0.linear1.weight
 |  0.004 | -0.073 |  0.100 |  0.038 | torch.Size([1024]) || body1_2.0.encoder.layers.0.linear1.bias
 | -0.003 | -0.261 |  0.205 |  0.028 | torch.Size([256, 1024]) || body1_2.0.encoder.layers.0.linear2.weight
 | -0.007 | -0.058 |  0.044 |  0.021 | torch.Size([256]) || body1_2.0.encoder.layers.0.linear2.bias
 |  0.996 |  0.805 |  1.144 |  0.069 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.weight
 |  0.008 | -0.139 |  0.151 |  0.067 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm1.bias
 |  1.001 |  0.798 |  1.225 |  0.061 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.weight
 |  0.011 | -0.235 |  0.253 |  0.088 | torch.Size([256]) || body1_2.0.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body1_2.0.position_encoding.position_ids
 |  0.001 | -4.538 |  4.876 |  0.995 | torch.Size([4096, 256]) || body1_2.0.position_encoding.pe.weight
 | -0.001 | -0.292 |  0.231 |  0.038 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.0.weight
 |  0.002 | -0.101 |  0.085 |  0.033 | torch.Size([64]) || body1_2.1.body.0.bias
 | -0.005 | -0.270 |  0.292 |  0.035 | torch.Size([64, 64, 3, 3]) || body1_2.1.body.2.weight
 | -0.016 | -0.104 |  0.048 |  0.033 | torch.Size([64]) || body1_2.1.body.2.bias
 |  0.000 | -0.289 |  0.254 |  0.051 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.0.weight
 |  0.014 | -0.118 |  0.119 |  0.048 | torch.Size([64]) || body2_1.0.body.0.bias
 | -0.000 | -0.323 |  0.497 |  0.049 | torch.Size([64, 64, 3, 3]) || body2_1.0.body.2.weight
 | -0.005 | -0.146 |  0.159 |  0.077 | torch.Size([64]) || body2_1.0.body.2.bias
 |  0.000 | -0.332 |  0.375 |  0.061 | torch.Size([768, 256]) || body2_1.1.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.327 |  0.356 |  0.071 | torch.Size([256, 256]) || body2_1.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.296 |  0.303 |  0.061 | torch.Size([1024, 256]) || body2_1.1.encoder.layers.0.linear1.weight
 |  0.010 | -0.128 |  0.131 |  0.042 | torch.Size([1024]) || body2_1.1.encoder.layers.0.linear1.bias
 | -0.000 | -0.272 |  0.286 |  0.050 | torch.Size([256, 1024]) || body2_1.1.encoder.layers.0.linear2.weight
 | -0.001 | -0.070 |  0.075 |  0.031 | torch.Size([256]) || body2_1.1.encoder.layers.0.linear2.bias
 |  1.081 |  0.944 |  1.209 |  0.051 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.weight
 |  0.003 | -0.157 |  0.172 |  0.075 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm1.bias
 |  1.212 |  1.026 |  1.413 |  0.075 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.weight
 |  0.001 | -0.119 |  0.114 |  0.034 | torch.Size([256]) || body2_1.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_1.1.position_encoding.position_ids
 | -0.001 | -4.994 |  4.878 |  0.999 | torch.Size([4096, 256]) || body2_1.1.position_encoding.pe.weight
 | -0.003 | -0.347 |  0.344 |  0.109 | torch.Size([128, 1, 5, 5]) || fusion2_1.0.weight
 |  0.014 | -0.267 |  0.261 |  0.122 | torch.Size([128]) || fusion2_1.0.bias
 |  0.000 | -0.209 |  0.241 |  0.055 | torch.Size([64, 128, 1, 1]) || fusion2_1.1.weight
 | -0.006 | -0.190 |  0.167 |  0.092 | torch.Size([64]) || fusion2_1.1.bias
 |  0.002 | -0.213 |  0.230 |  0.045 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.0.weight
 |  0.001 | -0.148 |  0.233 |  0.086 | torch.Size([64]) || body2_2.0.body.0.bias
 |  0.000 | -0.219 |  0.224 |  0.044 | torch.Size([64, 64, 3, 3]) || body2_2.0.body.2.weight
 | -0.004 | -0.238 |  0.218 |  0.109 | torch.Size([64]) || body2_2.0.body.2.bias
 | -0.000 | -0.426 |  0.353 |  0.067 | torch.Size([768, 256]) || body2_2.1.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.345 |  0.392 |  0.083 | torch.Size([256, 256]) || body2_2.1.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.250 |  0.275 |  0.061 | torch.Size([1024, 256]) || body2_2.1.encoder.layers.0.linear1.weight
 | -0.001 | -0.156 |  0.139 |  0.052 | torch.Size([1024]) || body2_2.1.encoder.layers.0.linear1.bias
 |  0.000 | -0.252 |  0.293 |  0.050 | torch.Size([256, 1024]) || body2_2.1.encoder.layers.0.linear2.weight
 |  0.002 | -0.051 |  0.057 |  0.025 | torch.Size([256]) || body2_2.1.encoder.layers.0.linear2.bias
 |  1.109 |  0.943 |  1.275 |  0.055 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.weight
 |  0.001 | -0.188 |  0.222 |  0.082 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm1.bias
 |  1.169 |  0.969 |  1.349 |  0.057 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.weight
 |  0.000 | -0.117 |  0.108 |  0.037 | torch.Size([256]) || body2_2.1.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_2.1.position_encoding.position_ids
 | -0.001 | -4.834 |  4.669 |  0.998 | torch.Size([4096, 256]) || body2_2.1.position_encoding.pe.weight
 | -0.000 | -0.318 |  0.399 |  0.104 | torch.Size([128, 1, 5, 5]) || fusion2_2.0.weight
 | -0.015 | -0.210 |  0.215 |  0.117 | torch.Size([128]) || fusion2_2.0.bias
 | -0.001 | -0.247 |  0.246 |  0.060 | torch.Size([64, 128, 1, 1]) || fusion2_2.1.weight
 | -0.019 | -0.157 |  0.159 |  0.067 | torch.Size([64]) || fusion2_2.1.bias
 | -0.000 | -0.239 |  0.240 |  0.054 | torch.Size([768, 256]) || body2_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.001 | -0.258 |  0.254 |  0.058 | torch.Size([256, 256]) || body2_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.234 |  0.232 |  0.052 | torch.Size([1024, 256]) || body2_3.encoder.layers.0.linear1.weight
 | -0.029 | -0.153 |  0.096 |  0.042 | torch.Size([1024]) || body2_3.encoder.layers.0.linear1.bias
 | -0.000 | -0.212 |  0.204 |  0.040 | torch.Size([256, 1024]) || body2_3.encoder.layers.0.linear2.weight
 |  0.002 | -0.053 |  0.074 |  0.022 | torch.Size([256]) || body2_3.encoder.layers.0.linear2.bias
 |  1.064 |  0.951 |  1.199 |  0.043 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.weight
 |  0.000 | -0.134 |  0.180 |  0.052 | torch.Size([256]) || body2_3.encoder.layers.0.norm1.bias
 |  1.037 |  0.905 |  1.192 |  0.047 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.weight
 | -0.001 | -0.101 |  0.077 |  0.031 | torch.Size([256]) || body2_3.encoder.layers.0.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body2_3.position_encoding.position_ids
 | -0.000 | -4.715 |  5.524 |  0.998 | torch.Size([4096, 256]) || body2_3.position_encoding.pe.weight
 |  0.000 | -0.238 |  0.259 |  0.039 | torch.Size([64, 64, 3, 3]) || body3_1.0.weight
 |  0.018 | -0.064 |  0.070 |  0.032 | torch.Size([64]) || body3_1.0.bias
 |  0.000 | -0.182 |  0.181 |  0.039 | torch.Size([768, 256]) || body3_1.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.162 |  0.166 |  0.040 | torch.Size([256, 256]) || body3_1.2.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.290 |  0.238 |  0.048 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.0.linear1.weight
 | -0.010 | -0.110 |  0.100 |  0.038 | torch.Size([1024]) || body3_1.2.encoder.layers.0.linear1.bias
 | -0.003 | -0.279 |  0.297 |  0.034 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.0.linear2.weight
 | -0.006 | -0.067 |  0.075 |  0.028 | torch.Size([256]) || body3_1.2.encoder.layers.0.linear2.bias
 |  1.005 |  0.917 |  1.102 |  0.029 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.089 |  0.085 |  0.032 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm1.bias
 |  1.124 |  1.002 |  1.279 |  0.052 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.weight
 |  0.002 | -0.091 |  0.093 |  0.035 | torch.Size([256]) || body3_1.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.155 |  0.165 |  0.038 | torch.Size([768, 256]) || body3_1.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.133 |  0.141 |  0.038 | torch.Size([256, 256]) || body3_1.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.321 |  0.284 |  0.047 | torch.Size([1024, 256]) || body3_1.2.encoder.layers.1.linear1.weight
 | -0.006 | -0.094 |  0.096 |  0.037 | torch.Size([1024]) || body3_1.2.encoder.layers.1.linear1.bias
 | -0.003 | -0.359 |  0.425 |  0.033 | torch.Size([256, 1024]) || body3_1.2.encoder.layers.1.linear2.weight
 | -0.007 | -0.066 |  0.049 |  0.023 | torch.Size([256]) || body3_1.2.encoder.layers.1.linear2.bias
 |  0.998 |  0.950 |  1.117 |  0.025 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.weight
 | -0.001 | -0.066 |  0.067 |  0.026 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm1.bias
 |  1.141 |  1.003 |  1.305 |  0.053 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.weight
 |  0.001 | -0.055 |  0.055 |  0.022 | torch.Size([256]) || body3_1.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_1.2.position_encoding.position_ids
 |  0.002 | -4.658 |  4.616 |  0.999 | torch.Size([4096, 256]) || body3_1.2.position_encoding.pe.weight
 |  0.001 | -0.320 |  0.391 |  0.069 | torch.Size([128, 1, 5, 5]) || fusion3_1.0.weight
 |  0.006 | -0.235 |  0.243 |  0.123 | torch.Size([128]) || fusion3_1.0.bias
 | -0.000 | -0.137 |  0.139 |  0.028 | torch.Size([64, 128, 1, 1]) || fusion3_1.1.weight
 | -0.010 | -0.198 |  0.191 |  0.098 | torch.Size([64]) || fusion3_1.1.bias
 | -0.000 | -0.151 |  0.118 |  0.026 | torch.Size([64, 64, 3, 3]) || body3_2.0.weight
 |  0.063 | -0.122 |  0.127 |  0.039 | torch.Size([64]) || body3_2.0.bias
 |  0.000 | -0.144 |  0.128 |  0.040 | torch.Size([768, 256]) || body3_2.2.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.110 |  0.110 |  0.037 | torch.Size([256, 256]) || body3_2.2.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.202 |  0.207 |  0.052 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.0.linear1.weight
 | -0.044 | -0.139 |  0.065 |  0.039 | torch.Size([1024]) || body3_2.2.encoder.layers.0.linear1.bias
 | -0.002 | -0.170 |  0.160 |  0.037 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.0.linear2.weight
 | -0.009 | -0.063 |  0.040 |  0.023 | torch.Size([256]) || body3_2.2.encoder.layers.0.linear2.bias
 |  0.997 |  0.831 |  1.076 |  0.031 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.weight
 | -0.003 | -0.126 |  0.181 |  0.045 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm1.bias
 |  1.060 |  0.923 |  1.204 |  0.052 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.weight
 | -0.001 | -0.155 |  0.105 |  0.045 | torch.Size([256]) || body3_2.2.encoder.layers.0.norm2.bias
 |  0.000 | -0.109 |  0.116 |  0.038 | torch.Size([768, 256]) || body3_2.2.encoder.layers.1.self_attn.in_proj_weight
 | -0.000 | -0.120 |  0.103 |  0.036 | torch.Size([256, 256]) || body3_2.2.encoder.layers.1.self_attn.out_proj.weight
 | -0.000 | -0.199 |  0.191 |  0.049 | torch.Size([1024, 256]) || body3_2.2.encoder.layers.1.linear1.weight
 | -0.025 | -0.106 |  0.089 |  0.038 | torch.Size([1024]) || body3_2.2.encoder.layers.1.linear1.bias
 | -0.001 | -0.159 |  0.157 |  0.036 | torch.Size([256, 1024]) || body3_2.2.encoder.layers.1.linear2.weight
 | -0.009 | -0.068 |  0.047 |  0.024 | torch.Size([256]) || body3_2.2.encoder.layers.1.linear2.bias
 |  0.986 |  0.915 |  1.033 |  0.021 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.weight
 | -0.000 | -0.108 |  0.124 |  0.046 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm1.bias
 |  1.066 |  0.951 |  1.160 |  0.037 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.weight
 | -0.000 | -0.051 |  0.049 |  0.019 | torch.Size([256]) || body3_2.2.encoder.layers.1.norm2.bias
 | 2047.500 |  0.000 | 4095.000 | 1182.558 | torch.Size([1, 4096]) || body3_2.2.position_encoding.position_ids
 |  0.001 | -5.086 |  5.021 |  1.000 | torch.Size([4096, 256]) || body3_2.2.position_encoding.pe.weight
 |  0.002 | -0.237 |  0.251 |  0.083 | torch.Size([128, 1, 5, 5]) || fusion3_2.0.weight
 |  0.002 | -0.203 |  0.222 |  0.104 | torch.Size([128]) || fusion3_2.0.bias
 |  0.001 | -0.159 |  0.176 |  0.046 | torch.Size([64, 128, 1, 1]) || fusion3_2.1.weight
 |  0.006 | -0.099 |  0.128 |  0.050 | torch.Size([64]) || fusion3_2.1.bias
 | -0.001 | -0.268 |  0.199 |  0.050 | torch.Size([256, 256]) || body3_3.linear_encoding.weight
 | -0.005 | -0.145 |  0.171 |  0.068 | torch.Size([256]) || body3_3.linear_encoding.bias
 | -0.000 | -0.234 |  0.215 |  0.045 | torch.Size([1024, 256]) || body3_3.mlp_head.0.weight
 | -0.027 | -0.123 |  0.074 |  0.039 | torch.Size([1024]) || body3_3.mlp_head.0.bias
 | -0.000 | -0.221 |  0.190 |  0.032 | torch.Size([256, 1024]) || body3_3.mlp_head.3.weight
 |  0.002 | -0.088 |  0.079 |  0.030 | torch.Size([256]) || body3_3.mlp_head.3.bias
 |  0.000 | -0.159 |  0.153 |  0.041 | torch.Size([768, 256]) || body3_3.encoder.layers.0.self_attn.in_proj_weight
 |  0.000 | -0.195 |  0.154 |  0.040 | torch.Size([256, 256]) || body3_3.encoder.layers.0.self_attn.out_proj.weight
 |  0.000 | -0.199 |  0.208 |  0.044 | torch.Size([1024, 256]) || body3_3.encoder.layers.0.linear1.weight
 | -0.036 | -0.135 |  0.063 |  0.037 | torch.Size([1024]) || body3_3.encoder.layers.0.linear1.bias
 |  0.000 | -0.226 |  0.228 |  0.031 | torch.Size([256, 1024]) || body3_3.encoder.layers.0.linear2.weight
 | -0.000 | -0.084 |  0.073 |  0.025 | torch.Size([256]) || body3_3.encoder.layers.0.linear2.bias
 |  0.945 |  0.848 |  1.030 |  0.031 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.weight
 | -0.000 | -0.092 |  0.121 |  0.037 | torch.Size([256]) || body3_3.encoder.layers.0.norm1.bias
 |  0.861 |  0.763 |  1.005 |  0.041 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.weight
 | -0.000 | -0.183 |  0.180 |  0.062 | torch.Size([256]) || body3_3.encoder.layers.0.norm2.bias
 | -0.000 | -0.127 |  0.139 |  0.036 | torch.Size([192, 1, 5, 5]) || fusion3_3.0.weight
 |  0.004 | -0.186 |  0.229 |  0.075 | torch.Size([192]) || fusion3_3.0.bias
 |  0.000 | -0.132 |  0.116 |  0.022 | torch.Size([64, 192, 1, 1]) || fusion3_3.1.weight
 | -0.003 | -0.040 |  0.028 |  0.017 | torch.Size([64]) || fusion3_3.1.bias
 | -0.002 | -0.514 |  0.135 |  0.038 | torch.Size([256, 256]) || body3_4.linear_encoding.weight
 |  0.004 | -0.065 |  0.115 |  0.026 | torch.Size([256]) || body3_4.linear_encoding.bias
 | -0.001 | -0.272 |  0.262 |  0.046 | torch.Size([1024, 256]) || body3_4.mlp_head.0.weight
 | -0.050 | -0.164 |  0.059 |  0.037 | torch.Size([1024]) || body3_4.mlp_head.0.bias
 | -0.000 | -0.251 |  0.276 |  0.029 | torch.Size([256, 1024]) || body3_4.mlp_head.3.weight
 | -0.004 | -0.135 |  0.089 |  0.033 | torch.Size([256]) || body3_4.mlp_head.3.bias
 | -0.000 | -0.224 |  0.224 |  0.044 | torch.Size([768, 256]) || body3_4.encoder.layers.0.self_attn.in_proj_weight
 | -0.000 | -0.156 |  0.146 |  0.033 | torch.Size([256, 256]) || body3_4.encoder.layers.0.self_attn.out_proj.weight
 | -0.000 | -0.216 |  0.199 |  0.039 | torch.Size([1024, 256]) || body3_4.encoder.layers.0.linear1.weight
 | -0.040 | -0.152 |  0.067 |  0.037 | torch.Size([1024]) || body3_4.encoder.layers.0.linear1.bias
 |  0.000 | -0.192 |  0.171 |  0.021 | torch.Size([256, 1024]) || body3_4.encoder.layers.0.linear2.weight
 |  0.000 | -0.063 |  0.060 |  0.023 | torch.Size([256]) || body3_4.encoder.layers.0.linear2.bias
 |  0.767 |  0.577 |  0.931 |  0.070 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.weight
 |  0.000 | -0.225 |  0.183 |  0.073 | torch.Size([256]) || body3_4.encoder.layers.0.norm1.bias
 |  0.750 |  0.424 |  1.025 |  0.107 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.weight
 |  0.000 | -0.207 |  0.193 |  0.084 | torch.Size([256]) || body3_4.encoder.layers.0.norm2.bias
 |  0.000 | -0.049 |  0.049 |  0.010 | torch.Size([3, 64, 3, 3]) || tail.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([3]) || tail.bias

25-05-19 11:28:33.550 : <epoch:  0, iter:  40,000, lr:5.000e-05> G_loss: 6.688e-05 
25-05-19 11:28:33.557 : Saving the model.
25-05-19 11:28:34.378 : ---1--> airplane_111_00.jpg | 30.41dB
25-05-19 11:28:34.553 : ---2--> airplane_111_01.jpg | 35.34dB
25-05-19 11:28:34.732 : ---3--> airplane_111_10.jpg | 32.84dB
25-05-19 11:28:34.906 : ---4--> airplane_111_11.jpg | 32.91dB
25-05-19 11:28:35.084 : ---5--> airport_111_00.jpg | 34.47dB
25-05-19 11:28:35.270 : ---6--> airport_111_01.jpg | 32.37dB
25-05-19 11:28:35.442 : ---7--> airport_111_10.jpg | 31.93dB
25-05-19 11:28:35.625 : ---8--> airport_111_11.jpg | 32.89dB
25-05-19 11:28:35.806 : ---9--> baseball_diamond_111_00.jpg | 32.71dB
25-05-19 11:28:35.984 : --10--> baseball_diamond_111_01.jpg | 34.28dB
25-05-19 11:28:36.162 : --11--> baseball_diamond_111_10.jpg | 32.55dB
25-05-19 11:28:36.345 : --12--> baseball_diamond_111_11.jpg | 35.35dB
25-05-19 11:28:36.520 : --13--> basketball_court_111_00.jpg | 30.55dB
25-05-19 11:28:36.697 : --14--> basketball_court_111_01.jpg | 30.10dB
25-05-19 11:28:36.873 : --15--> basketball_court_111_10.jpg | 33.37dB
25-05-19 11:28:37.054 : --16--> basketball_court_111_11.jpg | 31.61dB
25-05-19 11:28:37.229 : --17--> beach_111_00.jpg | 28.58dB
25-05-19 11:28:37.407 : --18--> beach_111_01.jpg | 31.73dB
25-05-19 11:28:37.585 : --19--> beach_111_10.jpg | 29.75dB
25-05-19 11:28:37.765 : --20--> beach_111_11.jpg | 34.36dB
25-05-19 11:28:37.943 : --21--> bridge_111_00.jpg | 40.80dB
25-05-19 11:28:38.118 : --22--> bridge_111_01.jpg | 34.33dB
25-05-19 11:28:38.298 : --23--> bridge_111_10.jpg | 33.24dB
25-05-19 11:28:38.475 : --24--> bridge_111_11.jpg | 36.63dB
25-05-19 11:28:38.658 : --25--> chaparral_111_00.jpg | 30.30dB
25-05-19 11:28:38.831 : --26--> chaparral_111_01.jpg | 30.51dB
25-05-19 11:28:39.007 : --27--> chaparral_111_10.jpg | 30.86dB
25-05-19 11:28:39.184 : --28--> chaparral_111_11.jpg | 28.67dB
25-05-19 11:28:39.360 : --29--> church_111_00.jpg | 31.61dB
25-05-19 11:28:39.545 : --30--> church_111_01.jpg | 30.60dB
25-05-19 11:28:39.725 : --31--> church_111_10.jpg | 34.41dB
25-05-19 11:28:39.904 : --32--> church_111_11.jpg | 30.42dB
25-05-19 11:28:40.078 : --33--> circular_farmland_111_00.jpg | 32.77dB
25-05-19 11:28:40.256 : --34--> circular_farmland_111_01.jpg | 33.80dB
25-05-19 11:28:40.435 : --35--> circular_farmland_111_10.jpg | 33.96dB
25-05-19 11:28:40.617 : --36--> circular_farmland_111_11.jpg | 34.12dB
25-05-19 11:28:40.793 : --37--> cloud_111_00.jpg | 41.01dB
25-05-19 11:28:40.974 : --38--> cloud_111_01.jpg | 36.80dB
25-05-19 11:28:41.151 : --39--> cloud_111_10.jpg | 36.35dB
25-05-19 11:28:41.328 : --40--> cloud_111_11.jpg | 36.84dB
25-05-19 11:28:41.505 : --41--> commercial_area_111_00.jpg | 33.32dB
25-05-19 11:28:41.681 : --42--> commercial_area_111_01.jpg | 32.36dB
25-05-19 11:28:41.860 : --43--> commercial_area_111_10.jpg | 33.14dB
25-05-19 11:28:42.041 : --44--> commercial_area_111_11.jpg | 33.03dB
25-05-19 11:28:42.220 : --45--> dense_residential_111_00.jpg | 30.14dB
25-05-19 11:28:42.398 : --46--> dense_residential_111_01.jpg | 29.22dB
25-05-19 11:28:42.580 : --47--> dense_residential_111_10.jpg | 29.64dB
25-05-19 11:28:42.756 : --48--> dense_residential_111_11.jpg | 29.52dB
25-05-19 11:28:42.938 : --49--> desert_111_00.jpg | 36.85dB
25-05-19 11:28:43.116 : --50--> desert_111_01.jpg | 36.74dB
25-05-19 11:28:43.298 : --51--> desert_111_10.jpg | 36.92dB
25-05-19 11:28:43.473 : --52--> desert_111_11.jpg | 37.05dB
25-05-19 11:28:43.654 : --53--> forest_111_00.jpg | 33.01dB
25-05-19 11:28:43.833 : --54--> forest_111_01.jpg | 32.10dB
25-05-19 11:28:44.009 : --55--> forest_111_10.jpg | 31.72dB
25-05-19 11:28:44.193 : --56--> forest_111_11.jpg | 32.66dB
25-05-19 11:28:44.366 : --57--> freeway_111_00.jpg | 33.82dB
25-05-19 11:28:44.550 : --58--> freeway_111_01.jpg | 34.91dB
25-05-19 11:28:44.723 : --59--> freeway_111_10.jpg | 34.77dB
25-05-19 11:28:44.907 : --60--> freeway_111_11.jpg | 34.80dB
25-05-19 11:28:45.083 : --61--> golf_course_111_00.jpg | 32.72dB
25-05-19 11:28:45.259 : --62--> golf_course_111_01.jpg | 32.10dB
25-05-19 11:28:45.437 : --63--> golf_course_111_10.jpg | 33.51dB
25-05-19 11:28:45.614 : --64--> golf_course_111_11.jpg | 33.90dB
25-05-19 11:28:45.797 : --65--> ground_track_field_111_00.jpg | 33.32dB
25-05-19 11:28:45.972 : --66--> ground_track_field_111_01.jpg | 29.37dB
25-05-19 11:28:46.152 : --67--> ground_track_field_111_10.jpg | 30.74dB
25-05-19 11:28:46.328 : --68--> ground_track_field_111_11.jpg | 29.98dB
25-05-19 11:28:46.506 : --69--> harbor_111_00.jpg | 32.84dB
25-05-19 11:28:46.685 : --70--> harbor_111_01.jpg | 31.17dB
25-05-19 11:28:46.864 : --71--> harbor_111_10.jpg | 30.73dB
25-05-19 11:28:47.043 : --72--> harbor_111_11.jpg | 32.43dB
25-05-19 11:28:47.221 : --73--> industrial_area_111_00.jpg | 31.55dB
25-05-19 11:28:47.396 : --74--> industrial_area_111_01.jpg | 31.79dB
25-05-19 11:28:47.573 : --75--> industrial_area_111_10.jpg | 31.92dB
25-05-19 11:28:47.752 : --76--> industrial_area_111_11.jpg | 31.31dB
25-05-19 11:28:47.931 : --77--> intersection_111_00.jpg | 30.59dB
25-05-19 11:28:48.107 : --78--> intersection_111_01.jpg | 30.73dB
25-05-19 11:28:48.289 : --79--> intersection_111_10.jpg | 30.45dB
25-05-19 11:28:48.464 : --80--> intersection_111_11.jpg | 30.22dB
25-05-19 11:28:48.644 : --81--> island_111_00.jpg | 31.41dB
25-05-19 11:28:48.822 : --82--> island_111_01.jpg | 33.85dB
25-05-19 11:28:49.002 : --83--> island_111_10.jpg | 32.46dB
25-05-19 11:28:49.178 : --84--> island_111_11.jpg | 32.02dB
25-05-19 11:28:49.362 : --85--> lake_111_00.jpg | 32.49dB
25-05-19 11:28:49.540 : --86--> lake_111_01.jpg | 32.30dB
25-05-19 11:28:49.716 : --87--> lake_111_10.jpg | 31.60dB
25-05-19 11:28:49.900 : --88--> lake_111_11.jpg | 31.02dB
25-05-19 11:28:50.085 : --89--> meadow_111_00.jpg | 30.05dB
25-05-19 11:28:50.262 : --90--> meadow_111_01.jpg | 30.16dB
25-05-19 11:28:50.441 : --91--> meadow_111_10.jpg | 30.19dB
25-05-19 11:28:50.617 : --92--> meadow_111_11.jpg | 30.34dB
25-05-19 11:28:50.802 : --93--> medium_residential_111_00.jpg | 28.69dB
25-05-19 11:28:50.977 : --94--> medium_residential_111_01.jpg | 28.15dB
25-05-19 11:28:51.153 : --95--> medium_residential_111_10.jpg | 28.50dB
25-05-19 11:28:51.330 : --96--> medium_residential_111_11.jpg | 29.02dB
25-05-19 11:28:51.510 : --97--> mobile_home_park_111_00.jpg | 30.96dB
25-05-19 11:28:51.691 : --98--> mobile_home_park_111_01.jpg | 31.44dB
25-05-19 11:28:51.868 : --99--> mobile_home_park_111_10.jpg | 31.75dB
25-05-19 11:28:52.044 : -100--> mobile_home_park_111_11.jpg | 31.81dB
25-05-19 11:28:52.229 : -101--> mountain_111_00.jpg | 28.87dB
25-05-19 11:28:52.405 : -102--> mountain_111_01.jpg | 29.53dB
25-05-19 11:28:52.584 : -103--> mountain_111_10.jpg | 29.32dB
25-05-19 11:28:52.760 : -104--> mountain_111_11.jpg | 29.64dB
25-05-19 11:28:52.942 : -105--> overpass_111_00.jpg | 30.09dB
25-05-19 11:28:53.121 : -106--> overpass_111_01.jpg | 29.96dB
25-05-19 11:28:53.309 : -107--> overpass_111_10.jpg | 30.56dB
25-05-19 11:28:53.485 : -108--> overpass_111_11.jpg | 31.30dB
25-05-19 11:28:53.660 : -109--> palace_111_00.jpg | 30.02dB
25-05-19 11:28:53.845 : -110--> palace_111_01.jpg | 29.81dB
25-05-19 11:28:54.028 : -111--> palace_111_10.jpg | 31.02dB
25-05-19 11:28:54.206 : -112--> palace_111_11.jpg | 29.38dB
25-05-19 11:28:54.387 : -113--> parking_lot_111_00.jpg | 29.31dB
25-05-19 11:28:54.560 : -114--> parking_lot_111_01.jpg | 29.56dB
25-05-19 11:28:54.749 : -115--> parking_lot_111_10.jpg | 31.12dB
25-05-19 11:28:54.923 : -116--> parking_lot_111_11.jpg | 29.98dB
25-05-19 11:28:55.100 : -117--> railway_111_00.jpg | 30.12dB
25-05-19 11:28:55.282 : -118--> railway_111_01.jpg | 29.66dB
25-05-19 11:28:55.460 : -119--> railway_111_10.jpg | 32.44dB
25-05-19 11:28:55.637 : -120--> railway_111_11.jpg | 29.03dB
25-05-19 11:28:55.817 : -121--> railway_station_111_00.jpg | 30.81dB
25-05-19 11:28:55.997 : -122--> railway_station_111_01.jpg | 31.32dB
25-05-19 11:28:56.175 : -123--> railway_station_111_10.jpg | 31.00dB
25-05-19 11:28:56.353 : -124--> railway_station_111_11.jpg | 31.52dB
25-05-19 11:28:56.528 : -125--> rectangular_farmland_111_00.jpg | 33.37dB
25-05-19 11:28:56.703 : -126--> rectangular_farmland_111_01.jpg | 31.87dB
25-05-19 11:28:56.880 : -127--> rectangular_farmland_111_10.jpg | 33.76dB
25-05-19 11:28:57.057 : -128--> rectangular_farmland_111_11.jpg | 34.07dB
25-05-19 11:28:57.236 : -129--> river_111_00.jpg | 30.15dB
25-05-19 11:28:57.415 : -130--> river_111_01.jpg | 29.97dB
25-05-19 11:28:57.593 : -131--> river_111_10.jpg | 29.47dB
25-05-19 11:28:57.771 : -132--> river_111_11.jpg | 31.31dB
25-05-19 11:28:57.949 : -133--> roundabout_111_00.jpg | 30.42dB
25-05-19 11:28:58.128 : -134--> roundabout_111_01.jpg | 32.05dB
25-05-19 11:28:58.307 : -135--> roundabout_111_10.jpg | 30.36dB
25-05-19 11:28:58.485 : -136--> roundabout_111_11.jpg | 30.71dB
25-05-19 11:28:58.665 : -137--> runway_111_00.jpg | 36.39dB
25-05-19 11:28:58.842 : -138--> runway_111_01.jpg | 35.80dB
25-05-19 11:28:59.023 : -139--> runway_111_10.jpg | 36.47dB
25-05-19 11:28:59.200 : -140--> runway_111_11.jpg | 37.40dB
25-05-19 11:28:59.378 : -141--> sea_ice_111_00.jpg | 33.60dB
25-05-19 11:28:59.557 : -142--> sea_ice_111_01.jpg | 34.69dB
25-05-19 11:28:59.729 : -143--> sea_ice_111_10.jpg | 33.61dB
25-05-19 11:28:59.903 : -144--> sea_ice_111_11.jpg | 34.66dB
25-05-19 11:29:00.081 : -145--> ship_111_00.jpg | 38.54dB
25-05-19 11:29:00.258 : -146--> ship_111_01.jpg | 34.50dB
25-05-19 11:29:00.439 : -147--> ship_111_10.jpg | 42.66dB
25-05-19 11:29:00.618 : -148--> ship_111_11.jpg | 39.99dB
25-05-19 11:29:00.797 : -149--> snowberg_111_00.jpg | 34.15dB
25-05-19 11:29:00.975 : -150--> snowberg_111_01.jpg | 32.74dB
25-05-19 11:29:01.156 : -151--> snowberg_111_10.jpg | 31.96dB
25-05-19 11:29:01.335 : -152--> snowberg_111_11.jpg | 31.97dB
25-05-19 11:29:01.515 : -153--> sparse_residential_111_00.jpg | 30.43dB
25-05-19 11:29:01.692 : -154--> sparse_residential_111_01.jpg | 30.69dB
25-05-19 11:29:01.871 : -155--> sparse_residential_111_10.jpg | 29.72dB
25-05-19 11:29:02.054 : -156--> sparse_residential_111_11.jpg | 30.02dB
25-05-19 11:29:02.235 : -157--> stadium_111_00.jpg | 30.20dB
25-05-19 11:29:02.415 : -158--> stadium_111_01.jpg | 30.05dB
25-05-19 11:29:02.591 : -159--> stadium_111_10.jpg | 31.37dB
25-05-19 11:29:02.769 : -160--> stadium_111_11.jpg | 30.17dB
25-05-19 11:29:02.948 : -161--> storage_tank_111_00.jpg | 31.84dB
25-05-19 11:29:03.125 : -162--> storage_tank_111_01.jpg | 32.00dB
25-05-19 11:29:03.303 : -163--> storage_tank_111_10.jpg | 30.79dB
25-05-19 11:29:03.485 : -164--> storage_tank_111_11.jpg | 31.28dB
25-05-19 11:29:03.663 : -165--> tennis_court_111_00.jpg | 32.00dB
25-05-19 11:29:03.837 : -166--> tennis_court_111_01.jpg | 31.51dB
25-05-19 11:29:04.014 : -167--> tennis_court_111_10.jpg | 31.67dB
25-05-19 11:29:04.197 : -168--> tennis_court_111_11.jpg | 29.63dB
25-05-19 11:29:04.375 : -169--> terrace_111_00.jpg | 32.24dB
25-05-19 11:29:04.552 : -170--> terrace_111_01.jpg | 33.33dB
25-05-19 11:29:04.728 : -171--> terrace_111_10.jpg | 32.30dB
25-05-19 11:29:04.911 : -172--> terrace_111_11.jpg | 32.32dB
25-05-19 11:29:05.091 : -173--> thermal_power_station_111_00.jpg | 30.10dB
25-05-19 11:29:05.269 : -174--> thermal_power_station_111_01.jpg | 31.65dB
25-05-19 11:29:05.449 : -175--> thermal_power_station_111_10.jpg | 29.87dB
25-05-19 11:29:05.628 : -176--> thermal_power_station_111_11.jpg | 30.43dB
25-05-19 11:29:05.807 : -177--> wetland_111_00.jpg | 31.38dB
25-05-19 11:29:05.980 : -178--> wetland_111_01.jpg | 31.40dB
25-05-19 11:29:06.167 : -179--> wetland_111_10.jpg | 31.65dB
25-05-19 11:29:06.345 : -180--> wetland_111_11.jpg | 30.98dB
25-05-19 11:29:06.357 : <epoch:  0, iter:  40,000, Average PSNR : 32.14dB

25-05-19 13:04:53.669 : <epoch:  0, iter:  45,000, lr:5.000e-05> G_loss: 6.689e-05 
25-05-19 13:04:53.670 : Saving the model.
25-05-19 13:04:54.313 : ---1--> airplane_111_00.jpg | 30.42dB
25-05-19 13:04:54.489 : ---2--> airplane_111_01.jpg | 35.33dB
25-05-19 13:04:54.669 : ---3--> airplane_111_10.jpg | 32.84dB
25-05-19 13:04:54.850 : ---4--> airplane_111_11.jpg | 32.95dB
25-05-19 13:04:55.026 : ---5--> airport_111_00.jpg | 34.46dB
25-05-19 13:04:55.212 : ---6--> airport_111_01.jpg | 32.36dB
25-05-19 13:04:55.386 : ---7--> airport_111_10.jpg | 31.91dB
25-05-19 13:04:55.568 : ---8--> airport_111_11.jpg | 32.87dB
25-05-19 13:04:55.742 : ---9--> baseball_diamond_111_00.jpg | 32.71dB
25-05-19 13:04:55.927 : --10--> baseball_diamond_111_01.jpg | 34.28dB
25-05-19 13:04:56.103 : --11--> baseball_diamond_111_10.jpg | 32.54dB
25-05-19 13:04:56.282 : --12--> baseball_diamond_111_11.jpg | 35.33dB
25-05-19 13:04:56.457 : --13--> basketball_court_111_00.jpg | 30.54dB
25-05-19 13:04:56.638 : --14--> basketball_court_111_01.jpg | 30.11dB
25-05-19 13:04:56.816 : --15--> basketball_court_111_10.jpg | 33.39dB
25-05-19 13:04:56.992 : --16--> basketball_court_111_11.jpg | 31.62dB
25-05-19 13:04:57.166 : --17--> beach_111_00.jpg | 28.59dB
25-05-19 13:04:57.349 : --18--> beach_111_01.jpg | 31.74dB
25-05-19 13:04:57.535 : --19--> beach_111_10.jpg | 29.76dB
25-05-19 13:04:57.708 : --20--> beach_111_11.jpg | 34.38dB
25-05-19 13:04:57.890 : --21--> bridge_111_00.jpg | 40.81dB
25-05-19 13:04:58.067 : --22--> bridge_111_01.jpg | 34.32dB
25-05-19 13:04:58.248 : --23--> bridge_111_10.jpg | 33.23dB
25-05-19 13:04:58.436 : --24--> bridge_111_11.jpg | 36.61dB
25-05-19 13:04:58.610 : --25--> chaparral_111_00.jpg | 30.30dB
25-05-19 13:04:58.791 : --26--> chaparral_111_01.jpg | 30.57dB
25-05-19 13:04:58.967 : --27--> chaparral_111_10.jpg | 30.87dB
25-05-19 13:04:59.149 : --28--> chaparral_111_11.jpg | 28.68dB
25-05-19 13:04:59.324 : --29--> church_111_00.jpg | 31.61dB
25-05-19 13:04:59.505 : --30--> church_111_01.jpg | 30.60dB
25-05-19 13:04:59.680 : --31--> church_111_10.jpg | 34.40dB
25-05-19 13:04:59.857 : --32--> church_111_11.jpg | 30.41dB
25-05-19 13:05:00.036 : --33--> circular_farmland_111_00.jpg | 32.76dB
25-05-19 13:05:00.212 : --34--> circular_farmland_111_01.jpg | 33.80dB
25-05-19 13:05:00.385 : --35--> circular_farmland_111_10.jpg | 33.98dB
25-05-19 13:05:00.569 : --36--> circular_farmland_111_11.jpg | 34.12dB
25-05-19 13:05:00.741 : --37--> cloud_111_00.jpg | 41.04dB
25-05-19 13:05:00.919 : --38--> cloud_111_01.jpg | 36.82dB
25-05-19 13:05:01.100 : --39--> cloud_111_10.jpg | 36.37dB
25-05-19 13:05:01.281 : --40--> cloud_111_11.jpg | 36.82dB
25-05-19 13:05:01.458 : --41--> commercial_area_111_00.jpg | 33.33dB
25-05-19 13:05:01.635 : --42--> commercial_area_111_01.jpg | 32.37dB
25-05-19 13:05:01.816 : --43--> commercial_area_111_10.jpg | 33.14dB
25-05-19 13:05:01.999 : --44--> commercial_area_111_11.jpg | 33.02dB
25-05-19 13:05:02.173 : --45--> dense_residential_111_00.jpg | 30.16dB
25-05-19 13:05:02.354 : --46--> dense_residential_111_01.jpg | 29.24dB
25-05-19 13:05:02.530 : --47--> dense_residential_111_10.jpg | 29.64dB
25-05-19 13:05:02.710 : --48--> dense_residential_111_11.jpg | 29.52dB
25-05-19 13:05:02.888 : --49--> desert_111_00.jpg | 36.88dB
25-05-19 13:05:03.068 : --50--> desert_111_01.jpg | 36.74dB
25-05-19 13:05:03.245 : --51--> desert_111_10.jpg | 36.92dB
25-05-19 13:05:03.424 : --52--> desert_111_11.jpg | 37.02dB
25-05-19 13:05:03.605 : --53--> forest_111_00.jpg | 33.02dB
25-05-19 13:05:03.781 : --54--> forest_111_01.jpg | 32.09dB
25-05-19 13:05:03.965 : --55--> forest_111_10.jpg | 31.72dB
25-05-19 13:05:04.139 : --56--> forest_111_11.jpg | 32.66dB
25-05-19 13:05:04.321 : --57--> freeway_111_00.jpg | 33.83dB
25-05-19 13:05:04.495 : --58--> freeway_111_01.jpg | 34.90dB
25-05-19 13:05:04.677 : --59--> freeway_111_10.jpg | 34.76dB
25-05-19 13:05:04.855 : --60--> freeway_111_11.jpg | 34.78dB
25-05-19 13:05:05.035 : --61--> golf_course_111_00.jpg | 32.72dB
25-05-19 13:05:05.214 : --62--> golf_course_111_01.jpg | 32.10dB
25-05-19 13:05:05.390 : --63--> golf_course_111_10.jpg | 33.50dB
25-05-19 13:05:05.566 : --64--> golf_course_111_11.jpg | 33.89dB
25-05-19 13:05:05.747 : --65--> ground_track_field_111_00.jpg | 33.29dB
25-05-19 13:05:05.926 : --66--> ground_track_field_111_01.jpg | 29.37dB
25-05-19 13:05:06.104 : --67--> ground_track_field_111_10.jpg | 30.75dB
25-05-19 13:05:06.283 : --68--> ground_track_field_111_11.jpg | 29.97dB
25-05-19 13:05:06.466 : --69--> harbor_111_00.jpg | 32.83dB
25-05-19 13:05:06.644 : --70--> harbor_111_01.jpg | 31.15dB
25-05-19 13:05:06.820 : --71--> harbor_111_10.jpg | 30.74dB
25-05-19 13:05:07.000 : --72--> harbor_111_11.jpg | 32.39dB
25-05-19 13:05:07.174 : --73--> industrial_area_111_00.jpg | 31.57dB
25-05-19 13:05:07.353 : --74--> industrial_area_111_01.jpg | 31.79dB
25-05-19 13:05:07.534 : --75--> industrial_area_111_10.jpg | 31.91dB
25-05-19 13:05:07.715 : --76--> industrial_area_111_11.jpg | 31.32dB
25-05-19 13:05:07.897 : --77--> intersection_111_00.jpg | 30.59dB
25-05-19 13:05:08.075 : --78--> intersection_111_01.jpg | 30.72dB
25-05-19 13:05:08.255 : --79--> intersection_111_10.jpg | 30.45dB
25-05-19 13:05:08.431 : --80--> intersection_111_11.jpg | 30.22dB
25-05-19 13:05:08.605 : --81--> island_111_00.jpg | 31.43dB
25-05-19 13:05:08.780 : --82--> island_111_01.jpg | 33.84dB
25-05-19 13:05:08.967 : --83--> island_111_10.jpg | 32.46dB
25-05-19 13:05:09.146 : --84--> island_111_11.jpg | 32.04dB
25-05-19 13:05:09.328 : --85--> lake_111_00.jpg | 32.48dB
25-05-19 13:05:09.505 : --86--> lake_111_01.jpg | 32.30dB
25-05-19 13:05:09.687 : --87--> lake_111_10.jpg | 31.61dB
25-05-19 13:05:09.865 : --88--> lake_111_11.jpg | 31.02dB
25-05-19 13:05:10.054 : --89--> meadow_111_00.jpg | 30.04dB
25-05-19 13:05:10.230 : --90--> meadow_111_01.jpg | 30.14dB
25-05-19 13:05:10.408 : --91--> meadow_111_10.jpg | 30.18dB
25-05-19 13:05:10.586 : --92--> meadow_111_11.jpg | 30.34dB
25-05-19 13:05:10.766 : --93--> medium_residential_111_00.jpg | 28.69dB
25-05-19 13:05:10.943 : --94--> medium_residential_111_01.jpg | 28.17dB
25-05-19 13:05:11.120 : --95--> medium_residential_111_10.jpg | 28.51dB
25-05-19 13:05:11.299 : --96--> medium_residential_111_11.jpg | 29.02dB
25-05-19 13:05:11.478 : --97--> mobile_home_park_111_00.jpg | 30.95dB
25-05-19 13:05:11.655 : --98--> mobile_home_park_111_01.jpg | 31.42dB
25-05-19 13:05:11.836 : --99--> mobile_home_park_111_10.jpg | 31.73dB
25-05-19 13:05:12.012 : -100--> mobile_home_park_111_11.jpg | 31.79dB
25-05-19 13:05:12.189 : -101--> mountain_111_00.jpg | 28.87dB
25-05-19 13:05:12.375 : -102--> mountain_111_01.jpg | 29.53dB
25-05-19 13:05:12.549 : -103--> mountain_111_10.jpg | 29.31dB
25-05-19 13:05:12.726 : -104--> mountain_111_11.jpg | 29.64dB
25-05-19 13:05:12.905 : -105--> overpass_111_00.jpg | 30.09dB
25-05-19 13:05:13.085 : -106--> overpass_111_01.jpg | 29.96dB
25-05-19 13:05:13.263 : -107--> overpass_111_10.jpg | 30.57dB
25-05-19 13:05:13.440 : -108--> overpass_111_11.jpg | 31.32dB
25-05-19 13:05:13.621 : -109--> palace_111_00.jpg | 30.00dB
25-05-19 13:05:13.808 : -110--> palace_111_01.jpg | 29.81dB
25-05-19 13:05:13.983 : -111--> palace_111_10.jpg | 31.01dB
25-05-19 13:05:14.169 : -112--> palace_111_11.jpg | 29.38dB
25-05-19 13:05:14.342 : -113--> parking_lot_111_00.jpg | 29.32dB
25-05-19 13:05:14.527 : -114--> parking_lot_111_01.jpg | 29.58dB
25-05-19 13:05:14.706 : -115--> parking_lot_111_10.jpg | 31.12dB
25-05-19 13:05:14.886 : -116--> parking_lot_111_11.jpg | 29.98dB
25-05-19 13:05:15.067 : -117--> railway_111_00.jpg | 30.13dB
25-05-19 13:05:15.242 : -118--> railway_111_01.jpg | 29.67dB
25-05-19 13:05:15.427 : -119--> railway_111_10.jpg | 32.44dB
25-05-19 13:05:15.601 : -120--> railway_111_11.jpg | 29.05dB
25-05-19 13:05:15.781 : -121--> railway_station_111_00.jpg | 30.81dB
25-05-19 13:05:15.955 : -122--> railway_station_111_01.jpg | 31.32dB
25-05-19 13:05:16.135 : -123--> railway_station_111_10.jpg | 31.01dB
25-05-19 13:05:16.320 : -124--> railway_station_111_11.jpg | 31.52dB
25-05-19 13:05:16.497 : -125--> rectangular_farmland_111_00.jpg | 33.35dB
25-05-19 13:05:16.675 : -126--> rectangular_farmland_111_01.jpg | 31.82dB
25-05-19 13:05:16.852 : -127--> rectangular_farmland_111_10.jpg | 33.77dB
25-05-19 13:05:17.036 : -128--> rectangular_farmland_111_11.jpg | 34.06dB
25-05-19 13:05:17.214 : -129--> river_111_00.jpg | 30.13dB
25-05-19 13:05:17.391 : -130--> river_111_01.jpg | 29.97dB
25-05-19 13:05:17.572 : -131--> river_111_10.jpg | 29.46dB
25-05-19 13:05:17.750 : -132--> river_111_11.jpg | 31.30dB
25-05-19 13:05:17.933 : -133--> roundabout_111_00.jpg | 30.43dB
25-05-19 13:05:18.115 : -134--> roundabout_111_01.jpg | 32.04dB
25-05-19 13:05:18.291 : -135--> roundabout_111_10.jpg | 30.36dB
25-05-19 13:05:18.473 : -136--> roundabout_111_11.jpg | 30.69dB
25-05-19 13:05:18.652 : -137--> runway_111_00.jpg | 36.41dB
25-05-19 13:05:18.832 : -138--> runway_111_01.jpg | 35.78dB
25-05-19 13:05:19.013 : -139--> runway_111_10.jpg | 36.48dB
25-05-19 13:05:19.191 : -140--> runway_111_11.jpg | 37.41dB
25-05-19 13:05:19.374 : -141--> sea_ice_111_00.jpg | 33.58dB
25-05-19 13:05:19.553 : -142--> sea_ice_111_01.jpg | 34.66dB
25-05-19 13:05:19.732 : -143--> sea_ice_111_10.jpg | 33.60dB
25-05-19 13:05:19.908 : -144--> sea_ice_111_11.jpg | 34.67dB
25-05-19 13:05:20.086 : -145--> ship_111_00.jpg | 38.56dB
25-05-19 13:05:20.265 : -146--> ship_111_01.jpg | 34.51dB
25-05-19 13:05:20.445 : -147--> ship_111_10.jpg | 42.69dB
25-05-19 13:05:20.624 : -148--> ship_111_11.jpg | 39.99dB
25-05-19 13:05:20.808 : -149--> snowberg_111_00.jpg | 34.15dB
25-05-19 13:05:20.982 : -150--> snowberg_111_01.jpg | 32.77dB
25-05-19 13:05:21.166 : -151--> snowberg_111_10.jpg | 31.96dB
25-05-19 13:05:21.344 : -152--> snowberg_111_11.jpg | 31.97dB
25-05-19 13:05:21.521 : -153--> sparse_residential_111_00.jpg | 30.43dB
25-05-19 13:05:21.696 : -154--> sparse_residential_111_01.jpg | 30.68dB
25-05-19 13:05:21.878 : -155--> sparse_residential_111_10.jpg | 29.73dB
25-05-19 13:05:22.052 : -156--> sparse_residential_111_11.jpg | 30.01dB
25-05-19 13:05:22.232 : -157--> stadium_111_00.jpg | 30.21dB
25-05-19 13:05:22.410 : -158--> stadium_111_01.jpg | 30.07dB
25-05-19 13:05:22.595 : -159--> stadium_111_10.jpg | 31.37dB
25-05-19 13:05:22.769 : -160--> stadium_111_11.jpg | 30.16dB
25-05-19 13:05:22.953 : -161--> storage_tank_111_00.jpg | 31.86dB
25-05-19 13:05:23.140 : -162--> storage_tank_111_01.jpg | 32.00dB
25-05-19 13:05:23.313 : -163--> storage_tank_111_10.jpg | 30.80dB
25-05-19 13:05:23.489 : -164--> storage_tank_111_11.jpg | 31.26dB
25-05-19 13:05:23.670 : -165--> tennis_court_111_00.jpg | 31.97dB
25-05-19 13:05:23.846 : -166--> tennis_court_111_01.jpg | 31.50dB
25-05-19 13:05:24.027 : -167--> tennis_court_111_10.jpg | 31.72dB
25-05-19 13:05:24.207 : -168--> tennis_court_111_11.jpg | 29.63dB
25-05-19 13:05:24.386 : -169--> terrace_111_00.jpg | 32.24dB
25-05-19 13:05:24.567 : -170--> terrace_111_01.jpg | 33.32dB
25-05-19 13:05:24.740 : -171--> terrace_111_10.jpg | 32.29dB
25-05-19 13:05:24.926 : -172--> terrace_111_11.jpg | 32.30dB
25-05-19 13:05:25.106 : -173--> thermal_power_station_111_00.jpg | 30.09dB
25-05-19 13:05:25.284 : -174--> thermal_power_station_111_01.jpg | 31.67dB
25-05-19 13:05:25.464 : -175--> thermal_power_station_111_10.jpg | 29.86dB
25-05-19 13:05:25.640 : -176--> thermal_power_station_111_11.jpg | 30.44dB
25-05-19 13:05:25.815 : -177--> wetland_111_00.jpg | 31.38dB
25-05-19 13:05:25.998 : -178--> wetland_111_01.jpg | 31.41dB
25-05-19 13:05:26.175 : -179--> wetland_111_10.jpg | 31.64dB
25-05-19 13:05:26.354 : -180--> wetland_111_11.jpg | 30.98dB
25-05-19 13:05:26.362 : <epoch:  0, iter:  45,000, Average PSNR : 32.14dB

25-05-19 14:41:16.488 : <epoch:  0, iter:  50,000, lr:1.250e-05> G_loss: 1.584e-04 
25-05-19 14:41:16.490 : Saving the model.
25-05-19 14:41:17.283 : ---1--> airplane_111_00.jpg | 30.43dB
25-05-19 14:41:17.463 : ---2--> airplane_111_01.jpg | 35.35dB
25-05-19 14:41:17.641 : ---3--> airplane_111_10.jpg | 32.86dB
25-05-19 14:41:17.814 : ---4--> airplane_111_11.jpg | 32.93dB
25-05-19 14:41:17.993 : ---5--> airport_111_00.jpg | 34.48dB
25-05-19 14:41:18.177 : ---6--> airport_111_01.jpg | 32.37dB
25-05-19 14:41:18.355 : ---7--> airport_111_10.jpg | 31.90dB
25-05-19 14:41:18.534 : ---8--> airport_111_11.jpg | 32.90dB
25-05-19 14:41:18.712 : ---9--> baseball_diamond_111_00.jpg | 32.70dB
25-05-19 14:41:18.890 : --10--> baseball_diamond_111_01.jpg | 34.32dB
25-05-19 14:41:19.067 : --11--> baseball_diamond_111_10.jpg | 32.56dB
25-05-19 14:41:19.242 : --12--> baseball_diamond_111_11.jpg | 35.37dB
25-05-19 14:41:19.422 : --13--> basketball_court_111_00.jpg | 30.55dB
25-05-19 14:41:19.597 : --14--> basketball_court_111_01.jpg | 30.11dB
25-05-19 14:41:19.778 : --15--> basketball_court_111_10.jpg | 33.39dB
25-05-19 14:41:19.952 : --16--> basketball_court_111_11.jpg | 31.63dB
25-05-19 14:41:20.134 : --17--> beach_111_00.jpg | 28.60dB
25-05-19 14:41:20.309 : --18--> beach_111_01.jpg | 31.75dB
25-05-19 14:41:20.495 : --19--> beach_111_10.jpg | 29.76dB
25-05-19 14:41:20.669 : --20--> beach_111_11.jpg | 34.40dB
25-05-19 14:41:20.847 : --21--> bridge_111_00.jpg | 40.87dB
25-05-19 14:41:21.027 : --22--> bridge_111_01.jpg | 34.34dB
25-05-19 14:41:21.205 : --23--> bridge_111_10.jpg | 33.24dB
25-05-19 14:41:21.381 : --24--> bridge_111_11.jpg | 36.65dB
25-05-19 14:41:21.562 : --25--> chaparral_111_00.jpg | 30.31dB
25-05-19 14:41:21.741 : --26--> chaparral_111_01.jpg | 30.57dB
25-05-19 14:41:21.917 : --27--> chaparral_111_10.jpg | 30.87dB
25-05-19 14:41:22.092 : --28--> chaparral_111_11.jpg | 28.69dB
25-05-19 14:41:22.271 : --29--> church_111_00.jpg | 31.62dB
25-05-19 14:41:22.452 : --30--> church_111_01.jpg | 30.60dB
25-05-19 14:41:22.630 : --31--> church_111_10.jpg | 34.39dB
25-05-19 14:41:22.809 : --32--> church_111_11.jpg | 30.44dB
25-05-19 14:41:22.987 : --33--> circular_farmland_111_00.jpg | 32.77dB
25-05-19 14:41:23.164 : --34--> circular_farmland_111_01.jpg | 33.77dB
25-05-19 14:41:23.344 : --35--> circular_farmland_111_10.jpg | 33.97dB
25-05-19 14:41:23.524 : --36--> circular_farmland_111_11.jpg | 34.12dB
25-05-19 14:41:23.703 : --37--> cloud_111_00.jpg | 40.98dB
25-05-19 14:41:23.881 : --38--> cloud_111_01.jpg | 36.83dB
25-05-19 14:41:24.059 : --39--> cloud_111_10.jpg | 36.35dB
25-05-19 14:41:24.238 : --40--> cloud_111_11.jpg | 36.82dB
25-05-19 14:41:24.418 : --41--> commercial_area_111_00.jpg | 33.33dB
25-05-19 14:41:24.594 : --42--> commercial_area_111_01.jpg | 32.37dB
25-05-19 14:41:24.773 : --43--> commercial_area_111_10.jpg | 33.13dB
25-05-19 14:41:24.955 : --44--> commercial_area_111_11.jpg | 33.03dB
25-05-19 14:41:25.135 : --45--> dense_residential_111_00.jpg | 30.17dB
25-05-19 14:41:25.314 : --46--> dense_residential_111_01.jpg | 29.25dB
25-05-19 14:41:25.491 : --47--> dense_residential_111_10.jpg | 29.66dB
25-05-19 14:41:25.675 : --48--> dense_residential_111_11.jpg | 29.53dB
25-05-19 14:41:25.854 : --49--> desert_111_00.jpg | 36.85dB
25-05-19 14:41:26.035 : --50--> desert_111_01.jpg | 36.76dB
25-05-19 14:41:26.218 : --51--> desert_111_10.jpg | 36.92dB
25-05-19 14:41:26.393 : --52--> desert_111_11.jpg | 37.00dB
25-05-19 14:41:26.572 : --53--> forest_111_00.jpg | 33.01dB
25-05-19 14:41:26.755 : --54--> forest_111_01.jpg | 32.11dB
25-05-19 14:41:26.930 : --55--> forest_111_10.jpg | 31.74dB
25-05-19 14:41:27.107 : --56--> forest_111_11.jpg | 32.65dB
25-05-19 14:41:27.283 : --57--> freeway_111_00.jpg | 33.84dB
25-05-19 14:41:27.467 : --58--> freeway_111_01.jpg | 34.95dB
25-05-19 14:41:27.650 : --59--> freeway_111_10.jpg | 34.78dB
25-05-19 14:41:27.829 : --60--> freeway_111_11.jpg | 34.81dB
25-05-19 14:41:28.010 : --61--> golf_course_111_00.jpg | 32.72dB
25-05-19 14:41:28.194 : --62--> golf_course_111_01.jpg | 32.11dB
25-05-19 14:41:28.376 : --63--> golf_course_111_10.jpg | 33.51dB
25-05-19 14:41:28.558 : --64--> golf_course_111_11.jpg | 33.88dB
25-05-19 14:41:28.736 : --65--> ground_track_field_111_00.jpg | 33.35dB
25-05-19 14:41:28.913 : --66--> ground_track_field_111_01.jpg | 29.38dB
25-05-19 14:41:29.092 : --67--> ground_track_field_111_10.jpg | 30.77dB
25-05-19 14:41:29.277 : --68--> ground_track_field_111_11.jpg | 29.99dB
25-05-19 14:41:29.456 : --69--> harbor_111_00.jpg | 32.84dB
25-05-19 14:41:29.635 : --70--> harbor_111_01.jpg | 31.16dB
25-05-19 14:41:29.814 : --71--> harbor_111_10.jpg | 30.73dB
25-05-19 14:41:29.994 : --72--> harbor_111_11.jpg | 32.41dB
25-05-19 14:41:30.169 : --73--> industrial_area_111_00.jpg | 31.56dB
25-05-19 14:41:30.351 : --74--> industrial_area_111_01.jpg | 31.82dB
25-05-19 14:41:30.535 : --75--> industrial_area_111_10.jpg | 31.93dB
25-05-19 14:41:30.714 : --76--> industrial_area_111_11.jpg | 31.34dB
25-05-19 14:41:30.895 : --77--> intersection_111_00.jpg | 30.62dB
25-05-19 14:41:31.075 : --78--> intersection_111_01.jpg | 30.74dB
25-05-19 14:41:31.251 : --79--> intersection_111_10.jpg | 30.45dB
25-05-19 14:41:31.428 : --80--> intersection_111_11.jpg | 30.24dB
25-05-19 14:41:31.605 : --81--> island_111_00.jpg | 31.43dB
25-05-19 14:41:31.795 : --82--> island_111_01.jpg | 33.85dB
25-05-19 14:41:31.971 : --83--> island_111_10.jpg | 32.47dB
25-05-19 14:41:32.155 : --84--> island_111_11.jpg | 32.05dB
25-05-19 14:41:32.334 : --85--> lake_111_00.jpg | 32.50dB
25-05-19 14:41:32.512 : --86--> lake_111_01.jpg | 32.29dB
25-05-19 14:41:32.692 : --87--> lake_111_10.jpg | 31.62dB
25-05-19 14:41:32.867 : --88--> lake_111_11.jpg | 31.04dB
25-05-19 14:41:33.048 : --89--> meadow_111_00.jpg | 30.05dB
25-05-19 14:41:33.227 : --90--> meadow_111_01.jpg | 30.15dB
25-05-19 14:41:33.413 : --91--> meadow_111_10.jpg | 30.20dB
25-05-19 14:41:33.591 : --92--> meadow_111_11.jpg | 30.35dB
25-05-19 14:41:33.770 : --93--> medium_residential_111_00.jpg | 28.69dB
25-05-19 14:41:33.953 : --94--> medium_residential_111_01.jpg | 28.16dB
25-05-19 14:41:34.137 : --95--> medium_residential_111_10.jpg | 28.51dB
25-05-19 14:41:34.311 : --96--> medium_residential_111_11.jpg | 29.02dB
25-05-19 14:41:34.487 : --97--> mobile_home_park_111_00.jpg | 30.97dB
25-05-19 14:41:34.667 : --98--> mobile_home_park_111_01.jpg | 31.45dB
25-05-19 14:41:34.851 : --99--> mobile_home_park_111_10.jpg | 31.77dB
25-05-19 14:41:35.028 : -100--> mobile_home_park_111_11.jpg | 31.83dB
25-05-19 14:41:35.209 : -101--> mountain_111_00.jpg | 28.87dB
25-05-19 14:41:35.393 : -102--> mountain_111_01.jpg | 29.53dB
25-05-19 14:41:35.573 : -103--> mountain_111_10.jpg | 29.30dB
25-05-19 14:41:35.754 : -104--> mountain_111_11.jpg | 29.63dB
25-05-19 14:41:35.932 : -105--> overpass_111_00.jpg | 30.10dB
25-05-19 14:41:36.116 : -106--> overpass_111_01.jpg | 29.99dB
25-05-19 14:41:36.295 : -107--> overpass_111_10.jpg | 30.58dB
25-05-19 14:41:36.473 : -108--> overpass_111_11.jpg | 31.33dB
25-05-19 14:41:36.651 : -109--> palace_111_00.jpg | 30.03dB
25-05-19 14:41:36.830 : -110--> palace_111_01.jpg | 29.83dB
25-05-19 14:41:37.018 : -111--> palace_111_10.jpg | 31.01dB
25-05-19 14:41:37.199 : -112--> palace_111_11.jpg | 29.38dB
25-05-19 14:41:37.384 : -113--> parking_lot_111_00.jpg | 29.32dB
25-05-19 14:41:37.570 : -114--> parking_lot_111_01.jpg | 29.58dB
25-05-19 14:41:37.754 : -115--> parking_lot_111_10.jpg | 31.14dB
25-05-19 14:41:37.941 : -116--> parking_lot_111_11.jpg | 30.00dB
25-05-19 14:41:38.125 : -117--> railway_111_00.jpg | 30.14dB
25-05-19 14:41:38.312 : -118--> railway_111_01.jpg | 29.67dB
25-05-19 14:41:38.494 : -119--> railway_111_10.jpg | 32.44dB
25-05-19 14:41:38.681 : -120--> railway_111_11.jpg | 29.03dB
25-05-19 14:41:38.865 : -121--> railway_station_111_00.jpg | 30.81dB
25-05-19 14:41:39.046 : -122--> railway_station_111_01.jpg | 31.33dB
25-05-19 14:41:39.225 : -123--> railway_station_111_10.jpg | 31.01dB
25-05-19 14:41:39.407 : -124--> railway_station_111_11.jpg | 31.52dB
25-05-19 14:41:39.586 : -125--> rectangular_farmland_111_00.jpg | 33.41dB
25-05-19 14:41:39.767 : -126--> rectangular_farmland_111_01.jpg | 31.87dB
25-05-19 14:41:39.950 : -127--> rectangular_farmland_111_10.jpg | 33.76dB
25-05-19 14:41:40.135 : -128--> rectangular_farmland_111_11.jpg | 34.08dB
25-05-19 14:41:40.314 : -129--> river_111_00.jpg | 30.14dB
25-05-19 14:41:40.492 : -130--> river_111_01.jpg | 29.98dB
25-05-19 14:41:40.673 : -131--> river_111_10.jpg | 29.47dB
25-05-19 14:41:40.858 : -132--> river_111_11.jpg | 31.30dB
25-05-19 14:41:41.041 : -133--> roundabout_111_00.jpg | 30.44dB
25-05-19 14:41:41.224 : -134--> roundabout_111_01.jpg | 32.04dB
25-05-19 14:41:41.408 : -135--> roundabout_111_10.jpg | 30.35dB
25-05-19 14:41:41.586 : -136--> roundabout_111_11.jpg | 30.71dB
25-05-19 14:41:41.770 : -137--> runway_111_00.jpg | 36.44dB
25-05-19 14:41:41.950 : -138--> runway_111_01.jpg | 35.80dB
25-05-19 14:41:42.130 : -139--> runway_111_10.jpg | 36.46dB
25-05-19 14:41:42.314 : -140--> runway_111_11.jpg | 37.43dB
25-05-19 14:41:42.495 : -141--> sea_ice_111_00.jpg | 33.62dB
25-05-19 14:41:42.676 : -142--> sea_ice_111_01.jpg | 34.70dB
25-05-19 14:41:42.857 : -143--> sea_ice_111_10.jpg | 33.62dB
25-05-19 14:41:43.036 : -144--> sea_ice_111_11.jpg | 34.66dB
25-05-19 14:41:43.218 : -145--> ship_111_00.jpg | 38.57dB
25-05-19 14:41:43.402 : -146--> ship_111_01.jpg | 34.56dB
25-05-19 14:41:43.578 : -147--> ship_111_10.jpg | 42.77dB
25-05-19 14:41:43.762 : -148--> ship_111_11.jpg | 40.03dB
25-05-19 14:41:43.941 : -149--> snowberg_111_00.jpg | 34.15dB
25-05-19 14:41:44.120 : -150--> snowberg_111_01.jpg | 32.76dB
25-05-19 14:41:44.298 : -151--> snowberg_111_10.jpg | 31.95dB
25-05-19 14:41:44.479 : -152--> snowberg_111_11.jpg | 31.96dB
25-05-19 14:41:44.658 : -153--> sparse_residential_111_00.jpg | 30.44dB
25-05-19 14:41:44.840 : -154--> sparse_residential_111_01.jpg | 30.69dB
25-05-19 14:41:45.020 : -155--> sparse_residential_111_10.jpg | 29.74dB
25-05-19 14:41:45.197 : -156--> sparse_residential_111_11.jpg | 30.02dB
25-05-19 14:41:45.377 : -157--> stadium_111_00.jpg | 30.23dB
25-05-19 14:41:45.559 : -158--> stadium_111_01.jpg | 30.09dB
25-05-19 14:41:45.741 : -159--> stadium_111_10.jpg | 31.38dB
25-05-19 14:41:45.922 : -160--> stadium_111_11.jpg | 30.17dB
25-05-19 14:41:46.104 : -161--> storage_tank_111_00.jpg | 31.85dB
25-05-19 14:41:46.289 : -162--> storage_tank_111_01.jpg | 32.01dB
25-05-19 14:41:46.468 : -163--> storage_tank_111_10.jpg | 30.80dB
25-05-19 14:41:46.652 : -164--> storage_tank_111_11.jpg | 31.26dB
25-05-19 14:41:46.834 : -165--> tennis_court_111_00.jpg | 32.01dB
25-05-19 14:41:47.013 : -166--> tennis_court_111_01.jpg | 31.52dB
25-05-19 14:41:47.194 : -167--> tennis_court_111_10.jpg | 31.77dB
25-05-19 14:41:47.373 : -168--> tennis_court_111_11.jpg | 29.64dB
25-05-19 14:41:47.554 : -169--> terrace_111_00.jpg | 32.23dB
25-05-19 14:41:47.734 : -170--> terrace_111_01.jpg | 33.34dB
25-05-19 14:41:47.914 : -171--> terrace_111_10.jpg | 32.30dB
25-05-19 14:41:48.100 : -172--> terrace_111_11.jpg | 32.31dB
25-05-19 14:41:48.279 : -173--> thermal_power_station_111_00.jpg | 30.09dB
25-05-19 14:41:48.463 : -174--> thermal_power_station_111_01.jpg | 31.68dB
25-05-19 14:41:48.643 : -175--> thermal_power_station_111_10.jpg | 29.85dB
25-05-19 14:41:48.822 : -176--> thermal_power_station_111_11.jpg | 30.45dB
25-05-19 14:41:49.002 : -177--> wetland_111_00.jpg | 31.38dB
25-05-19 14:41:49.185 : -178--> wetland_111_01.jpg | 31.41dB
25-05-19 14:41:49.362 : -179--> wetland_111_10.jpg | 31.65dB
25-05-19 14:41:49.538 : -180--> wetland_111_11.jpg | 30.99dB
25-05-19 14:41:49.548 : <epoch:  0, iter:  50,000, Average PSNR : 32.15dB

25-05-22 10:55:26.498 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/100_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 25
      sigma_test: 25
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test_4fen
      dataroot_L: None
      sigma: 25
      sigma_test: 25
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [30000, 50000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 5000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-22 10:55:26.498 : Random seed: 5609
25-05-22 10:55:26.824 : Number of train images: 31,005, iters: 31,005
25-05-22 10:55:29.267 : 
Networks name: DRNet
Params number: 18333721
Net structure:
DRNet(
  (m_head): Sequential(
    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (m_down1): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down2): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down3): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_body): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up3): Sequential(
    (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up2): Sequential(
    (0): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up1): Sequential(
    (0): ConvTranspose2d(192, 96, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_tail): Sequential(
    (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (fft): ResBlock_fft_bench(
    (mag): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
    (mag_bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (mag_relu): ReLU(inplace=True)
    (pha): Sequential(
      (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (4): Sigmoid()
    )
    (conv1): Conv2d(6, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
  (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (conv2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
  (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu2): ReLU()
  (conv3): Conv2d(96, 384, kernel_size=(4, 4), stride=(4, 4))
  (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu3): ReLU()
)

25-05-22 10:55:30.035 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.001 | -0.166 |  0.188 |  0.042 | torch.Size([96, 3, 3, 3]) || m_head.0.weight
 |  1.000 |  0.690 |  1.333 |  0.155 | torch.Size([32]) || m_down1.0.trans_block.ln1.weight
 | -0.026 | -0.272 |  0.279 |  0.131 | torch.Size([32]) || m_down1.0.trans_block.ln1.bias
 | -0.078 | -0.695 |  1.039 |  0.371 | torch.Size([1, 15, 15]) || m_down1.0.trans_block.msa.relative_position_params
 |  0.000 | -0.284 |  0.324 |  0.060 | torch.Size([96, 32, 1, 1]) || m_down1.0.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.110 |  0.107 |  0.047 | torch.Size([96]) || m_down1.0.trans_block.msa.embedding_layer1.bias
 |  0.002 | -0.174 |  0.223 |  0.053 | torch.Size([32, 32, 1, 1]) || m_down1.0.trans_block.msa.linear1.weight
 |  0.005 | -0.078 |  0.114 |  0.051 | torch.Size([32]) || m_down1.0.trans_block.msa.linear1.bias
 |  1.186 |  1.012 |  1.426 |  0.113 | torch.Size([32]) || m_down1.0.trans_block.ln2.weight
 | -0.010 | -0.165 |  0.135 |  0.059 | torch.Size([32]) || m_down1.0.trans_block.ln2.bias
 |  0.005 | -0.586 |  1.295 |  0.114 | torch.Size([128, 32]) || m_down1.0.trans_block.mlp.0.weight
 | -0.023 | -0.187 |  0.150 |  0.069 | torch.Size([128]) || m_down1.0.trans_block.mlp.0.bias
 |  0.000 | -0.460 |  0.717 |  0.086 | torch.Size([32, 128]) || m_down1.0.trans_block.mlp.2.weight
 | -0.004 | -0.113 |  0.275 |  0.090 | torch.Size([32]) || m_down1.0.trans_block.mlp.2.bias
 |  0.006 | -0.481 |  0.460 |  0.094 | torch.Size([96, 96, 1, 1]) || m_down1.0.conv1_1.weight
 | -0.003 | -0.432 |  0.406 |  0.110 | torch.Size([96]) || m_down1.0.conv1_1.bias
 | -0.092 | -0.180 |  0.001 |  0.090 | torch.Size([1, 1, 1, 1, 3]) || m_down1.0.conv3d.weight
 | -0.024 | -0.024 | -0.024 |    nan | torch.Size([1]) || m_down1.0.conv3d.bias
 |  0.006 | -0.337 |  0.475 |  0.073 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.0.weight
 | -0.004 | -0.470 |  0.358 |  0.072 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.2.weight
 |  1.906 | -2.333 |  2.825 |  0.813 | torch.Size([64, 16]) || m_down1.0.mamba_layers.0.mixer.A_log
 |  1.081 |  0.345 |  1.364 |  0.174 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.D
 | -0.000 | -0.468 |  0.530 |  0.121 | torch.Size([128, 32]) || m_down1.0.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.436 |  0.458 |  0.166 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.0.mixer.conv1d.weight
 | -0.011 | -0.234 |  0.181 |  0.088 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.889 |  0.703 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.0.mixer.x_proj.weight
 |  0.005 | -0.791 |  0.938 |  0.248 | torch.Size([64, 2]) || m_down1.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.077 | -1.579 |  0.442 |  0.373 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.629 |  0.546 |  0.115 | torch.Size([32, 64]) || m_down1.0.mamba_layers.0.mixer.out_proj.weight
 |  1.133 |  0.910 |  1.650 |  0.129 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.weight
 |  0.013 | -0.367 |  0.299 |  0.157 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.bias
 |  1.905 | -0.797 |  2.773 |  0.795 | torch.Size([64, 16]) || m_down1.0.mamba_layers.1.mixer.A_log
 |  1.161 |  0.905 |  1.359 |  0.086 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.D
 |  0.001 | -0.586 |  0.458 |  0.127 | torch.Size([128, 32]) || m_down1.0.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.365 |  0.485 |  0.156 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.1.mixer.conv1d.weight
 | -0.004 | -0.303 |  0.279 |  0.165 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.563 |  0.743 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.1.mixer.x_proj.weight
 |  0.013 | -0.312 |  0.472 |  0.146 | torch.Size([64, 2]) || m_down1.0.mamba_layers.1.mixer.dt_proj.weight
 |  0.052 | -0.313 |  0.269 |  0.122 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.003 | -0.367 |  0.425 |  0.118 | torch.Size([32, 64]) || m_down1.0.mamba_layers.1.mixer.out_proj.weight
 |  1.170 |  0.994 |  1.344 |  0.097 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.weight
 | -0.005 | -0.256 |  0.350 |  0.138 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.bias
 |  1.917 | -0.070 |  2.775 |  0.765 | torch.Size([64, 16]) || m_down1.0.mamba_layers.2.mixer.A_log
 |  1.018 |  0.941 |  1.120 |  0.038 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.D
 |  0.000 | -0.340 |  0.349 |  0.107 | torch.Size([128, 32]) || m_down1.0.mamba_layers.2.mixer.in_proj.weight
 | -0.012 | -0.582 |  0.568 |  0.294 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.2.mixer.conv1d.weight
 | -0.031 | -0.499 |  0.487 |  0.284 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.219 |  0.189 |  0.076 | torch.Size([34, 64]) || m_down1.0.mamba_layers.2.mixer.x_proj.weight
 | -0.055 | -0.705 |  0.714 |  0.417 | torch.Size([64, 2]) || m_down1.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.715 | -6.856 | -2.311 |  1.285 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.dt_proj.bias
 | -0.003 | -0.242 |  0.287 |  0.083 | torch.Size([32, 64]) || m_down1.0.mamba_layers.2.mixer.out_proj.weight
 |  1.005 |  0.927 |  1.096 |  0.037 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.weight
 |  0.006 | -0.039 |  0.061 |  0.023 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.bias
 |  1.916 | -0.244 |  2.776 |  0.766 | torch.Size([64, 16]) || m_down1.0.mamba_layers.3.mixer.A_log
 |  1.011 |  0.942 |  1.097 |  0.034 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.D
 |  0.003 | -0.276 |  0.271 |  0.106 | torch.Size([128, 32]) || m_down1.0.mamba_layers.3.mixer.in_proj.weight
 |  0.004 | -0.596 |  0.566 |  0.297 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.3.mixer.conv1d.weight
 | -0.071 | -0.626 |  0.545 |  0.307 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.201 |  0.214 |  0.076 | torch.Size([34, 64]) || m_down1.0.mamba_layers.3.mixer.x_proj.weight
 |  0.039 | -0.688 |  0.780 |  0.425 | torch.Size([64, 2]) || m_down1.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.400 | -7.091 | -2.271 |  1.482 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.241 |  0.288 |  0.083 | torch.Size([32, 64]) || m_down1.0.mamba_layers.3.mixer.out_proj.weight
 |  1.000 |  0.945 |  1.041 |  0.024 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.weight
 | -0.003 | -0.041 |  0.032 |  0.020 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.bias
 |  0.172 |  0.084 |  0.261 |  0.125 | torch.Size([2]) || m_down1.0.pcbam_module.h_cw.weight
 |  0.094 | -0.058 |  0.226 |  0.143 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.h_cw.conv.weight
 |  0.559 |  0.261 |  0.856 |  0.421 | torch.Size([2]) || m_down1.0.pcbam_module.w_hc.weight
 |  0.076 | -0.096 |  0.188 |  0.151 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.w_hc.conv.weight
 |  0.612 |  0.582 |  0.641 |  0.042 | torch.Size([2]) || m_down1.0.pcbam_module.c_hw.weight
 |  0.040 | -0.233 |  0.379 |  0.311 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.c_hw.conv.weight
 |  1.055 |  0.769 |  1.285 |  0.145 | torch.Size([32]) || m_down1.1.trans_block.ln1.weight
 |  0.019 | -0.283 |  0.280 |  0.134 | torch.Size([32]) || m_down1.1.trans_block.ln1.bias
 | -0.225 | -0.784 |  0.824 |  0.322 | torch.Size([1, 15, 15]) || m_down1.1.trans_block.msa.relative_position_params
 |  0.001 | -0.380 |  0.366 |  0.088 | torch.Size([96, 32, 1, 1]) || m_down1.1.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.193 |  0.185 |  0.052 | torch.Size([96]) || m_down1.1.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.196 |  0.207 |  0.053 | torch.Size([32, 32, 1, 1]) || m_down1.1.trans_block.msa.linear1.weight
 |  0.000 | -0.139 |  0.101 |  0.048 | torch.Size([32]) || m_down1.1.trans_block.msa.linear1.bias
 |  1.164 |  0.991 |  1.293 |  0.073 | torch.Size([32]) || m_down1.1.trans_block.ln2.weight
 | -0.000 | -0.123 |  0.174 |  0.067 | torch.Size([32]) || m_down1.1.trans_block.ln2.bias
 | -0.001 | -0.905 |  0.562 |  0.114 | torch.Size([128, 32]) || m_down1.1.trans_block.mlp.0.weight
 | -0.011 | -0.235 |  0.116 |  0.054 | torch.Size([128]) || m_down1.1.trans_block.mlp.0.bias
 | -0.000 | -0.661 |  0.622 |  0.099 | torch.Size([32, 128]) || m_down1.1.trans_block.mlp.2.weight
 | -0.009 | -0.120 |  0.228 |  0.080 | torch.Size([32]) || m_down1.1.trans_block.mlp.2.bias
 |  0.006 | -0.455 |  0.573 |  0.096 | torch.Size([96, 96, 1, 1]) || m_down1.1.conv1_1.weight
 | -0.008 | -0.200 |  0.272 |  0.064 | torch.Size([96]) || m_down1.1.conv1_1.bias
 | -0.077 | -0.289 |  0.036 |  0.183 | torch.Size([1, 1, 1, 1, 3]) || m_down1.1.conv3d.weight
 | -0.012 | -0.012 | -0.012 |    nan | torch.Size([1]) || m_down1.1.conv3d.bias
 | -0.002 | -0.406 |  0.342 |  0.064 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.0.weight
 | -0.006 | -0.314 |  0.292 |  0.064 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.2.weight
 |  1.917 | -0.011 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.0.mixer.A_log
 |  1.048 |  0.985 |  1.166 |  0.047 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.D
 | -0.000 | -0.443 |  0.430 |  0.086 | torch.Size([128, 32]) || m_down1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.015 | -0.304 |  0.314 |  0.114 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.0.mixer.conv1d.weight
 |  0.015 | -0.205 |  0.208 |  0.064 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.142 |  0.135 |  0.031 | torch.Size([34, 64]) || m_down1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.002 | -0.062 |  0.053 |  0.025 | torch.Size([64, 2]) || m_down1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.001 | -0.024 |  0.032 |  0.009 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.369 |  0.356 |  0.083 | torch.Size([32, 64]) || m_down1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.113 |  0.927 |  1.290 |  0.105 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.weight
 |  0.012 | -0.156 |  0.187 |  0.076 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.bias
 |  1.918 | -0.212 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.1.mixer.A_log
 |  1.091 |  0.987 |  1.491 |  0.090 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.D
 |  0.000 | -0.626 |  0.634 |  0.094 | torch.Size([128, 32]) || m_down1.1.mamba_layers.1.mixer.in_proj.weight
 |  0.001 | -0.329 |  0.372 |  0.124 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.196 |  0.186 |  0.088 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.001 | -0.183 |  0.294 |  0.048 | torch.Size([34, 64]) || m_down1.1.mamba_layers.1.mixer.x_proj.weight
 |  0.006 | -0.151 |  0.153 |  0.037 | torch.Size([64, 2]) || m_down1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.008 | -0.160 |  0.449 |  0.077 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.004 | -0.548 |  0.372 |  0.087 | torch.Size([32, 64]) || m_down1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.134 |  1.020 |  1.298 |  0.072 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.weight
 | -0.002 | -0.096 |  0.087 |  0.053 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.bias
 |  1.917 | -0.016 |  2.774 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.2.mixer.A_log
 |  1.000 |  0.959 |  1.044 |  0.021 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.D
 | -0.001 | -0.232 |  0.277 |  0.106 | torch.Size([128, 32]) || m_down1.1.mamba_layers.2.mixer.in_proj.weight
 | -0.024 | -0.515 |  0.512 |  0.285 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.2.mixer.conv1d.weight
 | -0.017 | -0.508 |  0.448 |  0.282 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.151 |  0.153 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.2.mixer.x_proj.weight
 |  0.092 | -0.700 |  0.704 |  0.396 | torch.Size([64, 2]) || m_down1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.418 | -6.864 | -2.343 |  1.239 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.223 |  0.208 |  0.075 | torch.Size([32, 64]) || m_down1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.000 |  0.965 |  1.039 |  0.021 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.weight
 |  0.002 | -0.037 |  0.031 |  0.016 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.bias
 |  1.917 | -0.041 |  2.777 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.3.mixer.A_log
 |  1.006 |  0.963 |  1.083 |  0.027 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.296 |  0.355 |  0.109 | torch.Size([128, 32]) || m_down1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.023 | -0.521 |  0.538 |  0.299 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.3.mixer.conv1d.weight
 |  0.047 | -0.418 |  0.512 |  0.241 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.156 |  0.181 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.694 |  0.699 |  0.380 | torch.Size([64, 2]) || m_down1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.585 | -6.892 | -2.263 |  1.350 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.001 | -0.238 |  0.246 |  0.078 | torch.Size([32, 64]) || m_down1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.025 |  0.962 |  1.116 |  0.037 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.weight
 | -0.001 | -0.048 |  0.055 |  0.028 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.bias
 |  0.133 |  0.115 |  0.151 |  0.025 | torch.Size([2]) || m_down1.1.pcbam_module.h_cw.weight
 |  0.159 |  0.056 |  0.311 |  0.134 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.h_cw.conv.weight
 |  0.356 |  0.181 |  0.530 |  0.247 | torch.Size([2]) || m_down1.1.pcbam_module.w_hc.weight
 |  0.196 |  0.121 |  0.253 |  0.068 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.w_hc.conv.weight
 |  0.723 |  0.569 |  0.877 |  0.218 | torch.Size([2]) || m_down1.1.pcbam_module.c_hw.weight
 | -0.098 | -0.318 |  0.113 |  0.215 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.322 |  0.291 |  0.051 | torch.Size([192, 96, 2, 2]) || m_down1.2.weight
 |  1.094 |  0.726 |  1.718 |  0.242 | torch.Size([64]) || m_down2.0.trans_block.ln1.weight
 | -0.005 | -0.464 |  0.477 |  0.219 | torch.Size([64]) || m_down2.0.trans_block.ln1.bias
 | -0.205 | -1.957 |  1.787 |  0.695 | torch.Size([2, 15, 15]) || m_down2.0.trans_block.msa.relative_position_params
 |  0.000 | -0.432 |  0.426 |  0.075 | torch.Size([192, 64, 1, 1]) || m_down2.0.trans_block.msa.embedding_layer1.weight
 | -0.005 | -0.203 |  0.184 |  0.046 | torch.Size([192]) || m_down2.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.243 |  0.233 |  0.051 | torch.Size([64, 64, 1, 1]) || m_down2.0.trans_block.msa.linear1.weight
 |  0.002 | -0.116 |  0.184 |  0.043 | torch.Size([64]) || m_down2.0.trans_block.msa.linear1.bias
 |  1.134 |  0.800 |  1.470 |  0.135 | torch.Size([64]) || m_down2.0.trans_block.ln2.weight
 |  0.008 | -0.138 |  0.250 |  0.071 | torch.Size([64]) || m_down2.0.trans_block.ln2.bias
 |  0.002 | -0.502 |  0.472 |  0.094 | torch.Size([256, 64]) || m_down2.0.trans_block.mlp.0.weight
 | -0.047 | -0.278 |  0.063 |  0.048 | torch.Size([256]) || m_down2.0.trans_block.mlp.0.bias
 |  0.001 | -0.387 |  0.367 |  0.072 | torch.Size([64, 256]) || m_down2.0.trans_block.mlp.2.weight
 |  0.022 | -0.105 |  0.114 |  0.048 | torch.Size([64]) || m_down2.0.trans_block.mlp.2.bias
 |  0.008 | -0.714 |  0.843 |  0.097 | torch.Size([192, 192, 1, 1]) || m_down2.0.conv1_1.weight
 |  0.003 | -0.553 |  0.627 |  0.115 | torch.Size([192]) || m_down2.0.conv1_1.bias
 | -0.075 | -0.231 |  0.012 |  0.135 | torch.Size([1, 1, 1, 1, 3]) || m_down2.0.conv3d.weight
 | -0.010 | -0.010 | -0.010 |    nan | torch.Size([1]) || m_down2.0.conv3d.bias
 |  0.001 | -0.403 |  0.407 |  0.059 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.0.weight
 | -0.000 | -0.270 |  0.382 |  0.060 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.0.mamba_layers.0.mixer.A_log
 |  1.008 |  0.996 |  1.123 |  0.022 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.D
 | -0.000 | -0.279 |  0.257 |  0.032 | torch.Size([256, 64]) || m_down2.0.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.288 |  0.301 |  0.062 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.138 |  0.069 |  0.025 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.062 |  0.058 |  0.018 | torch.Size([36, 128]) || m_down2.0.mamba_layers.0.mixer.x_proj.weight
 |  0.001 | -0.049 |  0.055 |  0.018 | torch.Size([128, 4]) || m_down2.0.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.001 |  0.001 |  0.000 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.224 |  0.271 |  0.033 | torch.Size([64, 128]) || m_down2.0.mamba_layers.0.mixer.out_proj.weight
 |  1.038 |  0.896 |  1.214 |  0.080 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.weight
 |  0.003 | -0.141 |  0.146 |  0.071 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.bias
 |  1.916 | -0.326 |  2.773 |  0.767 | torch.Size([128, 16]) || m_down2.0.mamba_layers.1.mixer.A_log
 |  1.033 |  0.993 |  1.252 |  0.053 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.D
 | -0.000 | -0.330 |  0.352 |  0.050 | torch.Size([256, 64]) || m_down2.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.333 |  0.428 |  0.092 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.1.mixer.conv1d.weight
 |  0.017 | -0.173 |  0.316 |  0.071 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.245 |  0.181 |  0.034 | torch.Size([36, 128]) || m_down2.0.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.093 |  0.087 |  0.021 | torch.Size([128, 4]) || m_down2.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.010 | -0.302 |  0.159 |  0.052 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.346 |  0.348 |  0.052 | torch.Size([64, 128]) || m_down2.0.mamba_layers.1.mixer.out_proj.weight
 |  1.053 |  0.926 |  1.208 |  0.072 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.weight
 |  0.002 | -0.248 |  0.239 |  0.129 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.bias
 |  1.917 | -0.026 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.2.mixer.A_log
 |  0.986 |  0.946 |  1.030 |  0.019 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.D
 |  0.000 | -0.205 |  0.194 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.2.mixer.in_proj.weight
 | -0.003 | -0.515 |  0.512 |  0.273 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.2.mixer.conv1d.weight
 | -0.026 | -0.511 |  0.497 |  0.296 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.130 |  0.212 |  0.052 | torch.Size([36, 128]) || m_down2.0.mamba_layers.2.mixer.x_proj.weight
 |  0.014 | -0.500 |  0.501 |  0.292 | torch.Size([128, 4]) || m_down2.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.641 | -6.908 | -2.258 |  1.372 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.205 |  0.194 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.2.mixer.out_proj.weight
 |  0.970 |  0.895 |  1.032 |  0.030 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.weight
 |  0.002 | -0.087 |  0.060 |  0.028 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.bias
 |  1.917 | -0.019 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.3.mixer.A_log
 |  0.989 |  0.936 |  1.054 |  0.017 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.D
 |  0.001 | -0.194 |  0.185 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.3.mixer.in_proj.weight
 | -0.001 | -0.548 |  0.520 |  0.274 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.486 |  0.485 |  0.289 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.199 |  0.242 |  0.053 | torch.Size([36, 128]) || m_down2.0.mamba_layers.3.mixer.x_proj.weight
 |  0.011 | -0.496 |  0.500 |  0.303 | torch.Size([128, 4]) || m_down2.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.465 | -6.853 | -2.276 |  1.292 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.187 |  0.229 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.3.mixer.out_proj.weight
 |  0.976 |  0.929 |  1.036 |  0.024 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.weight
 | -0.002 | -0.041 |  0.063 |  0.022 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.bias
 |  0.628 |  0.129 |  1.127 |  0.706 | torch.Size([2]) || m_down2.0.pcbam_module.h_cw.weight
 |  0.096 | -0.115 |  0.409 |  0.277 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.h_cw.conv.weight
 |  0.672 |  0.597 |  0.747 |  0.106 | torch.Size([2]) || m_down2.0.pcbam_module.w_hc.weight
 |  0.041 | -0.109 |  0.315 |  0.238 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.w_hc.conv.weight
 |  0.594 |  0.347 |  0.840 |  0.349 | torch.Size([2]) || m_down2.0.pcbam_module.c_hw.weight
 | -0.017 | -0.083 |  0.061 |  0.073 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.c_hw.conv.weight
 |  1.163 |  0.867 |  1.732 |  0.226 | torch.Size([64]) || m_down2.1.trans_block.ln1.weight
 |  0.012 | -0.364 |  0.465 |  0.164 | torch.Size([64]) || m_down2.1.trans_block.ln1.bias
 | -0.006 | -1.165 |  0.641 |  0.241 | torch.Size([2, 15, 15]) || m_down2.1.trans_block.msa.relative_position_params
 | -0.000 | -0.375 |  0.429 |  0.082 | torch.Size([192, 64, 1, 1]) || m_down2.1.trans_block.msa.embedding_layer1.weight
 | -0.003 | -0.287 |  0.230 |  0.062 | torch.Size([192]) || m_down2.1.trans_block.msa.embedding_layer1.bias
 |  0.001 | -0.174 |  0.169 |  0.045 | torch.Size([64, 64, 1, 1]) || m_down2.1.trans_block.msa.linear1.weight
 | -0.000 | -0.118 |  0.181 |  0.045 | torch.Size([64]) || m_down2.1.trans_block.msa.linear1.bias
 |  1.050 |  0.735 |  1.351 |  0.145 | torch.Size([64]) || m_down2.1.trans_block.ln2.weight
 |  0.004 | -0.187 |  0.243 |  0.100 | torch.Size([64]) || m_down2.1.trans_block.ln2.bias
 | -0.000 | -0.474 |  0.472 |  0.076 | torch.Size([256, 64]) || m_down2.1.trans_block.mlp.0.weight
 | -0.040 | -0.315 |  0.072 |  0.057 | torch.Size([256]) || m_down2.1.trans_block.mlp.0.bias
 | -0.000 | -0.415 |  0.464 |  0.053 | torch.Size([64, 256]) || m_down2.1.trans_block.mlp.2.weight
 |  0.000 | -0.071 |  0.066 |  0.032 | torch.Size([64]) || m_down2.1.trans_block.mlp.2.bias
 | -0.008 | -1.075 |  0.517 |  0.102 | torch.Size([192, 192, 1, 1]) || m_down2.1.conv1_1.weight
 |  0.001 | -0.346 |  0.336 |  0.087 | torch.Size([192]) || m_down2.1.conv1_1.bias
 |  0.084 | -0.019 |  0.274 |  0.165 | torch.Size([1, 1, 1, 1, 3]) || m_down2.1.conv3d.weight
 | -0.003 | -0.003 | -0.003 |    nan | torch.Size([1]) || m_down2.1.conv3d.bias
 | -0.003 | -0.386 |  0.295 |  0.058 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.0.weight
 |  0.001 | -0.299 |  0.306 |  0.057 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.2.weight
 |  1.917 | -0.006 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.0.mixer.A_log
 |  1.022 |  0.995 |  1.229 |  0.039 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.D
 |  0.000 | -0.262 |  0.250 |  0.039 | torch.Size([256, 64]) || m_down2.1.mamba_layers.0.mixer.in_proj.weight
 | -0.002 | -0.408 |  0.287 |  0.073 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.001 | -0.080 |  0.116 |  0.028 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.169 |  0.167 |  0.024 | torch.Size([36, 128]) || m_down2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.049 |  0.052 |  0.018 | torch.Size([128, 4]) || m_down2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.066 |  0.079 |  0.016 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.275 |  0.271 |  0.042 | torch.Size([64, 128]) || m_down2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.027 |  0.861 |  1.223 |  0.072 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.weight
 |  0.001 | -0.164 |  0.200 |  0.093 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.bias
 |  1.917 | -0.249 |  2.773 |  0.765 | torch.Size([128, 16]) || m_down2.1.mamba_layers.1.mixer.A_log
 |  1.038 |  0.996 |  1.246 |  0.065 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.D
 | -0.000 | -0.421 |  0.421 |  0.051 | torch.Size([256, 64]) || m_down2.1.mamba_layers.1.mixer.in_proj.weight
 |  0.004 | -0.332 |  0.368 |  0.094 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.009 | -0.132 |  0.248 |  0.046 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.257 |  0.268 |  0.037 | torch.Size([36, 128]) || m_down2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.255 |  0.251 |  0.029 | torch.Size([128, 4]) || m_down2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.002 | -0.301 |  0.161 |  0.044 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.384 |  0.375 |  0.052 | torch.Size([64, 128]) || m_down2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.056 |  0.955 |  1.390 |  0.090 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.weight
 | -0.007 | -0.214 |  0.198 |  0.125 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.027 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.2.mixer.A_log
 |  0.991 |  0.947 |  1.079 |  0.022 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.D
 | -0.001 | -0.227 |  0.203 |  0.076 | torch.Size([256, 64]) || m_down2.1.mamba_layers.2.mixer.in_proj.weight
 | -0.006 | -0.562 |  0.540 |  0.284 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.2.mixer.conv1d.weight
 |  0.016 | -0.490 |  0.503 |  0.266 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.167 |  0.167 |  0.053 | torch.Size([36, 128]) || m_down2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.021 | -0.500 |  0.499 |  0.284 | torch.Size([128, 4]) || m_down2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.836 | -6.905 | -2.270 |  1.399 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.173 |  0.187 |  0.055 | torch.Size([64, 128]) || m_down2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.987 |  0.919 |  1.065 |  0.029 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.weight
 |  0.003 | -0.065 |  0.078 |  0.025 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.036 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.3.mixer.A_log
 |  0.988 |  0.951 |  1.053 |  0.020 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.208 |  0.275 |  0.074 | torch.Size([256, 64]) || m_down2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.000 | -0.513 |  0.520 |  0.280 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.3.mixer.conv1d.weight
 |  0.056 | -0.522 |  0.494 |  0.264 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.144 |  0.130 |  0.052 | torch.Size([36, 128]) || m_down2.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.500 |  0.499 |  0.290 | torch.Size([128, 4]) || m_down2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.409 | -6.903 | -2.272 |  1.291 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.180 |  0.196 |  0.054 | torch.Size([64, 128]) || m_down2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.978 |  0.923 |  1.033 |  0.027 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.weight
 |  0.001 | -0.055 |  0.052 |  0.022 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.bias
 |  0.854 |  0.685 |  1.023 |  0.239 | torch.Size([2]) || m_down2.1.pcbam_module.h_cw.weight
 |  0.126 | -0.032 |  0.306 |  0.170 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.h_cw.conv.weight
 |  0.686 |  0.581 |  0.791 |  0.148 | torch.Size([2]) || m_down2.1.pcbam_module.w_hc.weight
 |  0.055 | -0.241 |  0.343 |  0.292 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.w_hc.conv.weight
 |  0.884 |  0.742 |  1.027 |  0.201 | torch.Size([2]) || m_down2.1.pcbam_module.c_hw.weight
 | -0.045 | -0.242 |  0.258 |  0.266 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.c_hw.conv.weight
 | -0.001 | -0.268 |  0.410 |  0.043 | torch.Size([384, 192, 2, 2]) || m_down2.2.weight
 |  0.985 |  0.619 |  1.644 |  0.229 | torch.Size([128]) || m_down3.0.trans_block.ln1.weight
 |  0.005 | -0.589 |  0.596 |  0.248 | torch.Size([128]) || m_down3.0.trans_block.ln1.bias
 |  0.053 | -2.559 |  0.993 |  0.349 | torch.Size([4, 15, 15]) || m_down3.0.trans_block.msa.relative_position_params
 | -0.000 | -0.396 |  0.385 |  0.051 | torch.Size([384, 128, 1, 1]) || m_down3.0.trans_block.msa.embedding_layer1.weight
 |  0.006 | -0.191 |  0.266 |  0.055 | torch.Size([384]) || m_down3.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.167 |  0.168 |  0.040 | torch.Size([128, 128, 1, 1]) || m_down3.0.trans_block.msa.linear1.weight
 |  0.001 | -0.112 |  0.102 |  0.043 | torch.Size([128]) || m_down3.0.trans_block.msa.linear1.bias
 |  0.899 |  0.460 |  1.325 |  0.165 | torch.Size([128]) || m_down3.0.trans_block.ln2.weight
 |  0.001 | -0.337 |  0.354 |  0.114 | torch.Size([128]) || m_down3.0.trans_block.ln2.bias
 | -0.000 | -0.404 |  0.379 |  0.046 | torch.Size([512, 128]) || m_down3.0.trans_block.mlp.0.weight
 | -0.027 | -0.351 |  0.066 |  0.044 | torch.Size([512]) || m_down3.0.trans_block.mlp.0.bias
 | -0.000 | -0.395 |  0.447 |  0.037 | torch.Size([128, 512]) || m_down3.0.trans_block.mlp.2.weight
 |  0.002 | -0.119 |  0.198 |  0.054 | torch.Size([128]) || m_down3.0.trans_block.mlp.2.bias
 |  0.004 | -0.535 |  1.740 |  0.081 | torch.Size([384, 384, 1, 1]) || m_down3.0.conv1_1.weight
 | -0.003 | -0.797 |  0.615 |  0.131 | torch.Size([384]) || m_down3.0.conv1_1.bias
 | -0.085 | -0.264 |  0.007 |  0.154 | torch.Size([1, 1, 1, 1, 3]) || m_down3.0.conv3d.weight
 | -0.004 | -0.004 | -0.004 |    nan | torch.Size([1]) || m_down3.0.conv3d.bias
 |  0.001 | -0.374 |  0.294 |  0.045 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.0.weight
 | -0.000 | -0.225 |  0.276 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.0.mixer.A_log
 |  1.001 |  0.991 |  1.096 |  0.010 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.D
 | -0.000 | -0.092 |  0.112 |  0.011 | torch.Size([512, 128]) || m_down3.0.mamba_layers.0.mixer.in_proj.weight
 | -0.002 | -0.147 |  0.116 |  0.023 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.0.mixer.conv1d.weight
 | -0.002 | -0.119 |  0.155 |  0.036 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.051 |  0.051 |  0.012 | torch.Size([40, 256]) || m_down3.0.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.041 |  0.047 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.001 |  0.000 |  0.000 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.173 |  0.134 |  0.016 | torch.Size([128, 256]) || m_down3.0.mamba_layers.0.mixer.out_proj.weight
 |  1.000 |  0.985 |  1.028 |  0.008 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.weight
 |  0.001 | -0.022 |  0.021 |  0.011 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.bias
 |  1.917 | -0.005 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.1.mixer.A_log
 |  1.013 |  0.998 |  1.312 |  0.045 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.D
 |  0.000 | -0.319 |  0.274 |  0.019 | torch.Size([512, 128]) || m_down3.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.291 |  0.278 |  0.042 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.1.mixer.conv1d.weight
 | -0.003 | -0.247 |  0.232 |  0.054 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.119 |  0.124 |  0.013 | torch.Size([40, 256]) || m_down3.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.039 |  0.058 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.096 |  0.024 |  0.006 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.404 |  0.294 |  0.024 | torch.Size([128, 256]) || m_down3.0.mamba_layers.1.mixer.out_proj.weight
 |  0.951 |  0.856 |  1.181 |  0.053 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.weight
 |  0.013 | -0.146 |  0.153 |  0.094 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.bias
 |  1.917 | -0.002 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.2.mixer.A_log
 |  0.980 |  0.949 |  1.021 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.D
 |  0.000 | -0.146 |  0.150 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.2.mixer.in_proj.weight
 | -0.015 | -0.540 |  0.508 |  0.280 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.2.mixer.conv1d.weight
 |  0.031 | -0.514 |  0.482 |  0.274 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.101 |  0.096 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.2.mixer.x_proj.weight
 | -0.000 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.489 | -6.888 | -2.309 |  1.322 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.133 |  0.164 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.2.mixer.out_proj.weight
 |  0.957 |  0.904 |  1.041 |  0.022 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.weight
 |  0.001 | -0.069 |  0.061 |  0.030 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.bias
 |  1.917 | -0.001 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.3.mixer.A_log
 |  0.981 |  0.942 |  1.030 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.D
 | -0.000 | -0.134 |  0.143 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.3.mixer.in_proj.weight
 |  0.006 | -0.505 |  0.531 |  0.280 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.489 |  0.493 |  0.255 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.088 |  0.090 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.3.mixer.x_proj.weight
 | -0.002 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.511 | -6.890 | -2.277 |  1.395 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.120 |  0.131 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.3.mixer.out_proj.weight
 |  0.956 |  0.898 |  1.003 |  0.020 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.weight
 | -0.000 | -0.063 |  0.066 |  0.028 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.bias
 |  0.708 |  0.548 |  0.869 |  0.227 | torch.Size([2]) || m_down3.0.pcbam_module.h_cw.weight
 |  0.052 | -0.055 |  0.193 |  0.128 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.h_cw.conv.weight
 |  0.294 |  0.254 |  0.335 |  0.058 | torch.Size([2]) || m_down3.0.pcbam_module.w_hc.weight
 |  0.018 | -0.114 |  0.228 |  0.184 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.w_hc.conv.weight
 |  0.568 |  0.250 |  0.886 |  0.450 | torch.Size([2]) || m_down3.0.pcbam_module.c_hw.weight
 | -0.089 | -0.353 |  0.103 |  0.166 | torch.Size([1, 1, 1, 5]) || m_down3.0.pcbam_module.c_hw.conv.weight
 |  1.082 |  0.617 |  1.594 |  0.241 | torch.Size([128]) || m_down3.1.trans_block.ln1.weight
 | -0.017 | -0.805 |  0.657 |  0.216 | torch.Size([128]) || m_down3.1.trans_block.ln1.bias
 |  0.002 | -2.820 |  1.248 |  0.323 | torch.Size([4, 15, 15]) || m_down3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.438 |  0.448 |  0.056 | torch.Size([384, 128, 1, 1]) || m_down3.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.231 |  0.239 |  0.048 | torch.Size([384]) || m_down3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.168 |  0.162 |  0.039 | torch.Size([128, 128, 1, 1]) || m_down3.1.trans_block.msa.linear1.weight
 |  0.000 | -0.134 |  0.142 |  0.053 | torch.Size([128]) || m_down3.1.trans_block.msa.linear1.bias
 |  0.906 |  0.434 |  1.276 |  0.188 | torch.Size([128]) || m_down3.1.trans_block.ln2.weight
 | -0.006 | -0.377 |  0.429 |  0.168 | torch.Size([128]) || m_down3.1.trans_block.ln2.bias
 | -0.000 | -0.444 |  0.369 |  0.058 | torch.Size([512, 128]) || m_down3.1.trans_block.mlp.0.weight
 | -0.044 | -0.237 |  0.033 |  0.052 | torch.Size([512]) || m_down3.1.trans_block.mlp.0.bias
 | -0.000 | -0.363 |  0.362 |  0.044 | torch.Size([128, 512]) || m_down3.1.trans_block.mlp.2.weight
 |  0.004 | -0.124 |  0.144 |  0.052 | torch.Size([128]) || m_down3.1.trans_block.mlp.2.bias
 | -0.003 | -1.792 |  0.663 |  0.088 | torch.Size([384, 384, 1, 1]) || m_down3.1.conv1_1.weight
 |  0.010 | -0.559 |  0.409 |  0.092 | torch.Size([384]) || m_down3.1.conv1_1.bias
 |  0.089 | -0.010 |  0.283 |  0.168 | torch.Size([1, 1, 1, 1, 3]) || m_down3.1.conv3d.weight
 | -0.001 | -0.001 | -0.001 |    nan | torch.Size([1]) || m_down3.1.conv3d.bias
 | -0.005 | -0.366 |  0.422 |  0.047 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.0.weight
 | -0.000 | -0.258 |  0.301 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.2.weight
 |  1.917 | -0.001 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.0.mixer.A_log
 |  1.011 |  0.995 |  1.145 |  0.025 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.299 |  0.306 |  0.026 | torch.Size([512, 128]) || m_down3.1.mamba_layers.0.mixer.in_proj.weight
 | -0.000 | -0.385 |  0.281 |  0.053 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.123 |  0.103 |  0.034 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.079 |  0.086 |  0.014 | torch.Size([40, 256]) || m_down3.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.039 |  0.057 |  0.012 | torch.Size([256, 8]) || m_down3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.025 |  0.011 |  0.002 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.217 |  0.221 |  0.028 | torch.Size([128, 256]) || m_down3.1.mamba_layers.0.mixer.out_proj.weight
 |  0.991 |  0.871 |  1.205 |  0.058 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.weight
 |  0.004 | -0.118 |  0.137 |  0.074 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.bias
 |  1.917 | -0.045 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.1.mixer.A_log
 |  1.021 |  0.951 |  1.316 |  0.049 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.D
 |  0.000 | -0.307 |  0.343 |  0.033 | torch.Size([512, 128]) || m_down3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.003 | -0.379 |  0.349 |  0.065 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.246 |  0.218 |  0.044 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.182 |  0.211 |  0.024 | torch.Size([40, 256]) || m_down3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.078 |  0.083 |  0.016 | torch.Size([256, 8]) || m_down3.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.010 | -0.109 |  0.196 |  0.031 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.282 |  0.299 |  0.034 | torch.Size([128, 256]) || m_down3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.013 |  0.833 |  1.240 |  0.080 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.weight
 | -0.003 | -0.171 |  0.186 |  0.102 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.083 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.2.mixer.A_log
 |  0.980 |  0.935 |  1.075 |  0.019 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.169 |  0.159 |  0.052 | torch.Size([512, 128]) || m_down3.1.mamba_layers.2.mixer.in_proj.weight
 | -0.011 | -0.553 |  0.567 |  0.278 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.2.mixer.conv1d.weight
 |  0.016 | -0.520 |  0.512 |  0.290 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.123 |  0.113 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.205 | torch.Size([256, 8]) || m_down3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.526 | -6.818 | -2.284 |  1.305 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.180 |  0.134 |  0.039 | torch.Size([128, 256]) || m_down3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.959 |  0.875 |  1.031 |  0.026 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.weight
 | -0.001 | -0.085 |  0.053 |  0.021 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.003 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.3.mixer.A_log
 |  0.980 |  0.933 |  1.019 |  0.014 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.D
 |  0.000 | -0.142 |  0.144 |  0.051 | torch.Size([512, 128]) || m_down3.1.mamba_layers.3.mixer.in_proj.weight
 |  0.010 | -0.543 |  0.539 |  0.277 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.3.mixer.conv1d.weight
 |  0.001 | -0.509 |  0.478 |  0.287 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.108 |  0.116 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.204 | torch.Size([256, 8]) || m_down3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.747 | -6.882 | -2.256 |  1.391 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.127 |  0.129 |  0.037 | torch.Size([128, 256]) || m_down3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.950 |  0.895 |  1.003 |  0.023 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.weight
 | -0.001 | -0.083 |  0.076 |  0.022 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.bias
 |  0.680 |  0.554 |  0.806 |  0.178 | torch.Size([2]) || m_down3.1.pcbam_module.h_cw.weight
 | -0.003 | -0.204 |  0.262 |  0.239 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.h_cw.conv.weight
 |  0.425 |  0.112 |  0.739 |  0.444 | torch.Size([2]) || m_down3.1.pcbam_module.w_hc.weight
 | -0.021 | -0.245 |  0.315 |  0.296 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.w_hc.conv.weight
 |  0.600 |  0.591 |  0.608 |  0.012 | torch.Size([2]) || m_down3.1.pcbam_module.c_hw.weight
 |  0.115 | -0.168 |  0.354 |  0.257 | torch.Size([1, 1, 1, 5]) || m_down3.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.486 |  0.307 |  0.032 | torch.Size([768, 384, 2, 2]) || m_down3.2.weight
 |  0.806 |  0.359 |  1.208 |  0.146 | torch.Size([256]) || m_body.0.trans_block.ln1.weight
 | -0.011 | -0.671 |  0.494 |  0.135 | torch.Size([256]) || m_body.0.trans_block.ln1.bias
 |  0.054 | -4.731 |  0.715 |  0.332 | torch.Size([8, 15, 15]) || m_body.0.trans_block.msa.relative_position_params
 | -0.000 | -0.386 |  0.387 |  0.037 | torch.Size([768, 256, 1, 1]) || m_body.0.trans_block.msa.embedding_layer1.weight
 |  0.002 | -0.203 |  0.206 |  0.053 | torch.Size([768]) || m_body.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.238 |  0.238 |  0.042 | torch.Size([256, 256, 1, 1]) || m_body.0.trans_block.msa.linear1.weight
 |  0.002 | -0.259 |  0.145 |  0.057 | torch.Size([256]) || m_body.0.trans_block.msa.linear1.bias
 |  0.853 |  0.381 |  1.185 |  0.123 | torch.Size([256]) || m_body.0.trans_block.ln2.weight
 |  0.002 | -0.200 |  0.276 |  0.081 | torch.Size([256]) || m_body.0.trans_block.ln2.bias
 |  0.000 | -0.256 |  0.283 |  0.034 | torch.Size([1024, 256]) || m_body.0.trans_block.mlp.0.weight
 | -0.011 | -0.233 |  0.103 |  0.042 | torch.Size([1024]) || m_body.0.trans_block.mlp.0.bias
 | -0.000 | -0.293 |  0.322 |  0.031 | torch.Size([256, 1024]) || m_body.0.trans_block.mlp.2.weight
 |  0.005 | -0.198 |  0.154 |  0.053 | torch.Size([256]) || m_body.0.trans_block.mlp.2.bias
 | -0.001 | -1.113 |  0.866 |  0.051 | torch.Size([768, 768, 1, 1]) || m_body.0.conv1_1.weight
 |  0.001 | -1.478 |  0.989 |  0.095 | torch.Size([768]) || m_body.0.conv1_1.bias
 |  0.074 | -0.007 |  0.234 |  0.138 | torch.Size([1, 1, 1, 1, 3]) || m_body.0.conv3d.weight
 |  0.027 |  0.027 |  0.027 |    nan | torch.Size([1]) || m_body.0.conv3d.bias
 |  0.000 | -0.236 |  0.257 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.0.weight
 | -0.000 | -0.237 |  0.211 |  0.036 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.D
 |  0.000 | -0.028 |  0.027 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.025 |  0.027 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.004 |  0.003 |  0.001 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.035 |  0.036 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.033 |  0.038 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.042 |  0.037 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.0.mixer.out_proj.weight
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.bias
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.001 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.D
 |  0.000 | -0.029 |  0.030 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.1.mixer.in_proj.weight
 |  0.000 | -0.035 |  0.059 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.1.mixer.conv1d.weight
 | -0.000 | -0.018 |  0.022 |  0.006 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.034 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.034 |  0.030 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.045 |  0.041 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.999 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.weight
 | -0.000 | -0.001 |  0.001 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.bias
 |  1.917 | -0.025 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.A_log
 |  0.999 |  0.976 |  1.013 |  0.004 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.D
 | -0.000 | -0.085 |  0.085 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.2.mixer.in_proj.weight
 | -0.007 | -0.504 |  0.517 |  0.289 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.2.mixer.conv1d.weight
 | -0.005 | -0.500 |  0.495 |  0.307 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.068 |  0.069 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.579 | -6.906 | -2.283 |  1.361 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.096 |  0.080 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.2.mixer.out_proj.weight
 |  0.995 |  0.985 |  1.008 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.weight
 |  0.000 | -0.013 |  0.007 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.bias
 |  1.917 | -0.015 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.A_log
 |  0.998 |  0.984 |  1.009 |  0.003 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.D
 |  0.000 | -0.082 |  0.078 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.3.mixer.in_proj.weight
 | -0.013 | -0.509 |  0.501 |  0.287 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.3.mixer.conv1d.weight
 |  0.003 | -0.501 |  0.496 |  0.280 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.070 |  0.067 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.3.mixer.x_proj.weight
 |  0.002 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.612 | -6.907 | -2.259 |  1.325 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.063 |  0.065 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.3.mixer.out_proj.weight
 |  0.995 |  0.986 |  1.006 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.weight
 | -0.000 | -0.009 |  0.009 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.bias
 |  1.123 |  0.893 |  1.353 |  0.326 | torch.Size([2]) || m_body.0.pcbam_module.h_cw.weight
 | -0.665 | -0.955 | -0.499 |  0.252 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.h_cw.conv.weight
 |  0.383 |  0.161 |  0.605 |  0.314 | torch.Size([2]) || m_body.0.pcbam_module.w_hc.weight
 | -0.519 | -0.608 | -0.346 |  0.150 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.w_hc.conv.weight
 |  1.013 |  0.112 |  1.913 |  1.274 | torch.Size([2]) || m_body.0.pcbam_module.c_hw.weight
 | -0.083 | -0.981 |  1.949 |  1.184 | torch.Size([1, 1, 1, 5]) || m_body.0.pcbam_module.c_hw.conv.weight
 |  0.747 |  0.306 |  1.000 |  0.127 | torch.Size([256]) || m_body.1.trans_block.ln1.weight
 |  0.028 | -0.815 |  0.540 |  0.165 | torch.Size([256]) || m_body.1.trans_block.ln1.bias
 |  0.052 | -3.909 |  0.815 |  0.351 | torch.Size([8, 15, 15]) || m_body.1.trans_block.msa.relative_position_params
 | -0.000 | -0.306 |  0.295 |  0.036 | torch.Size([768, 256, 1, 1]) || m_body.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.221 |  0.248 |  0.068 | torch.Size([768]) || m_body.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.278 |  0.275 |  0.037 | torch.Size([256, 256, 1, 1]) || m_body.1.trans_block.msa.linear1.weight
 | -0.003 | -0.193 |  0.214 |  0.058 | torch.Size([256]) || m_body.1.trans_block.msa.linear1.bias
 |  0.866 |  0.519 |  1.098 |  0.100 | torch.Size([256]) || m_body.1.trans_block.ln2.weight
 |  0.007 | -0.263 |  0.320 |  0.103 | torch.Size([256]) || m_body.1.trans_block.ln2.bias
 |  0.001 | -0.362 |  0.358 |  0.054 | torch.Size([1024, 256]) || m_body.1.trans_block.mlp.0.weight
 | -0.051 | -0.199 |  0.056 |  0.038 | torch.Size([1024]) || m_body.1.trans_block.mlp.0.bias
 | -0.001 | -0.438 |  0.395 |  0.051 | torch.Size([256, 1024]) || m_body.1.trans_block.mlp.2.weight
 | -0.000 | -0.218 |  0.139 |  0.051 | torch.Size([256]) || m_body.1.trans_block.mlp.2.bias
 | -0.001 | -1.065 |  0.764 |  0.056 | torch.Size([768, 768, 1, 1]) || m_body.1.conv1_1.weight
 |  0.000 | -0.311 |  0.925 |  0.086 | torch.Size([768]) || m_body.1.conv1_1.bias
 |  0.173 |  0.007 |  0.502 |  0.285 | torch.Size([1, 1, 1, 1, 3]) || m_body.1.conv3d.weight
 |  0.062 |  0.062 |  0.062 |    nan | torch.Size([1]) || m_body.1.conv3d.bias
 | -0.001 | -0.278 |  0.267 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.0.weight
 | -0.001 | -0.271 |  0.268 |  0.035 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.2.weight
 |  1.917 | -0.002 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.086 |  0.005 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.D
 | -0.000 | -0.126 |  0.113 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.085 |  0.292 |  0.012 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.016 |  0.060 |  0.003 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.055 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.035 |  0.029 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.006 |  0.004 |  0.000 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.153 |  0.095 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.0.mixer.out_proj.weight
 |  1.001 |  0.995 |  1.018 |  0.003 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.weight
 |  0.000 | -0.006 |  0.006 |  0.002 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.bias
 |  1.917 | -0.218 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.039 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.D
 |  0.000 | -0.169 |  0.149 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.1.mixer.in_proj.weight
 | -0.000 | -0.054 |  0.173 |  0.010 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.097 |  0.073 |  0.022 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.097 |  0.324 |  0.010 | torch.Size([48, 512]) || m_body.1.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.032 |  0.035 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.037 |  0.000 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.153 |  0.185 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.986 |  1.044 |  0.010 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.weight
 | -0.001 | -0.018 |  0.022 |  0.009 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.bias
 |  1.917 | -0.057 |  2.774 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.A_log
 |  0.998 |  0.962 |  1.045 |  0.005 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.D
 | -0.000 | -0.093 |  0.117 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.2.mixer.in_proj.weight
 |  0.004 | -0.511 |  0.502 |  0.282 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.2.mixer.conv1d.weight
 |  0.010 | -0.506 |  0.492 |  0.282 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.079 |  0.087 |  0.026 | torch.Size([48, 512]) || m_body.1.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.257 |  0.260 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.634 | -6.903 | -2.259 |  1.288 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.102 |  0.100 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.2.mixer.out_proj.weight
 |  0.995 |  0.958 |  1.009 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.weight
 |  0.000 | -0.023 |  0.021 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.bias
 |  1.917 | -0.068 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.A_log
 |  0.999 |  0.918 |  1.113 |  0.009 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.D
 |  0.000 | -0.121 |  0.118 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.530 |  0.505 |  0.292 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.3.mixer.conv1d.weight
 | -0.009 | -0.501 |  0.498 |  0.294 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.089 |  0.085 |  0.026 | torch.Size([48, 512]) || m_body.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.272 |  0.268 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.631 | -6.903 | -2.252 |  1.302 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.114 |  0.094 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.3.mixer.out_proj.weight
 |  0.999 |  0.970 |  1.027 |  0.008 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.weight
 |  0.000 | -0.015 |  0.017 |  0.006 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.bias
 |  1.209 |  0.870 |  1.547 |  0.479 | torch.Size([2]) || m_body.1.pcbam_module.h_cw.weight
 | -1.012 | -1.126 | -0.821 |  0.167 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.h_cw.conv.weight
 |  1.149 |  0.897 |  1.400 |  0.356 | torch.Size([2]) || m_body.1.pcbam_module.w_hc.weight
 | -0.941 | -1.056 | -0.784 |  0.141 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.w_hc.conv.weight
 |  1.486 |  0.077 |  2.894 |  1.992 | torch.Size([2]) || m_body.1.pcbam_module.c_hw.weight
 | -0.207 | -1.516 |  1.716 |  1.290 | torch.Size([1, 1, 1, 5]) || m_body.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.319 |  0.339 |  0.030 | torch.Size([768, 384, 2, 2]) || m_up3.0.weight
 |  0.962 |  0.584 |  1.379 |  0.156 | torch.Size([128]) || m_up3.1.trans_block.ln1.weight
 |  0.026 | -0.558 |  0.425 |  0.129 | torch.Size([128]) || m_up3.1.trans_block.ln1.bias
 |  0.050 | -3.792 |  0.658 |  0.308 | torch.Size([4, 15, 15]) || m_up3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.494 |  0.525 |  0.060 | torch.Size([384, 128, 1, 1]) || m_up3.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.260 |  0.243 |  0.069 | torch.Size([384]) || m_up3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.176 |  0.187 |  0.044 | torch.Size([128, 128, 1, 1]) || m_up3.1.trans_block.msa.linear1.weight
 | -0.001 | -0.100 |  0.216 |  0.043 | torch.Size([128]) || m_up3.1.trans_block.msa.linear1.bias
 |  0.882 |  0.709 |  1.047 |  0.070 | torch.Size([128]) || m_up3.1.trans_block.ln2.weight
 |  0.008 | -0.259 |  0.183 |  0.085 | torch.Size([128]) || m_up3.1.trans_block.ln2.bias
 |  0.000 | -0.341 |  0.316 |  0.059 | torch.Size([512, 128]) || m_up3.1.trans_block.mlp.0.weight
 | -0.038 | -0.192 |  0.067 |  0.044 | torch.Size([512]) || m_up3.1.trans_block.mlp.0.bias
 | -0.000 | -0.353 |  0.309 |  0.053 | torch.Size([128, 512]) || m_up3.1.trans_block.mlp.2.weight
 | -0.002 | -0.335 |  0.165 |  0.045 | torch.Size([128]) || m_up3.1.trans_block.mlp.2.bias
 | -0.001 | -2.353 |  0.670 |  0.086 | torch.Size([384, 384, 1, 1]) || m_up3.1.conv1_1.weight
 | -0.001 | -0.418 |  1.301 |  0.129 | torch.Size([384]) || m_up3.1.conv1_1.bias
 |  0.182 | -0.006 |  0.558 |  0.325 | torch.Size([1, 1, 1, 1, 3]) || m_up3.1.conv3d.weight
 | -0.005 | -0.005 | -0.005 |    nan | torch.Size([1]) || m_up3.1.conv3d.bias
 |  0.000 | -0.370 |  0.274 |  0.035 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.0.weight
 |  0.000 | -0.269 |  0.385 |  0.037 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.2.weight
 |  1.916 | -0.346 |  2.773 |  0.766 | torch.Size([256, 16]) || m_up3.1.mamba_layers.0.mixer.A_log
 |  1.051 |  0.998 |  1.320 |  0.072 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.398 |  0.382 |  0.043 | torch.Size([512, 128]) || m_up3.1.mamba_layers.0.mixer.in_proj.weight
 |  0.006 | -0.430 |  0.482 |  0.097 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.0.mixer.conv1d.weight
 |  0.011 | -0.171 |  0.346 |  0.065 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.171 |  0.228 |  0.025 | torch.Size([40, 256]) || m_up3.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.054 |  0.065 |  0.013 | torch.Size([256, 8]) || m_up3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.003 | -0.169 |  0.117 |  0.028 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.488 |  0.437 |  0.049 | torch.Size([128, 256]) || m_up3.1.mamba_layers.0.mixer.out_proj.weight
 |  1.031 |  0.912 |  1.168 |  0.064 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.weight
 | -0.002 | -0.272 |  0.275 |  0.119 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.bias
 |  1.916 | -0.849 |  3.034 |  0.769 | torch.Size([256, 16]) || m_up3.1.mamba_layers.1.mixer.A_log
 |  1.000 | -0.041 |  1.309 |  0.161 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.D
 | -0.000 | -0.424 |  0.423 |  0.055 | torch.Size([512, 128]) || m_up3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.004 | -0.463 |  0.365 |  0.108 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.019 | -0.292 |  0.284 |  0.171 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.555 |  0.538 |  0.074 | torch.Size([40, 256]) || m_up3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.002 | -0.605 |  0.692 |  0.095 | torch.Size([256, 8]) || m_up3.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.013 | -1.004 |  0.247 |  0.106 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.269 |  0.270 |  0.056 | torch.Size([128, 256]) || m_up3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.015 |  0.687 |  1.203 |  0.107 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.weight
 | -0.002 | -0.238 |  0.261 |  0.101 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.278 |  2.787 |  0.764 | torch.Size([256, 16]) || m_up3.1.mamba_layers.2.mixer.A_log
 |  0.982 |  0.690 |  1.037 |  0.038 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.181 |  0.193 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.2.mixer.in_proj.weight
 |  0.014 | -0.563 |  0.541 |  0.274 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.2.mixer.conv1d.weight
 | -0.029 | -0.525 |  0.491 |  0.291 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.164 |  0.147 |  0.042 | torch.Size([40, 256]) || m_up3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.000 | -0.413 |  0.371 |  0.205 | torch.Size([256, 8]) || m_up3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.530 | -6.922 | -2.275 |  1.363 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.000 | -0.153 |  0.157 |  0.040 | torch.Size([128, 256]) || m_up3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.958 |  0.882 |  1.029 |  0.026 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.weight
 |  0.002 | -0.054 |  0.074 |  0.021 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.033 |  2.773 |  0.765 | torch.Size([256, 16]) || m_up3.1.mamba_layers.3.mixer.A_log
 |  0.990 |  0.944 |  1.027 |  0.016 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.D
 | -0.000 | -0.162 |  0.159 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.3.mixer.in_proj.weight
 | -0.011 | -0.529 |  0.512 |  0.268 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.3.mixer.conv1d.weight
 | -0.005 | -0.548 |  0.532 |  0.309 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.119 |  0.118 |  0.038 | torch.Size([40, 256]) || m_up3.1.mamba_layers.3.mixer.x_proj.weight
 | -0.001 | -0.355 |  0.356 |  0.203 | torch.Size([256, 8]) || m_up3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.644 | -6.922 | -2.262 |  1.394 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.150 |  0.145 |  0.040 | torch.Size([128, 256]) || m_up3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.956 |  0.893 |  1.025 |  0.026 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.weight
 | -0.000 | -0.072 |  0.060 |  0.020 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.bias
 |  0.534 |  0.193 |  0.875 |  0.483 | torch.Size([2]) || m_up3.1.pcbam_module.h_cw.weight
 |  0.127 |  0.060 |  0.237 |  0.095 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.h_cw.conv.weight
 |  0.882 |  0.856 |  0.909 |  0.037 | torch.Size([2]) || m_up3.1.pcbam_module.w_hc.weight
 |  0.164 |  0.099 |  0.218 |  0.060 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.w_hc.conv.weight
 |  0.493 |  0.225 |  0.762 |  0.380 | torch.Size([2]) || m_up3.1.pcbam_module.c_hw.weight
 |  0.017 | -0.148 |  0.146 |  0.119 | torch.Size([1, 1, 1, 5]) || m_up3.1.pcbam_module.c_hw.conv.weight
 |  1.124 |  0.605 |  1.354 |  0.143 | torch.Size([128]) || m_up3.2.trans_block.ln1.weight
 | -0.004 | -0.493 |  0.500 |  0.122 | torch.Size([128]) || m_up3.2.trans_block.ln1.bias
 |  0.061 | -3.109 |  0.733 |  0.356 | torch.Size([4, 15, 15]) || m_up3.2.trans_block.msa.relative_position_params
 | -0.000 | -0.454 |  0.313 |  0.056 | torch.Size([384, 128, 1, 1]) || m_up3.2.trans_block.msa.embedding_layer1.weight
 | -0.001 | -0.182 |  0.190 |  0.057 | torch.Size([384]) || m_up3.2.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.191 |  0.200 |  0.047 | torch.Size([128, 128, 1, 1]) || m_up3.2.trans_block.msa.linear1.weight
 | -0.003 | -0.139 |  0.146 |  0.055 | torch.Size([128]) || m_up3.2.trans_block.msa.linear1.bias
 |  1.202 |  0.966 |  1.501 |  0.090 | torch.Size([128]) || m_up3.2.trans_block.ln2.weight
 | -0.000 | -0.268 |  0.288 |  0.113 | torch.Size([128]) || m_up3.2.trans_block.ln2.bias
 |  0.000 | -0.359 |  0.332 |  0.073 | torch.Size([512, 128]) || m_up3.2.trans_block.mlp.0.weight
 | -0.048 | -0.182 |  0.056 |  0.038 | torch.Size([512]) || m_up3.2.trans_block.mlp.0.bias
 |  0.000 | -0.345 |  0.389 |  0.070 | torch.Size([128, 512]) || m_up3.2.trans_block.mlp.2.weight
 | -0.002 | -0.141 |  0.214 |  0.052 | torch.Size([128]) || m_up3.2.trans_block.mlp.2.bias
 | -0.000 | -0.840 |  0.453 |  0.075 | torch.Size([384, 384, 1, 1]) || m_up3.2.conv1_1.weight
 |  0.001 | -0.553 |  1.061 |  0.104 | torch.Size([384]) || m_up3.2.conv1_1.bias
 | -0.065 | -0.203 |  0.006 |  0.120 | torch.Size([1, 1, 1, 1, 3]) || m_up3.2.conv3d.weight
 | -0.002 | -0.002 | -0.002 |    nan | torch.Size([1]) || m_up3.2.conv3d.bias
 | -0.001 | -0.316 |  0.352 |  0.051 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.0.weight
 |  0.000 | -0.439 |  0.398 |  0.051 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.2.weight
 |  1.916 | -1.142 |  2.794 |  0.767 | torch.Size([256, 16]) || m_up3.2.mamba_layers.0.mixer.A_log
 |  1.074 |  0.399 |  1.575 |  0.159 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.D
 | -0.000 | -0.326 |  0.326 |  0.071 | torch.Size([512, 128]) || m_up3.2.mamba_layers.0.mixer.in_proj.weight
 | -0.001 | -0.372 |  0.432 |  0.142 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.0.mixer.conv1d.weight
 | -0.010 | -0.303 |  0.267 |  0.104 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.666 |  0.471 |  0.075 | torch.Size([40, 256]) || m_up3.2.mamba_layers.0.mixer.x_proj.weight
 |  0.001 | -0.689 |  0.714 |  0.099 | torch.Size([256, 8]) || m_up3.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.019 | -1.178 |  0.291 |  0.120 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.587 |  0.443 |  0.076 | torch.Size([128, 256]) || m_up3.2.mamba_layers.0.mixer.out_proj.weight
 |  1.018 |  0.684 |  1.152 |  0.080 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.weight
 |  0.006 | -0.413 |  0.404 |  0.131 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.bias
 |  1.911 | -0.997 |  2.866 |  0.776 | torch.Size([256, 16]) || m_up3.2.mamba_layers.1.mixer.A_log
 |  1.070 | -0.093 |  1.506 |  0.137 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.D
 |  0.000 | -0.341 |  0.416 |  0.072 | torch.Size([512, 128]) || m_up3.2.mamba_layers.1.mixer.in_proj.weight
 |  0.005 | -0.536 |  0.448 |  0.147 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.1.mixer.conv1d.weight
 |  0.010 | -0.317 |  0.343 |  0.150 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.conv1d.bias
 |  0.002 | -0.720 |  1.146 |  0.091 | torch.Size([40, 256]) || m_up3.2.mamba_layers.1.mixer.x_proj.weight
 | -0.005 | -0.661 |  0.592 |  0.124 | torch.Size([256, 8]) || m_up3.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.014 | -0.455 |  0.173 |  0.107 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.430 |  0.404 |  0.075 | torch.Size([128, 256]) || m_up3.2.mamba_layers.1.mixer.out_proj.weight
 |  1.073 |  0.688 |  1.218 |  0.082 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.weight
 |  0.004 | -0.264 |  0.247 |  0.108 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.bias
 |  1.917 | -0.048 |  2.833 |  0.765 | torch.Size([256, 16]) || m_up3.2.mamba_layers.2.mixer.A_log
 |  1.027 |  0.972 |  1.345 |  0.035 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.D
 | -0.000 | -0.225 |  0.218 |  0.057 | torch.Size([512, 128]) || m_up3.2.mamba_layers.2.mixer.in_proj.weight
 |  0.002 | -0.647 |  0.629 |  0.294 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.2.mixer.conv1d.weight
 |  0.036 | -0.540 |  0.543 |  0.319 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.157 |  0.167 |  0.045 | torch.Size([40, 256]) || m_up3.2.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.440 |  0.466 |  0.205 | torch.Size([256, 8]) || m_up3.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.531 | -6.898 | -2.248 |  1.383 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.232 |  0.201 |  0.046 | torch.Size([128, 256]) || m_up3.2.mamba_layers.2.mixer.out_proj.weight
 |  1.023 |  0.970 |  1.089 |  0.025 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.weight
 |  0.000 | -0.092 |  0.101 |  0.038 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.bias
 |  1.917 | -0.027 |  2.774 |  0.764 | torch.Size([256, 16]) || m_up3.2.mamba_layers.3.mixer.A_log
 |  1.008 |  0.978 |  1.069 |  0.012 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.D
 | -0.000 | -0.197 |  0.174 |  0.054 | torch.Size([512, 128]) || m_up3.2.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.559 |  0.556 |  0.287 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.3.mixer.conv1d.weight
 | -0.022 | -0.537 |  0.538 |  0.301 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.176 |  0.175 |  0.041 | torch.Size([40, 256]) || m_up3.2.mamba_layers.3.mixer.x_proj.weight
 | -0.005 | -0.366 |  0.370 |  0.206 | torch.Size([256, 8]) || m_up3.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.526 | -6.891 | -2.236 |  1.228 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.182 |  0.181 |  0.043 | torch.Size([128, 256]) || m_up3.2.mamba_layers.3.mixer.out_proj.weight
 |  1.000 |  0.840 |  1.052 |  0.029 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.weight
 | -0.000 | -0.141 |  0.072 |  0.027 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.bias
 |  0.754 |  0.558 |  0.951 |  0.278 | torch.Size([2]) || m_up3.2.pcbam_module.h_cw.weight
 | -0.066 | -0.206 |  0.165 |  0.202 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.h_cw.conv.weight
 |  0.793 |  0.740 |  0.846 |  0.075 | torch.Size([2]) || m_up3.2.pcbam_module.w_hc.weight
 |  0.050 | -0.103 |  0.188 |  0.146 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.w_hc.conv.weight
 |  0.557 |  0.115 |  0.998 |  0.624 | torch.Size([2]) || m_up3.2.pcbam_module.c_hw.weight
 |  0.309 | -0.071 |  1.470 |  0.653 | torch.Size([1, 1, 1, 5]) || m_up3.2.pcbam_module.c_hw.conv.weight
 | -0.001 | -0.389 |  0.302 |  0.033 | torch.Size([384, 192, 2, 2]) || m_up2.0.weight
 |  1.337 |  1.001 |  1.550 |  0.134 | torch.Size([64]) || m_up2.1.trans_block.ln1.weight
 | -0.001 | -0.478 |  0.489 |  0.153 | torch.Size([64]) || m_up2.1.trans_block.ln1.bias
 |  0.173 | -2.433 |  0.911 |  0.344 | torch.Size([2, 15, 15]) || m_up2.1.trans_block.msa.relative_position_params
 |  0.000 | -0.498 |  0.523 |  0.107 | torch.Size([192, 64, 1, 1]) || m_up2.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.184 |  0.179 |  0.045 | torch.Size([192]) || m_up2.1.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.188 |  0.200 |  0.049 | torch.Size([64, 64, 1, 1]) || m_up2.1.trans_block.msa.linear1.weight
 | -0.002 | -0.169 |  0.195 |  0.049 | torch.Size([64]) || m_up2.1.trans_block.msa.linear1.bias
 |  1.060 |  0.803 |  1.204 |  0.076 | torch.Size([64]) || m_up2.1.trans_block.ln2.weight
 |  0.006 | -0.271 |  0.250 |  0.134 | torch.Size([64]) || m_up2.1.trans_block.ln2.bias
 | -0.000 | -0.354 |  0.340 |  0.091 | torch.Size([256, 64]) || m_up2.1.trans_block.mlp.0.weight
 | -0.045 | -0.342 |  0.221 |  0.073 | torch.Size([256]) || m_up2.1.trans_block.mlp.0.bias
 |  0.001 | -0.413 |  0.407 |  0.079 | torch.Size([64, 256]) || m_up2.1.trans_block.mlp.2.weight
 | -0.002 | -0.200 |  0.178 |  0.059 | torch.Size([64]) || m_up2.1.trans_block.mlp.2.bias
 |  0.002 | -0.430 |  2.089 |  0.100 | torch.Size([192, 192, 1, 1]) || m_up2.1.conv1_1.weight
 |  0.000 | -0.586 |  0.717 |  0.127 | torch.Size([192]) || m_up2.1.conv1_1.bias
 | -0.193 | -0.666 |  0.046 |  0.410 | torch.Size([1, 1, 1, 1, 3]) || m_up2.1.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_up2.1.conv3d.bias
 |  0.000 | -0.270 |  0.232 |  0.045 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.0.weight
 |  0.000 | -0.274 |  0.249 |  0.046 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.2.weight
 |  1.917 | -0.437 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.0.mixer.A_log
 |  1.111 |  0.999 |  1.283 |  0.057 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.D
 | -0.000 | -0.339 |  0.321 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.422 |  0.478 |  0.170 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.004 | -0.222 |  0.235 |  0.068 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.001 | -0.143 |  0.207 |  0.038 | torch.Size([36, 128]) || m_up2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.055 |  0.058 |  0.019 | torch.Size([128, 4]) || m_up2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.003 | -0.148 |  0.283 |  0.055 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.517 |  0.375 |  0.076 | torch.Size([64, 128]) || m_up2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.184 |  0.957 |  1.335 |  0.088 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.weight
 |  0.000 | -0.137 |  0.218 |  0.072 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.bias
 |  1.916 | -0.594 |  2.773 |  0.767 | torch.Size([128, 16]) || m_up2.1.mamba_layers.1.mixer.A_log
 |  1.147 |  0.999 |  1.410 |  0.066 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.D
 |  0.000 | -0.371 |  0.399 |  0.090 | torch.Size([256, 64]) || m_up2.1.mamba_layers.1.mixer.in_proj.weight
 | -0.007 | -0.484 |  0.666 |  0.184 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.009 | -0.303 |  0.277 |  0.118 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.235 |  0.301 |  0.063 | torch.Size([36, 128]) || m_up2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.113 |  0.278 |  0.041 | torch.Size([128, 4]) || m_up2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.031 | -0.147 |  0.237 |  0.062 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.001 | -0.380 |  0.459 |  0.089 | torch.Size([64, 128]) || m_up2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.202 |  0.868 |  1.356 |  0.106 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.weight
 |  0.001 | -0.216 |  0.245 |  0.083 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.042 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.2.mixer.A_log
 |  1.006 |  0.945 |  1.079 |  0.027 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.D
 |  0.001 | -0.231 |  0.260 |  0.075 | torch.Size([256, 64]) || m_up2.1.mamba_layers.2.mixer.in_proj.weight
 |  0.000 | -0.538 |  0.643 |  0.287 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.2.mixer.conv1d.weight
 | -0.027 | -0.537 |  0.491 |  0.306 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.176 |  0.172 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.016 | -0.497 |  0.500 |  0.287 | torch.Size([128, 4]) || m_up2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.802 | -6.895 | -2.292 |  1.396 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.207 |  0.193 |  0.059 | torch.Size([64, 128]) || m_up2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.996 |  0.934 |  1.139 |  0.034 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.weight
 | -0.000 | -0.056 |  0.047 |  0.017 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.015 |  2.775 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.3.mixer.A_log
 |  1.001 |  0.945 |  1.076 |  0.028 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.208 |  0.222 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.011 | -0.555 |  0.583 |  0.292 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.3.mixer.conv1d.weight
 | -0.014 | -0.564 |  0.564 |  0.316 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.223 |  0.174 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.3.mixer.x_proj.weight
 | -0.017 | -0.491 |  0.498 |  0.291 | torch.Size([128, 4]) || m_up2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.756 | -6.892 | -2.289 |  1.356 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.222 |  0.194 |  0.059 | torch.Size([64, 128]) || m_up2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.983 |  0.881 |  1.098 |  0.033 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.weight
 | -0.001 | -0.083 |  0.073 |  0.023 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.bias
 |  0.168 |  0.121 |  0.214 |  0.066 | torch.Size([2]) || m_up2.1.pcbam_module.h_cw.weight
 |  0.023 | -0.076 |  0.160 |  0.122 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.h_cw.conv.weight
 |  0.691 |  0.688 |  0.694 |  0.004 | torch.Size([2]) || m_up2.1.pcbam_module.w_hc.weight
 | -0.088 | -0.298 |  0.067 |  0.188 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.w_hc.conv.weight
 |  0.887 |  0.834 |  0.941 |  0.076 | torch.Size([2]) || m_up2.1.pcbam_module.c_hw.weight
 | -0.051 | -0.194 |  0.028 |  0.124 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.c_hw.conv.weight
 |  1.362 |  1.043 |  1.568 |  0.122 | torch.Size([64]) || m_up2.2.trans_block.ln1.weight
 |  0.036 | -0.424 |  0.509 |  0.136 | torch.Size([64]) || m_up2.2.trans_block.ln1.bias
 |  0.131 | -2.465 |  0.732 |  0.331 | torch.Size([2, 15, 15]) || m_up2.2.trans_block.msa.relative_position_params
 |  0.000 | -0.475 |  0.536 |  0.102 | torch.Size([192, 64, 1, 1]) || m_up2.2.trans_block.msa.embedding_layer1.weight
 |  0.000 | -0.259 |  0.292 |  0.069 | torch.Size([192]) || m_up2.2.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.270 |  0.234 |  0.050 | torch.Size([64, 64, 1, 1]) || m_up2.2.trans_block.msa.linear1.weight
 |  0.003 | -0.225 |  0.360 |  0.058 | torch.Size([64]) || m_up2.2.trans_block.msa.linear1.bias
 |  1.068 |  0.644 |  1.268 |  0.120 | torch.Size([64]) || m_up2.2.trans_block.ln2.weight
 |  0.014 | -0.399 |  0.391 |  0.121 | torch.Size([64]) || m_up2.2.trans_block.ln2.bias
 |  0.002 | -0.390 |  0.420 |  0.089 | torch.Size([256, 64]) || m_up2.2.trans_block.mlp.0.weight
 | -0.043 | -0.175 |  0.086 |  0.041 | torch.Size([256]) || m_up2.2.trans_block.mlp.0.bias
 | -0.001 | -0.329 |  0.367 |  0.077 | torch.Size([64, 256]) || m_up2.2.trans_block.mlp.2.weight
 |  0.002 | -0.234 |  0.236 |  0.058 | torch.Size([64]) || m_up2.2.trans_block.mlp.2.bias
 |  0.002 | -0.467 |  1.970 |  0.100 | torch.Size([192, 192, 1, 1]) || m_up2.2.conv1_1.weight
 | -0.002 | -0.390 |  0.749 |  0.114 | torch.Size([192]) || m_up2.2.conv1_1.bias
 | -0.201 | -0.641 |  0.023 |  0.381 | torch.Size([1, 1, 1, 1, 3]) || m_up2.2.conv3d.weight
 | -0.008 | -0.008 | -0.008 |    nan | torch.Size([1]) || m_up2.2.conv3d.bias
 |  0.001 | -0.420 |  0.426 |  0.055 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.0.weight
 | -0.000 | -0.317 |  0.428 |  0.056 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.2.weight
 |  1.915 | -0.421 |  2.782 |  0.770 | torch.Size([128, 16]) || m_up2.2.mamba_layers.0.mixer.A_log
 |  1.149 |  0.722 |  1.475 |  0.104 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.D
 |  0.000 | -0.491 |  0.397 |  0.095 | torch.Size([256, 64]) || m_up2.2.mamba_layers.0.mixer.in_proj.weight
 |  0.031 | -0.543 |  0.704 |  0.191 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.0.mixer.conv1d.weight
 |  0.038 | -0.235 |  0.277 |  0.095 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.conv1d.bias
 | -0.003 | -0.529 |  0.737 |  0.077 | torch.Size([36, 128]) || m_up2.2.mamba_layers.0.mixer.x_proj.weight
 | -0.007 | -0.441 |  0.322 |  0.103 | torch.Size([128, 4]) || m_up2.2.mamba_layers.0.mixer.dt_proj.weight
 | -0.015 | -0.607 |  0.316 |  0.119 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.371 |  0.539 |  0.097 | torch.Size([64, 128]) || m_up2.2.mamba_layers.0.mixer.out_proj.weight
 |  1.245 |  0.939 |  1.393 |  0.097 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.weight
 |  0.008 | -0.510 |  0.450 |  0.163 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.bias
 |  1.919 | -0.504 |  2.883 |  0.766 | torch.Size([128, 16]) || m_up2.2.mamba_layers.1.mixer.A_log
 |  1.150 |  0.792 |  1.461 |  0.097 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.D
 |  0.000 | -0.492 |  0.539 |  0.101 | torch.Size([256, 64]) || m_up2.2.mamba_layers.1.mixer.in_proj.weight
 |  0.011 | -0.651 |  1.011 |  0.203 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.1.mixer.conv1d.weight
 |  0.027 | -0.312 |  0.290 |  0.117 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.493 |  0.573 |  0.101 | torch.Size([36, 128]) || m_up2.2.mamba_layers.1.mixer.x_proj.weight
 |  0.002 | -0.484 |  0.386 |  0.105 | torch.Size([128, 4]) || m_up2.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.053 | -0.216 |  0.601 |  0.110 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.505 |  0.467 |  0.097 | torch.Size([64, 128]) || m_up2.2.mamba_layers.1.mixer.out_proj.weight
 |  1.273 |  0.857 |  1.483 |  0.127 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.weight
 |  0.003 | -0.171 |  0.342 |  0.088 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.bias
 |  1.917 | -0.028 |  2.774 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.2.mixer.A_log
 |  1.015 |  0.954 |  1.124 |  0.030 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.D
 | -0.000 | -0.321 |  0.293 |  0.077 | torch.Size([256, 64]) || m_up2.2.mamba_layers.2.mixer.in_proj.weight
 | -0.004 | -0.557 |  0.541 |  0.288 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.2.mixer.conv1d.weight
 |  0.065 | -0.557 |  0.560 |  0.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.213 |  0.186 |  0.054 | torch.Size([36, 128]) || m_up2.2.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.497 |  0.499 |  0.286 | torch.Size([128, 4]) || m_up2.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.495 | -6.884 | -2.259 |  1.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.277 |  0.259 |  0.064 | torch.Size([64, 128]) || m_up2.2.mamba_layers.2.mixer.out_proj.weight
 |  1.010 |  0.904 |  1.127 |  0.042 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.weight
 |  0.002 | -0.072 |  0.079 |  0.026 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.bias
 |  1.917 | -0.069 |  2.777 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.3.mixer.A_log
 |  1.022 |  0.961 |  1.195 |  0.040 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.D
 |  0.000 | -0.318 |  0.267 |  0.077 | torch.Size([256, 64]) || m_up2.2.mamba_layers.3.mixer.in_proj.weight
 |  0.008 | -0.609 |  0.585 |  0.287 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.3.mixer.conv1d.weight
 |  0.030 | -0.524 |  0.547 |  0.301 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.233 |  0.186 |  0.057 | torch.Size([36, 128]) || m_up2.2.mamba_layers.3.mixer.x_proj.weight
 |  0.004 | -0.568 |  0.579 |  0.290 | torch.Size([128, 4]) || m_up2.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.642 | -6.849 | -2.291 |  1.277 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.dt_proj.bias
 |  0.000 | -0.232 |  0.280 |  0.064 | torch.Size([64, 128]) || m_up2.2.mamba_layers.3.mixer.out_proj.weight
 |  1.010 |  0.913 |  1.117 |  0.042 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.weight
 |  0.003 | -0.068 |  0.065 |  0.026 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.bias
 |  0.309 |  0.187 |  0.430 |  0.172 | torch.Size([2]) || m_up2.2.pcbam_module.h_cw.weight
 |  0.113 | -0.026 |  0.206 |  0.123 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.h_cw.conv.weight
 |  0.821 |  0.758 |  0.884 |  0.089 | torch.Size([2]) || m_up2.2.pcbam_module.w_hc.weight
 |  0.060 | -0.076 |  0.129 |  0.118 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.w_hc.conv.weight
 |  0.737 |  0.713 |  0.762 |  0.035 | torch.Size([2]) || m_up2.2.pcbam_module.c_hw.weight
 |  0.146 |  0.098 |  0.187 |  0.045 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.178 |  0.175 |  0.027 | torch.Size([192, 96, 2, 2]) || m_up1.0.weight
 |  1.177 |  0.801 |  1.393 |  0.189 | torch.Size([32]) || m_up1.1.trans_block.ln1.weight
 | -0.009 | -0.335 |  0.483 |  0.202 | torch.Size([32]) || m_up1.1.trans_block.ln1.bias
 |  0.132 | -1.052 |  0.836 |  0.423 | torch.Size([1, 15, 15]) || m_up1.1.trans_block.msa.relative_position_params
 | -0.000 | -0.412 |  0.367 |  0.104 | torch.Size([96, 32, 1, 1]) || m_up1.1.trans_block.msa.embedding_layer1.weight
 | -0.010 | -0.345 |  0.346 |  0.156 | torch.Size([96]) || m_up1.1.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.271 |  0.239 |  0.073 | torch.Size([32, 32, 1, 1]) || m_up1.1.trans_block.msa.linear1.weight
 |  0.003 | -0.099 |  0.118 |  0.053 | torch.Size([32]) || m_up1.1.trans_block.msa.linear1.bias
 |  1.640 |  1.304 |  1.977 |  0.169 | torch.Size([32]) || m_up1.1.trans_block.ln2.weight
 | -0.005 | -0.307 |  0.292 |  0.175 | torch.Size([32]) || m_up1.1.trans_block.ln2.bias
 |  0.001 | -0.742 |  0.704 |  0.159 | torch.Size([128, 32]) || m_up1.1.trans_block.mlp.0.weight
 | -0.016 | -0.368 |  0.340 |  0.114 | torch.Size([128]) || m_up1.1.trans_block.mlp.0.bias
 | -0.000 | -0.648 |  0.814 |  0.127 | torch.Size([32, 128]) || m_up1.1.trans_block.mlp.2.weight
 | -0.032 | -0.416 |  0.259 |  0.167 | torch.Size([32]) || m_up1.1.trans_block.mlp.2.bias
 | -0.005 | -1.279 |  0.464 |  0.122 | torch.Size([96, 96, 1, 1]) || m_up1.1.conv1_1.weight
 | -0.001 | -0.241 |  0.276 |  0.079 | torch.Size([96]) || m_up1.1.conv1_1.bias
 |  0.020 | -0.254 |  0.396 |  0.337 | torch.Size([1, 1, 1, 1, 3]) || m_up1.1.conv3d.weight
 |  0.002 |  0.002 |  0.002 |    nan | torch.Size([1]) || m_up1.1.conv3d.bias
 | -0.001 | -0.571 |  0.715 |  0.085 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.0.weight
 |  0.000 | -0.610 |  0.792 |  0.093 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.2.weight
 |  1.912 | -0.265 |  2.774 |  0.773 | torch.Size([64, 16]) || m_up1.1.mamba_layers.0.mixer.A_log
 |  1.113 |  0.949 |  1.416 |  0.097 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.D
 | -0.001 | -0.468 |  0.608 |  0.124 | torch.Size([128, 32]) || m_up1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.013 | -0.520 |  0.407 |  0.168 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.0.mixer.conv1d.weight
 | -0.001 | -0.185 |  0.271 |  0.089 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.004 | -0.393 |  0.421 |  0.092 | torch.Size([34, 64]) || m_up1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.011 | -0.519 |  0.299 |  0.129 | torch.Size([64, 2]) || m_up1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.029 | -0.776 |  0.461 |  0.212 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.001 | -0.352 |  0.416 |  0.115 | torch.Size([32, 64]) || m_up1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.202 |  0.985 |  1.390 |  0.118 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.weight
 |  0.001 | -0.220 |  0.136 |  0.072 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.bias
 |  1.906 | -0.980 |  2.773 |  0.783 | torch.Size([64, 16]) || m_up1.1.mamba_layers.1.mixer.A_log
 |  1.176 |  1.062 |  1.330 |  0.056 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.D
 |  0.001 | -0.400 |  0.511 |  0.122 | torch.Size([128, 32]) || m_up1.1.mamba_layers.1.mixer.in_proj.weight
 | -0.008 | -0.489 |  0.367 |  0.155 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.1.mixer.conv1d.weight
 | -0.031 | -0.320 |  0.243 |  0.168 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.381 |  0.282 |  0.069 | torch.Size([34, 64]) || m_up1.1.mamba_layers.1.mixer.x_proj.weight
 | -0.012 | -0.374 |  0.249 |  0.085 | torch.Size([64, 2]) || m_up1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.090 | -0.090 |  0.505 |  0.090 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.004 | -0.603 |  0.486 |  0.128 | torch.Size([32, 64]) || m_up1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.171 |  0.931 |  1.352 |  0.086 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.weight
 |  0.005 | -0.152 |  0.203 |  0.097 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.bias
 |  1.916 | -0.065 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.2.mixer.A_log
 |  1.035 |  0.952 |  1.174 |  0.042 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.D
 | -0.002 | -0.349 |  0.357 |  0.112 | torch.Size([128, 32]) || m_up1.1.mamba_layers.2.mixer.in_proj.weight
 |  0.011 | -0.625 |  0.692 |  0.294 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.2.mixer.conv1d.weight
 |  0.007 | -0.517 |  0.487 |  0.303 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.213 |  0.240 |  0.082 | torch.Size([34, 64]) || m_up1.1.mamba_layers.2.mixer.x_proj.weight
 | -0.082 | -0.708 |  0.700 |  0.396 | torch.Size([64, 2]) || m_up1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.429 | -6.865 | -2.310 |  1.242 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.334 |  0.259 |  0.086 | torch.Size([32, 64]) || m_up1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.026 |  0.966 |  1.096 |  0.028 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.weight
 | -0.004 | -0.042 |  0.034 |  0.022 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.bias
 |  1.913 | -0.037 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.3.mixer.A_log
 |  1.027 |  0.965 |  1.117 |  0.034 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.265 |  0.315 |  0.107 | torch.Size([128, 32]) || m_up1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.011 | -0.514 |  0.564 |  0.295 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.3.mixer.conv1d.weight
 | -0.005 | -0.546 |  0.538 |  0.325 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.206 |  0.234 |  0.083 | torch.Size([34, 64]) || m_up1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.750 |  0.694 |  0.409 | torch.Size([64, 2]) || m_up1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.497 | -6.875 | -2.319 |  1.352 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.003 | -0.246 |  0.249 |  0.084 | torch.Size([32, 64]) || m_up1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.015 |  0.949 |  1.065 |  0.028 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.weight
 | -0.002 | -0.042 |  0.062 |  0.021 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.bias
 |  0.533 |  0.169 |  0.896 |  0.514 | torch.Size([2]) || m_up1.1.pcbam_module.h_cw.weight
 | -0.028 | -0.107 |  0.094 |  0.107 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.h_cw.conv.weight
 |  0.068 |  0.002 |  0.134 |  0.093 | torch.Size([2]) || m_up1.1.pcbam_module.w_hc.weight
 | -0.115 | -0.242 |  0.043 |  0.145 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.w_hc.conv.weight
 |  0.449 |  0.107 |  0.791 |  0.484 | torch.Size([2]) || m_up1.1.pcbam_module.c_hw.weight
 |  0.015 | -0.251 |  0.345 |  0.304 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.c_hw.conv.weight
 |  1.259 |  0.956 |  1.576 |  0.162 | torch.Size([32]) || m_up1.2.trans_block.ln1.weight
 |  0.011 | -0.395 |  0.459 |  0.171 | torch.Size([32]) || m_up1.2.trans_block.ln1.bias
 | -0.143 | -0.850 |  0.643 |  0.354 | torch.Size([1, 15, 15]) || m_up1.2.trans_block.msa.relative_position_params
 | -0.001 | -0.592 |  0.655 |  0.142 | torch.Size([96, 32, 1, 1]) || m_up1.2.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.217 |  0.139 |  0.041 | torch.Size([96]) || m_up1.2.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.157 |  0.161 |  0.047 | torch.Size([32, 32, 1, 1]) || m_up1.2.trans_block.msa.linear1.weight
 |  0.001 | -0.105 |  0.112 |  0.039 | torch.Size([32]) || m_up1.2.trans_block.msa.linear1.bias
 |  1.009 |  0.826 |  1.195 |  0.089 | torch.Size([32]) || m_up1.2.trans_block.ln2.weight
 | -0.005 | -0.150 |  0.195 |  0.075 | torch.Size([32]) || m_up1.2.trans_block.ln2.bias
 |  0.001 | -0.563 |  0.424 |  0.079 | torch.Size([128, 32]) || m_up1.2.trans_block.mlp.0.weight
 | -0.005 | -0.202 |  0.093 |  0.047 | torch.Size([128]) || m_up1.2.trans_block.mlp.0.bias
 | -0.001 | -0.341 |  0.371 |  0.085 | torch.Size([32, 128]) || m_up1.2.trans_block.mlp.2.weight
 | -0.003 | -0.105 |  0.207 |  0.057 | torch.Size([32]) || m_up1.2.trans_block.mlp.2.bias
 | -0.001 | -0.746 |  0.505 |  0.105 | torch.Size([96, 96, 1, 1]) || m_up1.2.conv1_1.weight
 | -0.002 | -0.225 |  0.383 |  0.064 | torch.Size([96]) || m_up1.2.conv1_1.bias
 |  0.103 | -0.055 |  0.356 |  0.221 | torch.Size([1, 1, 1, 1, 3]) || m_up1.2.conv3d.weight
 |  0.005 |  0.005 |  0.005 |    nan | torch.Size([1]) || m_up1.2.conv3d.bias
 |  0.002 | -0.323 |  0.610 |  0.079 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.0.weight
 | -0.000 | -0.555 |  0.757 |  0.095 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.2.weight
 |  1.913 | -0.746 |  2.773 |  0.775 | torch.Size([64, 16]) || m_up1.2.mamba_layers.0.mixer.A_log
 |  1.120 |  0.987 |  1.403 |  0.076 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.D
 |  0.001 | -0.492 |  0.513 |  0.123 | torch.Size([128, 32]) || m_up1.2.mamba_layers.0.mixer.in_proj.weight
 | -0.004 | -0.389 |  0.437 |  0.164 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.0.mixer.conv1d.weight
 |  0.006 | -0.089 |  0.131 |  0.050 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.528 |  0.348 |  0.102 | torch.Size([34, 64]) || m_up1.2.mamba_layers.0.mixer.x_proj.weight
 | -0.001 | -0.097 |  0.143 |  0.040 | torch.Size([64, 2]) || m_up1.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.028 | -0.378 |  0.653 |  0.187 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.352 |  0.395 |  0.110 | torch.Size([32, 64]) || m_up1.2.mamba_layers.0.mixer.out_proj.weight
 |  1.253 |  0.900 |  1.446 |  0.113 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.weight
 |  0.014 | -0.223 |  0.275 |  0.105 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.bias
 |  1.913 | -0.540 |  2.783 |  0.778 | torch.Size([64, 16]) || m_up1.2.mamba_layers.1.mixer.A_log
 |  1.193 |  0.974 |  1.458 |  0.106 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.D
 |  0.001 | -0.624 |  0.624 |  0.139 | torch.Size([128, 32]) || m_up1.2.mamba_layers.1.mixer.in_proj.weight
 |  0.012 | -0.574 |  0.689 |  0.185 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.1.mixer.conv1d.weight
 |  0.018 | -0.238 |  0.220 |  0.102 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.conv1d.bias
 |  0.001 | -0.540 |  0.579 |  0.122 | torch.Size([34, 64]) || m_up1.2.mamba_layers.1.mixer.x_proj.weight
 | -0.048 | -0.482 |  0.250 |  0.154 | torch.Size([64, 2]) || m_up1.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.042 | -0.451 |  0.549 |  0.160 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.dt_proj.bias
 | -0.002 | -0.732 |  0.578 |  0.146 | torch.Size([32, 64]) || m_up1.2.mamba_layers.1.mixer.out_proj.weight
 |  1.227 |  0.943 |  1.396 |  0.105 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.weight
 |  0.005 | -0.113 |  0.106 |  0.049 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.bias
 |  1.917 | -0.069 |  2.777 |  0.765 | torch.Size([64, 16]) || m_up1.2.mamba_layers.2.mixer.A_log
 |  1.014 |  0.955 |  1.170 |  0.043 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.D
 |  0.000 | -0.336 |  0.312 |  0.108 | torch.Size([128, 32]) || m_up1.2.mamba_layers.2.mixer.in_proj.weight
 | -0.022 | -0.580 |  0.575 |  0.281 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.2.mixer.conv1d.weight
 |  0.010 | -0.524 |  0.522 |  0.322 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.227 |  0.224 |  0.076 | torch.Size([34, 64]) || m_up1.2.mamba_layers.2.mixer.x_proj.weight
 |  0.070 | -0.709 |  0.670 |  0.392 | torch.Size([64, 2]) || m_up1.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.717 | -6.818 | -2.344 |  1.385 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.002 | -0.329 |  0.300 |  0.086 | torch.Size([32, 64]) || m_up1.2.mamba_layers.2.mixer.out_proj.weight
 |  1.009 |  0.916 |  1.089 |  0.042 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.weight
 |  0.001 | -0.039 |  0.026 |  0.018 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.bias
 |  1.916 | -0.057 |  2.776 |  0.766 | torch.Size([64, 16]) || m_up1.2.mamba_layers.3.mixer.A_log
 |  1.007 |  0.942 |  1.114 |  0.035 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.D
 | -0.002 | -0.361 |  0.428 |  0.109 | torch.Size([128, 32]) || m_up1.2.mamba_layers.3.mixer.in_proj.weight
 |  0.012 | -0.638 |  0.544 |  0.296 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.3.mixer.conv1d.weight
 |  0.083 | -0.442 |  0.552 |  0.280 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.conv1d.bias
 | -0.004 | -0.238 |  0.253 |  0.077 | torch.Size([34, 64]) || m_up1.2.mamba_layers.3.mixer.x_proj.weight
 | -0.115 | -0.707 |  0.686 |  0.390 | torch.Size([64, 2]) || m_up1.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.758 | -6.877 | -2.275 |  1.309 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.002 | -0.392 |  0.276 |  0.088 | torch.Size([32, 64]) || m_up1.2.mamba_layers.3.mixer.out_proj.weight
 |  1.018 |  0.968 |  1.186 |  0.043 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.weight
 | -0.002 | -0.043 |  0.055 |  0.018 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.bias
 |  0.666 |  0.459 |  0.874 |  0.294 | torch.Size([2]) || m_up1.2.pcbam_module.h_cw.weight
 |  0.147 |  0.087 |  0.185 |  0.053 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.h_cw.conv.weight
 |  0.182 |  0.079 |  0.285 |  0.146 | torch.Size([2]) || m_up1.2.pcbam_module.w_hc.weight
 | -0.014 | -0.144 |  0.210 |  0.194 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.w_hc.conv.weight
 |  0.236 |  0.093 |  0.378 |  0.201 | torch.Size([2]) || m_up1.2.pcbam_module.c_hw.weight
 |  0.078 | -0.043 |  0.183 |  0.114 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.c_hw.conv.weight
 |  0.000 | -0.061 |  0.067 |  0.014 | torch.Size([3, 96, 3, 3]) || m_tail.0.weight
 | -0.029 | -0.131 |  0.157 |  0.083 | torch.Size([3, 3, 1, 1]) || fft.mag.weight
 |  0.178 | -0.197 |  0.457 |  0.338 | torch.Size([3]) || fft.mag.bias
 |  0.162 |  0.028 |  0.320 |  0.148 | torch.Size([3]) || fft.mag_bn.weight
 | -0.796 | -2.134 | -0.114 |  1.159 | torch.Size([3]) || fft.mag_bn.bias
 | -2.340 | -7.169 |  3.582 |  5.458 | torch.Size([3]) || fft.mag_bn.running_mean
 | 440.826 | 196.210 | 869.354 | 372.355 | torch.Size([3]) || fft.mag_bn.running_var
 |  0.010 | -0.300 |  0.165 |  0.157 | torch.Size([3, 3, 1, 1]) || fft.pha.0.weight
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.0.bias
 |  1.177 |  0.834 |  1.432 |  0.308 | torch.Size([3]) || fft.pha.1.weight
 |  0.324 |  0.205 |  0.396 |  0.104 | torch.Size([3]) || fft.pha.1.bias
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.1.running_mean
 |  0.026 |  0.017 |  0.038 |  0.011 | torch.Size([3]) || fft.pha.1.running_var
 | -0.086 | -0.660 |  0.867 |  0.494 | torch.Size([3, 3, 1, 1]) || fft.pha.3.weight
 |  0.009 | -0.146 |  0.139 |  0.144 | torch.Size([3]) || fft.pha.3.bias
 |  0.311 | -0.158 |  2.024 |  0.841 | torch.Size([1, 6, 1, 1]) || fft.conv1.weight
 |  0.029 |  0.029 |  0.029 |    nan | torch.Size([1]) || fft.conv1.bias
 | -0.001 | -0.085 |  0.074 |  0.023 | torch.Size([96, 96, 1, 1]) || conv1.weight
 | -0.000 | -0.016 |  0.021 |  0.005 | torch.Size([96]) || conv1.bias
 |  0.415 |  0.004 |  0.891 |  0.224 | torch.Size([96]) || bn1.weight
 | -0.088 | -0.192 | -0.011 |  0.040 | torch.Size([96]) || bn1.bias
 | -0.002 | -0.042 |  0.056 |  0.028 | torch.Size([96]) || bn1.running_mean
 |  0.001 |  0.000 |  0.005 |  0.001 | torch.Size([96]) || bn1.running_var
 | -0.002 | -0.065 |  0.059 |  0.014 | torch.Size([192, 96, 2, 2]) || conv2.weight
 | -0.000 | -0.011 |  0.012 |  0.004 | torch.Size([192]) || conv2.bias
 |  0.415 |  0.019 |  0.895 |  0.226 | torch.Size([192]) || bn2.weight
 | -0.079 | -0.207 | -0.008 |  0.039 | torch.Size([192]) || bn2.bias
 | -0.025 | -0.117 |  0.091 |  0.047 | torch.Size([192]) || bn2.running_mean
 |  0.019 |  0.000 |  0.060 |  0.011 | torch.Size([192]) || bn2.running_var
 | -0.001 | -0.044 |  0.041 |  0.007 | torch.Size([384, 96, 4, 4]) || conv3.weight
 | -0.000 | -0.022 |  0.014 |  0.005 | torch.Size([384]) || conv3.bias
 |  0.439 |  0.046 |  0.919 |  0.222 | torch.Size([384]) || bn3.weight
 | -0.069 | -0.198 |  0.026 |  0.035 | torch.Size([384]) || bn3.bias
 | -0.063 | -0.188 |  0.156 |  0.042 | torch.Size([384]) || bn3.running_mean
 |  0.049 |  0.002 |  0.182 |  0.025 | torch.Size([384]) || bn3.running_var

25-05-22 10:56:58.103 :   task: DRNet25
  model: plain
  gpu_ids: [0, 1, 2, 3]
  scale: 3
  n_channels: 3
  merge_bn: True
  merge_bn_startpoint: 400000
  path:[
    root: denoising
    pretrained_netG: denoising/DRNet25/models/100_G.pth
    task: denoising/DRNet25
    log: denoising/DRNet25
    options: denoising/DRNet25/options
    models: denoising/DRNet25/models
    images: denoising/DRNet25/images
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: drnet
      dataroot_H: trainsets/AllImages
      dataroot_L: None
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 3
      dataloader_batch_size: 1
      sigma: 25
      sigma_test: 25
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: drnet
      dataroot_H: testsets/NWPU-RESISC45_test_4fen
      dataroot_L: None
      sigma: 25
      sigma_test: 25
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: drnet
    in_nc: 3
    out_nc: 3
    nc: 64
    nb: 17
    gc: 32
    ng: 2
    reduction: 16
    act_mode: BR
    upsample_mode: convtranspose
    downsample_mode: strideconv
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 3
  ]
  train:[
    G_lossfn_type: l2
    G_lossfn_weight: 0.1
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [30000, 50000, 120000, 240000, 24000000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 10000
    checkpoint_save: 10000
    checkpoint_print: 10000
  ]
  opt_path: options/train_drnet.json
  is_train: True

25-05-22 10:56:58.104 : Random seed: 6792
25-05-22 10:56:58.231 : Number of train images: 31,005, iters: 31,005
25-05-22 10:57:00.209 : 
Networks name: DRNet
Params number: 18333721
Net structure:
DRNet(
  (m_head): Sequential(
    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (m_down1): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down2): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down3): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_body): Sequential(
    (0): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=256, bias=True)
        )
      )
      (conv1_1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=256, out_features=1024, bias=False)
            (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
            (act): SiLU()
            (x_proj): Linear(in_features=512, out_features=48, bias=False)
            (dt_proj): Linear(in_features=16, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=256, bias=False)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up3): Sequential(
    (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=512, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=512, out_features=128, bias=True)
        )
      )
      (conv1_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up2): Sequential(
    (0): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=256, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (conv1_1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_up1): Sequential(
    (0): ConvTranspose2d(192, 96, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): ResBlock_CD2C(
      (trans_block): Block(
        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (msa): WMSA(
          (embedding_layer1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))
          (linear1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
        )
        (drop_path): Identity()
        (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=32, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=32, bias=True)
        )
      )
      (conv1_1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
      (conv3d): Conv3d(1, 1, kernel_size=(1, 1, 3), stride=(1, 1, 1), padding=(0, 0, 1))
      (conv_block): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (mamba_layers): ModuleList(
        (0-3): 4 x Block(
          (mixer): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (drop_path): Identity()
        )
      )
      (pcbam_module): MCALayer(
        (h_cw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (w_hc): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
        (c_hw): MCAGate(
          (pools): ModuleList(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): StdPool()
          )
          (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
  )
  (m_tail): Sequential(
    (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (fft): ResBlock_fft_bench(
    (mag): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
    (mag_bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (mag_relu): ReLU(inplace=True)
    (pha): Sequential(
      (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
      (4): Sigmoid()
    )
    (conv1): Conv2d(6, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
  (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (conv2): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
  (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu2): ReLU()
  (conv3): Conv2d(96, 384, kernel_size=(4, 4), stride=(4, 4))
  (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu3): ReLU()
)

25-05-22 10:57:00.943 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.001 | -0.166 |  0.188 |  0.042 | torch.Size([96, 3, 3, 3]) || m_head.0.weight
 |  1.000 |  0.690 |  1.333 |  0.155 | torch.Size([32]) || m_down1.0.trans_block.ln1.weight
 | -0.026 | -0.272 |  0.279 |  0.131 | torch.Size([32]) || m_down1.0.trans_block.ln1.bias
 | -0.078 | -0.695 |  1.039 |  0.371 | torch.Size([1, 15, 15]) || m_down1.0.trans_block.msa.relative_position_params
 |  0.000 | -0.284 |  0.324 |  0.060 | torch.Size([96, 32, 1, 1]) || m_down1.0.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.110 |  0.107 |  0.047 | torch.Size([96]) || m_down1.0.trans_block.msa.embedding_layer1.bias
 |  0.002 | -0.174 |  0.223 |  0.053 | torch.Size([32, 32, 1, 1]) || m_down1.0.trans_block.msa.linear1.weight
 |  0.005 | -0.078 |  0.114 |  0.051 | torch.Size([32]) || m_down1.0.trans_block.msa.linear1.bias
 |  1.186 |  1.012 |  1.426 |  0.113 | torch.Size([32]) || m_down1.0.trans_block.ln2.weight
 | -0.010 | -0.165 |  0.135 |  0.059 | torch.Size([32]) || m_down1.0.trans_block.ln2.bias
 |  0.005 | -0.586 |  1.295 |  0.114 | torch.Size([128, 32]) || m_down1.0.trans_block.mlp.0.weight
 | -0.023 | -0.187 |  0.150 |  0.069 | torch.Size([128]) || m_down1.0.trans_block.mlp.0.bias
 |  0.000 | -0.460 |  0.717 |  0.086 | torch.Size([32, 128]) || m_down1.0.trans_block.mlp.2.weight
 | -0.004 | -0.113 |  0.275 |  0.090 | torch.Size([32]) || m_down1.0.trans_block.mlp.2.bias
 |  0.006 | -0.481 |  0.460 |  0.094 | torch.Size([96, 96, 1, 1]) || m_down1.0.conv1_1.weight
 | -0.003 | -0.432 |  0.406 |  0.110 | torch.Size([96]) || m_down1.0.conv1_1.bias
 | -0.092 | -0.180 |  0.001 |  0.090 | torch.Size([1, 1, 1, 1, 3]) || m_down1.0.conv3d.weight
 | -0.024 | -0.024 | -0.024 |    nan | torch.Size([1]) || m_down1.0.conv3d.bias
 |  0.006 | -0.337 |  0.475 |  0.073 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.0.weight
 | -0.004 | -0.470 |  0.358 |  0.072 | torch.Size([32, 32, 3, 3]) || m_down1.0.conv_block.2.weight
 |  1.906 | -2.333 |  2.825 |  0.813 | torch.Size([64, 16]) || m_down1.0.mamba_layers.0.mixer.A_log
 |  1.081 |  0.345 |  1.364 |  0.174 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.D
 | -0.000 | -0.468 |  0.530 |  0.121 | torch.Size([128, 32]) || m_down1.0.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.436 |  0.458 |  0.166 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.0.mixer.conv1d.weight
 | -0.011 | -0.234 |  0.181 |  0.088 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.889 |  0.703 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.0.mixer.x_proj.weight
 |  0.005 | -0.791 |  0.938 |  0.248 | torch.Size([64, 2]) || m_down1.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.077 | -1.579 |  0.442 |  0.373 | torch.Size([64]) || m_down1.0.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.629 |  0.546 |  0.115 | torch.Size([32, 64]) || m_down1.0.mamba_layers.0.mixer.out_proj.weight
 |  1.133 |  0.910 |  1.650 |  0.129 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.weight
 |  0.013 | -0.367 |  0.299 |  0.157 | torch.Size([32]) || m_down1.0.mamba_layers.0.norm.bias
 |  1.905 | -0.797 |  2.773 |  0.795 | torch.Size([64, 16]) || m_down1.0.mamba_layers.1.mixer.A_log
 |  1.161 |  0.905 |  1.359 |  0.086 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.D
 |  0.001 | -0.586 |  0.458 |  0.127 | torch.Size([128, 32]) || m_down1.0.mamba_layers.1.mixer.in_proj.weight
 |  0.013 | -0.365 |  0.485 |  0.156 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.1.mixer.conv1d.weight
 | -0.004 | -0.303 |  0.279 |  0.165 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.563 |  0.743 |  0.123 | torch.Size([34, 64]) || m_down1.0.mamba_layers.1.mixer.x_proj.weight
 |  0.013 | -0.312 |  0.472 |  0.146 | torch.Size([64, 2]) || m_down1.0.mamba_layers.1.mixer.dt_proj.weight
 |  0.052 | -0.313 |  0.269 |  0.122 | torch.Size([64]) || m_down1.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.003 | -0.367 |  0.425 |  0.118 | torch.Size([32, 64]) || m_down1.0.mamba_layers.1.mixer.out_proj.weight
 |  1.170 |  0.994 |  1.344 |  0.097 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.weight
 | -0.005 | -0.256 |  0.350 |  0.138 | torch.Size([32]) || m_down1.0.mamba_layers.1.norm.bias
 |  1.917 | -0.070 |  2.775 |  0.765 | torch.Size([64, 16]) || m_down1.0.mamba_layers.2.mixer.A_log
 |  1.018 |  0.941 |  1.120 |  0.038 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.D
 |  0.000 | -0.340 |  0.349 |  0.107 | torch.Size([128, 32]) || m_down1.0.mamba_layers.2.mixer.in_proj.weight
 | -0.012 | -0.582 |  0.568 |  0.294 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.2.mixer.conv1d.weight
 | -0.031 | -0.499 |  0.487 |  0.284 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.219 |  0.189 |  0.076 | torch.Size([34, 64]) || m_down1.0.mamba_layers.2.mixer.x_proj.weight
 | -0.055 | -0.705 |  0.714 |  0.417 | torch.Size([64, 2]) || m_down1.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.715 | -6.856 | -2.311 |  1.285 | torch.Size([64]) || m_down1.0.mamba_layers.2.mixer.dt_proj.bias
 | -0.003 | -0.242 |  0.287 |  0.083 | torch.Size([32, 64]) || m_down1.0.mamba_layers.2.mixer.out_proj.weight
 |  1.005 |  0.927 |  1.096 |  0.037 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.weight
 |  0.006 | -0.039 |  0.061 |  0.023 | torch.Size([32]) || m_down1.0.mamba_layers.2.norm.bias
 |  1.916 | -0.244 |  2.776 |  0.766 | torch.Size([64, 16]) || m_down1.0.mamba_layers.3.mixer.A_log
 |  1.011 |  0.942 |  1.097 |  0.034 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.D
 |  0.003 | -0.276 |  0.271 |  0.106 | torch.Size([128, 32]) || m_down1.0.mamba_layers.3.mixer.in_proj.weight
 |  0.004 | -0.596 |  0.566 |  0.297 | torch.Size([64, 1, 4]) || m_down1.0.mamba_layers.3.mixer.conv1d.weight
 | -0.071 | -0.626 |  0.545 |  0.307 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.201 |  0.214 |  0.076 | torch.Size([34, 64]) || m_down1.0.mamba_layers.3.mixer.x_proj.weight
 |  0.039 | -0.688 |  0.780 |  0.425 | torch.Size([64, 2]) || m_down1.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.400 | -7.091 | -2.271 |  1.482 | torch.Size([64]) || m_down1.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.241 |  0.288 |  0.083 | torch.Size([32, 64]) || m_down1.0.mamba_layers.3.mixer.out_proj.weight
 |  1.000 |  0.945 |  1.041 |  0.024 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.weight
 | -0.003 | -0.041 |  0.032 |  0.020 | torch.Size([32]) || m_down1.0.mamba_layers.3.norm.bias
 |  0.172 |  0.084 |  0.261 |  0.125 | torch.Size([2]) || m_down1.0.pcbam_module.h_cw.weight
 |  0.094 | -0.058 |  0.226 |  0.143 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.h_cw.conv.weight
 |  0.559 |  0.261 |  0.856 |  0.421 | torch.Size([2]) || m_down1.0.pcbam_module.w_hc.weight
 |  0.076 | -0.096 |  0.188 |  0.151 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.w_hc.conv.weight
 |  0.612 |  0.582 |  0.641 |  0.042 | torch.Size([2]) || m_down1.0.pcbam_module.c_hw.weight
 |  0.040 | -0.233 |  0.379 |  0.311 | torch.Size([1, 1, 1, 3]) || m_down1.0.pcbam_module.c_hw.conv.weight
 |  1.055 |  0.769 |  1.285 |  0.145 | torch.Size([32]) || m_down1.1.trans_block.ln1.weight
 |  0.019 | -0.283 |  0.280 |  0.134 | torch.Size([32]) || m_down1.1.trans_block.ln1.bias
 | -0.225 | -0.784 |  0.824 |  0.322 | torch.Size([1, 15, 15]) || m_down1.1.trans_block.msa.relative_position_params
 |  0.001 | -0.380 |  0.366 |  0.088 | torch.Size([96, 32, 1, 1]) || m_down1.1.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.193 |  0.185 |  0.052 | torch.Size([96]) || m_down1.1.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.196 |  0.207 |  0.053 | torch.Size([32, 32, 1, 1]) || m_down1.1.trans_block.msa.linear1.weight
 |  0.000 | -0.139 |  0.101 |  0.048 | torch.Size([32]) || m_down1.1.trans_block.msa.linear1.bias
 |  1.164 |  0.991 |  1.293 |  0.073 | torch.Size([32]) || m_down1.1.trans_block.ln2.weight
 | -0.000 | -0.123 |  0.174 |  0.067 | torch.Size([32]) || m_down1.1.trans_block.ln2.bias
 | -0.001 | -0.905 |  0.562 |  0.114 | torch.Size([128, 32]) || m_down1.1.trans_block.mlp.0.weight
 | -0.011 | -0.235 |  0.116 |  0.054 | torch.Size([128]) || m_down1.1.trans_block.mlp.0.bias
 | -0.000 | -0.661 |  0.622 |  0.099 | torch.Size([32, 128]) || m_down1.1.trans_block.mlp.2.weight
 | -0.009 | -0.120 |  0.228 |  0.080 | torch.Size([32]) || m_down1.1.trans_block.mlp.2.bias
 |  0.006 | -0.455 |  0.573 |  0.096 | torch.Size([96, 96, 1, 1]) || m_down1.1.conv1_1.weight
 | -0.008 | -0.200 |  0.272 |  0.064 | torch.Size([96]) || m_down1.1.conv1_1.bias
 | -0.077 | -0.289 |  0.036 |  0.183 | torch.Size([1, 1, 1, 1, 3]) || m_down1.1.conv3d.weight
 | -0.012 | -0.012 | -0.012 |    nan | torch.Size([1]) || m_down1.1.conv3d.bias
 | -0.002 | -0.406 |  0.342 |  0.064 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.0.weight
 | -0.006 | -0.314 |  0.292 |  0.064 | torch.Size([32, 32, 3, 3]) || m_down1.1.conv_block.2.weight
 |  1.917 | -0.011 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.0.mixer.A_log
 |  1.048 |  0.985 |  1.166 |  0.047 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.D
 | -0.000 | -0.443 |  0.430 |  0.086 | torch.Size([128, 32]) || m_down1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.015 | -0.304 |  0.314 |  0.114 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.0.mixer.conv1d.weight
 |  0.015 | -0.205 |  0.208 |  0.064 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.142 |  0.135 |  0.031 | torch.Size([34, 64]) || m_down1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.002 | -0.062 |  0.053 |  0.025 | torch.Size([64, 2]) || m_down1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.001 | -0.024 |  0.032 |  0.009 | torch.Size([64]) || m_down1.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.001 | -0.369 |  0.356 |  0.083 | torch.Size([32, 64]) || m_down1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.113 |  0.927 |  1.290 |  0.105 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.weight
 |  0.012 | -0.156 |  0.187 |  0.076 | torch.Size([32]) || m_down1.1.mamba_layers.0.norm.bias
 |  1.918 | -0.212 |  2.773 |  0.764 | torch.Size([64, 16]) || m_down1.1.mamba_layers.1.mixer.A_log
 |  1.091 |  0.987 |  1.491 |  0.090 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.D
 |  0.000 | -0.626 |  0.634 |  0.094 | torch.Size([128, 32]) || m_down1.1.mamba_layers.1.mixer.in_proj.weight
 |  0.001 | -0.329 |  0.372 |  0.124 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.196 |  0.186 |  0.088 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.001 | -0.183 |  0.294 |  0.048 | torch.Size([34, 64]) || m_down1.1.mamba_layers.1.mixer.x_proj.weight
 |  0.006 | -0.151 |  0.153 |  0.037 | torch.Size([64, 2]) || m_down1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.008 | -0.160 |  0.449 |  0.077 | torch.Size([64]) || m_down1.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.004 | -0.548 |  0.372 |  0.087 | torch.Size([32, 64]) || m_down1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.134 |  1.020 |  1.298 |  0.072 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.weight
 | -0.002 | -0.096 |  0.087 |  0.053 | torch.Size([32]) || m_down1.1.mamba_layers.1.norm.bias
 |  1.917 | -0.016 |  2.774 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.2.mixer.A_log
 |  1.000 |  0.959 |  1.044 |  0.021 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.D
 | -0.001 | -0.232 |  0.277 |  0.106 | torch.Size([128, 32]) || m_down1.1.mamba_layers.2.mixer.in_proj.weight
 | -0.024 | -0.515 |  0.512 |  0.285 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.2.mixer.conv1d.weight
 | -0.017 | -0.508 |  0.448 |  0.282 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.151 |  0.153 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.2.mixer.x_proj.weight
 |  0.092 | -0.700 |  0.704 |  0.396 | torch.Size([64, 2]) || m_down1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.418 | -6.864 | -2.343 |  1.239 | torch.Size([64]) || m_down1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.223 |  0.208 |  0.075 | torch.Size([32, 64]) || m_down1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.000 |  0.965 |  1.039 |  0.021 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.weight
 |  0.002 | -0.037 |  0.031 |  0.016 | torch.Size([32]) || m_down1.1.mamba_layers.2.norm.bias
 |  1.917 | -0.041 |  2.777 |  0.765 | torch.Size([64, 16]) || m_down1.1.mamba_layers.3.mixer.A_log
 |  1.006 |  0.963 |  1.083 |  0.027 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.296 |  0.355 |  0.109 | torch.Size([128, 32]) || m_down1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.023 | -0.521 |  0.538 |  0.299 | torch.Size([64, 1, 4]) || m_down1.1.mamba_layers.3.mixer.conv1d.weight
 |  0.047 | -0.418 |  0.512 |  0.241 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.156 |  0.181 |  0.073 | torch.Size([34, 64]) || m_down1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.694 |  0.699 |  0.380 | torch.Size([64, 2]) || m_down1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.585 | -6.892 | -2.263 |  1.350 | torch.Size([64]) || m_down1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.001 | -0.238 |  0.246 |  0.078 | torch.Size([32, 64]) || m_down1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.025 |  0.962 |  1.116 |  0.037 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.weight
 | -0.001 | -0.048 |  0.055 |  0.028 | torch.Size([32]) || m_down1.1.mamba_layers.3.norm.bias
 |  0.133 |  0.115 |  0.151 |  0.025 | torch.Size([2]) || m_down1.1.pcbam_module.h_cw.weight
 |  0.159 |  0.056 |  0.311 |  0.134 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.h_cw.conv.weight
 |  0.356 |  0.181 |  0.530 |  0.247 | torch.Size([2]) || m_down1.1.pcbam_module.w_hc.weight
 |  0.196 |  0.121 |  0.253 |  0.068 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.w_hc.conv.weight
 |  0.723 |  0.569 |  0.877 |  0.218 | torch.Size([2]) || m_down1.1.pcbam_module.c_hw.weight
 | -0.098 | -0.318 |  0.113 |  0.215 | torch.Size([1, 1, 1, 3]) || m_down1.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.322 |  0.291 |  0.051 | torch.Size([192, 96, 2, 2]) || m_down1.2.weight
 |  1.094 |  0.726 |  1.718 |  0.242 | torch.Size([64]) || m_down2.0.trans_block.ln1.weight
 | -0.005 | -0.464 |  0.477 |  0.219 | torch.Size([64]) || m_down2.0.trans_block.ln1.bias
 | -0.205 | -1.957 |  1.787 |  0.695 | torch.Size([2, 15, 15]) || m_down2.0.trans_block.msa.relative_position_params
 |  0.000 | -0.432 |  0.426 |  0.075 | torch.Size([192, 64, 1, 1]) || m_down2.0.trans_block.msa.embedding_layer1.weight
 | -0.005 | -0.203 |  0.184 |  0.046 | torch.Size([192]) || m_down2.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.243 |  0.233 |  0.051 | torch.Size([64, 64, 1, 1]) || m_down2.0.trans_block.msa.linear1.weight
 |  0.002 | -0.116 |  0.184 |  0.043 | torch.Size([64]) || m_down2.0.trans_block.msa.linear1.bias
 |  1.134 |  0.800 |  1.470 |  0.135 | torch.Size([64]) || m_down2.0.trans_block.ln2.weight
 |  0.008 | -0.138 |  0.250 |  0.071 | torch.Size([64]) || m_down2.0.trans_block.ln2.bias
 |  0.002 | -0.502 |  0.472 |  0.094 | torch.Size([256, 64]) || m_down2.0.trans_block.mlp.0.weight
 | -0.047 | -0.278 |  0.063 |  0.048 | torch.Size([256]) || m_down2.0.trans_block.mlp.0.bias
 |  0.001 | -0.387 |  0.367 |  0.072 | torch.Size([64, 256]) || m_down2.0.trans_block.mlp.2.weight
 |  0.022 | -0.105 |  0.114 |  0.048 | torch.Size([64]) || m_down2.0.trans_block.mlp.2.bias
 |  0.008 | -0.714 |  0.843 |  0.097 | torch.Size([192, 192, 1, 1]) || m_down2.0.conv1_1.weight
 |  0.003 | -0.553 |  0.627 |  0.115 | torch.Size([192]) || m_down2.0.conv1_1.bias
 | -0.075 | -0.231 |  0.012 |  0.135 | torch.Size([1, 1, 1, 1, 3]) || m_down2.0.conv3d.weight
 | -0.010 | -0.010 | -0.010 |    nan | torch.Size([1]) || m_down2.0.conv3d.bias
 |  0.001 | -0.403 |  0.407 |  0.059 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.0.weight
 | -0.000 | -0.270 |  0.382 |  0.060 | torch.Size([64, 64, 3, 3]) || m_down2.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.0.mamba_layers.0.mixer.A_log
 |  1.008 |  0.996 |  1.123 |  0.022 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.D
 | -0.000 | -0.279 |  0.257 |  0.032 | torch.Size([256, 64]) || m_down2.0.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.288 |  0.301 |  0.062 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.138 |  0.069 |  0.025 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.062 |  0.058 |  0.018 | torch.Size([36, 128]) || m_down2.0.mamba_layers.0.mixer.x_proj.weight
 |  0.001 | -0.049 |  0.055 |  0.018 | torch.Size([128, 4]) || m_down2.0.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.001 |  0.001 |  0.000 | torch.Size([128]) || m_down2.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.224 |  0.271 |  0.033 | torch.Size([64, 128]) || m_down2.0.mamba_layers.0.mixer.out_proj.weight
 |  1.038 |  0.896 |  1.214 |  0.080 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.weight
 |  0.003 | -0.141 |  0.146 |  0.071 | torch.Size([64]) || m_down2.0.mamba_layers.0.norm.bias
 |  1.916 | -0.326 |  2.773 |  0.767 | torch.Size([128, 16]) || m_down2.0.mamba_layers.1.mixer.A_log
 |  1.033 |  0.993 |  1.252 |  0.053 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.D
 | -0.000 | -0.330 |  0.352 |  0.050 | torch.Size([256, 64]) || m_down2.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.333 |  0.428 |  0.092 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.1.mixer.conv1d.weight
 |  0.017 | -0.173 |  0.316 |  0.071 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.245 |  0.181 |  0.034 | torch.Size([36, 128]) || m_down2.0.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.093 |  0.087 |  0.021 | torch.Size([128, 4]) || m_down2.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.010 | -0.302 |  0.159 |  0.052 | torch.Size([128]) || m_down2.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.346 |  0.348 |  0.052 | torch.Size([64, 128]) || m_down2.0.mamba_layers.1.mixer.out_proj.weight
 |  1.053 |  0.926 |  1.208 |  0.072 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.weight
 |  0.002 | -0.248 |  0.239 |  0.129 | torch.Size([64]) || m_down2.0.mamba_layers.1.norm.bias
 |  1.917 | -0.026 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.2.mixer.A_log
 |  0.986 |  0.946 |  1.030 |  0.019 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.D
 |  0.000 | -0.205 |  0.194 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.2.mixer.in_proj.weight
 | -0.003 | -0.515 |  0.512 |  0.273 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.2.mixer.conv1d.weight
 | -0.026 | -0.511 |  0.497 |  0.296 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.130 |  0.212 |  0.052 | torch.Size([36, 128]) || m_down2.0.mamba_layers.2.mixer.x_proj.weight
 |  0.014 | -0.500 |  0.501 |  0.292 | torch.Size([128, 4]) || m_down2.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.641 | -6.908 | -2.258 |  1.372 | torch.Size([128]) || m_down2.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.205 |  0.194 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.2.mixer.out_proj.weight
 |  0.970 |  0.895 |  1.032 |  0.030 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.weight
 |  0.002 | -0.087 |  0.060 |  0.028 | torch.Size([64]) || m_down2.0.mamba_layers.2.norm.bias
 |  1.917 | -0.019 |  2.774 |  0.765 | torch.Size([128, 16]) || m_down2.0.mamba_layers.3.mixer.A_log
 |  0.989 |  0.936 |  1.054 |  0.017 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.D
 |  0.001 | -0.194 |  0.185 |  0.073 | torch.Size([256, 64]) || m_down2.0.mamba_layers.3.mixer.in_proj.weight
 | -0.001 | -0.548 |  0.520 |  0.274 | torch.Size([128, 1, 4]) || m_down2.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.486 |  0.485 |  0.289 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.199 |  0.242 |  0.053 | torch.Size([36, 128]) || m_down2.0.mamba_layers.3.mixer.x_proj.weight
 |  0.011 | -0.496 |  0.500 |  0.303 | torch.Size([128, 4]) || m_down2.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.465 | -6.853 | -2.276 |  1.292 | torch.Size([128]) || m_down2.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.187 |  0.229 |  0.055 | torch.Size([64, 128]) || m_down2.0.mamba_layers.3.mixer.out_proj.weight
 |  0.976 |  0.929 |  1.036 |  0.024 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.weight
 | -0.002 | -0.041 |  0.063 |  0.022 | torch.Size([64]) || m_down2.0.mamba_layers.3.norm.bias
 |  0.628 |  0.129 |  1.127 |  0.706 | torch.Size([2]) || m_down2.0.pcbam_module.h_cw.weight
 |  0.096 | -0.115 |  0.409 |  0.277 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.h_cw.conv.weight
 |  0.672 |  0.597 |  0.747 |  0.106 | torch.Size([2]) || m_down2.0.pcbam_module.w_hc.weight
 |  0.041 | -0.109 |  0.315 |  0.238 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.w_hc.conv.weight
 |  0.594 |  0.347 |  0.840 |  0.349 | torch.Size([2]) || m_down2.0.pcbam_module.c_hw.weight
 | -0.017 | -0.083 |  0.061 |  0.073 | torch.Size([1, 1, 1, 3]) || m_down2.0.pcbam_module.c_hw.conv.weight
 |  1.163 |  0.867 |  1.732 |  0.226 | torch.Size([64]) || m_down2.1.trans_block.ln1.weight
 |  0.012 | -0.364 |  0.465 |  0.164 | torch.Size([64]) || m_down2.1.trans_block.ln1.bias
 | -0.006 | -1.165 |  0.641 |  0.241 | torch.Size([2, 15, 15]) || m_down2.1.trans_block.msa.relative_position_params
 | -0.000 | -0.375 |  0.429 |  0.082 | torch.Size([192, 64, 1, 1]) || m_down2.1.trans_block.msa.embedding_layer1.weight
 | -0.003 | -0.287 |  0.230 |  0.062 | torch.Size([192]) || m_down2.1.trans_block.msa.embedding_layer1.bias
 |  0.001 | -0.174 |  0.169 |  0.045 | torch.Size([64, 64, 1, 1]) || m_down2.1.trans_block.msa.linear1.weight
 | -0.000 | -0.118 |  0.181 |  0.045 | torch.Size([64]) || m_down2.1.trans_block.msa.linear1.bias
 |  1.050 |  0.735 |  1.351 |  0.145 | torch.Size([64]) || m_down2.1.trans_block.ln2.weight
 |  0.004 | -0.187 |  0.243 |  0.100 | torch.Size([64]) || m_down2.1.trans_block.ln2.bias
 | -0.000 | -0.474 |  0.472 |  0.076 | torch.Size([256, 64]) || m_down2.1.trans_block.mlp.0.weight
 | -0.040 | -0.315 |  0.072 |  0.057 | torch.Size([256]) || m_down2.1.trans_block.mlp.0.bias
 | -0.000 | -0.415 |  0.464 |  0.053 | torch.Size([64, 256]) || m_down2.1.trans_block.mlp.2.weight
 |  0.000 | -0.071 |  0.066 |  0.032 | torch.Size([64]) || m_down2.1.trans_block.mlp.2.bias
 | -0.008 | -1.075 |  0.517 |  0.102 | torch.Size([192, 192, 1, 1]) || m_down2.1.conv1_1.weight
 |  0.001 | -0.346 |  0.336 |  0.087 | torch.Size([192]) || m_down2.1.conv1_1.bias
 |  0.084 | -0.019 |  0.274 |  0.165 | torch.Size([1, 1, 1, 1, 3]) || m_down2.1.conv3d.weight
 | -0.003 | -0.003 | -0.003 |    nan | torch.Size([1]) || m_down2.1.conv3d.bias
 | -0.003 | -0.386 |  0.295 |  0.058 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.0.weight
 |  0.001 | -0.299 |  0.306 |  0.057 | torch.Size([64, 64, 3, 3]) || m_down2.1.conv_block.2.weight
 |  1.917 | -0.006 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.0.mixer.A_log
 |  1.022 |  0.995 |  1.229 |  0.039 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.D
 |  0.000 | -0.262 |  0.250 |  0.039 | torch.Size([256, 64]) || m_down2.1.mamba_layers.0.mixer.in_proj.weight
 | -0.002 | -0.408 |  0.287 |  0.073 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.001 | -0.080 |  0.116 |  0.028 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.169 |  0.167 |  0.024 | torch.Size([36, 128]) || m_down2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.049 |  0.052 |  0.018 | torch.Size([128, 4]) || m_down2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.000 | -0.066 |  0.079 |  0.016 | torch.Size([128]) || m_down2.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.275 |  0.271 |  0.042 | torch.Size([64, 128]) || m_down2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.027 |  0.861 |  1.223 |  0.072 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.weight
 |  0.001 | -0.164 |  0.200 |  0.093 | torch.Size([64]) || m_down2.1.mamba_layers.0.norm.bias
 |  1.917 | -0.249 |  2.773 |  0.765 | torch.Size([128, 16]) || m_down2.1.mamba_layers.1.mixer.A_log
 |  1.038 |  0.996 |  1.246 |  0.065 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.D
 | -0.000 | -0.421 |  0.421 |  0.051 | torch.Size([256, 64]) || m_down2.1.mamba_layers.1.mixer.in_proj.weight
 |  0.004 | -0.332 |  0.368 |  0.094 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.009 | -0.132 |  0.248 |  0.046 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.257 |  0.268 |  0.037 | torch.Size([36, 128]) || m_down2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.255 |  0.251 |  0.029 | torch.Size([128, 4]) || m_down2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.002 | -0.301 |  0.161 |  0.044 | torch.Size([128]) || m_down2.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.384 |  0.375 |  0.052 | torch.Size([64, 128]) || m_down2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.056 |  0.955 |  1.390 |  0.090 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.weight
 | -0.007 | -0.214 |  0.198 |  0.125 | torch.Size([64]) || m_down2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.027 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.2.mixer.A_log
 |  0.991 |  0.947 |  1.079 |  0.022 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.D
 | -0.001 | -0.227 |  0.203 |  0.076 | torch.Size([256, 64]) || m_down2.1.mamba_layers.2.mixer.in_proj.weight
 | -0.006 | -0.562 |  0.540 |  0.284 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.2.mixer.conv1d.weight
 |  0.016 | -0.490 |  0.503 |  0.266 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.167 |  0.167 |  0.053 | torch.Size([36, 128]) || m_down2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.021 | -0.500 |  0.499 |  0.284 | torch.Size([128, 4]) || m_down2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.836 | -6.905 | -2.270 |  1.399 | torch.Size([128]) || m_down2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.001 | -0.173 |  0.187 |  0.055 | torch.Size([64, 128]) || m_down2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.987 |  0.919 |  1.065 |  0.029 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.weight
 |  0.003 | -0.065 |  0.078 |  0.025 | torch.Size([64]) || m_down2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.036 |  2.773 |  0.764 | torch.Size([128, 16]) || m_down2.1.mamba_layers.3.mixer.A_log
 |  0.988 |  0.951 |  1.053 |  0.020 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.208 |  0.275 |  0.074 | torch.Size([256, 64]) || m_down2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.000 | -0.513 |  0.520 |  0.280 | torch.Size([128, 1, 4]) || m_down2.1.mamba_layers.3.mixer.conv1d.weight
 |  0.056 | -0.522 |  0.494 |  0.264 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.conv1d.bias
 |  0.002 | -0.144 |  0.130 |  0.052 | torch.Size([36, 128]) || m_down2.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.500 |  0.499 |  0.290 | torch.Size([128, 4]) || m_down2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.409 | -6.903 | -2.272 |  1.291 | torch.Size([128]) || m_down2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.001 | -0.180 |  0.196 |  0.054 | torch.Size([64, 128]) || m_down2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.978 |  0.923 |  1.033 |  0.027 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.weight
 |  0.001 | -0.055 |  0.052 |  0.022 | torch.Size([64]) || m_down2.1.mamba_layers.3.norm.bias
 |  0.854 |  0.685 |  1.023 |  0.239 | torch.Size([2]) || m_down2.1.pcbam_module.h_cw.weight
 |  0.126 | -0.032 |  0.306 |  0.170 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.h_cw.conv.weight
 |  0.686 |  0.581 |  0.791 |  0.148 | torch.Size([2]) || m_down2.1.pcbam_module.w_hc.weight
 |  0.055 | -0.241 |  0.343 |  0.292 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.w_hc.conv.weight
 |  0.884 |  0.742 |  1.027 |  0.201 | torch.Size([2]) || m_down2.1.pcbam_module.c_hw.weight
 | -0.045 | -0.242 |  0.258 |  0.266 | torch.Size([1, 1, 1, 3]) || m_down2.1.pcbam_module.c_hw.conv.weight
 | -0.001 | -0.268 |  0.410 |  0.043 | torch.Size([384, 192, 2, 2]) || m_down2.2.weight
 |  0.985 |  0.619 |  1.644 |  0.229 | torch.Size([128]) || m_down3.0.trans_block.ln1.weight
 |  0.005 | -0.589 |  0.596 |  0.248 | torch.Size([128]) || m_down3.0.trans_block.ln1.bias
 |  0.053 | -2.559 |  0.993 |  0.349 | torch.Size([4, 15, 15]) || m_down3.0.trans_block.msa.relative_position_params
 | -0.000 | -0.396 |  0.385 |  0.051 | torch.Size([384, 128, 1, 1]) || m_down3.0.trans_block.msa.embedding_layer1.weight
 |  0.006 | -0.191 |  0.266 |  0.055 | torch.Size([384]) || m_down3.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.167 |  0.168 |  0.040 | torch.Size([128, 128, 1, 1]) || m_down3.0.trans_block.msa.linear1.weight
 |  0.001 | -0.112 |  0.102 |  0.043 | torch.Size([128]) || m_down3.0.trans_block.msa.linear1.bias
 |  0.899 |  0.460 |  1.325 |  0.165 | torch.Size([128]) || m_down3.0.trans_block.ln2.weight
 |  0.001 | -0.337 |  0.354 |  0.114 | torch.Size([128]) || m_down3.0.trans_block.ln2.bias
 | -0.000 | -0.404 |  0.379 |  0.046 | torch.Size([512, 128]) || m_down3.0.trans_block.mlp.0.weight
 | -0.027 | -0.351 |  0.066 |  0.044 | torch.Size([512]) || m_down3.0.trans_block.mlp.0.bias
 | -0.000 | -0.395 |  0.447 |  0.037 | torch.Size([128, 512]) || m_down3.0.trans_block.mlp.2.weight
 |  0.002 | -0.119 |  0.198 |  0.054 | torch.Size([128]) || m_down3.0.trans_block.mlp.2.bias
 |  0.004 | -0.535 |  1.740 |  0.081 | torch.Size([384, 384, 1, 1]) || m_down3.0.conv1_1.weight
 | -0.003 | -0.797 |  0.615 |  0.131 | torch.Size([384]) || m_down3.0.conv1_1.bias
 | -0.085 | -0.264 |  0.007 |  0.154 | torch.Size([1, 1, 1, 1, 3]) || m_down3.0.conv3d.weight
 | -0.004 | -0.004 | -0.004 |    nan | torch.Size([1]) || m_down3.0.conv3d.bias
 |  0.001 | -0.374 |  0.294 |  0.045 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.0.weight
 | -0.000 | -0.225 |  0.276 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.0.mixer.A_log
 |  1.001 |  0.991 |  1.096 |  0.010 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.D
 | -0.000 | -0.092 |  0.112 |  0.011 | torch.Size([512, 128]) || m_down3.0.mamba_layers.0.mixer.in_proj.weight
 | -0.002 | -0.147 |  0.116 |  0.023 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.0.mixer.conv1d.weight
 | -0.002 | -0.119 |  0.155 |  0.036 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.051 |  0.051 |  0.012 | torch.Size([40, 256]) || m_down3.0.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.041 |  0.047 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.001 |  0.000 |  0.000 | torch.Size([256]) || m_down3.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.173 |  0.134 |  0.016 | torch.Size([128, 256]) || m_down3.0.mamba_layers.0.mixer.out_proj.weight
 |  1.000 |  0.985 |  1.028 |  0.008 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.weight
 |  0.001 | -0.022 |  0.021 |  0.011 | torch.Size([128]) || m_down3.0.mamba_layers.0.norm.bias
 |  1.917 | -0.005 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.1.mixer.A_log
 |  1.013 |  0.998 |  1.312 |  0.045 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.D
 |  0.000 | -0.319 |  0.274 |  0.019 | torch.Size([512, 128]) || m_down3.0.mamba_layers.1.mixer.in_proj.weight
 | -0.001 | -0.291 |  0.278 |  0.042 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.1.mixer.conv1d.weight
 | -0.003 | -0.247 |  0.232 |  0.054 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.119 |  0.124 |  0.013 | torch.Size([40, 256]) || m_down3.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.039 |  0.058 |  0.013 | torch.Size([256, 8]) || m_down3.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.096 |  0.024 |  0.006 | torch.Size([256]) || m_down3.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.404 |  0.294 |  0.024 | torch.Size([128, 256]) || m_down3.0.mamba_layers.1.mixer.out_proj.weight
 |  0.951 |  0.856 |  1.181 |  0.053 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.weight
 |  0.013 | -0.146 |  0.153 |  0.094 | torch.Size([128]) || m_down3.0.mamba_layers.1.norm.bias
 |  1.917 | -0.002 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.2.mixer.A_log
 |  0.980 |  0.949 |  1.021 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.D
 |  0.000 | -0.146 |  0.150 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.2.mixer.in_proj.weight
 | -0.015 | -0.540 |  0.508 |  0.280 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.2.mixer.conv1d.weight
 |  0.031 | -0.514 |  0.482 |  0.274 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.101 |  0.096 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.2.mixer.x_proj.weight
 | -0.000 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.489 | -6.888 | -2.309 |  1.322 | torch.Size([256]) || m_down3.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.133 |  0.164 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.2.mixer.out_proj.weight
 |  0.957 |  0.904 |  1.041 |  0.022 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.weight
 |  0.001 | -0.069 |  0.061 |  0.030 | torch.Size([128]) || m_down3.0.mamba_layers.2.norm.bias
 |  1.917 | -0.001 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.0.mamba_layers.3.mixer.A_log
 |  0.981 |  0.942 |  1.030 |  0.012 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.D
 | -0.000 | -0.134 |  0.143 |  0.051 | torch.Size([512, 128]) || m_down3.0.mamba_layers.3.mixer.in_proj.weight
 |  0.006 | -0.505 |  0.531 |  0.280 | torch.Size([256, 1, 4]) || m_down3.0.mamba_layers.3.mixer.conv1d.weight
 |  0.008 | -0.489 |  0.493 |  0.255 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.088 |  0.090 |  0.037 | torch.Size([40, 256]) || m_down3.0.mamba_layers.3.mixer.x_proj.weight
 | -0.002 | -0.353 |  0.353 |  0.205 | torch.Size([256, 8]) || m_down3.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.511 | -6.890 | -2.277 |  1.395 | torch.Size([256]) || m_down3.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.120 |  0.131 |  0.036 | torch.Size([128, 256]) || m_down3.0.mamba_layers.3.mixer.out_proj.weight
 |  0.956 |  0.898 |  1.003 |  0.020 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.weight
 | -0.000 | -0.063 |  0.066 |  0.028 | torch.Size([128]) || m_down3.0.mamba_layers.3.norm.bias
 |  0.708 |  0.548 |  0.869 |  0.227 | torch.Size([2]) || m_down3.0.pcbam_module.h_cw.weight
 |  0.052 | -0.055 |  0.193 |  0.128 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.h_cw.conv.weight
 |  0.294 |  0.254 |  0.335 |  0.058 | torch.Size([2]) || m_down3.0.pcbam_module.w_hc.weight
 |  0.018 | -0.114 |  0.228 |  0.184 | torch.Size([1, 1, 1, 3]) || m_down3.0.pcbam_module.w_hc.conv.weight
 |  0.568 |  0.250 |  0.886 |  0.450 | torch.Size([2]) || m_down3.0.pcbam_module.c_hw.weight
 | -0.089 | -0.353 |  0.103 |  0.166 | torch.Size([1, 1, 1, 5]) || m_down3.0.pcbam_module.c_hw.conv.weight
 |  1.082 |  0.617 |  1.594 |  0.241 | torch.Size([128]) || m_down3.1.trans_block.ln1.weight
 | -0.017 | -0.805 |  0.657 |  0.216 | torch.Size([128]) || m_down3.1.trans_block.ln1.bias
 |  0.002 | -2.820 |  1.248 |  0.323 | torch.Size([4, 15, 15]) || m_down3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.438 |  0.448 |  0.056 | torch.Size([384, 128, 1, 1]) || m_down3.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.231 |  0.239 |  0.048 | torch.Size([384]) || m_down3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.168 |  0.162 |  0.039 | torch.Size([128, 128, 1, 1]) || m_down3.1.trans_block.msa.linear1.weight
 |  0.000 | -0.134 |  0.142 |  0.053 | torch.Size([128]) || m_down3.1.trans_block.msa.linear1.bias
 |  0.906 |  0.434 |  1.276 |  0.188 | torch.Size([128]) || m_down3.1.trans_block.ln2.weight
 | -0.006 | -0.377 |  0.429 |  0.168 | torch.Size([128]) || m_down3.1.trans_block.ln2.bias
 | -0.000 | -0.444 |  0.369 |  0.058 | torch.Size([512, 128]) || m_down3.1.trans_block.mlp.0.weight
 | -0.044 | -0.237 |  0.033 |  0.052 | torch.Size([512]) || m_down3.1.trans_block.mlp.0.bias
 | -0.000 | -0.363 |  0.362 |  0.044 | torch.Size([128, 512]) || m_down3.1.trans_block.mlp.2.weight
 |  0.004 | -0.124 |  0.144 |  0.052 | torch.Size([128]) || m_down3.1.trans_block.mlp.2.bias
 | -0.003 | -1.792 |  0.663 |  0.088 | torch.Size([384, 384, 1, 1]) || m_down3.1.conv1_1.weight
 |  0.010 | -0.559 |  0.409 |  0.092 | torch.Size([384]) || m_down3.1.conv1_1.bias
 |  0.089 | -0.010 |  0.283 |  0.168 | torch.Size([1, 1, 1, 1, 3]) || m_down3.1.conv3d.weight
 | -0.001 | -0.001 | -0.001 |    nan | torch.Size([1]) || m_down3.1.conv3d.bias
 | -0.005 | -0.366 |  0.422 |  0.047 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.0.weight
 | -0.000 | -0.258 |  0.301 |  0.041 | torch.Size([128, 128, 3, 3]) || m_down3.1.conv_block.2.weight
 |  1.917 | -0.001 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.0.mixer.A_log
 |  1.011 |  0.995 |  1.145 |  0.025 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.299 |  0.306 |  0.026 | torch.Size([512, 128]) || m_down3.1.mamba_layers.0.mixer.in_proj.weight
 | -0.000 | -0.385 |  0.281 |  0.053 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.0.mixer.conv1d.weight
 | -0.000 | -0.123 |  0.103 |  0.034 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.079 |  0.086 |  0.014 | torch.Size([40, 256]) || m_down3.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.039 |  0.057 |  0.012 | torch.Size([256, 8]) || m_down3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.025 |  0.011 |  0.002 | torch.Size([256]) || m_down3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.217 |  0.221 |  0.028 | torch.Size([128, 256]) || m_down3.1.mamba_layers.0.mixer.out_proj.weight
 |  0.991 |  0.871 |  1.205 |  0.058 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.weight
 |  0.004 | -0.118 |  0.137 |  0.074 | torch.Size([128]) || m_down3.1.mamba_layers.0.norm.bias
 |  1.917 | -0.045 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.1.mixer.A_log
 |  1.021 |  0.951 |  1.316 |  0.049 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.D
 |  0.000 | -0.307 |  0.343 |  0.033 | torch.Size([512, 128]) || m_down3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.003 | -0.379 |  0.349 |  0.065 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.246 |  0.218 |  0.044 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.182 |  0.211 |  0.024 | torch.Size([40, 256]) || m_down3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.000 | -0.078 |  0.083 |  0.016 | torch.Size([256, 8]) || m_down3.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.010 | -0.109 |  0.196 |  0.031 | torch.Size([256]) || m_down3.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.282 |  0.299 |  0.034 | torch.Size([128, 256]) || m_down3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.013 |  0.833 |  1.240 |  0.080 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.weight
 | -0.003 | -0.171 |  0.186 |  0.102 | torch.Size([128]) || m_down3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.083 |  2.773 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.2.mixer.A_log
 |  0.980 |  0.935 |  1.075 |  0.019 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.169 |  0.159 |  0.052 | torch.Size([512, 128]) || m_down3.1.mamba_layers.2.mixer.in_proj.weight
 | -0.011 | -0.553 |  0.567 |  0.278 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.2.mixer.conv1d.weight
 |  0.016 | -0.520 |  0.512 |  0.290 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.123 |  0.113 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.205 | torch.Size([256, 8]) || m_down3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.526 | -6.818 | -2.284 |  1.305 | torch.Size([256]) || m_down3.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.180 |  0.134 |  0.039 | torch.Size([128, 256]) || m_down3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.959 |  0.875 |  1.031 |  0.026 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.weight
 | -0.001 | -0.085 |  0.053 |  0.021 | torch.Size([128]) || m_down3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.003 |  2.774 |  0.764 | torch.Size([256, 16]) || m_down3.1.mamba_layers.3.mixer.A_log
 |  0.980 |  0.933 |  1.019 |  0.014 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.D
 |  0.000 | -0.142 |  0.144 |  0.051 | torch.Size([512, 128]) || m_down3.1.mamba_layers.3.mixer.in_proj.weight
 |  0.010 | -0.543 |  0.539 |  0.277 | torch.Size([256, 1, 4]) || m_down3.1.mamba_layers.3.mixer.conv1d.weight
 |  0.001 | -0.509 |  0.478 |  0.287 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.108 |  0.116 |  0.037 | torch.Size([40, 256]) || m_down3.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.353 |  0.354 |  0.204 | torch.Size([256, 8]) || m_down3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.747 | -6.882 | -2.256 |  1.391 | torch.Size([256]) || m_down3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.127 |  0.129 |  0.037 | torch.Size([128, 256]) || m_down3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.950 |  0.895 |  1.003 |  0.023 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.weight
 | -0.001 | -0.083 |  0.076 |  0.022 | torch.Size([128]) || m_down3.1.mamba_layers.3.norm.bias
 |  0.680 |  0.554 |  0.806 |  0.178 | torch.Size([2]) || m_down3.1.pcbam_module.h_cw.weight
 | -0.003 | -0.204 |  0.262 |  0.239 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.h_cw.conv.weight
 |  0.425 |  0.112 |  0.739 |  0.444 | torch.Size([2]) || m_down3.1.pcbam_module.w_hc.weight
 | -0.021 | -0.245 |  0.315 |  0.296 | torch.Size([1, 1, 1, 3]) || m_down3.1.pcbam_module.w_hc.conv.weight
 |  0.600 |  0.591 |  0.608 |  0.012 | torch.Size([2]) || m_down3.1.pcbam_module.c_hw.weight
 |  0.115 | -0.168 |  0.354 |  0.257 | torch.Size([1, 1, 1, 5]) || m_down3.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.486 |  0.307 |  0.032 | torch.Size([768, 384, 2, 2]) || m_down3.2.weight
 |  0.806 |  0.359 |  1.208 |  0.146 | torch.Size([256]) || m_body.0.trans_block.ln1.weight
 | -0.011 | -0.671 |  0.494 |  0.135 | torch.Size([256]) || m_body.0.trans_block.ln1.bias
 |  0.054 | -4.731 |  0.715 |  0.332 | torch.Size([8, 15, 15]) || m_body.0.trans_block.msa.relative_position_params
 | -0.000 | -0.386 |  0.387 |  0.037 | torch.Size([768, 256, 1, 1]) || m_body.0.trans_block.msa.embedding_layer1.weight
 |  0.002 | -0.203 |  0.206 |  0.053 | torch.Size([768]) || m_body.0.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.238 |  0.238 |  0.042 | torch.Size([256, 256, 1, 1]) || m_body.0.trans_block.msa.linear1.weight
 |  0.002 | -0.259 |  0.145 |  0.057 | torch.Size([256]) || m_body.0.trans_block.msa.linear1.bias
 |  0.853 |  0.381 |  1.185 |  0.123 | torch.Size([256]) || m_body.0.trans_block.ln2.weight
 |  0.002 | -0.200 |  0.276 |  0.081 | torch.Size([256]) || m_body.0.trans_block.ln2.bias
 |  0.000 | -0.256 |  0.283 |  0.034 | torch.Size([1024, 256]) || m_body.0.trans_block.mlp.0.weight
 | -0.011 | -0.233 |  0.103 |  0.042 | torch.Size([1024]) || m_body.0.trans_block.mlp.0.bias
 | -0.000 | -0.293 |  0.322 |  0.031 | torch.Size([256, 1024]) || m_body.0.trans_block.mlp.2.weight
 |  0.005 | -0.198 |  0.154 |  0.053 | torch.Size([256]) || m_body.0.trans_block.mlp.2.bias
 | -0.001 | -1.113 |  0.866 |  0.051 | torch.Size([768, 768, 1, 1]) || m_body.0.conv1_1.weight
 |  0.001 | -1.478 |  0.989 |  0.095 | torch.Size([768]) || m_body.0.conv1_1.bias
 |  0.074 | -0.007 |  0.234 |  0.138 | torch.Size([1, 1, 1, 1, 3]) || m_body.0.conv3d.weight
 |  0.027 |  0.027 |  0.027 |    nan | torch.Size([1]) || m_body.0.conv3d.bias
 |  0.000 | -0.236 |  0.257 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.0.weight
 | -0.000 | -0.237 |  0.211 |  0.036 | torch.Size([256, 256, 3, 3]) || m_body.0.conv_block.2.weight
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.D
 |  0.000 | -0.028 |  0.027 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.025 |  0.027 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.004 |  0.003 |  0.001 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.035 |  0.036 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.033 |  0.038 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.042 |  0.037 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.0.mixer.out_proj.weight
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.0.norm.bias
 |  1.917 | -0.000 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.001 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.D
 |  0.000 | -0.029 |  0.030 |  0.006 | torch.Size([1024, 256]) || m_body.0.mamba_layers.1.mixer.in_proj.weight
 |  0.000 | -0.035 |  0.059 |  0.009 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.1.mixer.conv1d.weight
 | -0.000 | -0.018 |  0.022 |  0.006 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.034 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.0.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.034 |  0.030 |  0.009 | torch.Size([512, 16]) || m_body.0.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.000 |  0.000 |  0.000 | torch.Size([512]) || m_body.0.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.045 |  0.041 |  0.009 | torch.Size([256, 512]) || m_body.0.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.999 |  1.000 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.weight
 | -0.000 | -0.001 |  0.001 |  0.000 | torch.Size([256]) || m_body.0.mamba_layers.1.norm.bias
 |  1.917 | -0.025 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.A_log
 |  0.999 |  0.976 |  1.013 |  0.004 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.D
 | -0.000 | -0.085 |  0.085 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.2.mixer.in_proj.weight
 | -0.007 | -0.504 |  0.517 |  0.289 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.2.mixer.conv1d.weight
 | -0.005 | -0.500 |  0.495 |  0.307 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.068 |  0.069 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.2.mixer.dt_proj.weight
 | -4.579 | -6.906 | -2.283 |  1.361 | torch.Size([512]) || m_body.0.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.096 |  0.080 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.2.mixer.out_proj.weight
 |  0.995 |  0.985 |  1.008 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.weight
 |  0.000 | -0.013 |  0.007 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.2.norm.bias
 |  1.917 | -0.015 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.A_log
 |  0.998 |  0.984 |  1.009 |  0.003 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.D
 |  0.000 | -0.082 |  0.078 |  0.036 | torch.Size([1024, 256]) || m_body.0.mamba_layers.3.mixer.in_proj.weight
 | -0.013 | -0.509 |  0.501 |  0.287 | torch.Size([512, 1, 4]) || m_body.0.mamba_layers.3.mixer.conv1d.weight
 |  0.003 | -0.501 |  0.496 |  0.280 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.070 |  0.067 |  0.026 | torch.Size([48, 512]) || m_body.0.mamba_layers.3.mixer.x_proj.weight
 |  0.002 | -0.250 |  0.250 |  0.145 | torch.Size([512, 16]) || m_body.0.mamba_layers.3.mixer.dt_proj.weight
 | -4.612 | -6.907 | -2.259 |  1.325 | torch.Size([512]) || m_body.0.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.063 |  0.065 |  0.026 | torch.Size([256, 512]) || m_body.0.mamba_layers.3.mixer.out_proj.weight
 |  0.995 |  0.986 |  1.006 |  0.004 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.weight
 | -0.000 | -0.009 |  0.009 |  0.003 | torch.Size([256]) || m_body.0.mamba_layers.3.norm.bias
 |  1.123 |  0.893 |  1.353 |  0.326 | torch.Size([2]) || m_body.0.pcbam_module.h_cw.weight
 | -0.665 | -0.955 | -0.499 |  0.252 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.h_cw.conv.weight
 |  0.383 |  0.161 |  0.605 |  0.314 | torch.Size([2]) || m_body.0.pcbam_module.w_hc.weight
 | -0.519 | -0.608 | -0.346 |  0.150 | torch.Size([1, 1, 1, 3]) || m_body.0.pcbam_module.w_hc.conv.weight
 |  1.013 |  0.112 |  1.913 |  1.274 | torch.Size([2]) || m_body.0.pcbam_module.c_hw.weight
 | -0.083 | -0.981 |  1.949 |  1.184 | torch.Size([1, 1, 1, 5]) || m_body.0.pcbam_module.c_hw.conv.weight
 |  0.747 |  0.306 |  1.000 |  0.127 | torch.Size([256]) || m_body.1.trans_block.ln1.weight
 |  0.028 | -0.815 |  0.540 |  0.165 | torch.Size([256]) || m_body.1.trans_block.ln1.bias
 |  0.052 | -3.909 |  0.815 |  0.351 | torch.Size([8, 15, 15]) || m_body.1.trans_block.msa.relative_position_params
 | -0.000 | -0.306 |  0.295 |  0.036 | torch.Size([768, 256, 1, 1]) || m_body.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.221 |  0.248 |  0.068 | torch.Size([768]) || m_body.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.278 |  0.275 |  0.037 | torch.Size([256, 256, 1, 1]) || m_body.1.trans_block.msa.linear1.weight
 | -0.003 | -0.193 |  0.214 |  0.058 | torch.Size([256]) || m_body.1.trans_block.msa.linear1.bias
 |  0.866 |  0.519 |  1.098 |  0.100 | torch.Size([256]) || m_body.1.trans_block.ln2.weight
 |  0.007 | -0.263 |  0.320 |  0.103 | torch.Size([256]) || m_body.1.trans_block.ln2.bias
 |  0.001 | -0.362 |  0.358 |  0.054 | torch.Size([1024, 256]) || m_body.1.trans_block.mlp.0.weight
 | -0.051 | -0.199 |  0.056 |  0.038 | torch.Size([1024]) || m_body.1.trans_block.mlp.0.bias
 | -0.001 | -0.438 |  0.395 |  0.051 | torch.Size([256, 1024]) || m_body.1.trans_block.mlp.2.weight
 | -0.000 | -0.218 |  0.139 |  0.051 | torch.Size([256]) || m_body.1.trans_block.mlp.2.bias
 | -0.001 | -1.065 |  0.764 |  0.056 | torch.Size([768, 768, 1, 1]) || m_body.1.conv1_1.weight
 |  0.000 | -0.311 |  0.925 |  0.086 | torch.Size([768]) || m_body.1.conv1_1.bias
 |  0.173 |  0.007 |  0.502 |  0.285 | torch.Size([1, 1, 1, 1, 3]) || m_body.1.conv3d.weight
 |  0.062 |  0.062 |  0.062 |    nan | torch.Size([1]) || m_body.1.conv3d.bias
 | -0.001 | -0.278 |  0.267 |  0.034 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.0.weight
 | -0.001 | -0.271 |  0.268 |  0.035 | torch.Size([256, 256, 3, 3]) || m_body.1.conv_block.2.weight
 |  1.917 | -0.002 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.A_log
 |  1.000 |  1.000 |  1.086 |  0.005 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.D
 | -0.000 | -0.126 |  0.113 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.0.mixer.in_proj.weight
 |  0.000 | -0.085 |  0.292 |  0.012 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.0.mixer.conv1d.weight
 |  0.000 | -0.016 |  0.060 |  0.003 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.conv1d.bias
 |  0.000 | -0.055 |  0.035 |  0.009 | torch.Size([48, 512]) || m_body.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.035 |  0.029 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.000 | -0.006 |  0.004 |  0.000 | torch.Size([512]) || m_body.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.153 |  0.095 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.0.mixer.out_proj.weight
 |  1.001 |  0.995 |  1.018 |  0.003 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.weight
 |  0.000 | -0.006 |  0.006 |  0.002 | torch.Size([256]) || m_body.1.mamba_layers.0.norm.bias
 |  1.917 | -0.218 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.A_log
 |  1.000 |  0.999 |  1.039 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.D
 |  0.000 | -0.169 |  0.149 |  0.007 | torch.Size([1024, 256]) || m_body.1.mamba_layers.1.mixer.in_proj.weight
 | -0.000 | -0.054 |  0.173 |  0.010 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.1.mixer.conv1d.weight
 |  0.001 | -0.097 |  0.073 |  0.022 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.097 |  0.324 |  0.010 | torch.Size([48, 512]) || m_body.1.mamba_layers.1.mixer.x_proj.weight
 |  0.000 | -0.032 |  0.035 |  0.009 | torch.Size([512, 16]) || m_body.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.000 | -0.037 |  0.000 |  0.002 | torch.Size([512]) || m_body.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.153 |  0.185 |  0.009 | torch.Size([256, 512]) || m_body.1.mamba_layers.1.mixer.out_proj.weight
 |  1.000 |  0.986 |  1.044 |  0.010 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.weight
 | -0.001 | -0.018 |  0.022 |  0.009 | torch.Size([256]) || m_body.1.mamba_layers.1.norm.bias
 |  1.917 | -0.057 |  2.774 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.A_log
 |  0.998 |  0.962 |  1.045 |  0.005 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.D
 | -0.000 | -0.093 |  0.117 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.2.mixer.in_proj.weight
 |  0.004 | -0.511 |  0.502 |  0.282 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.2.mixer.conv1d.weight
 |  0.010 | -0.506 |  0.492 |  0.282 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.conv1d.bias
 |  0.000 | -0.079 |  0.087 |  0.026 | torch.Size([48, 512]) || m_body.1.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.257 |  0.260 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.634 | -6.903 | -2.259 |  1.288 | torch.Size([512]) || m_body.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.102 |  0.100 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.2.mixer.out_proj.weight
 |  0.995 |  0.958 |  1.009 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.weight
 |  0.000 | -0.023 |  0.021 |  0.007 | torch.Size([256]) || m_body.1.mamba_layers.2.norm.bias
 |  1.917 | -0.068 |  2.773 |  0.764 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.A_log
 |  0.999 |  0.918 |  1.113 |  0.009 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.D
 |  0.000 | -0.121 |  0.118 |  0.036 | torch.Size([1024, 256]) || m_body.1.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.530 |  0.505 |  0.292 | torch.Size([512, 1, 4]) || m_body.1.mamba_layers.3.mixer.conv1d.weight
 | -0.009 | -0.501 |  0.498 |  0.294 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.089 |  0.085 |  0.026 | torch.Size([48, 512]) || m_body.1.mamba_layers.3.mixer.x_proj.weight
 |  0.001 | -0.272 |  0.268 |  0.145 | torch.Size([512, 16]) || m_body.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.631 | -6.903 | -2.252 |  1.302 | torch.Size([512]) || m_body.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.114 |  0.094 |  0.026 | torch.Size([256, 512]) || m_body.1.mamba_layers.3.mixer.out_proj.weight
 |  0.999 |  0.970 |  1.027 |  0.008 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.weight
 |  0.000 | -0.015 |  0.017 |  0.006 | torch.Size([256]) || m_body.1.mamba_layers.3.norm.bias
 |  1.209 |  0.870 |  1.547 |  0.479 | torch.Size([2]) || m_body.1.pcbam_module.h_cw.weight
 | -1.012 | -1.126 | -0.821 |  0.167 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.h_cw.conv.weight
 |  1.149 |  0.897 |  1.400 |  0.356 | torch.Size([2]) || m_body.1.pcbam_module.w_hc.weight
 | -0.941 | -1.056 | -0.784 |  0.141 | torch.Size([1, 1, 1, 3]) || m_body.1.pcbam_module.w_hc.conv.weight
 |  1.486 |  0.077 |  2.894 |  1.992 | torch.Size([2]) || m_body.1.pcbam_module.c_hw.weight
 | -0.207 | -1.516 |  1.716 |  1.290 | torch.Size([1, 1, 1, 5]) || m_body.1.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.319 |  0.339 |  0.030 | torch.Size([768, 384, 2, 2]) || m_up3.0.weight
 |  0.962 |  0.584 |  1.379 |  0.156 | torch.Size([128]) || m_up3.1.trans_block.ln1.weight
 |  0.026 | -0.558 |  0.425 |  0.129 | torch.Size([128]) || m_up3.1.trans_block.ln1.bias
 |  0.050 | -3.792 |  0.658 |  0.308 | torch.Size([4, 15, 15]) || m_up3.1.trans_block.msa.relative_position_params
 | -0.000 | -0.494 |  0.525 |  0.060 | torch.Size([384, 128, 1, 1]) || m_up3.1.trans_block.msa.embedding_layer1.weight
 | -0.000 | -0.260 |  0.243 |  0.069 | torch.Size([384]) || m_up3.1.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.176 |  0.187 |  0.044 | torch.Size([128, 128, 1, 1]) || m_up3.1.trans_block.msa.linear1.weight
 | -0.001 | -0.100 |  0.216 |  0.043 | torch.Size([128]) || m_up3.1.trans_block.msa.linear1.bias
 |  0.882 |  0.709 |  1.047 |  0.070 | torch.Size([128]) || m_up3.1.trans_block.ln2.weight
 |  0.008 | -0.259 |  0.183 |  0.085 | torch.Size([128]) || m_up3.1.trans_block.ln2.bias
 |  0.000 | -0.341 |  0.316 |  0.059 | torch.Size([512, 128]) || m_up3.1.trans_block.mlp.0.weight
 | -0.038 | -0.192 |  0.067 |  0.044 | torch.Size([512]) || m_up3.1.trans_block.mlp.0.bias
 | -0.000 | -0.353 |  0.309 |  0.053 | torch.Size([128, 512]) || m_up3.1.trans_block.mlp.2.weight
 | -0.002 | -0.335 |  0.165 |  0.045 | torch.Size([128]) || m_up3.1.trans_block.mlp.2.bias
 | -0.001 | -2.353 |  0.670 |  0.086 | torch.Size([384, 384, 1, 1]) || m_up3.1.conv1_1.weight
 | -0.001 | -0.418 |  1.301 |  0.129 | torch.Size([384]) || m_up3.1.conv1_1.bias
 |  0.182 | -0.006 |  0.558 |  0.325 | torch.Size([1, 1, 1, 1, 3]) || m_up3.1.conv3d.weight
 | -0.005 | -0.005 | -0.005 |    nan | torch.Size([1]) || m_up3.1.conv3d.bias
 |  0.000 | -0.370 |  0.274 |  0.035 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.0.weight
 |  0.000 | -0.269 |  0.385 |  0.037 | torch.Size([128, 128, 3, 3]) || m_up3.1.conv_block.2.weight
 |  1.916 | -0.346 |  2.773 |  0.766 | torch.Size([256, 16]) || m_up3.1.mamba_layers.0.mixer.A_log
 |  1.051 |  0.998 |  1.320 |  0.072 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.D
 |  0.000 | -0.398 |  0.382 |  0.043 | torch.Size([512, 128]) || m_up3.1.mamba_layers.0.mixer.in_proj.weight
 |  0.006 | -0.430 |  0.482 |  0.097 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.0.mixer.conv1d.weight
 |  0.011 | -0.171 |  0.346 |  0.065 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.171 |  0.228 |  0.025 | torch.Size([40, 256]) || m_up3.1.mamba_layers.0.mixer.x_proj.weight
 |  0.000 | -0.054 |  0.065 |  0.013 | torch.Size([256, 8]) || m_up3.1.mamba_layers.0.mixer.dt_proj.weight
 | -0.003 | -0.169 |  0.117 |  0.028 | torch.Size([256]) || m_up3.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.000 | -0.488 |  0.437 |  0.049 | torch.Size([128, 256]) || m_up3.1.mamba_layers.0.mixer.out_proj.weight
 |  1.031 |  0.912 |  1.168 |  0.064 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.weight
 | -0.002 | -0.272 |  0.275 |  0.119 | torch.Size([128]) || m_up3.1.mamba_layers.0.norm.bias
 |  1.916 | -0.849 |  3.034 |  0.769 | torch.Size([256, 16]) || m_up3.1.mamba_layers.1.mixer.A_log
 |  1.000 | -0.041 |  1.309 |  0.161 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.D
 | -0.000 | -0.424 |  0.423 |  0.055 | torch.Size([512, 128]) || m_up3.1.mamba_layers.1.mixer.in_proj.weight
 | -0.004 | -0.463 |  0.365 |  0.108 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.1.mixer.conv1d.weight
 |  0.019 | -0.292 |  0.284 |  0.171 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.555 |  0.538 |  0.074 | torch.Size([40, 256]) || m_up3.1.mamba_layers.1.mixer.x_proj.weight
 | -0.002 | -0.605 |  0.692 |  0.095 | torch.Size([256, 8]) || m_up3.1.mamba_layers.1.mixer.dt_proj.weight
 | -0.013 | -1.004 |  0.247 |  0.106 | torch.Size([256]) || m_up3.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.000 | -0.269 |  0.270 |  0.056 | torch.Size([128, 256]) || m_up3.1.mamba_layers.1.mixer.out_proj.weight
 |  1.015 |  0.687 |  1.203 |  0.107 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.weight
 | -0.002 | -0.238 |  0.261 |  0.101 | torch.Size([128]) || m_up3.1.mamba_layers.1.norm.bias
 |  1.917 | -0.278 |  2.787 |  0.764 | torch.Size([256, 16]) || m_up3.1.mamba_layers.2.mixer.A_log
 |  0.982 |  0.690 |  1.037 |  0.038 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.D
 |  0.000 | -0.181 |  0.193 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.2.mixer.in_proj.weight
 |  0.014 | -0.563 |  0.541 |  0.274 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.2.mixer.conv1d.weight
 | -0.029 | -0.525 |  0.491 |  0.291 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.conv1d.bias
 | -0.000 | -0.164 |  0.147 |  0.042 | torch.Size([40, 256]) || m_up3.1.mamba_layers.2.mixer.x_proj.weight
 |  0.000 | -0.413 |  0.371 |  0.205 | torch.Size([256, 8]) || m_up3.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.530 | -6.922 | -2.275 |  1.363 | torch.Size([256]) || m_up3.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.000 | -0.153 |  0.157 |  0.040 | torch.Size([128, 256]) || m_up3.1.mamba_layers.2.mixer.out_proj.weight
 |  0.958 |  0.882 |  1.029 |  0.026 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.weight
 |  0.002 | -0.054 |  0.074 |  0.021 | torch.Size([128]) || m_up3.1.mamba_layers.2.norm.bias
 |  1.917 | -0.033 |  2.773 |  0.765 | torch.Size([256, 16]) || m_up3.1.mamba_layers.3.mixer.A_log
 |  0.990 |  0.944 |  1.027 |  0.016 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.D
 | -0.000 | -0.162 |  0.159 |  0.052 | torch.Size([512, 128]) || m_up3.1.mamba_layers.3.mixer.in_proj.weight
 | -0.011 | -0.529 |  0.512 |  0.268 | torch.Size([256, 1, 4]) || m_up3.1.mamba_layers.3.mixer.conv1d.weight
 | -0.005 | -0.548 |  0.532 |  0.309 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.conv1d.bias
 | -0.000 | -0.119 |  0.118 |  0.038 | torch.Size([40, 256]) || m_up3.1.mamba_layers.3.mixer.x_proj.weight
 | -0.001 | -0.355 |  0.356 |  0.203 | torch.Size([256, 8]) || m_up3.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.644 | -6.922 | -2.262 |  1.394 | torch.Size([256]) || m_up3.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.150 |  0.145 |  0.040 | torch.Size([128, 256]) || m_up3.1.mamba_layers.3.mixer.out_proj.weight
 |  0.956 |  0.893 |  1.025 |  0.026 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.weight
 | -0.000 | -0.072 |  0.060 |  0.020 | torch.Size([128]) || m_up3.1.mamba_layers.3.norm.bias
 |  0.534 |  0.193 |  0.875 |  0.483 | torch.Size([2]) || m_up3.1.pcbam_module.h_cw.weight
 |  0.127 |  0.060 |  0.237 |  0.095 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.h_cw.conv.weight
 |  0.882 |  0.856 |  0.909 |  0.037 | torch.Size([2]) || m_up3.1.pcbam_module.w_hc.weight
 |  0.164 |  0.099 |  0.218 |  0.060 | torch.Size([1, 1, 1, 3]) || m_up3.1.pcbam_module.w_hc.conv.weight
 |  0.493 |  0.225 |  0.762 |  0.380 | torch.Size([2]) || m_up3.1.pcbam_module.c_hw.weight
 |  0.017 | -0.148 |  0.146 |  0.119 | torch.Size([1, 1, 1, 5]) || m_up3.1.pcbam_module.c_hw.conv.weight
 |  1.124 |  0.605 |  1.354 |  0.143 | torch.Size([128]) || m_up3.2.trans_block.ln1.weight
 | -0.004 | -0.493 |  0.500 |  0.122 | torch.Size([128]) || m_up3.2.trans_block.ln1.bias
 |  0.061 | -3.109 |  0.733 |  0.356 | torch.Size([4, 15, 15]) || m_up3.2.trans_block.msa.relative_position_params
 | -0.000 | -0.454 |  0.313 |  0.056 | torch.Size([384, 128, 1, 1]) || m_up3.2.trans_block.msa.embedding_layer1.weight
 | -0.001 | -0.182 |  0.190 |  0.057 | torch.Size([384]) || m_up3.2.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.191 |  0.200 |  0.047 | torch.Size([128, 128, 1, 1]) || m_up3.2.trans_block.msa.linear1.weight
 | -0.003 | -0.139 |  0.146 |  0.055 | torch.Size([128]) || m_up3.2.trans_block.msa.linear1.bias
 |  1.202 |  0.966 |  1.501 |  0.090 | torch.Size([128]) || m_up3.2.trans_block.ln2.weight
 | -0.000 | -0.268 |  0.288 |  0.113 | torch.Size([128]) || m_up3.2.trans_block.ln2.bias
 |  0.000 | -0.359 |  0.332 |  0.073 | torch.Size([512, 128]) || m_up3.2.trans_block.mlp.0.weight
 | -0.048 | -0.182 |  0.056 |  0.038 | torch.Size([512]) || m_up3.2.trans_block.mlp.0.bias
 |  0.000 | -0.345 |  0.389 |  0.070 | torch.Size([128, 512]) || m_up3.2.trans_block.mlp.2.weight
 | -0.002 | -0.141 |  0.214 |  0.052 | torch.Size([128]) || m_up3.2.trans_block.mlp.2.bias
 | -0.000 | -0.840 |  0.453 |  0.075 | torch.Size([384, 384, 1, 1]) || m_up3.2.conv1_1.weight
 |  0.001 | -0.553 |  1.061 |  0.104 | torch.Size([384]) || m_up3.2.conv1_1.bias
 | -0.065 | -0.203 |  0.006 |  0.120 | torch.Size([1, 1, 1, 1, 3]) || m_up3.2.conv3d.weight
 | -0.002 | -0.002 | -0.002 |    nan | torch.Size([1]) || m_up3.2.conv3d.bias
 | -0.001 | -0.316 |  0.352 |  0.051 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.0.weight
 |  0.000 | -0.439 |  0.398 |  0.051 | torch.Size([128, 128, 3, 3]) || m_up3.2.conv_block.2.weight
 |  1.916 | -1.142 |  2.794 |  0.767 | torch.Size([256, 16]) || m_up3.2.mamba_layers.0.mixer.A_log
 |  1.074 |  0.399 |  1.575 |  0.159 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.D
 | -0.000 | -0.326 |  0.326 |  0.071 | torch.Size([512, 128]) || m_up3.2.mamba_layers.0.mixer.in_proj.weight
 | -0.001 | -0.372 |  0.432 |  0.142 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.0.mixer.conv1d.weight
 | -0.010 | -0.303 |  0.267 |  0.104 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.conv1d.bias
 | -0.001 | -0.666 |  0.471 |  0.075 | torch.Size([40, 256]) || m_up3.2.mamba_layers.0.mixer.x_proj.weight
 |  0.001 | -0.689 |  0.714 |  0.099 | torch.Size([256, 8]) || m_up3.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.019 | -1.178 |  0.291 |  0.120 | torch.Size([256]) || m_up3.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.587 |  0.443 |  0.076 | torch.Size([128, 256]) || m_up3.2.mamba_layers.0.mixer.out_proj.weight
 |  1.018 |  0.684 |  1.152 |  0.080 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.weight
 |  0.006 | -0.413 |  0.404 |  0.131 | torch.Size([128]) || m_up3.2.mamba_layers.0.norm.bias
 |  1.911 | -0.997 |  2.866 |  0.776 | torch.Size([256, 16]) || m_up3.2.mamba_layers.1.mixer.A_log
 |  1.070 | -0.093 |  1.506 |  0.137 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.D
 |  0.000 | -0.341 |  0.416 |  0.072 | torch.Size([512, 128]) || m_up3.2.mamba_layers.1.mixer.in_proj.weight
 |  0.005 | -0.536 |  0.448 |  0.147 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.1.mixer.conv1d.weight
 |  0.010 | -0.317 |  0.343 |  0.150 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.conv1d.bias
 |  0.002 | -0.720 |  1.146 |  0.091 | torch.Size([40, 256]) || m_up3.2.mamba_layers.1.mixer.x_proj.weight
 | -0.005 | -0.661 |  0.592 |  0.124 | torch.Size([256, 8]) || m_up3.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.014 | -0.455 |  0.173 |  0.107 | torch.Size([256]) || m_up3.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.000 | -0.430 |  0.404 |  0.075 | torch.Size([128, 256]) || m_up3.2.mamba_layers.1.mixer.out_proj.weight
 |  1.073 |  0.688 |  1.218 |  0.082 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.weight
 |  0.004 | -0.264 |  0.247 |  0.108 | torch.Size([128]) || m_up3.2.mamba_layers.1.norm.bias
 |  1.917 | -0.048 |  2.833 |  0.765 | torch.Size([256, 16]) || m_up3.2.mamba_layers.2.mixer.A_log
 |  1.027 |  0.972 |  1.345 |  0.035 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.D
 | -0.000 | -0.225 |  0.218 |  0.057 | torch.Size([512, 128]) || m_up3.2.mamba_layers.2.mixer.in_proj.weight
 |  0.002 | -0.647 |  0.629 |  0.294 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.2.mixer.conv1d.weight
 |  0.036 | -0.540 |  0.543 |  0.319 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.157 |  0.167 |  0.045 | torch.Size([40, 256]) || m_up3.2.mamba_layers.2.mixer.x_proj.weight
 | -0.003 | -0.440 |  0.466 |  0.205 | torch.Size([256, 8]) || m_up3.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.531 | -6.898 | -2.248 |  1.383 | torch.Size([256]) || m_up3.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.232 |  0.201 |  0.046 | torch.Size([128, 256]) || m_up3.2.mamba_layers.2.mixer.out_proj.weight
 |  1.023 |  0.970 |  1.089 |  0.025 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.weight
 |  0.000 | -0.092 |  0.101 |  0.038 | torch.Size([128]) || m_up3.2.mamba_layers.2.norm.bias
 |  1.917 | -0.027 |  2.774 |  0.764 | torch.Size([256, 16]) || m_up3.2.mamba_layers.3.mixer.A_log
 |  1.008 |  0.978 |  1.069 |  0.012 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.D
 | -0.000 | -0.197 |  0.174 |  0.054 | torch.Size([512, 128]) || m_up3.2.mamba_layers.3.mixer.in_proj.weight
 | -0.002 | -0.559 |  0.556 |  0.287 | torch.Size([256, 1, 4]) || m_up3.2.mamba_layers.3.mixer.conv1d.weight
 | -0.022 | -0.537 |  0.538 |  0.301 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.176 |  0.175 |  0.041 | torch.Size([40, 256]) || m_up3.2.mamba_layers.3.mixer.x_proj.weight
 | -0.005 | -0.366 |  0.370 |  0.206 | torch.Size([256, 8]) || m_up3.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.526 | -6.891 | -2.236 |  1.228 | torch.Size([256]) || m_up3.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.182 |  0.181 |  0.043 | torch.Size([128, 256]) || m_up3.2.mamba_layers.3.mixer.out_proj.weight
 |  1.000 |  0.840 |  1.052 |  0.029 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.weight
 | -0.000 | -0.141 |  0.072 |  0.027 | torch.Size([128]) || m_up3.2.mamba_layers.3.norm.bias
 |  0.754 |  0.558 |  0.951 |  0.278 | torch.Size([2]) || m_up3.2.pcbam_module.h_cw.weight
 | -0.066 | -0.206 |  0.165 |  0.202 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.h_cw.conv.weight
 |  0.793 |  0.740 |  0.846 |  0.075 | torch.Size([2]) || m_up3.2.pcbam_module.w_hc.weight
 |  0.050 | -0.103 |  0.188 |  0.146 | torch.Size([1, 1, 1, 3]) || m_up3.2.pcbam_module.w_hc.conv.weight
 |  0.557 |  0.115 |  0.998 |  0.624 | torch.Size([2]) || m_up3.2.pcbam_module.c_hw.weight
 |  0.309 | -0.071 |  1.470 |  0.653 | torch.Size([1, 1, 1, 5]) || m_up3.2.pcbam_module.c_hw.conv.weight
 | -0.001 | -0.389 |  0.302 |  0.033 | torch.Size([384, 192, 2, 2]) || m_up2.0.weight
 |  1.337 |  1.001 |  1.550 |  0.134 | torch.Size([64]) || m_up2.1.trans_block.ln1.weight
 | -0.001 | -0.478 |  0.489 |  0.153 | torch.Size([64]) || m_up2.1.trans_block.ln1.bias
 |  0.173 | -2.433 |  0.911 |  0.344 | torch.Size([2, 15, 15]) || m_up2.1.trans_block.msa.relative_position_params
 |  0.000 | -0.498 |  0.523 |  0.107 | torch.Size([192, 64, 1, 1]) || m_up2.1.trans_block.msa.embedding_layer1.weight
 |  0.001 | -0.184 |  0.179 |  0.045 | torch.Size([192]) || m_up2.1.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.188 |  0.200 |  0.049 | torch.Size([64, 64, 1, 1]) || m_up2.1.trans_block.msa.linear1.weight
 | -0.002 | -0.169 |  0.195 |  0.049 | torch.Size([64]) || m_up2.1.trans_block.msa.linear1.bias
 |  1.060 |  0.803 |  1.204 |  0.076 | torch.Size([64]) || m_up2.1.trans_block.ln2.weight
 |  0.006 | -0.271 |  0.250 |  0.134 | torch.Size([64]) || m_up2.1.trans_block.ln2.bias
 | -0.000 | -0.354 |  0.340 |  0.091 | torch.Size([256, 64]) || m_up2.1.trans_block.mlp.0.weight
 | -0.045 | -0.342 |  0.221 |  0.073 | torch.Size([256]) || m_up2.1.trans_block.mlp.0.bias
 |  0.001 | -0.413 |  0.407 |  0.079 | torch.Size([64, 256]) || m_up2.1.trans_block.mlp.2.weight
 | -0.002 | -0.200 |  0.178 |  0.059 | torch.Size([64]) || m_up2.1.trans_block.mlp.2.bias
 |  0.002 | -0.430 |  2.089 |  0.100 | torch.Size([192, 192, 1, 1]) || m_up2.1.conv1_1.weight
 |  0.000 | -0.586 |  0.717 |  0.127 | torch.Size([192]) || m_up2.1.conv1_1.bias
 | -0.193 | -0.666 |  0.046 |  0.410 | torch.Size([1, 1, 1, 1, 3]) || m_up2.1.conv3d.weight
 |  0.001 |  0.001 |  0.001 |    nan | torch.Size([1]) || m_up2.1.conv3d.bias
 |  0.000 | -0.270 |  0.232 |  0.045 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.0.weight
 |  0.000 | -0.274 |  0.249 |  0.046 | torch.Size([64, 64, 3, 3]) || m_up2.1.conv_block.2.weight
 |  1.917 | -0.437 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.0.mixer.A_log
 |  1.111 |  0.999 |  1.283 |  0.057 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.D
 | -0.000 | -0.339 |  0.321 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.0.mixer.in_proj.weight
 |  0.002 | -0.422 |  0.478 |  0.170 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.0.mixer.conv1d.weight
 |  0.004 | -0.222 |  0.235 |  0.068 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.conv1d.bias
 |  0.001 | -0.143 |  0.207 |  0.038 | torch.Size([36, 128]) || m_up2.1.mamba_layers.0.mixer.x_proj.weight
 | -0.000 | -0.055 |  0.058 |  0.019 | torch.Size([128, 4]) || m_up2.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.003 | -0.148 |  0.283 |  0.055 | torch.Size([128]) || m_up2.1.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.517 |  0.375 |  0.076 | torch.Size([64, 128]) || m_up2.1.mamba_layers.0.mixer.out_proj.weight
 |  1.184 |  0.957 |  1.335 |  0.088 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.weight
 |  0.000 | -0.137 |  0.218 |  0.072 | torch.Size([64]) || m_up2.1.mamba_layers.0.norm.bias
 |  1.916 | -0.594 |  2.773 |  0.767 | torch.Size([128, 16]) || m_up2.1.mamba_layers.1.mixer.A_log
 |  1.147 |  0.999 |  1.410 |  0.066 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.D
 |  0.000 | -0.371 |  0.399 |  0.090 | torch.Size([256, 64]) || m_up2.1.mamba_layers.1.mixer.in_proj.weight
 | -0.007 | -0.484 |  0.666 |  0.184 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.1.mixer.conv1d.weight
 |  0.009 | -0.303 |  0.277 |  0.118 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.conv1d.bias
 |  0.000 | -0.235 |  0.301 |  0.063 | torch.Size([36, 128]) || m_up2.1.mamba_layers.1.mixer.x_proj.weight
 |  0.001 | -0.113 |  0.278 |  0.041 | torch.Size([128, 4]) || m_up2.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.031 | -0.147 |  0.237 |  0.062 | torch.Size([128]) || m_up2.1.mamba_layers.1.mixer.dt_proj.bias
 | -0.001 | -0.380 |  0.459 |  0.089 | torch.Size([64, 128]) || m_up2.1.mamba_layers.1.mixer.out_proj.weight
 |  1.202 |  0.868 |  1.356 |  0.106 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.weight
 |  0.001 | -0.216 |  0.245 |  0.083 | torch.Size([64]) || m_up2.1.mamba_layers.1.norm.bias
 |  1.917 | -0.042 |  2.773 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.2.mixer.A_log
 |  1.006 |  0.945 |  1.079 |  0.027 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.D
 |  0.001 | -0.231 |  0.260 |  0.075 | torch.Size([256, 64]) || m_up2.1.mamba_layers.2.mixer.in_proj.weight
 |  0.000 | -0.538 |  0.643 |  0.287 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.2.mixer.conv1d.weight
 | -0.027 | -0.537 |  0.491 |  0.306 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.176 |  0.172 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.2.mixer.x_proj.weight
 |  0.016 | -0.497 |  0.500 |  0.287 | torch.Size([128, 4]) || m_up2.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.802 | -6.895 | -2.292 |  1.396 | torch.Size([128]) || m_up2.1.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.207 |  0.193 |  0.059 | torch.Size([64, 128]) || m_up2.1.mamba_layers.2.mixer.out_proj.weight
 |  0.996 |  0.934 |  1.139 |  0.034 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.weight
 | -0.000 | -0.056 |  0.047 |  0.017 | torch.Size([64]) || m_up2.1.mamba_layers.2.norm.bias
 |  1.917 | -0.015 |  2.775 |  0.765 | torch.Size([128, 16]) || m_up2.1.mamba_layers.3.mixer.A_log
 |  1.001 |  0.945 |  1.076 |  0.028 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.D
 |  0.000 | -0.208 |  0.222 |  0.074 | torch.Size([256, 64]) || m_up2.1.mamba_layers.3.mixer.in_proj.weight
 | -0.011 | -0.555 |  0.583 |  0.292 | torch.Size([128, 1, 4]) || m_up2.1.mamba_layers.3.mixer.conv1d.weight
 | -0.014 | -0.564 |  0.564 |  0.316 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.223 |  0.174 |  0.055 | torch.Size([36, 128]) || m_up2.1.mamba_layers.3.mixer.x_proj.weight
 | -0.017 | -0.491 |  0.498 |  0.291 | torch.Size([128, 4]) || m_up2.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.756 | -6.892 | -2.289 |  1.356 | torch.Size([128]) || m_up2.1.mamba_layers.3.mixer.dt_proj.bias
 | -0.000 | -0.222 |  0.194 |  0.059 | torch.Size([64, 128]) || m_up2.1.mamba_layers.3.mixer.out_proj.weight
 |  0.983 |  0.881 |  1.098 |  0.033 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.weight
 | -0.001 | -0.083 |  0.073 |  0.023 | torch.Size([64]) || m_up2.1.mamba_layers.3.norm.bias
 |  0.168 |  0.121 |  0.214 |  0.066 | torch.Size([2]) || m_up2.1.pcbam_module.h_cw.weight
 |  0.023 | -0.076 |  0.160 |  0.122 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.h_cw.conv.weight
 |  0.691 |  0.688 |  0.694 |  0.004 | torch.Size([2]) || m_up2.1.pcbam_module.w_hc.weight
 | -0.088 | -0.298 |  0.067 |  0.188 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.w_hc.conv.weight
 |  0.887 |  0.834 |  0.941 |  0.076 | torch.Size([2]) || m_up2.1.pcbam_module.c_hw.weight
 | -0.051 | -0.194 |  0.028 |  0.124 | torch.Size([1, 1, 1, 3]) || m_up2.1.pcbam_module.c_hw.conv.weight
 |  1.362 |  1.043 |  1.568 |  0.122 | torch.Size([64]) || m_up2.2.trans_block.ln1.weight
 |  0.036 | -0.424 |  0.509 |  0.136 | torch.Size([64]) || m_up2.2.trans_block.ln1.bias
 |  0.131 | -2.465 |  0.732 |  0.331 | torch.Size([2, 15, 15]) || m_up2.2.trans_block.msa.relative_position_params
 |  0.000 | -0.475 |  0.536 |  0.102 | torch.Size([192, 64, 1, 1]) || m_up2.2.trans_block.msa.embedding_layer1.weight
 |  0.000 | -0.259 |  0.292 |  0.069 | torch.Size([192]) || m_up2.2.trans_block.msa.embedding_layer1.bias
 | -0.001 | -0.270 |  0.234 |  0.050 | torch.Size([64, 64, 1, 1]) || m_up2.2.trans_block.msa.linear1.weight
 |  0.003 | -0.225 |  0.360 |  0.058 | torch.Size([64]) || m_up2.2.trans_block.msa.linear1.bias
 |  1.068 |  0.644 |  1.268 |  0.120 | torch.Size([64]) || m_up2.2.trans_block.ln2.weight
 |  0.014 | -0.399 |  0.391 |  0.121 | torch.Size([64]) || m_up2.2.trans_block.ln2.bias
 |  0.002 | -0.390 |  0.420 |  0.089 | torch.Size([256, 64]) || m_up2.2.trans_block.mlp.0.weight
 | -0.043 | -0.175 |  0.086 |  0.041 | torch.Size([256]) || m_up2.2.trans_block.mlp.0.bias
 | -0.001 | -0.329 |  0.367 |  0.077 | torch.Size([64, 256]) || m_up2.2.trans_block.mlp.2.weight
 |  0.002 | -0.234 |  0.236 |  0.058 | torch.Size([64]) || m_up2.2.trans_block.mlp.2.bias
 |  0.002 | -0.467 |  1.970 |  0.100 | torch.Size([192, 192, 1, 1]) || m_up2.2.conv1_1.weight
 | -0.002 | -0.390 |  0.749 |  0.114 | torch.Size([192]) || m_up2.2.conv1_1.bias
 | -0.201 | -0.641 |  0.023 |  0.381 | torch.Size([1, 1, 1, 1, 3]) || m_up2.2.conv3d.weight
 | -0.008 | -0.008 | -0.008 |    nan | torch.Size([1]) || m_up2.2.conv3d.bias
 |  0.001 | -0.420 |  0.426 |  0.055 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.0.weight
 | -0.000 | -0.317 |  0.428 |  0.056 | torch.Size([64, 64, 3, 3]) || m_up2.2.conv_block.2.weight
 |  1.915 | -0.421 |  2.782 |  0.770 | torch.Size([128, 16]) || m_up2.2.mamba_layers.0.mixer.A_log
 |  1.149 |  0.722 |  1.475 |  0.104 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.D
 |  0.000 | -0.491 |  0.397 |  0.095 | torch.Size([256, 64]) || m_up2.2.mamba_layers.0.mixer.in_proj.weight
 |  0.031 | -0.543 |  0.704 |  0.191 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.0.mixer.conv1d.weight
 |  0.038 | -0.235 |  0.277 |  0.095 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.conv1d.bias
 | -0.003 | -0.529 |  0.737 |  0.077 | torch.Size([36, 128]) || m_up2.2.mamba_layers.0.mixer.x_proj.weight
 | -0.007 | -0.441 |  0.322 |  0.103 | torch.Size([128, 4]) || m_up2.2.mamba_layers.0.mixer.dt_proj.weight
 | -0.015 | -0.607 |  0.316 |  0.119 | torch.Size([128]) || m_up2.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.371 |  0.539 |  0.097 | torch.Size([64, 128]) || m_up2.2.mamba_layers.0.mixer.out_proj.weight
 |  1.245 |  0.939 |  1.393 |  0.097 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.weight
 |  0.008 | -0.510 |  0.450 |  0.163 | torch.Size([64]) || m_up2.2.mamba_layers.0.norm.bias
 |  1.919 | -0.504 |  2.883 |  0.766 | torch.Size([128, 16]) || m_up2.2.mamba_layers.1.mixer.A_log
 |  1.150 |  0.792 |  1.461 |  0.097 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.D
 |  0.000 | -0.492 |  0.539 |  0.101 | torch.Size([256, 64]) || m_up2.2.mamba_layers.1.mixer.in_proj.weight
 |  0.011 | -0.651 |  1.011 |  0.203 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.1.mixer.conv1d.weight
 |  0.027 | -0.312 |  0.290 |  0.117 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.conv1d.bias
 | -0.002 | -0.493 |  0.573 |  0.101 | torch.Size([36, 128]) || m_up2.2.mamba_layers.1.mixer.x_proj.weight
 |  0.002 | -0.484 |  0.386 |  0.105 | torch.Size([128, 4]) || m_up2.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.053 | -0.216 |  0.601 |  0.110 | torch.Size([128]) || m_up2.2.mamba_layers.1.mixer.dt_proj.bias
 |  0.001 | -0.505 |  0.467 |  0.097 | torch.Size([64, 128]) || m_up2.2.mamba_layers.1.mixer.out_proj.weight
 |  1.273 |  0.857 |  1.483 |  0.127 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.weight
 |  0.003 | -0.171 |  0.342 |  0.088 | torch.Size([64]) || m_up2.2.mamba_layers.1.norm.bias
 |  1.917 | -0.028 |  2.774 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.2.mixer.A_log
 |  1.015 |  0.954 |  1.124 |  0.030 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.D
 | -0.000 | -0.321 |  0.293 |  0.077 | torch.Size([256, 64]) || m_up2.2.mamba_layers.2.mixer.in_proj.weight
 | -0.004 | -0.557 |  0.541 |  0.288 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.2.mixer.conv1d.weight
 |  0.065 | -0.557 |  0.560 |  0.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.213 |  0.186 |  0.054 | torch.Size([36, 128]) || m_up2.2.mamba_layers.2.mixer.x_proj.weight
 | -0.001 | -0.497 |  0.499 |  0.286 | torch.Size([128, 4]) || m_up2.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.495 | -6.884 | -2.259 |  1.305 | torch.Size([128]) || m_up2.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.000 | -0.277 |  0.259 |  0.064 | torch.Size([64, 128]) || m_up2.2.mamba_layers.2.mixer.out_proj.weight
 |  1.010 |  0.904 |  1.127 |  0.042 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.weight
 |  0.002 | -0.072 |  0.079 |  0.026 | torch.Size([64]) || m_up2.2.mamba_layers.2.norm.bias
 |  1.917 | -0.069 |  2.777 |  0.764 | torch.Size([128, 16]) || m_up2.2.mamba_layers.3.mixer.A_log
 |  1.022 |  0.961 |  1.195 |  0.040 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.D
 |  0.000 | -0.318 |  0.267 |  0.077 | torch.Size([256, 64]) || m_up2.2.mamba_layers.3.mixer.in_proj.weight
 |  0.008 | -0.609 |  0.585 |  0.287 | torch.Size([128, 1, 4]) || m_up2.2.mamba_layers.3.mixer.conv1d.weight
 |  0.030 | -0.524 |  0.547 |  0.301 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.conv1d.bias
 |  0.000 | -0.233 |  0.186 |  0.057 | torch.Size([36, 128]) || m_up2.2.mamba_layers.3.mixer.x_proj.weight
 |  0.004 | -0.568 |  0.579 |  0.290 | torch.Size([128, 4]) || m_up2.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.642 | -6.849 | -2.291 |  1.277 | torch.Size([128]) || m_up2.2.mamba_layers.3.mixer.dt_proj.bias
 |  0.000 | -0.232 |  0.280 |  0.064 | torch.Size([64, 128]) || m_up2.2.mamba_layers.3.mixer.out_proj.weight
 |  1.010 |  0.913 |  1.117 |  0.042 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.weight
 |  0.003 | -0.068 |  0.065 |  0.026 | torch.Size([64]) || m_up2.2.mamba_layers.3.norm.bias
 |  0.309 |  0.187 |  0.430 |  0.172 | torch.Size([2]) || m_up2.2.pcbam_module.h_cw.weight
 |  0.113 | -0.026 |  0.206 |  0.123 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.h_cw.conv.weight
 |  0.821 |  0.758 |  0.884 |  0.089 | torch.Size([2]) || m_up2.2.pcbam_module.w_hc.weight
 |  0.060 | -0.076 |  0.129 |  0.118 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.w_hc.conv.weight
 |  0.737 |  0.713 |  0.762 |  0.035 | torch.Size([2]) || m_up2.2.pcbam_module.c_hw.weight
 |  0.146 |  0.098 |  0.187 |  0.045 | torch.Size([1, 1, 1, 3]) || m_up2.2.pcbam_module.c_hw.conv.weight
 | -0.000 | -0.178 |  0.175 |  0.027 | torch.Size([192, 96, 2, 2]) || m_up1.0.weight
 |  1.177 |  0.801 |  1.393 |  0.189 | torch.Size([32]) || m_up1.1.trans_block.ln1.weight
 | -0.009 | -0.335 |  0.483 |  0.202 | torch.Size([32]) || m_up1.1.trans_block.ln1.bias
 |  0.132 | -1.052 |  0.836 |  0.423 | torch.Size([1, 15, 15]) || m_up1.1.trans_block.msa.relative_position_params
 | -0.000 | -0.412 |  0.367 |  0.104 | torch.Size([96, 32, 1, 1]) || m_up1.1.trans_block.msa.embedding_layer1.weight
 | -0.010 | -0.345 |  0.346 |  0.156 | torch.Size([96]) || m_up1.1.trans_block.msa.embedding_layer1.bias
 | -0.000 | -0.271 |  0.239 |  0.073 | torch.Size([32, 32, 1, 1]) || m_up1.1.trans_block.msa.linear1.weight
 |  0.003 | -0.099 |  0.118 |  0.053 | torch.Size([32]) || m_up1.1.trans_block.msa.linear1.bias
 |  1.640 |  1.304 |  1.977 |  0.169 | torch.Size([32]) || m_up1.1.trans_block.ln2.weight
 | -0.005 | -0.307 |  0.292 |  0.175 | torch.Size([32]) || m_up1.1.trans_block.ln2.bias
 |  0.001 | -0.742 |  0.704 |  0.159 | torch.Size([128, 32]) || m_up1.1.trans_block.mlp.0.weight
 | -0.016 | -0.368 |  0.340 |  0.114 | torch.Size([128]) || m_up1.1.trans_block.mlp.0.bias
 | -0.000 | -0.648 |  0.814 |  0.127 | torch.Size([32, 128]) || m_up1.1.trans_block.mlp.2.weight
 | -0.032 | -0.416 |  0.259 |  0.167 | torch.Size([32]) || m_up1.1.trans_block.mlp.2.bias
 | -0.005 | -1.279 |  0.464 |  0.122 | torch.Size([96, 96, 1, 1]) || m_up1.1.conv1_1.weight
 | -0.001 | -0.241 |  0.276 |  0.079 | torch.Size([96]) || m_up1.1.conv1_1.bias
 |  0.020 | -0.254 |  0.396 |  0.337 | torch.Size([1, 1, 1, 1, 3]) || m_up1.1.conv3d.weight
 |  0.002 |  0.002 |  0.002 |    nan | torch.Size([1]) || m_up1.1.conv3d.bias
 | -0.001 | -0.571 |  0.715 |  0.085 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.0.weight
 |  0.000 | -0.610 |  0.792 |  0.093 | torch.Size([32, 32, 3, 3]) || m_up1.1.conv_block.2.weight
 |  1.912 | -0.265 |  2.774 |  0.773 | torch.Size([64, 16]) || m_up1.1.mamba_layers.0.mixer.A_log
 |  1.113 |  0.949 |  1.416 |  0.097 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.D
 | -0.001 | -0.468 |  0.608 |  0.124 | torch.Size([128, 32]) || m_up1.1.mamba_layers.0.mixer.in_proj.weight
 |  0.013 | -0.520 |  0.407 |  0.168 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.0.mixer.conv1d.weight
 | -0.001 | -0.185 |  0.271 |  0.089 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.conv1d.bias
 | -0.004 | -0.393 |  0.421 |  0.092 | torch.Size([34, 64]) || m_up1.1.mamba_layers.0.mixer.x_proj.weight
 | -0.011 | -0.519 |  0.299 |  0.129 | torch.Size([64, 2]) || m_up1.1.mamba_layers.0.mixer.dt_proj.weight
 |  0.029 | -0.776 |  0.461 |  0.212 | torch.Size([64]) || m_up1.1.mamba_layers.0.mixer.dt_proj.bias
 | -0.001 | -0.352 |  0.416 |  0.115 | torch.Size([32, 64]) || m_up1.1.mamba_layers.0.mixer.out_proj.weight
 |  1.202 |  0.985 |  1.390 |  0.118 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.weight
 |  0.001 | -0.220 |  0.136 |  0.072 | torch.Size([32]) || m_up1.1.mamba_layers.0.norm.bias
 |  1.906 | -0.980 |  2.773 |  0.783 | torch.Size([64, 16]) || m_up1.1.mamba_layers.1.mixer.A_log
 |  1.176 |  1.062 |  1.330 |  0.056 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.D
 |  0.001 | -0.400 |  0.511 |  0.122 | torch.Size([128, 32]) || m_up1.1.mamba_layers.1.mixer.in_proj.weight
 | -0.008 | -0.489 |  0.367 |  0.155 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.1.mixer.conv1d.weight
 | -0.031 | -0.320 |  0.243 |  0.168 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.conv1d.bias
 | -0.000 | -0.381 |  0.282 |  0.069 | torch.Size([34, 64]) || m_up1.1.mamba_layers.1.mixer.x_proj.weight
 | -0.012 | -0.374 |  0.249 |  0.085 | torch.Size([64, 2]) || m_up1.1.mamba_layers.1.mixer.dt_proj.weight
 |  0.090 | -0.090 |  0.505 |  0.090 | torch.Size([64]) || m_up1.1.mamba_layers.1.mixer.dt_proj.bias
 |  0.004 | -0.603 |  0.486 |  0.128 | torch.Size([32, 64]) || m_up1.1.mamba_layers.1.mixer.out_proj.weight
 |  1.171 |  0.931 |  1.352 |  0.086 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.weight
 |  0.005 | -0.152 |  0.203 |  0.097 | torch.Size([32]) || m_up1.1.mamba_layers.1.norm.bias
 |  1.916 | -0.065 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.2.mixer.A_log
 |  1.035 |  0.952 |  1.174 |  0.042 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.D
 | -0.002 | -0.349 |  0.357 |  0.112 | torch.Size([128, 32]) || m_up1.1.mamba_layers.2.mixer.in_proj.weight
 |  0.011 | -0.625 |  0.692 |  0.294 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.2.mixer.conv1d.weight
 |  0.007 | -0.517 |  0.487 |  0.303 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.conv1d.bias
 | -0.001 | -0.213 |  0.240 |  0.082 | torch.Size([34, 64]) || m_up1.1.mamba_layers.2.mixer.x_proj.weight
 | -0.082 | -0.708 |  0.700 |  0.396 | torch.Size([64, 2]) || m_up1.1.mamba_layers.2.mixer.dt_proj.weight
 | -4.429 | -6.865 | -2.310 |  1.242 | torch.Size([64]) || m_up1.1.mamba_layers.2.mixer.dt_proj.bias
 | -0.001 | -0.334 |  0.259 |  0.086 | torch.Size([32, 64]) || m_up1.1.mamba_layers.2.mixer.out_proj.weight
 |  1.026 |  0.966 |  1.096 |  0.028 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.weight
 | -0.004 | -0.042 |  0.034 |  0.022 | torch.Size([32]) || m_up1.1.mamba_layers.2.norm.bias
 |  1.913 | -0.037 |  2.774 |  0.766 | torch.Size([64, 16]) || m_up1.1.mamba_layers.3.mixer.A_log
 |  1.027 |  0.965 |  1.117 |  0.034 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.D
 | -0.001 | -0.265 |  0.315 |  0.107 | torch.Size([128, 32]) || m_up1.1.mamba_layers.3.mixer.in_proj.weight
 |  0.011 | -0.514 |  0.564 |  0.295 | torch.Size([64, 1, 4]) || m_up1.1.mamba_layers.3.mixer.conv1d.weight
 | -0.005 | -0.546 |  0.538 |  0.325 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.conv1d.bias
 | -0.001 | -0.206 |  0.234 |  0.083 | torch.Size([34, 64]) || m_up1.1.mamba_layers.3.mixer.x_proj.weight
 |  0.018 | -0.750 |  0.694 |  0.409 | torch.Size([64, 2]) || m_up1.1.mamba_layers.3.mixer.dt_proj.weight
 | -4.497 | -6.875 | -2.319 |  1.352 | torch.Size([64]) || m_up1.1.mamba_layers.3.mixer.dt_proj.bias
 |  0.003 | -0.246 |  0.249 |  0.084 | torch.Size([32, 64]) || m_up1.1.mamba_layers.3.mixer.out_proj.weight
 |  1.015 |  0.949 |  1.065 |  0.028 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.weight
 | -0.002 | -0.042 |  0.062 |  0.021 | torch.Size([32]) || m_up1.1.mamba_layers.3.norm.bias
 |  0.533 |  0.169 |  0.896 |  0.514 | torch.Size([2]) || m_up1.1.pcbam_module.h_cw.weight
 | -0.028 | -0.107 |  0.094 |  0.107 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.h_cw.conv.weight
 |  0.068 |  0.002 |  0.134 |  0.093 | torch.Size([2]) || m_up1.1.pcbam_module.w_hc.weight
 | -0.115 | -0.242 |  0.043 |  0.145 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.w_hc.conv.weight
 |  0.449 |  0.107 |  0.791 |  0.484 | torch.Size([2]) || m_up1.1.pcbam_module.c_hw.weight
 |  0.015 | -0.251 |  0.345 |  0.304 | torch.Size([1, 1, 1, 3]) || m_up1.1.pcbam_module.c_hw.conv.weight
 |  1.259 |  0.956 |  1.576 |  0.162 | torch.Size([32]) || m_up1.2.trans_block.ln1.weight
 |  0.011 | -0.395 |  0.459 |  0.171 | torch.Size([32]) || m_up1.2.trans_block.ln1.bias
 | -0.143 | -0.850 |  0.643 |  0.354 | torch.Size([1, 15, 15]) || m_up1.2.trans_block.msa.relative_position_params
 | -0.001 | -0.592 |  0.655 |  0.142 | torch.Size([96, 32, 1, 1]) || m_up1.2.trans_block.msa.embedding_layer1.weight
 | -0.002 | -0.217 |  0.139 |  0.041 | torch.Size([96]) || m_up1.2.trans_block.msa.embedding_layer1.bias
 |  0.000 | -0.157 |  0.161 |  0.047 | torch.Size([32, 32, 1, 1]) || m_up1.2.trans_block.msa.linear1.weight
 |  0.001 | -0.105 |  0.112 |  0.039 | torch.Size([32]) || m_up1.2.trans_block.msa.linear1.bias
 |  1.009 |  0.826 |  1.195 |  0.089 | torch.Size([32]) || m_up1.2.trans_block.ln2.weight
 | -0.005 | -0.150 |  0.195 |  0.075 | torch.Size([32]) || m_up1.2.trans_block.ln2.bias
 |  0.001 | -0.563 |  0.424 |  0.079 | torch.Size([128, 32]) || m_up1.2.trans_block.mlp.0.weight
 | -0.005 | -0.202 |  0.093 |  0.047 | torch.Size([128]) || m_up1.2.trans_block.mlp.0.bias
 | -0.001 | -0.341 |  0.371 |  0.085 | torch.Size([32, 128]) || m_up1.2.trans_block.mlp.2.weight
 | -0.003 | -0.105 |  0.207 |  0.057 | torch.Size([32]) || m_up1.2.trans_block.mlp.2.bias
 | -0.001 | -0.746 |  0.505 |  0.105 | torch.Size([96, 96, 1, 1]) || m_up1.2.conv1_1.weight
 | -0.002 | -0.225 |  0.383 |  0.064 | torch.Size([96]) || m_up1.2.conv1_1.bias
 |  0.103 | -0.055 |  0.356 |  0.221 | torch.Size([1, 1, 1, 1, 3]) || m_up1.2.conv3d.weight
 |  0.005 |  0.005 |  0.005 |    nan | torch.Size([1]) || m_up1.2.conv3d.bias
 |  0.002 | -0.323 |  0.610 |  0.079 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.0.weight
 | -0.000 | -0.555 |  0.757 |  0.095 | torch.Size([32, 32, 3, 3]) || m_up1.2.conv_block.2.weight
 |  1.913 | -0.746 |  2.773 |  0.775 | torch.Size([64, 16]) || m_up1.2.mamba_layers.0.mixer.A_log
 |  1.120 |  0.987 |  1.403 |  0.076 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.D
 |  0.001 | -0.492 |  0.513 |  0.123 | torch.Size([128, 32]) || m_up1.2.mamba_layers.0.mixer.in_proj.weight
 | -0.004 | -0.389 |  0.437 |  0.164 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.0.mixer.conv1d.weight
 |  0.006 | -0.089 |  0.131 |  0.050 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.conv1d.bias
 | -0.000 | -0.528 |  0.348 |  0.102 | torch.Size([34, 64]) || m_up1.2.mamba_layers.0.mixer.x_proj.weight
 | -0.001 | -0.097 |  0.143 |  0.040 | torch.Size([64, 2]) || m_up1.2.mamba_layers.0.mixer.dt_proj.weight
 |  0.028 | -0.378 |  0.653 |  0.187 | torch.Size([64]) || m_up1.2.mamba_layers.0.mixer.dt_proj.bias
 |  0.000 | -0.352 |  0.395 |  0.110 | torch.Size([32, 64]) || m_up1.2.mamba_layers.0.mixer.out_proj.weight
 |  1.253 |  0.900 |  1.446 |  0.113 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.weight
 |  0.014 | -0.223 |  0.275 |  0.105 | torch.Size([32]) || m_up1.2.mamba_layers.0.norm.bias
 |  1.913 | -0.540 |  2.783 |  0.778 | torch.Size([64, 16]) || m_up1.2.mamba_layers.1.mixer.A_log
 |  1.193 |  0.974 |  1.458 |  0.106 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.D
 |  0.001 | -0.624 |  0.624 |  0.139 | torch.Size([128, 32]) || m_up1.2.mamba_layers.1.mixer.in_proj.weight
 |  0.012 | -0.574 |  0.689 |  0.185 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.1.mixer.conv1d.weight
 |  0.018 | -0.238 |  0.220 |  0.102 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.conv1d.bias
 |  0.001 | -0.540 |  0.579 |  0.122 | torch.Size([34, 64]) || m_up1.2.mamba_layers.1.mixer.x_proj.weight
 | -0.048 | -0.482 |  0.250 |  0.154 | torch.Size([64, 2]) || m_up1.2.mamba_layers.1.mixer.dt_proj.weight
 |  0.042 | -0.451 |  0.549 |  0.160 | torch.Size([64]) || m_up1.2.mamba_layers.1.mixer.dt_proj.bias
 | -0.002 | -0.732 |  0.578 |  0.146 | torch.Size([32, 64]) || m_up1.2.mamba_layers.1.mixer.out_proj.weight
 |  1.227 |  0.943 |  1.396 |  0.105 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.weight
 |  0.005 | -0.113 |  0.106 |  0.049 | torch.Size([32]) || m_up1.2.mamba_layers.1.norm.bias
 |  1.917 | -0.069 |  2.777 |  0.765 | torch.Size([64, 16]) || m_up1.2.mamba_layers.2.mixer.A_log
 |  1.014 |  0.955 |  1.170 |  0.043 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.D
 |  0.000 | -0.336 |  0.312 |  0.108 | torch.Size([128, 32]) || m_up1.2.mamba_layers.2.mixer.in_proj.weight
 | -0.022 | -0.580 |  0.575 |  0.281 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.2.mixer.conv1d.weight
 |  0.010 | -0.524 |  0.522 |  0.322 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.conv1d.bias
 |  0.002 | -0.227 |  0.224 |  0.076 | torch.Size([34, 64]) || m_up1.2.mamba_layers.2.mixer.x_proj.weight
 |  0.070 | -0.709 |  0.670 |  0.392 | torch.Size([64, 2]) || m_up1.2.mamba_layers.2.mixer.dt_proj.weight
 | -4.717 | -6.818 | -2.344 |  1.385 | torch.Size([64]) || m_up1.2.mamba_layers.2.mixer.dt_proj.bias
 |  0.002 | -0.329 |  0.300 |  0.086 | torch.Size([32, 64]) || m_up1.2.mamba_layers.2.mixer.out_proj.weight
 |  1.009 |  0.916 |  1.089 |  0.042 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.weight
 |  0.001 | -0.039 |  0.026 |  0.018 | torch.Size([32]) || m_up1.2.mamba_layers.2.norm.bias
 |  1.916 | -0.057 |  2.776 |  0.766 | torch.Size([64, 16]) || m_up1.2.mamba_layers.3.mixer.A_log
 |  1.007 |  0.942 |  1.114 |  0.035 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.D
 | -0.002 | -0.361 |  0.428 |  0.109 | torch.Size([128, 32]) || m_up1.2.mamba_layers.3.mixer.in_proj.weight
 |  0.012 | -0.638 |  0.544 |  0.296 | torch.Size([64, 1, 4]) || m_up1.2.mamba_layers.3.mixer.conv1d.weight
 |  0.083 | -0.442 |  0.552 |  0.280 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.conv1d.bias
 | -0.004 | -0.238 |  0.253 |  0.077 | torch.Size([34, 64]) || m_up1.2.mamba_layers.3.mixer.x_proj.weight
 | -0.115 | -0.707 |  0.686 |  0.390 | torch.Size([64, 2]) || m_up1.2.mamba_layers.3.mixer.dt_proj.weight
 | -4.758 | -6.877 | -2.275 |  1.309 | torch.Size([64]) || m_up1.2.mamba_layers.3.mixer.dt_proj.bias
 | -0.002 | -0.392 |  0.276 |  0.088 | torch.Size([32, 64]) || m_up1.2.mamba_layers.3.mixer.out_proj.weight
 |  1.018 |  0.968 |  1.186 |  0.043 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.weight
 | -0.002 | -0.043 |  0.055 |  0.018 | torch.Size([32]) || m_up1.2.mamba_layers.3.norm.bias
 |  0.666 |  0.459 |  0.874 |  0.294 | torch.Size([2]) || m_up1.2.pcbam_module.h_cw.weight
 |  0.147 |  0.087 |  0.185 |  0.053 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.h_cw.conv.weight
 |  0.182 |  0.079 |  0.285 |  0.146 | torch.Size([2]) || m_up1.2.pcbam_module.w_hc.weight
 | -0.014 | -0.144 |  0.210 |  0.194 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.w_hc.conv.weight
 |  0.236 |  0.093 |  0.378 |  0.201 | torch.Size([2]) || m_up1.2.pcbam_module.c_hw.weight
 |  0.078 | -0.043 |  0.183 |  0.114 | torch.Size([1, 1, 1, 3]) || m_up1.2.pcbam_module.c_hw.conv.weight
 |  0.000 | -0.061 |  0.067 |  0.014 | torch.Size([3, 96, 3, 3]) || m_tail.0.weight
 | -0.029 | -0.131 |  0.157 |  0.083 | torch.Size([3, 3, 1, 1]) || fft.mag.weight
 |  0.178 | -0.197 |  0.457 |  0.338 | torch.Size([3]) || fft.mag.bias
 |  0.162 |  0.028 |  0.320 |  0.148 | torch.Size([3]) || fft.mag_bn.weight
 | -0.796 | -2.134 | -0.114 |  1.159 | torch.Size([3]) || fft.mag_bn.bias
 | -2.340 | -7.169 |  3.582 |  5.458 | torch.Size([3]) || fft.mag_bn.running_mean
 | 440.826 | 196.210 | 869.354 | 372.355 | torch.Size([3]) || fft.mag_bn.running_var
 |  0.010 | -0.300 |  0.165 |  0.157 | torch.Size([3, 3, 1, 1]) || fft.pha.0.weight
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.0.bias
 |  1.177 |  0.834 |  1.432 |  0.308 | torch.Size([3]) || fft.pha.1.weight
 |  0.324 |  0.205 |  0.396 |  0.104 | torch.Size([3]) || fft.pha.1.bias
 |  0.039 | -0.012 |  0.122 |  0.072 | torch.Size([3]) || fft.pha.1.running_mean
 |  0.026 |  0.017 |  0.038 |  0.011 | torch.Size([3]) || fft.pha.1.running_var
 | -0.086 | -0.660 |  0.867 |  0.494 | torch.Size([3, 3, 1, 1]) || fft.pha.3.weight
 |  0.009 | -0.146 |  0.139 |  0.144 | torch.Size([3]) || fft.pha.3.bias
 |  0.311 | -0.158 |  2.024 |  0.841 | torch.Size([1, 6, 1, 1]) || fft.conv1.weight
 |  0.029 |  0.029 |  0.029 |    nan | torch.Size([1]) || fft.conv1.bias
 | -0.001 | -0.085 |  0.074 |  0.023 | torch.Size([96, 96, 1, 1]) || conv1.weight
 | -0.000 | -0.016 |  0.021 |  0.005 | torch.Size([96]) || conv1.bias
 |  0.415 |  0.004 |  0.891 |  0.224 | torch.Size([96]) || bn1.weight
 | -0.088 | -0.192 | -0.011 |  0.040 | torch.Size([96]) || bn1.bias
 | -0.002 | -0.042 |  0.056 |  0.028 | torch.Size([96]) || bn1.running_mean
 |  0.001 |  0.000 |  0.005 |  0.001 | torch.Size([96]) || bn1.running_var
 | -0.002 | -0.065 |  0.059 |  0.014 | torch.Size([192, 96, 2, 2]) || conv2.weight
 | -0.000 | -0.011 |  0.012 |  0.004 | torch.Size([192]) || conv2.bias
 |  0.415 |  0.019 |  0.895 |  0.226 | torch.Size([192]) || bn2.weight
 | -0.079 | -0.207 | -0.008 |  0.039 | torch.Size([192]) || bn2.bias
 | -0.025 | -0.117 |  0.091 |  0.047 | torch.Size([192]) || bn2.running_mean
 |  0.019 |  0.000 |  0.060 |  0.011 | torch.Size([192]) || bn2.running_var
 | -0.001 | -0.044 |  0.041 |  0.007 | torch.Size([384, 96, 4, 4]) || conv3.weight
 | -0.000 | -0.022 |  0.014 |  0.005 | torch.Size([384]) || conv3.bias
 |  0.439 |  0.046 |  0.919 |  0.222 | torch.Size([384]) || bn3.weight
 | -0.069 | -0.198 |  0.026 |  0.035 | torch.Size([384]) || bn3.bias
 | -0.063 | -0.188 |  0.156 |  0.042 | torch.Size([384]) || bn3.running_mean
 |  0.049 |  0.002 |  0.182 |  0.025 | torch.Size([384]) || bn3.running_var

25-05-22 11:28:49.156 : <epoch:  0, iter:  10,000, lr:1.000e-04> G_loss: 4.926e-05 
25-05-22 11:28:49.157 : Saving the model.
25-05-22 11:28:49.859 : ---1--> airplane_111_00.jpg | 30.28dB
25-05-22 11:28:49.934 : ---2--> airplane_111_01.jpg | 35.18dB
25-05-22 11:28:50.003 : ---3--> airplane_111_10.jpg | 32.70dB
25-05-22 11:28:50.085 : ---4--> airplane_111_11.jpg | 32.79dB
25-05-22 11:28:50.163 : ---5--> airport_111_00.jpg | 34.49dB
25-05-22 11:28:50.240 : ---6--> airport_111_01.jpg | 32.36dB
25-05-22 11:28:50.311 : ---7--> airport_111_10.jpg | 31.89dB
25-05-22 11:28:50.382 : ---8--> airport_111_11.jpg | 32.80dB
25-05-22 11:28:50.456 : ---9--> baseball_diamond_111_00.jpg | 32.66dB
25-05-22 11:28:50.528 : --10--> baseball_diamond_111_01.jpg | 34.23dB
25-05-22 11:28:50.615 : --11--> baseball_diamond_111_10.jpg | 32.52dB
25-05-22 11:28:50.689 : --12--> baseball_diamond_111_11.jpg | 35.46dB
25-05-22 11:28:50.769 : --13--> basketball_court_111_00.jpg | 30.46dB
25-05-22 11:28:50.864 : --14--> basketball_court_111_01.jpg | 30.06dB
25-05-22 11:28:50.944 : --15--> basketball_court_111_10.jpg | 33.47dB
25-05-22 11:28:51.034 : --16--> basketball_court_111_11.jpg | 31.53dB
25-05-22 11:28:51.117 : --17--> beach_111_00.jpg | 28.41dB
25-05-22 11:28:51.189 : --18--> beach_111_01.jpg | 31.63dB
25-05-22 11:28:51.289 : --19--> beach_111_10.jpg | 29.61dB
25-05-22 11:28:51.359 : --20--> beach_111_11.jpg | 34.34dB
25-05-22 11:28:51.450 : --21--> bridge_111_00.jpg | 40.79dB
25-05-22 11:28:51.524 : --22--> bridge_111_01.jpg | 34.28dB
25-05-22 11:28:51.613 : --23--> bridge_111_10.jpg | 33.17dB
25-05-22 11:28:51.704 : --24--> bridge_111_11.jpg | 36.73dB
25-05-22 11:28:51.805 : --25--> chaparral_111_00.jpg | 30.16dB
25-05-22 11:28:51.900 : --26--> chaparral_111_01.jpg | 30.43dB
25-05-22 11:28:51.983 : --27--> chaparral_111_10.jpg | 30.77dB
25-05-22 11:28:52.059 : --28--> chaparral_111_11.jpg | 28.56dB
25-05-22 11:28:52.133 : --29--> church_111_00.jpg | 31.60dB
25-05-22 11:28:52.217 : --30--> church_111_01.jpg | 30.47dB
25-05-22 11:28:52.303 : --31--> church_111_10.jpg | 34.37dB
25-05-22 11:28:52.379 : --32--> church_111_11.jpg | 30.27dB
25-05-22 11:28:52.449 : --33--> circular_farmland_111_00.jpg | 32.73dB
25-05-22 11:28:52.533 : --34--> circular_farmland_111_01.jpg | 33.81dB
25-05-22 11:28:52.606 : --35--> circular_farmland_111_10.jpg | 34.02dB
25-05-22 11:28:52.684 : --36--> circular_farmland_111_11.jpg | 34.10dB
25-05-22 11:28:52.756 : --37--> cloud_111_00.jpg | 39.40dB
25-05-22 11:28:52.843 : --38--> cloud_111_01.jpg | 36.37dB
25-05-22 11:28:52.911 : --39--> cloud_111_10.jpg | 36.11dB
25-05-22 11:28:52.982 : --40--> cloud_111_11.jpg | 36.71dB
25-05-22 11:28:53.052 : --41--> commercial_area_111_00.jpg | 33.29dB
25-05-22 11:28:53.148 : --42--> commercial_area_111_01.jpg | 32.32dB
25-05-22 11:28:53.232 : --43--> commercial_area_111_10.jpg | 33.10dB
25-05-22 11:28:53.326 : --44--> commercial_area_111_11.jpg | 32.99dB
25-05-22 11:28:53.415 : --45--> dense_residential_111_00.jpg | 29.97dB
25-05-22 11:28:53.524 : --46--> dense_residential_111_01.jpg | 29.10dB
25-05-22 11:28:53.600 : --47--> dense_residential_111_10.jpg | 29.50dB
25-05-22 11:28:53.683 : --48--> dense_residential_111_11.jpg | 29.33dB
25-05-22 11:28:53.759 : --49--> desert_111_00.jpg | 36.55dB
25-05-22 11:28:53.833 : --50--> desert_111_01.jpg | 36.41dB
25-05-22 11:28:53.926 : --51--> desert_111_10.jpg | 36.66dB
25-05-22 11:28:54.015 : --52--> desert_111_11.jpg | 36.71dB
25-05-22 11:28:54.115 : --53--> forest_111_00.jpg | 32.95dB
25-05-22 11:28:54.185 : --54--> forest_111_01.jpg | 32.04dB
25-05-22 11:28:54.269 : --55--> forest_111_10.jpg | 31.65dB
25-05-22 11:28:54.341 : --56--> forest_111_11.jpg | 32.68dB
25-05-22 11:28:54.417 : --57--> freeway_111_00.jpg | 33.86dB
25-05-22 11:28:54.503 : --58--> freeway_111_01.jpg | 34.88dB
25-05-22 11:28:54.580 : --59--> freeway_111_10.jpg | 34.64dB
25-05-22 11:28:54.659 : --60--> freeway_111_11.jpg | 34.71dB
25-05-22 11:28:54.745 : --61--> golf_course_111_00.jpg | 32.72dB
25-05-22 11:28:54.819 : --62--> golf_course_111_01.jpg | 32.07dB
25-05-22 11:28:54.905 : --63--> golf_course_111_10.jpg | 33.48dB
25-05-22 11:28:54.995 : --64--> golf_course_111_11.jpg | 33.90dB
25-05-22 11:28:55.081 : --65--> ground_track_field_111_00.jpg | 33.31dB
25-05-22 11:28:55.157 : --66--> ground_track_field_111_01.jpg | 29.24dB
25-05-22 11:28:55.225 : --67--> ground_track_field_111_10.jpg | 30.71dB
25-05-22 11:28:55.299 : --68--> ground_track_field_111_11.jpg | 29.85dB
25-05-22 11:28:55.382 : --69--> harbor_111_00.jpg | 32.76dB
25-05-22 11:28:55.468 : --70--> harbor_111_01.jpg | 31.09dB
25-05-22 11:28:55.545 : --71--> harbor_111_10.jpg | 30.65dB
25-05-22 11:28:55.622 : --72--> harbor_111_11.jpg | 32.39dB
25-05-22 11:28:55.697 : --73--> industrial_area_111_00.jpg | 31.37dB
25-05-22 11:28:55.785 : --74--> industrial_area_111_01.jpg | 31.66dB
25-05-22 11:28:55.861 : --75--> industrial_area_111_10.jpg | 31.77dB
25-05-22 11:28:55.940 : --76--> industrial_area_111_11.jpg | 31.19dB
25-05-22 11:28:56.022 : --77--> intersection_111_00.jpg | 30.58dB
25-05-22 11:28:56.102 : --78--> intersection_111_01.jpg | 30.71dB
25-05-22 11:28:56.182 : --79--> intersection_111_10.jpg | 30.37dB
25-05-22 11:28:56.264 : --80--> intersection_111_11.jpg | 30.15dB
25-05-22 11:28:56.345 : --81--> island_111_00.jpg | 31.28dB
25-05-22 11:28:56.412 : --82--> island_111_01.jpg | 33.72dB
25-05-22 11:28:56.490 : --83--> island_111_10.jpg | 32.32dB
25-05-22 11:28:56.557 : --84--> island_111_11.jpg | 31.88dB
25-05-22 11:28:56.634 : --85--> lake_111_00.jpg | 32.47dB
25-05-22 11:28:56.726 : --86--> lake_111_01.jpg | 32.28dB
25-05-22 11:28:56.795 : --87--> lake_111_10.jpg | 31.54dB
25-05-22 11:28:56.873 : --88--> lake_111_11.jpg | 30.96dB
25-05-22 11:28:56.951 : --89--> meadow_111_00.jpg | 29.91dB
25-05-22 11:28:57.031 : --90--> meadow_111_01.jpg | 30.02dB
25-05-22 11:28:57.130 : --91--> meadow_111_10.jpg | 30.04dB
25-05-22 11:28:57.198 : --92--> meadow_111_11.jpg | 30.23dB
25-05-22 11:28:57.294 : --93--> medium_residential_111_00.jpg | 28.55dB
25-05-22 11:28:57.370 : --94--> medium_residential_111_01.jpg | 28.03dB
25-05-22 11:28:57.469 : --95--> medium_residential_111_10.jpg | 28.38dB
25-05-22 11:28:57.556 : --96--> medium_residential_111_11.jpg | 28.87dB
25-05-22 11:28:57.644 : --97--> mobile_home_park_111_00.jpg | 30.82dB
25-05-22 11:28:57.722 : --98--> mobile_home_park_111_01.jpg | 31.33dB
25-05-22 11:28:57.819 : --99--> mobile_home_park_111_10.jpg | 31.61dB
25-05-22 11:28:57.895 : -100--> mobile_home_park_111_11.jpg | 31.67dB
25-05-22 11:28:57.992 : -101--> mountain_111_00.jpg | 28.79dB
25-05-22 11:28:58.067 : -102--> mountain_111_01.jpg | 29.45dB
25-05-22 11:28:58.139 : -103--> mountain_111_10.jpg | 29.24dB
25-05-22 11:28:58.218 : -104--> mountain_111_11.jpg | 29.56dB
25-05-22 11:28:58.291 : -105--> overpass_111_00.jpg | 29.97dB
25-05-22 11:28:58.381 : -106--> overpass_111_01.jpg | 29.81dB
25-05-22 11:28:58.452 : -107--> overpass_111_10.jpg | 30.37dB
25-05-22 11:28:58.537 : -108--> overpass_111_11.jpg | 31.19dB
25-05-22 11:28:58.612 : -109--> palace_111_00.jpg | 29.92dB
25-05-22 11:28:58.680 : -110--> palace_111_01.jpg | 29.77dB
25-05-22 11:28:58.746 : -111--> palace_111_10.jpg | 30.93dB
25-05-22 11:28:58.821 : -112--> palace_111_11.jpg | 29.26dB
25-05-22 11:28:58.893 : -113--> parking_lot_111_00.jpg | 29.18dB
25-05-22 11:28:58.981 : -114--> parking_lot_111_01.jpg | 29.45dB
25-05-22 11:28:59.067 : -115--> parking_lot_111_10.jpg | 30.99dB
25-05-22 11:28:59.146 : -116--> parking_lot_111_11.jpg | 29.79dB
25-05-22 11:28:59.218 : -117--> railway_111_00.jpg | 30.07dB
25-05-22 11:28:59.293 : -118--> railway_111_01.jpg | 29.46dB
25-05-22 11:28:59.365 : -119--> railway_111_10.jpg | 32.39dB
25-05-22 11:28:59.440 : -120--> railway_111_11.jpg | 28.96dB
25-05-22 11:28:59.516 : -121--> railway_station_111_00.jpg | 30.81dB
25-05-22 11:28:59.600 : -122--> railway_station_111_01.jpg | 31.25dB
25-05-22 11:28:59.668 : -123--> railway_station_111_10.jpg | 30.95dB
25-05-22 11:28:59.740 : -124--> railway_station_111_11.jpg | 31.53dB
25-05-22 11:28:59.818 : -125--> rectangular_farmland_111_00.jpg | 33.39dB
25-05-22 11:28:59.897 : -126--> rectangular_farmland_111_01.jpg | 31.83dB
25-05-22 11:28:59.973 : -127--> rectangular_farmland_111_10.jpg | 33.78dB
25-05-22 11:29:00.052 : -128--> rectangular_farmland_111_11.jpg | 34.11dB
25-05-22 11:29:00.134 : -129--> river_111_00.jpg | 30.05dB
25-05-22 11:29:00.215 : -130--> river_111_01.jpg | 29.85dB
25-05-22 11:29:00.307 : -131--> river_111_10.jpg | 29.31dB
25-05-22 11:29:00.403 : -132--> river_111_11.jpg | 31.22dB
25-05-22 11:29:00.496 : -133--> roundabout_111_00.jpg | 30.35dB
25-05-22 11:29:00.577 : -134--> roundabout_111_01.jpg | 31.99dB
25-05-22 11:29:00.659 : -135--> roundabout_111_10.jpg | 30.31dB
25-05-22 11:29:00.757 : -136--> roundabout_111_11.jpg | 30.62dB
25-05-22 11:29:00.838 : -137--> runway_111_00.jpg | 36.49dB
25-05-22 11:29:00.928 : -138--> runway_111_01.jpg | 35.87dB
25-05-22 11:29:01.008 : -139--> runway_111_10.jpg | 36.61dB
25-05-22 11:29:01.084 : -140--> runway_111_11.jpg | 37.51dB
25-05-22 11:29:01.161 : -141--> sea_ice_111_00.jpg | 33.39dB
25-05-22 11:29:01.248 : -142--> sea_ice_111_01.jpg | 34.45dB
25-05-22 11:29:01.332 : -143--> sea_ice_111_10.jpg | 33.52dB
25-05-22 11:29:01.399 : -144--> sea_ice_111_11.jpg | 34.50dB
25-05-22 11:29:01.471 : -145--> ship_111_00.jpg | 38.69dB
25-05-22 11:29:01.554 : -146--> ship_111_01.jpg | 34.51dB
25-05-22 11:29:01.635 : -147--> ship_111_10.jpg | 42.67dB
25-05-22 11:29:01.705 : -148--> ship_111_11.jpg | 40.11dB
25-05-22 11:29:01.773 : -149--> snowberg_111_00.jpg | 33.94dB
25-05-22 11:29:01.846 : -150--> snowberg_111_01.jpg | 32.36dB
25-05-22 11:29:01.920 : -151--> snowberg_111_10.jpg | 31.60dB
25-05-22 11:29:01.995 : -152--> snowberg_111_11.jpg | 31.66dB
25-05-22 11:29:02.086 : -153--> sparse_residential_111_00.jpg | 30.32dB
25-05-22 11:29:02.173 : -154--> sparse_residential_111_01.jpg | 30.63dB
25-05-22 11:29:02.249 : -155--> sparse_residential_111_10.jpg | 29.63dB
25-05-22 11:29:02.323 : -156--> sparse_residential_111_11.jpg | 29.90dB
25-05-22 11:29:02.389 : -157--> stadium_111_00.jpg | 30.11dB
25-05-22 11:29:02.468 : -158--> stadium_111_01.jpg | 29.90dB
25-05-22 11:29:02.548 : -159--> stadium_111_10.jpg | 31.21dB
25-05-22 11:29:02.630 : -160--> stadium_111_11.jpg | 30.02dB
25-05-22 11:29:02.705 : -161--> storage_tank_111_00.jpg | 31.72dB
25-05-22 11:29:02.794 : -162--> storage_tank_111_01.jpg | 31.98dB
25-05-22 11:29:02.881 : -163--> storage_tank_111_10.jpg | 30.67dB
25-05-22 11:29:02.960 : -164--> storage_tank_111_11.jpg | 31.14dB
25-05-22 11:29:03.043 : -165--> tennis_court_111_00.jpg | 31.82dB
25-05-22 11:29:03.115 : -166--> tennis_court_111_01.jpg | 31.43dB
25-05-22 11:29:03.200 : -167--> tennis_court_111_10.jpg | 31.53dB
25-05-22 11:29:03.288 : -168--> tennis_court_111_11.jpg | 29.52dB
25-05-22 11:29:03.359 : -169--> terrace_111_00.jpg | 32.06dB
25-05-22 11:29:03.443 : -170--> terrace_111_01.jpg | 33.07dB
25-05-22 11:29:03.533 : -171--> terrace_111_10.jpg | 32.10dB
25-05-22 11:29:03.605 : -172--> terrace_111_11.jpg | 32.12dB
25-05-22 11:29:03.684 : -173--> thermal_power_station_111_00.jpg | 29.99dB
25-05-22 11:29:03.770 : -174--> thermal_power_station_111_01.jpg | 31.52dB
25-05-22 11:29:03.865 : -175--> thermal_power_station_111_10.jpg | 29.72dB
25-05-22 11:29:03.940 : -176--> thermal_power_station_111_11.jpg | 30.33dB
25-05-22 11:29:04.024 : -177--> wetland_111_00.jpg | 31.29dB
25-05-22 11:29:04.123 : -178--> wetland_111_01.jpg | 31.34dB
25-05-22 11:29:04.189 : -179--> wetland_111_10.jpg | 31.59dB
25-05-22 11:29:04.263 : -180--> wetland_111_11.jpg | 30.88dB
25-05-22 11:29:04.274 : <epoch:  0, iter:  10,000, Average PSNR : 32.03dB

25-05-22 12:01:18.707 : <epoch:  0, iter:  20,000, lr:1.000e-04> G_loss: 1.019e-04 
25-05-22 12:01:18.707 : Saving the model.
25-05-22 12:01:19.407 : ---1--> airplane_111_00.jpg | 30.58dB
25-05-22 12:01:19.494 : ---2--> airplane_111_01.jpg | 35.30dB
25-05-22 12:01:19.561 : ---3--> airplane_111_10.jpg | 32.88dB
25-05-22 12:01:19.633 : ---4--> airplane_111_11.jpg | 32.96dB
25-05-22 12:01:19.714 : ---5--> airport_111_00.jpg | 34.48dB
25-05-22 12:01:19.784 : ---6--> airport_111_01.jpg | 32.43dB
25-05-22 12:01:19.865 : ---7--> airport_111_10.jpg | 31.97dB
25-05-22 12:01:19.942 : ---8--> airport_111_11.jpg | 32.90dB
25-05-22 12:01:20.014 : ---9--> baseball_diamond_111_00.jpg | 32.76dB
25-05-22 12:01:20.087 : --10--> baseball_diamond_111_01.jpg | 34.39dB
25-05-22 12:01:20.165 : --11--> baseball_diamond_111_10.jpg | 32.60dB
25-05-22 12:01:20.228 : --12--> baseball_diamond_111_11.jpg | 35.51dB
25-05-22 12:01:20.295 : --13--> basketball_court_111_00.jpg | 30.61dB
25-05-22 12:01:20.383 : --14--> basketball_court_111_01.jpg | 30.20dB
25-05-22 12:01:20.453 : --15--> basketball_court_111_10.jpg | 33.55dB
25-05-22 12:01:20.540 : --16--> basketball_court_111_11.jpg | 31.67dB
25-05-22 12:01:20.610 : --17--> beach_111_00.jpg | 28.73dB
25-05-22 12:01:20.685 : --18--> beach_111_01.jpg | 31.85dB
25-05-22 12:01:20.760 : --19--> beach_111_10.jpg | 29.84dB
25-05-22 12:01:20.829 : --20--> beach_111_11.jpg | 34.44dB
25-05-22 12:01:20.895 : --21--> bridge_111_00.jpg | 40.77dB
25-05-22 12:01:20.964 : --22--> bridge_111_01.jpg | 34.40dB
25-05-22 12:01:21.047 : --23--> bridge_111_10.jpg | 33.39dB
25-05-22 12:01:21.125 : --24--> bridge_111_11.jpg | 36.84dB
25-05-22 12:01:21.199 : --25--> chaparral_111_00.jpg | 30.34dB
25-05-22 12:01:21.280 : --26--> chaparral_111_01.jpg | 30.56dB
25-05-22 12:01:21.352 : --27--> chaparral_111_10.jpg | 30.99dB
25-05-22 12:01:21.421 : --28--> chaparral_111_11.jpg | 28.76dB
25-05-22 12:01:21.496 : --29--> church_111_00.jpg | 31.75dB
25-05-22 12:01:21.563 : --30--> church_111_01.jpg | 30.73dB
25-05-22 12:01:21.631 : --31--> church_111_10.jpg | 34.45dB
25-05-22 12:01:21.719 : --32--> church_111_11.jpg | 30.55dB
25-05-22 12:01:21.794 : --33--> circular_farmland_111_00.jpg | 32.90dB
25-05-22 12:01:21.885 : --34--> circular_farmland_111_01.jpg | 33.90dB
25-05-22 12:01:21.974 : --35--> circular_farmland_111_10.jpg | 34.07dB
25-05-22 12:01:22.049 : --36--> circular_farmland_111_11.jpg | 34.13dB
25-05-22 12:01:22.121 : --37--> cloud_111_00.jpg | 40.56dB
25-05-22 12:01:22.204 : --38--> cloud_111_01.jpg | 36.69dB
25-05-22 12:01:22.296 : --39--> cloud_111_10.jpg | 36.31dB
25-05-22 12:01:22.389 : --40--> cloud_111_11.jpg | 36.87dB
25-05-22 12:01:22.485 : --41--> commercial_area_111_00.jpg | 33.34dB
25-05-22 12:01:22.559 : --42--> commercial_area_111_01.jpg | 32.47dB
25-05-22 12:01:22.640 : --43--> commercial_area_111_10.jpg | 33.17dB
25-05-22 12:01:22.719 : --44--> commercial_area_111_11.jpg | 33.11dB
25-05-22 12:01:22.792 : --45--> dense_residential_111_00.jpg | 30.29dB
25-05-22 12:01:22.864 : --46--> dense_residential_111_01.jpg | 29.37dB
25-05-22 12:01:22.938 : --47--> dense_residential_111_10.jpg | 29.73dB
25-05-22 12:01:23.015 : --48--> dense_residential_111_11.jpg | 29.63dB
25-05-22 12:01:23.085 : --49--> desert_111_00.jpg | 36.58dB
25-05-22 12:01:23.159 : --50--> desert_111_01.jpg | 36.30dB
25-05-22 12:01:23.228 : --51--> desert_111_10.jpg | 36.58dB
25-05-22 12:01:23.297 : --52--> desert_111_11.jpg | 36.71dB
25-05-22 12:01:23.379 : --53--> forest_111_00.jpg | 33.00dB
25-05-22 12:01:23.468 : --54--> forest_111_01.jpg | 32.09dB
25-05-22 12:01:23.539 : --55--> forest_111_10.jpg | 31.77dB
25-05-22 12:01:23.615 : --56--> forest_111_11.jpg | 32.76dB
25-05-22 12:01:23.690 : --57--> freeway_111_00.jpg | 33.88dB
25-05-22 12:01:23.764 : --58--> freeway_111_01.jpg | 35.04dB
25-05-22 12:01:23.837 : --59--> freeway_111_10.jpg | 34.75dB
25-05-22 12:01:23.912 : --60--> freeway_111_11.jpg | 34.83dB
25-05-22 12:01:23.980 : --61--> golf_course_111_00.jpg | 32.78dB
25-05-22 12:01:24.052 : --62--> golf_course_111_01.jpg | 32.19dB
25-05-22 12:01:24.135 : --63--> golf_course_111_10.jpg | 33.54dB
25-05-22 12:01:24.211 : --64--> golf_course_111_11.jpg | 33.97dB
25-05-22 12:01:24.297 : --65--> ground_track_field_111_00.jpg | 33.43dB
25-05-22 12:01:24.372 : --66--> ground_track_field_111_01.jpg | 29.42dB
25-05-22 12:01:24.454 : --67--> ground_track_field_111_10.jpg | 30.84dB
25-05-22 12:01:24.520 : --68--> ground_track_field_111_11.jpg | 30.00dB
25-05-22 12:01:24.603 : --69--> harbor_111_00.jpg | 32.83dB
25-05-22 12:01:24.687 : --70--> harbor_111_01.jpg | 31.20dB
25-05-22 12:01:24.785 : --71--> harbor_111_10.jpg | 30.79dB
25-05-22 12:01:24.894 : --72--> harbor_111_11.jpg | 32.48dB
25-05-22 12:01:24.968 : --73--> industrial_area_111_00.jpg | 31.68dB
25-05-22 12:01:25.040 : --74--> industrial_area_111_01.jpg | 31.86dB
25-05-22 12:01:25.110 : --75--> industrial_area_111_10.jpg | 31.92dB
25-05-22 12:01:25.192 : --76--> industrial_area_111_11.jpg | 31.38dB
25-05-22 12:01:25.287 : --77--> intersection_111_00.jpg | 30.73dB
25-05-22 12:01:25.371 : --78--> intersection_111_01.jpg | 30.81dB
25-05-22 12:01:25.440 : --79--> intersection_111_10.jpg | 30.55dB
25-05-22 12:01:25.514 : --80--> intersection_111_11.jpg | 30.36dB
25-05-22 12:01:25.585 : --81--> island_111_00.jpg | 31.45dB
25-05-22 12:01:25.675 : --82--> island_111_01.jpg | 33.84dB
25-05-22 12:01:25.744 : --83--> island_111_10.jpg | 32.51dB
25-05-22 12:01:25.833 : --84--> island_111_11.jpg | 31.96dB
25-05-22 12:01:25.904 : --85--> lake_111_00.jpg | 32.51dB
25-05-22 12:01:25.985 : --86--> lake_111_01.jpg | 32.32dB
25-05-22 12:01:26.059 : --87--> lake_111_10.jpg | 31.67dB
25-05-22 12:01:26.128 : --88--> lake_111_11.jpg | 31.01dB
25-05-22 12:01:26.198 : --89--> meadow_111_00.jpg | 30.08dB
25-05-22 12:01:26.270 : --90--> meadow_111_01.jpg | 30.14dB
25-05-22 12:01:26.361 : --91--> meadow_111_10.jpg | 30.19dB
25-05-22 12:01:26.439 : --92--> meadow_111_11.jpg | 30.36dB
25-05-22 12:01:26.535 : --93--> medium_residential_111_00.jpg | 28.84dB
25-05-22 12:01:26.613 : --94--> medium_residential_111_01.jpg | 28.28dB
25-05-22 12:01:26.684 : --95--> medium_residential_111_10.jpg | 28.65dB
25-05-22 12:01:26.773 : --96--> medium_residential_111_11.jpg | 29.10dB
25-05-22 12:01:26.843 : --97--> mobile_home_park_111_00.jpg | 30.97dB
25-05-22 12:01:26.914 : --98--> mobile_home_park_111_01.jpg | 31.55dB
25-05-22 12:01:27.003 : --99--> mobile_home_park_111_10.jpg | 31.78dB
25-05-22 12:01:27.078 : -100--> mobile_home_park_111_11.jpg | 31.80dB
25-05-22 12:01:27.185 : -101--> mountain_111_00.jpg | 28.87dB
25-05-22 12:01:27.253 : -102--> mountain_111_01.jpg | 29.50dB
25-05-22 12:01:27.324 : -103--> mountain_111_10.jpg | 29.32dB
25-05-22 12:01:27.408 : -104--> mountain_111_11.jpg | 29.62dB
25-05-22 12:01:27.492 : -105--> overpass_111_00.jpg | 30.22dB
25-05-22 12:01:27.568 : -106--> overpass_111_01.jpg | 30.00dB
25-05-22 12:01:27.647 : -107--> overpass_111_10.jpg | 30.57dB
25-05-22 12:01:27.725 : -108--> overpass_111_11.jpg | 31.35dB
25-05-22 12:01:27.801 : -109--> palace_111_00.jpg | 30.05dB
25-05-22 12:01:27.879 : -110--> palace_111_01.jpg | 29.97dB
25-05-22 12:01:27.954 : -111--> palace_111_10.jpg | 31.00dB
25-05-22 12:01:28.027 : -112--> palace_111_11.jpg | 29.44dB
25-05-22 12:01:28.117 : -113--> parking_lot_111_00.jpg | 29.33dB
25-05-22 12:01:28.185 : -114--> parking_lot_111_01.jpg | 29.66dB
25-05-22 12:01:28.261 : -115--> parking_lot_111_10.jpg | 31.19dB
25-05-22 12:01:28.347 : -116--> parking_lot_111_11.jpg | 30.04dB
25-05-22 12:01:28.416 : -117--> railway_111_00.jpg | 30.20dB
25-05-22 12:01:28.509 : -118--> railway_111_01.jpg | 29.77dB
25-05-22 12:01:28.582 : -119--> railway_111_10.jpg | 32.50dB
25-05-22 12:01:28.669 : -120--> railway_111_11.jpg | 29.16dB
25-05-22 12:01:28.738 : -121--> railway_station_111_00.jpg | 30.99dB
25-05-22 12:01:28.823 : -122--> railway_station_111_01.jpg | 31.43dB
25-05-22 12:01:28.906 : -123--> railway_station_111_10.jpg | 31.12dB
25-05-22 12:01:28.979 : -124--> railway_station_111_11.jpg | 31.68dB
25-05-22 12:01:29.050 : -125--> rectangular_farmland_111_00.jpg | 33.49dB
25-05-22 12:01:29.118 : -126--> rectangular_farmland_111_01.jpg | 32.01dB
25-05-22 12:01:29.191 : -127--> rectangular_farmland_111_10.jpg | 33.82dB
25-05-22 12:01:29.263 : -128--> rectangular_farmland_111_11.jpg | 34.15dB
25-05-22 12:01:29.353 : -129--> river_111_00.jpg | 30.19dB
25-05-22 12:01:29.427 : -130--> river_111_01.jpg | 29.99dB
25-05-22 12:01:29.499 : -131--> river_111_10.jpg | 29.59dB
25-05-22 12:01:29.577 : -132--> river_111_11.jpg | 31.39dB
25-05-22 12:01:29.658 : -133--> roundabout_111_00.jpg | 30.55dB
25-05-22 12:01:29.726 : -134--> roundabout_111_01.jpg | 32.12dB
25-05-22 12:01:29.807 : -135--> roundabout_111_10.jpg | 30.41dB
25-05-22 12:01:29.880 : -136--> roundabout_111_11.jpg | 30.73dB
25-05-22 12:01:29.956 : -137--> runway_111_00.jpg | 36.50dB
25-05-22 12:01:30.037 : -138--> runway_111_01.jpg | 35.90dB
25-05-22 12:01:30.109 : -139--> runway_111_10.jpg | 36.59dB
25-05-22 12:01:30.187 : -140--> runway_111_11.jpg | 37.59dB
25-05-22 12:01:30.274 : -141--> sea_ice_111_00.jpg | 33.61dB
25-05-22 12:01:30.345 : -142--> sea_ice_111_01.jpg | 34.57dB
25-05-22 12:01:30.414 : -143--> sea_ice_111_10.jpg | 33.64dB
25-05-22 12:01:30.482 : -144--> sea_ice_111_11.jpg | 34.71dB
25-05-22 12:01:30.553 : -145--> ship_111_00.jpg | 38.75dB
25-05-22 12:01:30.633 : -146--> ship_111_01.jpg | 34.60dB
25-05-22 12:01:30.703 : -147--> ship_111_10.jpg | 42.70dB
25-05-22 12:01:30.787 : -148--> ship_111_11.jpg | 40.13dB
25-05-22 12:01:30.858 : -149--> snowberg_111_00.jpg | 34.19dB
25-05-22 12:01:30.928 : -150--> snowberg_111_01.jpg | 32.82dB
25-05-22 12:01:31.007 : -151--> snowberg_111_10.jpg | 32.01dB
25-05-22 12:01:31.075 : -152--> snowberg_111_11.jpg | 31.97dB
25-05-22 12:01:31.149 : -153--> sparse_residential_111_00.jpg | 30.51dB
25-05-22 12:01:31.232 : -154--> sparse_residential_111_01.jpg | 30.71dB
25-05-22 12:01:31.318 : -155--> sparse_residential_111_10.jpg | 29.82dB
25-05-22 12:01:31.385 : -156--> sparse_residential_111_11.jpg | 30.02dB
25-05-22 12:01:31.455 : -157--> stadium_111_00.jpg | 30.33dB
25-05-22 12:01:31.549 : -158--> stadium_111_01.jpg | 30.13dB
25-05-22 12:01:31.637 : -159--> stadium_111_10.jpg | 31.39dB
25-05-22 12:01:31.718 : -160--> stadium_111_11.jpg | 30.19dB
25-05-22 12:01:31.802 : -161--> storage_tank_111_00.jpg | 31.83dB
25-05-22 12:01:31.882 : -162--> storage_tank_111_01.jpg | 32.07dB
25-05-22 12:01:31.957 : -163--> storage_tank_111_10.jpg | 30.77dB
25-05-22 12:01:32.027 : -164--> storage_tank_111_11.jpg | 31.31dB
25-05-22 12:01:32.101 : -165--> tennis_court_111_00.jpg | 32.04dB
25-05-22 12:01:32.182 : -166--> tennis_court_111_01.jpg | 31.51dB
25-05-22 12:01:32.251 : -167--> tennis_court_111_10.jpg | 31.96dB
25-05-22 12:01:32.327 : -168--> tennis_court_111_11.jpg | 29.72dB
25-05-22 12:01:32.393 : -169--> terrace_111_00.jpg | 32.23dB
25-05-22 12:01:32.471 : -170--> terrace_111_01.jpg | 33.26dB
25-05-22 12:01:32.548 : -171--> terrace_111_10.jpg | 32.25dB
25-05-22 12:01:32.634 : -172--> terrace_111_11.jpg | 32.25dB
25-05-22 12:01:32.708 : -173--> thermal_power_station_111_00.jpg | 30.11dB
25-05-22 12:01:32.781 : -174--> thermal_power_station_111_01.jpg | 31.65dB
25-05-22 12:01:32.875 : -175--> thermal_power_station_111_10.jpg | 29.95dB
25-05-22 12:01:32.963 : -176--> thermal_power_station_111_11.jpg | 30.57dB
25-05-22 12:01:33.032 : -177--> wetland_111_00.jpg | 31.38dB
25-05-22 12:01:33.112 : -178--> wetland_111_01.jpg | 31.43dB
25-05-22 12:01:33.177 : -179--> wetland_111_10.jpg | 31.68dB
25-05-22 12:01:33.255 : -180--> wetland_111_11.jpg | 31.03dB
25-05-22 12:01:33.265 : <epoch:  0, iter:  20,000, Average PSNR : 32.19dB

25-05-22 12:33:37.635 : <epoch:  0, iter:  30,000, lr:2.500e-05> G_loss: 8.366e-05 
25-05-22 12:33:37.636 : Saving the model.
25-05-22 12:33:38.329 : ---1--> airplane_111_00.jpg | 30.63dB
25-05-22 12:33:38.403 : ---2--> airplane_111_01.jpg | 35.48dB
25-05-22 12:33:38.480 : ---3--> airplane_111_10.jpg | 32.91dB
25-05-22 12:33:38.561 : ---4--> airplane_111_11.jpg | 33.03dB
25-05-22 12:33:38.644 : ---5--> airport_111_00.jpg | 34.55dB
25-05-22 12:33:38.720 : ---6--> airport_111_01.jpg | 32.49dB
25-05-22 12:33:38.796 : ---7--> airport_111_10.jpg | 32.06dB
25-05-22 12:33:38.871 : ---8--> airport_111_11.jpg | 32.89dB
25-05-22 12:33:38.938 : ---9--> baseball_diamond_111_00.jpg | 32.75dB
25-05-22 12:33:39.010 : --10--> baseball_diamond_111_01.jpg | 34.35dB
25-05-22 12:33:39.083 : --11--> baseball_diamond_111_10.jpg | 32.61dB
25-05-22 12:33:39.177 : --12--> baseball_diamond_111_11.jpg | 35.47dB
25-05-22 12:33:39.258 : --13--> basketball_court_111_00.jpg | 30.56dB
25-05-22 12:33:39.334 : --14--> basketball_court_111_01.jpg | 30.20dB
25-05-22 12:33:39.427 : --15--> basketball_court_111_10.jpg | 33.55dB
25-05-22 12:33:39.499 : --16--> basketball_court_111_11.jpg | 31.68dB
25-05-22 12:33:39.574 : --17--> beach_111_00.jpg | 28.69dB
25-05-22 12:33:39.652 : --18--> beach_111_01.jpg | 31.86dB
25-05-22 12:33:39.739 : --19--> beach_111_10.jpg | 29.83dB
25-05-22 12:33:39.815 : --20--> beach_111_11.jpg | 34.49dB
25-05-22 12:33:39.896 : --21--> bridge_111_00.jpg | 40.74dB
25-05-22 12:33:39.972 : --22--> bridge_111_01.jpg | 34.37dB
25-05-22 12:33:40.057 : --23--> bridge_111_10.jpg | 33.26dB
25-05-22 12:33:40.145 : --24--> bridge_111_11.jpg | 36.84dB
25-05-22 12:33:40.226 : --25--> chaparral_111_00.jpg | 30.40dB
25-05-22 12:33:40.308 : --26--> chaparral_111_01.jpg | 30.56dB
25-05-22 12:33:40.388 : --27--> chaparral_111_10.jpg | 31.03dB
25-05-22 12:33:40.465 : --28--> chaparral_111_11.jpg | 28.65dB
25-05-22 12:33:40.541 : --29--> church_111_00.jpg | 31.76dB
25-05-22 12:33:40.617 : --30--> church_111_01.jpg | 30.71dB
25-05-22 12:33:40.689 : --31--> church_111_10.jpg | 34.47dB
25-05-22 12:33:40.762 : --32--> church_111_11.jpg | 30.60dB
25-05-22 12:33:40.833 : --33--> circular_farmland_111_00.jpg | 32.89dB
25-05-22 12:33:40.904 : --34--> circular_farmland_111_01.jpg | 33.91dB
25-05-22 12:33:40.984 : --35--> circular_farmland_111_10.jpg | 34.12dB
25-05-22 12:33:41.057 : --36--> circular_farmland_111_11.jpg | 34.14dB
25-05-22 12:33:41.132 : --37--> cloud_111_00.jpg | 40.33dB
25-05-22 12:33:41.216 : --38--> cloud_111_01.jpg | 36.66dB
25-05-22 12:33:41.295 : --39--> cloud_111_10.jpg | 36.32dB
25-05-22 12:33:41.375 : --40--> cloud_111_11.jpg | 36.84dB
25-05-22 12:33:41.444 : --41--> commercial_area_111_00.jpg | 33.33dB
25-05-22 12:33:41.520 : --42--> commercial_area_111_01.jpg | 32.41dB
25-05-22 12:33:41.601 : --43--> commercial_area_111_10.jpg | 33.17dB
25-05-22 12:33:41.676 : --44--> commercial_area_111_11.jpg | 33.07dB
25-05-22 12:33:41.754 : --45--> dense_residential_111_00.jpg | 30.20dB
25-05-22 12:33:41.832 : --46--> dense_residential_111_01.jpg | 29.39dB
25-05-22 12:33:41.922 : --47--> dense_residential_111_10.jpg | 29.81dB
25-05-22 12:33:41.996 : --48--> dense_residential_111_11.jpg | 29.55dB
25-05-22 12:33:42.077 : --49--> desert_111_00.jpg | 36.58dB
25-05-22 12:33:42.167 : --50--> desert_111_01.jpg | 36.44dB
25-05-22 12:33:42.236 : --51--> desert_111_10.jpg | 36.63dB
25-05-22 12:33:42.308 : --52--> desert_111_11.jpg | 36.72dB
25-05-22 12:33:42.387 : --53--> forest_111_00.jpg | 33.01dB
25-05-22 12:33:42.471 : --54--> forest_111_01.jpg | 32.08dB
25-05-22 12:33:42.548 : --55--> forest_111_10.jpg | 31.76dB
25-05-22 12:33:42.625 : --56--> forest_111_11.jpg | 32.72dB
25-05-22 12:33:42.700 : --57--> freeway_111_00.jpg | 33.87dB
25-05-22 12:33:42.775 : --58--> freeway_111_01.jpg | 35.01dB
25-05-22 12:33:42.855 : --59--> freeway_111_10.jpg | 34.66dB
25-05-22 12:33:42.941 : --60--> freeway_111_11.jpg | 34.81dB
25-05-22 12:33:43.025 : --61--> golf_course_111_00.jpg | 32.80dB
25-05-22 12:33:40.650 : --62--> golf_course_111_01.jpg | 32.17dB
25-05-22 12:33:40.729 : --63--> golf_course_111_10.jpg | 33.53dB
25-05-22 12:33:40.802 : --64--> golf_course_111_11.jpg | 33.94dB
25-05-22 12:33:40.879 : --65--> ground_track_field_111_00.jpg | 33.47dB
25-05-22 12:33:40.971 : --66--> ground_track_field_111_01.jpg | 29.44dB
25-05-22 12:33:41.049 : --67--> ground_track_field_111_10.jpg | 30.87dB
25-05-22 12:33:41.123 : --68--> ground_track_field_111_11.jpg | 29.95dB
25-05-22 12:33:41.202 : --69--> harbor_111_00.jpg | 32.91dB
25-05-22 12:33:41.274 : --70--> harbor_111_01.jpg | 31.27dB
25-05-22 12:33:41.351 : --71--> harbor_111_10.jpg | 30.76dB
25-05-22 12:33:41.440 : --72--> harbor_111_11.jpg | 32.53dB
25-05-22 12:33:41.508 : --73--> industrial_area_111_00.jpg | 31.65dB
25-05-22 12:33:41.579 : --74--> industrial_area_111_01.jpg | 31.82dB
25-05-22 12:33:41.659 : --75--> industrial_area_111_10.jpg | 32.09dB
25-05-22 12:33:41.745 : --76--> industrial_area_111_11.jpg | 31.48dB
25-05-22 12:33:41.838 : --77--> intersection_111_00.jpg | 30.79dB
25-05-22 12:33:41.914 : --78--> intersection_111_01.jpg | 30.78dB
25-05-22 12:33:41.992 : --79--> intersection_111_10.jpg | 30.50dB
25-05-22 12:33:42.065 : --80--> intersection_111_11.jpg | 30.34dB
25-05-22 12:33:42.131 : --81--> island_111_00.jpg | 31.34dB
25-05-22 12:33:42.201 : --82--> island_111_01.jpg | 33.88dB
25-05-22 12:33:42.280 : --83--> island_111_10.jpg | 32.56dB
25-05-22 12:33:42.358 : --84--> island_111_11.jpg | 31.98dB
25-05-22 12:33:42.436 : --85--> lake_111_00.jpg | 32.49dB
25-05-22 12:33:42.511 : --86--> lake_111_01.jpg | 32.32dB
25-05-22 12:33:42.585 : --87--> lake_111_10.jpg | 31.59dB
25-05-22 12:33:42.658 : --88--> lake_111_11.jpg | 31.00dB
25-05-22 12:33:42.729 : --89--> meadow_111_00.jpg | 29.97dB
25-05-22 12:33:42.810 : --90--> meadow_111_01.jpg | 30.02dB
25-05-22 12:33:42.894 : --91--> meadow_111_10.jpg | 30.09dB
25-05-22 12:33:42.963 : --92--> meadow_111_11.jpg | 30.22dB
25-05-22 12:33:43.034 : --93--> medium_residential_111_00.jpg | 28.86dB
25-05-22 12:33:43.110 : --94--> medium_residential_111_01.jpg | 28.18dB
25-05-22 12:33:43.193 : --95--> medium_residential_111_10.jpg | 28.54dB
25-05-22 12:33:43.265 : --96--> medium_residential_111_11.jpg | 29.19dB
25-05-22 12:33:43.344 : --97--> mobile_home_park_111_00.jpg | 31.03dB
25-05-22 12:33:43.415 : --98--> mobile_home_park_111_01.jpg | 31.55dB
25-05-22 12:33:43.486 : --99--> mobile_home_park_111_10.jpg | 31.82dB
25-05-22 12:33:43.554 : -100--> mobile_home_park_111_11.jpg | 31.88dB
25-05-22 12:33:43.632 : -101--> mountain_111_00.jpg | 28.93dB
25-05-22 12:33:43.709 : -102--> mountain_111_01.jpg | 29.62dB
25-05-22 12:33:43.781 : -103--> mountain_111_10.jpg | 29.37dB
25-05-22 12:33:43.857 : -104--> mountain_111_11.jpg | 29.69dB
25-05-22 12:33:43.926 : -105--> overpass_111_00.jpg | 30.28dB
25-05-22 12:33:44.013 : -106--> overpass_111_01.jpg | 30.03dB
25-05-22 12:33:44.095 : -107--> overpass_111_10.jpg | 30.64dB
25-05-22 12:33:44.162 : -108--> overpass_111_11.jpg | 31.37dB
25-05-22 12:33:44.239 : -109--> palace_111_00.jpg | 30.11dB
25-05-22 12:33:44.325 : -110--> palace_111_01.jpg | 29.97dB
25-05-22 12:33:44.393 : -111--> palace_111_10.jpg | 30.97dB
25-05-22 12:33:44.498 : -112--> palace_111_11.jpg | 29.45dB
25-05-22 12:33:44.569 : -113--> parking_lot_111_00.jpg | 29.41dB
25-05-22 12:33:44.645 : -114--> parking_lot_111_01.jpg | 29.70dB
25-05-22 12:33:44.713 : -115--> parking_lot_111_10.jpg | 31.24dB
25-05-22 12:33:44.784 : -116--> parking_lot_111_11.jpg | 30.03dB
25-05-22 12:33:44.857 : -117--> railway_111_00.jpg | 30.24dB
25-05-22 12:33:44.925 : -118--> railway_111_01.jpg | 29.78dB
25-05-22 12:33:44.999 : -119--> railway_111_10.jpg | 32.55dB
25-05-22 12:33:45.078 : -120--> railway_111_11.jpg | 29.19dB
25-05-22 12:33:45.172 : -121--> railway_station_111_00.jpg | 30.99dB
25-05-22 12:33:45.245 : -122--> railway_station_111_01.jpg | 31.45dB
25-05-22 12:33:45.321 : -123--> railway_station_111_10.jpg | 31.06dB
25-05-22 12:33:45.408 : -124--> railway_station_111_11.jpg | 31.60dB
25-05-22 12:33:45.478 : -125--> rectangular_farmland_111_00.jpg | 33.51dB
25-05-22 12:33:45.552 : -126--> rectangular_farmland_111_01.jpg | 31.98dB
25-05-22 12:33:45.643 : -127--> rectangular_farmland_111_10.jpg | 33.87dB
25-05-22 12:33:45.732 : -128--> rectangular_farmland_111_11.jpg | 34.18dB
25-05-22 12:33:45.802 : -129--> river_111_00.jpg | 30.18dB
25-05-22 12:33:45.877 : -130--> river_111_01.jpg | 29.99dB
25-05-22 12:33:45.944 : -131--> river_111_10.jpg | 29.57dB
25-05-22 12:33:46.015 : -132--> river_111_11.jpg | 31.35dB
25-05-22 12:33:46.084 : -133--> roundabout_111_00.jpg | 30.56dB
25-05-22 12:33:46.156 : -134--> roundabout_111_01.jpg | 32.20dB
25-05-22 12:33:46.230 : -135--> roundabout_111_10.jpg | 30.40dB
25-05-22 12:33:46.302 : -136--> roundabout_111_11.jpg | 30.80dB
25-05-22 12:33:46.388 : -137--> runway_111_00.jpg | 36.53dB
25-05-22 12:33:46.485 : -138--> runway_111_01.jpg | 35.90dB
25-05-22 12:33:46.556 : -139--> runway_111_10.jpg | 36.59dB
25-05-22 12:33:46.627 : -140--> runway_111_11.jpg | 37.61dB
25-05-22 12:33:46.709 : -141--> sea_ice_111_00.jpg | 33.54dB
25-05-22 12:33:46.787 : -142--> sea_ice_111_01.jpg | 34.62dB
25-05-22 12:33:46.862 : -143--> sea_ice_111_10.jpg | 33.66dB
25-05-22 12:33:46.954 : -144--> sea_ice_111_11.jpg | 34.68dB
25-05-22 12:33:47.050 : -145--> ship_111_00.jpg | 38.78dB
25-05-22 12:33:47.126 : -146--> ship_111_01.jpg | 34.60dB
25-05-22 12:33:47.210 : -147--> ship_111_10.jpg | 42.61dB
25-05-22 12:33:47.284 : -148--> ship_111_11.jpg | 40.13dB
25-05-22 12:33:47.360 : -149--> snowberg_111_00.jpg | 34.23dB
25-05-22 12:33:47.429 : -150--> snowberg_111_01.jpg | 32.76dB
25-05-22 12:33:47.508 : -151--> snowberg_111_10.jpg | 31.95dB
25-05-22 12:33:47.582 : -152--> snowberg_111_11.jpg | 31.99dB
25-05-22 12:33:47.679 : -153--> sparse_residential_111_00.jpg | 30.50dB
25-05-22 12:33:47.763 : -154--> sparse_residential_111_01.jpg | 30.72dB
25-05-22 12:33:47.840 : -155--> sparse_residential_111_10.jpg | 29.71dB
25-05-22 12:33:47.933 : -156--> sparse_residential_111_11.jpg | 30.01dB
25-05-22 12:33:48.015 : -157--> stadium_111_00.jpg | 30.37dB
25-05-22 12:33:48.109 : -158--> stadium_111_01.jpg | 30.08dB
25-05-22 12:33:48.186 : -159--> stadium_111_10.jpg | 31.40dB
25-05-22 12:33:48.254 : -160--> stadium_111_11.jpg | 30.17dB
25-05-22 12:33:48.329 : -161--> storage_tank_111_00.jpg | 31.79dB
25-05-22 12:33:48.406 : -162--> storage_tank_111_01.jpg | 32.06dB
25-05-22 12:33:48.489 : -163--> storage_tank_111_10.jpg | 30.79dB
25-05-22 12:33:48.562 : -164--> storage_tank_111_11.jpg | 31.31dB
25-05-22 12:33:48.636 : -165--> tennis_court_111_00.jpg | 32.15dB
25-05-22 12:33:48.709 : -166--> tennis_court_111_01.jpg | 31.58dB
25-05-22 12:33:48.791 : -167--> tennis_court_111_10.jpg | 32.02dB
25-05-22 12:33:48.863 : -168--> tennis_court_111_11.jpg | 29.71dB
25-05-22 12:33:48.933 : -169--> terrace_111_00.jpg | 32.25dB
25-05-22 12:33:49.010 : -170--> terrace_111_01.jpg | 33.29dB
25-05-22 12:33:49.083 : -171--> terrace_111_10.jpg | 32.28dB
25-05-22 12:33:49.168 : -172--> terrace_111_11.jpg | 32.27dB
25-05-22 12:33:49.240 : -173--> thermal_power_station_111_00.jpg | 30.07dB
25-05-22 12:33:49.314 : -174--> thermal_power_station_111_01.jpg | 31.64dB
25-05-22 12:33:49.402 : -175--> thermal_power_station_111_10.jpg | 29.92dB
25-05-22 12:33:49.472 : -176--> thermal_power_station_111_11.jpg | 30.43dB
25-05-22 12:33:49.544 : -177--> wetland_111_00.jpg | 31.35dB
25-05-22 12:33:49.619 : -178--> wetland_111_01.jpg | 31.41dB
25-05-22 12:33:49.688 : -179--> wetland_111_10.jpg | 31.68dB
25-05-22 12:33:49.769 : -180--> wetland_111_11.jpg | 31.00dB
25-05-22 12:33:49.778 : <epoch:  0, iter:  30,000, Average PSNR : 32.19dB

25-05-22 13:06:27.664 : <epoch:  1, iter:  40,000, lr:5.000e-05> G_loss: 2.197e-05 
25-05-22 13:06:27.665 : Saving the model.
25-05-22 13:06:28.378 : ---1--> airplane_111_00.jpg | 30.67dB
25-05-22 13:06:28.461 : ---2--> airplane_111_01.jpg | 35.43dB
25-05-22 13:06:28.540 : ---3--> airplane_111_10.jpg | 33.02dB
25-05-22 13:06:28.633 : ---4--> airplane_111_11.jpg | 33.13dB
25-05-22 13:06:28.701 : ---5--> airport_111_00.jpg | 34.63dB
25-05-22 13:06:28.772 : ---6--> airport_111_01.jpg | 32.55dB
25-05-22 13:06:28.855 : ---7--> airport_111_10.jpg | 32.10dB
25-05-22 13:06:28.939 : ---8--> airport_111_11.jpg | 32.98dB
25-05-22 13:06:29.010 : ---9--> baseball_diamond_111_00.jpg | 32.84dB
25-05-22 13:06:29.084 : --10--> baseball_diamond_111_01.jpg | 34.45dB
25-05-22 13:06:29.170 : --11--> baseball_diamond_111_10.jpg | 32.72dB
25-05-22 13:06:29.253 : --12--> baseball_diamond_111_11.jpg | 35.55dB
25-05-22 13:06:29.332 : --13--> basketball_court_111_00.jpg | 30.63dB
25-05-22 13:06:29.406 : --14--> basketball_court_111_01.jpg | 30.24dB
25-05-22 13:06:29.493 : --15--> basketball_court_111_10.jpg | 33.64dB
25-05-22 13:06:29.586 : --16--> basketball_court_111_11.jpg | 31.69dB
25-05-22 13:06:29.664 : --17--> beach_111_00.jpg | 28.78dB
25-05-22 13:06:29.743 : --18--> beach_111_01.jpg | 31.92dB
25-05-22 13:06:29.819 : --19--> beach_111_10.jpg | 29.90dB
25-05-22 13:06:29.898 : --20--> beach_111_11.jpg | 34.57dB
25-05-22 13:06:29.970 : --21--> bridge_111_00.jpg | 40.95dB
25-05-22 13:06:30.047 : --22--> bridge_111_01.jpg | 34.41dB
25-05-22 13:06:30.127 : --23--> bridge_111_10.jpg | 33.43dB
25-05-22 13:06:30.209 : --24--> bridge_111_11.jpg | 36.92dB
25-05-22 13:06:30.302 : --25--> chaparral_111_00.jpg | 30.48dB
25-05-22 13:06:30.413 : --26--> chaparral_111_01.jpg | 30.62dB
25-05-22 13:06:30.501 : --27--> chaparral_111_10.jpg | 30.96dB
25-05-22 13:06:30.576 : --28--> chaparral_111_11.jpg | 28.81dB
25-05-22 13:06:30.656 : --29--> church_111_00.jpg | 31.84dB
25-05-22 13:06:30.726 : --30--> church_111_01.jpg | 30.84dB
25-05-22 13:06:30.806 : --31--> church_111_10.jpg | 34.50dB
25-05-22 13:06:30.884 : --32--> church_111_11.jpg | 30.68dB
25-05-22 13:06:30.955 : --33--> circular_farmland_111_00.jpg | 33.00dB
25-05-22 13:06:31.051 : --34--> circular_farmland_111_01.jpg | 33.98dB
25-05-22 13:06:31.135 : --35--> circular_farmland_111_10.jpg | 34.18dB
25-05-22 13:06:31.219 : --36--> circular_farmland_111_11.jpg | 34.20dB
25-05-22 13:06:31.314 : --37--> cloud_111_00.jpg | 41.01dB
25-05-22 13:06:31.387 : --38--> cloud_111_01.jpg | 36.78dB
25-05-22 13:06:31.463 : --39--> cloud_111_10.jpg | 36.37dB
25-05-22 13:06:31.538 : --40--> cloud_111_11.jpg | 36.94dB
25-05-22 13:06:31.609 : --41--> commercial_area_111_00.jpg | 33.37dB
25-05-22 13:06:31.712 : --42--> commercial_area_111_01.jpg | 32.51dB
25-05-22 13:06:31.789 : --43--> commercial_area_111_10.jpg | 33.23dB
25-05-22 13:06:31.867 : --44--> commercial_area_111_11.jpg | 33.17dB
25-05-22 13:06:31.959 : --45--> dense_residential_111_00.jpg | 30.40dB
25-05-22 13:06:32.041 : --46--> dense_residential_111_01.jpg | 29.43dB
25-05-22 13:06:32.125 : --47--> dense_residential_111_10.jpg | 29.89dB
25-05-22 13:06:32.207 : --48--> dense_residential_111_11.jpg | 29.72dB
25-05-22 13:06:32.281 : --49--> desert_111_00.jpg | 36.72dB
25-05-22 13:06:32.371 : --50--> desert_111_01.jpg | 36.53dB
25-05-22 13:06:32.453 : --51--> desert_111_10.jpg | 36.77dB
25-05-22 13:06:32.546 : --52--> desert_111_11.jpg | 36.86dB
25-05-22 13:06:32.635 : --53--> forest_111_00.jpg | 33.01dB
25-05-22 13:06:32.708 : --54--> forest_111_01.jpg | 32.12dB
25-05-22 13:06:32.790 : --55--> forest_111_10.jpg | 31.81dB
25-05-22 13:06:32.875 : --56--> forest_111_11.jpg | 32.77dB
25-05-22 13:06:32.956 : --57--> freeway_111_00.jpg | 33.96dB
25-05-22 13:06:33.047 : --58--> freeway_111_01.jpg | 35.23dB
25-05-22 13:06:33.125 : --59--> freeway_111_10.jpg | 34.94dB
25-05-22 13:06:33.208 : --60--> freeway_111_11.jpg | 34.91dB
25-05-22 13:06:33.290 : --61--> golf_course_111_00.jpg | 32.86dB
25-05-22 13:06:33.373 : --62--> golf_course_111_01.jpg | 32.25dB
25-05-22 13:06:33.454 : --63--> golf_course_111_10.jpg | 33.62dB
25-05-22 13:06:33.539 : --64--> golf_course_111_11.jpg | 34.00dB
25-05-22 13:06:33.615 : --65--> ground_track_field_111_00.jpg | 33.57dB
25-05-22 13:06:33.691 : --66--> ground_track_field_111_01.jpg | 29.50dB
25-05-22 13:06:33.776 : --67--> ground_track_field_111_10.jpg | 30.91dB
25-05-22 13:06:33.873 : --68--> ground_track_field_111_11.jpg | 30.07dB
25-05-22 13:06:33.964 : --69--> harbor_111_00.jpg | 32.97dB
25-05-22 13:06:34.041 : --70--> harbor_111_01.jpg | 31.32dB
25-05-22 13:06:34.132 : --71--> harbor_111_10.jpg | 30.87dB
25-05-22 13:06:34.216 : --72--> harbor_111_11.jpg | 32.58dB
25-05-22 13:06:34.309 : --73--> industrial_area_111_00.jpg | 31.77dB
25-05-22 13:06:34.397 : --74--> industrial_area_111_01.jpg | 32.00dB
25-05-22 13:06:34.494 : --75--> industrial_area_111_10.jpg | 32.15dB
25-05-22 13:06:34.565 : --76--> industrial_area_111_11.jpg | 31.59dB
25-05-22 13:06:34.637 : --77--> intersection_111_00.jpg | 30.83dB
25-05-22 13:06:34.707 : --78--> intersection_111_01.jpg | 30.90dB
25-05-22 13:06:34.788 : --79--> intersection_111_10.jpg | 30.63dB
25-05-22 13:06:34.873 : --80--> intersection_111_11.jpg | 30.42dB
25-05-22 13:06:34.943 : --81--> island_111_00.jpg | 31.50dB
25-05-22 13:06:35.022 : --82--> island_111_01.jpg | 33.89dB
25-05-22 13:06:35.102 : --83--> island_111_10.jpg | 32.63dB
25-05-22 13:06:35.178 : --84--> island_111_11.jpg | 32.03dB
25-05-22 13:06:35.252 : --85--> lake_111_00.jpg | 32.55dB
25-05-22 13:06:35.326 : --86--> lake_111_01.jpg | 32.34dB
25-05-22 13:06:35.411 : --87--> lake_111_10.jpg | 31.67dB
25-05-22 13:06:35.491 : --88--> lake_111_11.jpg | 31.04dB
25-05-22 13:06:35.582 : --89--> meadow_111_00.jpg | 30.10dB
25-05-22 13:06:35.653 : --90--> meadow_111_01.jpg | 30.06dB
25-05-22 13:06:35.723 : --91--> meadow_111_10.jpg | 30.24dB
25-05-22 13:06:35.809 : --92--> meadow_111_11.jpg | 30.37dB
25-05-22 13:06:35.902 : --93--> medium_residential_111_00.jpg | 28.90dB
25-05-22 13:06:35.982 : --94--> medium_residential_111_01.jpg | 28.35dB
25-05-22 13:06:36.061 : --95--> medium_residential_111_10.jpg | 28.71dB
25-05-22 13:06:36.137 : --96--> medium_residential_111_11.jpg | 29.25dB
25-05-22 13:06:36.209 : --97--> mobile_home_park_111_00.jpg | 31.10dB
25-05-22 13:06:36.285 : --98--> mobile_home_park_111_01.jpg | 31.63dB
25-05-22 13:06:36.362 : --99--> mobile_home_park_111_10.jpg | 31.89dB
25-05-22 13:06:36.444 : -100--> mobile_home_park_111_11.jpg | 31.90dB
25-05-22 13:06:36.528 : -101--> mountain_111_00.jpg | 28.95dB
25-05-22 13:06:36.595 : -102--> mountain_111_01.jpg | 29.67dB
25-05-22 13:06:36.666 : -103--> mountain_111_10.jpg | 29.38dB
25-05-22 13:06:36.745 : -104--> mountain_111_11.jpg | 29.74dB
25-05-22 13:06:36.813 : -105--> overpass_111_00.jpg | 30.34dB
25-05-22 13:06:36.884 : -106--> overpass_111_01.jpg | 30.06dB
25-05-22 13:06:36.955 : -107--> overpass_111_10.jpg | 30.69dB
25-05-22 13:06:37.050 : -108--> overpass_111_11.jpg | 31.43dB
25-05-22 13:06:37.121 : -109--> palace_111_00.jpg | 30.15dB
25-05-22 13:06:37.198 : -110--> palace_111_01.jpg | 30.01dB
25-05-22 13:06:37.275 : -111--> palace_111_10.jpg | 31.07dB
25-05-22 13:06:37.363 : -112--> palace_111_11.jpg | 29.49dB
25-05-22 13:06:37.444 : -113--> parking_lot_111_00.jpg | 29.46dB
25-05-22 13:06:37.517 : -114--> parking_lot_111_01.jpg | 29.76dB
25-05-22 13:06:37.595 : -115--> parking_lot_111_10.jpg | 31.31dB
25-05-22 13:06:37.669 : -116--> parking_lot_111_11.jpg | 30.13dB
25-05-22 13:06:37.740 : -117--> railway_111_00.jpg | 30.24dB
25-05-22 13:06:37.819 : -118--> railway_111_01.jpg | 29.83dB
25-05-22 13:06:37.893 : -119--> railway_111_10.jpg | 32.59dB
25-05-22 13:06:37.960 : -120--> railway_111_11.jpg | 29.27dB
25-05-22 13:06:38.065 : -121--> railway_station_111_00.jpg | 31.04dB
25-05-22 13:06:38.138 : -122--> railway_station_111_01.jpg | 31.52dB
25-05-22 13:06:38.213 : -123--> railway_station_111_10.jpg | 31.15dB
25-05-22 13:06:38.288 : -124--> railway_station_111_11.jpg | 31.68dB
25-05-22 13:06:38.366 : -125--> rectangular_farmland_111_00.jpg | 33.51dB
25-05-22 13:06:38.441 : -126--> rectangular_farmland_111_01.jpg | 32.07dB
25-05-22 13:06:38.528 : -127--> rectangular_farmland_111_10.jpg | 33.91dB
25-05-22 13:06:38.604 : -128--> rectangular_farmland_111_11.jpg | 34.23dB
25-05-22 13:06:38.677 : -129--> river_111_00.jpg | 30.27dB
25-05-22 13:06:38.754 : -130--> river_111_01.jpg | 30.05dB
25-05-22 13:06:38.844 : -131--> river_111_10.jpg | 29.66dB
25-05-22 13:06:38.924 : -132--> river_111_11.jpg | 31.42dB
25-05-22 13:06:39.001 : -133--> roundabout_111_00.jpg | 30.61dB
25-05-22 13:06:39.089 : -134--> roundabout_111_01.jpg | 32.20dB
25-05-22 13:06:39.169 : -135--> roundabout_111_10.jpg | 30.43dB
25-05-22 13:06:39.241 : -136--> roundabout_111_11.jpg | 30.93dB
25-05-22 13:06:39.317 : -137--> runway_111_00.jpg | 36.64dB
25-05-22 13:06:39.393 : -138--> runway_111_01.jpg | 35.98dB
25-05-22 13:06:39.472 : -139--> runway_111_10.jpg | 36.64dB
25-05-22 13:06:39.556 : -140--> runway_111_11.jpg | 37.65dB
25-05-22 13:06:39.626 : -141--> sea_ice_111_00.jpg | 33.71dB
25-05-22 13:06:39.701 : -142--> sea_ice_111_01.jpg | 34.67dB
25-05-22 13:06:39.776 : -143--> sea_ice_111_10.jpg | 33.78dB
25-05-22 13:06:39.871 : -144--> sea_ice_111_11.jpg | 34.80dB
25-05-22 13:06:39.952 : -145--> ship_111_00.jpg | 38.81dB
25-05-22 13:06:40.023 : -146--> ship_111_01.jpg | 34.62dB
25-05-22 13:06:40.097 : -147--> ship_111_10.jpg | 42.77dB
25-05-22 13:06:40.166 : -148--> ship_111_11.jpg | 40.22dB
25-05-22 13:06:40.235 : -149--> snowberg_111_00.jpg | 34.27dB
25-05-22 13:06:40.327 : -150--> snowberg_111_01.jpg | 32.93dB
25-05-22 13:06:40.401 : -151--> snowberg_111_10.jpg | 32.02dB
25-05-22 13:06:40.478 : -152--> snowberg_111_11.jpg | 32.10dB
25-05-22 13:06:40.562 : -153--> sparse_residential_111_00.jpg | 30.60dB
25-05-22 13:06:40.657 : -154--> sparse_residential_111_01.jpg | 30.77dB
25-05-22 13:06:40.731 : -155--> sparse_residential_111_10.jpg | 29.86dB
25-05-22 13:06:40.803 : -156--> sparse_residential_111_11.jpg | 30.09dB
25-05-22 13:06:40.907 : -157--> stadium_111_00.jpg | 30.43dB
25-05-22 13:06:41.016 : -158--> stadium_111_01.jpg | 30.20dB
25-05-22 13:06:41.091 : -159--> stadium_111_10.jpg | 31.47dB
25-05-22 13:06:41.171 : -160--> stadium_111_11.jpg | 30.30dB
25-05-22 13:06:41.244 : -161--> storage_tank_111_00.jpg | 31.91dB
25-05-22 13:06:41.321 : -162--> storage_tank_111_01.jpg | 32.13dB
25-05-22 13:06:41.414 : -163--> storage_tank_111_10.jpg | 30.86dB
25-05-22 13:06:41.494 : -164--> storage_tank_111_11.jpg | 31.41dB
25-05-22 13:06:41.582 : -165--> tennis_court_111_00.jpg | 32.23dB
25-05-22 13:06:41.663 : -166--> tennis_court_111_01.jpg | 31.64dB
25-05-22 13:06:41.736 : -167--> tennis_court_111_10.jpg | 32.07dB
25-05-22 13:06:41.834 : -168--> tennis_court_111_11.jpg | 29.73dB
25-05-22 13:06:41.916 : -169--> terrace_111_00.jpg | 32.34dB
25-05-22 13:06:41.999 : -170--> terrace_111_01.jpg | 33.43dB
25-05-22 13:06:42.085 : -171--> terrace_111_10.jpg | 32.33dB
25-05-22 13:06:42.163 : -172--> terrace_111_11.jpg | 32.36dB
25-05-22 13:06:42.251 : -173--> thermal_power_station_111_00.jpg | 30.18dB
25-05-22 13:06:42.322 : -174--> thermal_power_station_111_01.jpg | 31.73dB
25-05-22 13:06:39.884 : -175--> thermal_power_station_111_10.jpg | 30.01dB
25-05-22 13:06:39.955 : -176--> thermal_power_station_111_11.jpg | 30.62dB
25-05-22 13:06:40.025 : -177--> wetland_111_00.jpg | 31.44dB
25-05-22 13:06:40.115 : -178--> wetland_111_01.jpg | 31.49dB
25-05-22 13:06:40.196 : -179--> wetland_111_10.jpg | 31.72dB
25-05-22 13:06:40.271 : -180--> wetland_111_11.jpg | 31.06dB
25-05-22 13:06:40.281 : <epoch:  1, iter:  40,000, Average PSNR : 32.27dB

25-05-22 13:38:44.252 : <epoch:  1, iter:  50,000, lr:1.250e-05> G_loss: 7.927e-05 
25-05-22 13:38:44.253 : Saving the model.
25-05-22 13:38:44.960 : ---1--> airplane_111_00.jpg | 30.70dB
25-05-22 13:38:45.032 : ---2--> airplane_111_01.jpg | 35.52dB
25-05-22 13:38:45.110 : ---3--> airplane_111_10.jpg | 32.97dB
25-05-22 13:38:45.175 : ---4--> airplane_111_11.jpg | 33.06dB
25-05-22 13:38:45.253 : ---5--> airport_111_00.jpg | 34.62dB
25-05-22 13:38:45.328 : ---6--> airport_111_01.jpg | 32.55dB
25-05-22 13:38:45.406 : ---7--> airport_111_10.jpg | 32.11dB
25-05-22 13:38:45.485 : ---8--> airport_111_11.jpg | 32.98dB
25-05-22 13:38:45.553 : ---9--> baseball_diamond_111_00.jpg | 32.83dB
25-05-22 13:38:45.628 : --10--> baseball_diamond_111_01.jpg | 34.45dB
25-05-22 13:38:45.700 : --11--> baseball_diamond_111_10.jpg | 32.69dB
25-05-22 13:38:45.778 : --12--> baseball_diamond_111_11.jpg | 35.55dB
25-05-22 13:38:45.848 : --13--> basketball_court_111_00.jpg | 30.65dB
25-05-22 13:38:45.925 : --14--> basketball_court_111_01.jpg | 30.24dB
25-05-22 13:38:46.009 : --15--> basketball_court_111_10.jpg | 33.63dB
25-05-22 13:38:46.077 : --16--> basketball_court_111_11.jpg | 31.70dB
25-05-22 13:38:46.156 : --17--> beach_111_00.jpg | 28.77dB
25-05-22 13:38:46.239 : --18--> beach_111_01.jpg | 31.91dB
25-05-22 13:38:46.312 : --19--> beach_111_10.jpg | 29.88dB
25-05-22 13:38:46.394 : --20--> beach_111_11.jpg | 34.57dB
25-05-22 13:38:46.464 : --21--> bridge_111_00.jpg | 40.88dB
25-05-22 13:38:46.561 : --22--> bridge_111_01.jpg | 34.46dB
25-05-22 13:38:46.634 : --23--> bridge_111_10.jpg | 33.42dB
25-05-22 13:38:46.705 : --24--> bridge_111_11.jpg | 36.95dB
25-05-22 13:38:46.792 : --25--> chaparral_111_00.jpg | 30.48dB
25-05-22 13:38:46.879 : --26--> chaparral_111_01.jpg | 30.72dB
25-05-22 13:38:46.961 : --27--> chaparral_111_10.jpg | 30.94dB
25-05-22 13:38:47.034 : --28--> chaparral_111_11.jpg | 28.87dB
25-05-22 13:38:47.142 : --29--> church_111_00.jpg | 31.83dB
25-05-22 13:38:47.211 : --30--> church_111_01.jpg | 30.83dB
25-05-22 13:38:47.282 : --31--> church_111_10.jpg | 34.51dB
25-05-22 13:38:47.361 : --32--> church_111_11.jpg | 30.65dB
25-05-22 13:38:47.429 : --33--> circular_farmland_111_00.jpg | 32.99dB
25-05-22 13:38:47.537 : --34--> circular_farmland_111_01.jpg | 33.98dB
25-05-22 13:38:47.615 : --35--> circular_farmland_111_10.jpg | 34.22dB
25-05-22 13:38:47.682 : --36--> circular_farmland_111_11.jpg | 34.24dB
25-05-22 13:38:47.767 : --37--> cloud_111_00.jpg | 41.17dB
25-05-22 13:38:47.846 : --38--> cloud_111_01.jpg | 36.84dB
25-05-22 13:38:47.943 : --39--> cloud_111_10.jpg | 36.43dB
25-05-22 13:38:48.019 : --40--> cloud_111_11.jpg | 36.95dB
25-05-22 13:38:48.098 : --41--> commercial_area_111_00.jpg | 33.38dB
25-05-22 13:38:48.189 : --42--> commercial_area_111_01.jpg | 32.51dB
25-05-22 13:38:48.264 : --43--> commercial_area_111_10.jpg | 33.26dB
25-05-22 13:38:48.351 : --44--> commercial_area_111_11.jpg | 33.17dB
25-05-22 13:38:48.437 : --45--> dense_residential_111_00.jpg | 30.37dB
25-05-22 13:38:48.537 : --46--> dense_residential_111_01.jpg | 29.42dB
25-05-22 13:38:48.617 : --47--> dense_residential_111_10.jpg | 29.88dB
25-05-22 13:38:48.700 : --48--> dense_residential_111_11.jpg | 29.72dB
25-05-22 13:38:48.793 : --49--> desert_111_00.jpg | 36.74dB
25-05-22 13:38:48.887 : --50--> desert_111_01.jpg | 36.61dB
25-05-22 13:38:48.957 : --51--> desert_111_10.jpg | 36.81dB
25-05-22 13:38:49.045 : --52--> desert_111_11.jpg | 36.91dB
25-05-22 13:38:49.126 : --53--> forest_111_00.jpg | 33.03dB
25-05-22 13:38:49.221 : --54--> forest_111_01.jpg | 32.17dB
25-05-22 13:38:49.294 : --55--> forest_111_10.jpg | 31.81dB
25-05-22 13:38:49.382 : --56--> forest_111_11.jpg | 32.78dB
25-05-22 13:38:49.460 : --57--> freeway_111_00.jpg | 33.93dB
25-05-22 13:38:49.549 : --58--> freeway_111_01.jpg | 35.15dB
25-05-22 13:38:49.619 : --59--> freeway_111_10.jpg | 34.90dB
25-05-22 13:38:49.692 : --60--> freeway_111_11.jpg | 34.91dB
25-05-22 13:38:49.777 : --61--> golf_course_111_00.jpg | 32.84dB
25-05-22 13:38:49.844 : --62--> golf_course_111_01.jpg | 32.25dB
25-05-22 13:38:49.917 : --63--> golf_course_111_10.jpg | 33.63dB
25-05-22 13:38:49.995 : --64--> golf_course_111_11.jpg | 34.03dB
25-05-22 13:38:50.074 : --65--> ground_track_field_111_00.jpg | 33.53dB
25-05-22 13:38:50.173 : --66--> ground_track_field_111_01.jpg | 29.48dB
25-05-22 13:38:50.249 : --67--> ground_track_field_111_10.jpg | 30.92dB
25-05-22 13:38:50.320 : --68--> ground_track_field_111_11.jpg | 30.06dB
25-05-22 13:38:50.396 : --69--> harbor_111_00.jpg | 32.96dB
25-05-22 13:38:50.474 : --70--> harbor_111_01.jpg | 31.32dB
25-05-22 13:38:50.550 : --71--> harbor_111_10.jpg | 30.88dB
25-05-22 13:38:50.635 : --72--> harbor_111_11.jpg | 32.59dB
25-05-22 13:38:50.714 : --73--> industrial_area_111_00.jpg | 31.75dB
25-05-22 13:38:50.801 : --74--> industrial_area_111_01.jpg | 31.98dB
25-05-22 13:38:50.895 : --75--> industrial_area_111_10.jpg | 32.15dB
25-05-22 13:38:50.968 : --76--> industrial_area_111_11.jpg | 31.57dB
25-05-22 13:38:51.053 : --77--> intersection_111_00.jpg | 30.81dB
25-05-22 13:38:51.140 : --78--> intersection_111_01.jpg | 30.90dB
25-05-22 13:38:51.230 : --79--> intersection_111_10.jpg | 30.64dB
25-05-22 13:38:51.304 : --80--> intersection_111_11.jpg | 30.43dB
25-05-22 13:38:51.392 : --81--> island_111_00.jpg | 31.56dB
25-05-22 13:38:51.475 : --82--> island_111_01.jpg | 33.92dB
25-05-22 13:38:51.558 : --83--> island_111_10.jpg | 32.65dB
25-05-22 13:38:51.629 : --84--> island_111_11.jpg | 32.11dB
25-05-22 13:38:51.719 : --85--> lake_111_00.jpg | 32.55dB
25-05-22 13:38:51.817 : --86--> lake_111_01.jpg | 32.37dB
25-05-22 13:38:51.895 : --87--> lake_111_10.jpg | 31.72dB
25-05-22 13:38:51.981 : --88--> lake_111_11.jpg | 31.07dB
25-05-22 13:38:52.055 : --89--> meadow_111_00.jpg | 30.12dB
25-05-22 13:38:52.139 : --90--> meadow_111_01.jpg | 30.20dB
25-05-22 13:38:52.208 : --91--> meadow_111_10.jpg | 30.25dB
25-05-22 13:38:52.306 : --92--> meadow_111_11.jpg | 30.38dB
25-05-22 13:38:52.391 : --93--> medium_residential_111_00.jpg | 28.89dB
25-05-22 13:38:52.482 : --94--> medium_residential_111_01.jpg | 28.35dB
25-05-22 13:38:52.561 : --95--> medium_residential_111_10.jpg | 28.73dB
25-05-22 13:38:52.659 : --96--> medium_residential_111_11.jpg | 29.24dB
25-05-22 13:38:52.736 : --97--> mobile_home_park_111_00.jpg | 31.12dB
25-05-22 13:38:52.821 : --98--> mobile_home_park_111_01.jpg | 31.65dB
25-05-22 13:38:52.896 : --99--> mobile_home_park_111_10.jpg | 31.90dB
25-05-22 13:38:52.986 : -100--> mobile_home_park_111_11.jpg | 31.92dB
25-05-22 13:38:53.078 : -101--> mountain_111_00.jpg | 28.94dB
25-05-22 13:38:53.153 : -102--> mountain_111_01.jpg | 29.66dB
25-05-22 13:38:53.228 : -103--> mountain_111_10.jpg | 29.41dB
25-05-22 13:38:53.297 : -104--> mountain_111_11.jpg | 29.74dB
25-05-22 13:38:53.368 : -105--> overpass_111_00.jpg | 30.33dB
25-05-22 13:38:53.445 : -106--> overpass_111_01.jpg | 30.04dB
25-05-22 13:38:53.515 : -107--> overpass_111_10.jpg | 30.78dB
25-05-22 13:38:53.593 : -108--> overpass_111_11.jpg | 31.43dB
25-05-22 13:38:53.681 : -109--> palace_111_00.jpg | 30.14dB
25-05-22 13:38:53.764 : -110--> palace_111_01.jpg | 30.01dB
25-05-22 13:38:53.839 : -111--> palace_111_10.jpg | 31.14dB
25-05-22 13:38:53.924 : -112--> palace_111_11.jpg | 29.49dB
25-05-22 13:38:54.005 : -113--> parking_lot_111_00.jpg | 29.46dB
25-05-22 13:38:54.087 : -114--> parking_lot_111_01.jpg | 29.75dB
25-05-22 13:38:54.169 : -115--> parking_lot_111_10.jpg | 31.34dB
25-05-22 13:38:54.252 : -116--> parking_lot_111_11.jpg | 30.16dB
25-05-22 13:38:54.325 : -117--> railway_111_00.jpg | 30.29dB
25-05-22 13:38:54.398 : -118--> railway_111_01.jpg | 29.83dB
25-05-22 13:38:54.477 : -119--> railway_111_10.jpg | 32.63dB
25-05-22 13:38:54.551 : -120--> railway_111_11.jpg | 29.27dB
25-05-22 13:38:54.638 : -121--> railway_station_111_00.jpg | 31.05dB
25-05-22 13:38:54.716 : -122--> railway_station_111_01.jpg | 31.53dB
25-05-22 13:38:54.789 : -123--> railway_station_111_10.jpg | 31.17dB
25-05-22 13:38:54.871 : -124--> railway_station_111_11.jpg | 31.74dB
25-05-22 13:38:54.947 : -125--> rectangular_farmland_111_00.jpg | 33.51dB
25-05-22 13:38:55.025 : -126--> rectangular_farmland_111_01.jpg | 32.04dB
25-05-22 13:38:55.112 : -127--> rectangular_farmland_111_10.jpg | 33.91dB
25-05-22 13:38:55.188 : -128--> rectangular_farmland_111_11.jpg | 34.28dB
25-05-22 13:38:55.284 : -129--> river_111_00.jpg | 30.31dB
25-05-22 13:38:55.355 : -130--> river_111_01.jpg | 30.05dB
25-05-22 13:38:55.439 : -131--> river_111_10.jpg | 29.62dB
25-05-22 13:38:55.511 : -132--> river_111_11.jpg | 31.41dB
25-05-22 13:38:55.591 : -133--> roundabout_111_00.jpg | 30.64dB
25-05-22 13:38:55.667 : -134--> roundabout_111_01.jpg | 32.23dB
25-05-22 13:38:55.739 : -135--> roundabout_111_10.jpg | 30.45dB
25-05-22 13:38:55.813 : -136--> roundabout_111_11.jpg | 30.94dB
25-05-22 13:38:55.883 : -137--> runway_111_00.jpg | 36.58dB
25-05-22 13:38:55.955 : -138--> runway_111_01.jpg | 35.96dB
25-05-22 13:38:56.028 : -139--> runway_111_10.jpg | 36.65dB
25-05-22 13:38:56.104 : -140--> runway_111_11.jpg | 37.63dB
25-05-22 13:38:56.183 : -141--> sea_ice_111_00.jpg | 33.74dB
25-05-22 13:38:56.285 : -142--> sea_ice_111_01.jpg | 34.74dB
25-05-22 13:38:56.370 : -143--> sea_ice_111_10.jpg | 33.78dB
25-05-22 13:38:56.466 : -144--> sea_ice_111_11.jpg | 34.80dB
25-05-22 13:38:56.542 : -145--> ship_111_00.jpg | 38.80dB
25-05-22 13:38:56.620 : -146--> ship_111_01.jpg | 34.63dB
25-05-22 13:38:56.713 : -147--> ship_111_10.jpg | 42.77dB
25-05-22 13:38:56.784 : -148--> ship_111_11.jpg | 40.16dB
25-05-22 13:38:56.878 : -149--> snowberg_111_00.jpg | 34.29dB
25-05-22 13:38:56.964 : -150--> snowberg_111_01.jpg | 32.93dB
25-05-22 13:38:57.044 : -151--> snowberg_111_10.jpg | 32.13dB
25-05-22 13:38:57.125 : -152--> snowberg_111_11.jpg | 32.11dB
25-05-22 13:38:57.210 : -153--> sparse_residential_111_00.jpg | 30.59dB
25-05-22 13:38:57.282 : -154--> sparse_residential_111_01.jpg | 30.78dB
25-05-22 13:38:57.361 : -155--> sparse_residential_111_10.jpg | 29.88dB
25-05-22 13:38:57.461 : -156--> sparse_residential_111_11.jpg | 30.08dB
25-05-22 13:38:57.533 : -157--> stadium_111_00.jpg | 30.45dB
25-05-22 13:38:57.606 : -158--> stadium_111_01.jpg | 30.24dB
25-05-22 13:38:57.674 : -159--> stadium_111_10.jpg | 31.50dB
25-05-22 13:38:57.760 : -160--> stadium_111_11.jpg | 30.31dB
25-05-22 13:38:57.833 : -161--> storage_tank_111_00.jpg | 31.93dB
25-05-22 13:38:57.906 : -162--> storage_tank_111_01.jpg | 32.15dB
25-05-22 13:38:57.984 : -163--> storage_tank_111_10.jpg | 30.91dB
25-05-22 13:38:58.071 : -164--> storage_tank_111_11.jpg | 31.41dB
25-05-22 13:38:58.153 : -165--> tennis_court_111_00.jpg | 32.22dB
25-05-22 13:38:58.230 : -166--> tennis_court_111_01.jpg | 31.66dB
25-05-22 13:38:58.318 : -167--> tennis_court_111_10.jpg | 32.08dB
25-05-22 13:38:58.393 : -168--> tennis_court_111_11.jpg | 29.76dB
25-05-22 13:38:58.474 : -169--> terrace_111_00.jpg | 32.30dB
25-05-22 13:38:58.548 : -170--> terrace_111_01.jpg | 33.44dB
25-05-22 13:38:58.625 : -171--> terrace_111_10.jpg | 32.36dB
25-05-22 13:38:58.710 : -172--> terrace_111_11.jpg | 32.41dB
25-05-22 13:38:58.780 : -173--> thermal_power_station_111_00.jpg | 30.20dB
25-05-22 13:38:58.854 : -174--> thermal_power_station_111_01.jpg | 31.69dB
25-05-22 13:38:58.933 : -175--> thermal_power_station_111_10.jpg | 30.03dB
25-05-22 13:38:59.013 : -176--> thermal_power_station_111_11.jpg | 30.62dB
25-05-22 13:38:59.088 : -177--> wetland_111_00.jpg | 31.44dB
25-05-22 13:38:59.177 : -178--> wetland_111_01.jpg | 31.50dB
25-05-22 13:38:59.265 : -179--> wetland_111_10.jpg | 31.74dB
25-05-22 13:38:59.334 : -180--> wetland_111_11.jpg | 31.05dB
25-05-22 13:38:59.344 : <epoch:  1, iter:  50,000, Average PSNR : 32.28dB

25-05-22 14:11:35.494 : <epoch:  1, iter:  60,000, lr:2.500e-05> G_loss: 4.954e-05 
25-05-22 14:11:35.495 : Saving the model.
25-05-22 14:11:36.197 : ---1--> airplane_111_00.jpg | 30.69dB
25-05-22 14:11:36.289 : ---2--> airplane_111_01.jpg | 35.57dB
25-05-22 14:11:36.363 : ---3--> airplane_111_10.jpg | 33.03dB
25-05-22 14:11:36.447 : ---4--> airplane_111_11.jpg | 33.15dB
25-05-22 14:11:36.525 : ---5--> airport_111_00.jpg | 34.65dB
25-05-22 14:11:36.607 : ---6--> airport_111_01.jpg | 32.58dB
25-05-22 14:11:36.683 : ---7--> airport_111_10.jpg | 32.12dB
25-05-22 14:11:36.749 : ---8--> airport_111_11.jpg | 33.01dB
25-05-22 14:11:36.820 : ---9--> baseball_diamond_111_00.jpg | 32.84dB
25-05-22 14:11:36.898 : --10--> baseball_diamond_111_01.jpg | 34.46dB
25-05-22 14:11:36.970 : --11--> baseball_diamond_111_10.jpg | 32.76dB
25-05-22 14:11:37.076 : --12--> baseball_diamond_111_11.jpg | 35.58dB
25-05-22 14:11:37.146 : --13--> basketball_court_111_00.jpg | 30.67dB
25-05-22 14:11:37.226 : --14--> basketball_court_111_01.jpg | 30.25dB
25-05-22 14:11:37.319 : --15--> basketball_court_111_10.jpg | 33.60dB
25-05-22 14:11:37.396 : --16--> basketball_court_111_11.jpg | 31.72dB
25-05-22 14:11:37.466 : --17--> beach_111_00.jpg | 28.75dB
25-05-22 14:11:37.541 : --18--> beach_111_01.jpg | 31.94dB
25-05-22 14:11:37.615 : --19--> beach_111_10.jpg | 29.93dB
25-05-22 14:11:37.699 : --20--> beach_111_11.jpg | 34.56dB
25-05-22 14:11:37.782 : --21--> bridge_111_00.jpg | 40.96dB
25-05-22 14:11:37.857 : --22--> bridge_111_01.jpg | 34.49dB
25-05-22 14:11:37.937 : --23--> bridge_111_10.jpg | 33.42dB
25-05-22 14:11:38.017 : --24--> bridge_111_11.jpg | 36.96dB
25-05-22 14:11:38.101 : --25--> chaparral_111_00.jpg | 30.52dB
25-05-22 14:11:38.173 : --26--> chaparral_111_01.jpg | 30.74dB
25-05-22 14:11:38.245 : --27--> chaparral_111_10.jpg | 31.03dB
25-05-22 14:11:38.318 : --28--> chaparral_111_11.jpg | 28.87dB
25-05-22 14:11:38.388 : --29--> church_111_00.jpg | 31.84dB
25-05-22 14:11:38.475 : --30--> church_111_01.jpg | 30.86dB
25-05-22 14:11:38.558 : --31--> church_111_10.jpg | 34.52dB
25-05-22 14:11:38.634 : --32--> church_111_11.jpg | 30.70dB
25-05-22 14:11:38.709 : --33--> circular_farmland_111_00.jpg | 33.00dB
25-05-22 14:11:38.796 : --34--> circular_farmland_111_01.jpg | 33.99dB
25-05-22 14:11:38.868 : --35--> circular_farmland_111_10.jpg | 34.20dB
25-05-22 14:11:38.936 : --36--> circular_farmland_111_11.jpg | 34.23dB
25-05-22 14:11:39.018 : --37--> cloud_111_00.jpg | 40.99dB
25-05-22 14:11:39.117 : --38--> cloud_111_01.jpg | 36.83dB
25-05-22 14:11:39.189 : --39--> cloud_111_10.jpg | 36.43dB
25-05-22 14:11:39.257 : --40--> cloud_111_11.jpg | 36.94dB
25-05-22 14:11:39.347 : --41--> commercial_area_111_00.jpg | 33.39dB
25-05-22 14:11:39.418 : --42--> commercial_area_111_01.jpg | 32.52dB
25-05-22 14:11:39.492 : --43--> commercial_area_111_10.jpg | 33.22dB
25-05-22 14:11:39.565 : --44--> commercial_area_111_11.jpg | 33.19dB
25-05-22 14:11:39.638 : --45--> dense_residential_111_00.jpg | 30.41dB
25-05-22 14:11:39.714 : --46--> dense_residential_111_01.jpg | 29.47dB
25-05-22 14:11:39.791 : --47--> dense_residential_111_10.jpg | 29.93dB
25-05-22 14:11:39.862 : --48--> dense_residential_111_11.jpg | 29.73dB
25-05-22 14:11:39.940 : --49--> desert_111_00.jpg | 36.73dB
25-05-22 14:11:40.014 : --50--> desert_111_01.jpg | 36.57dB
25-05-22 14:11:40.095 : --51--> desert_111_10.jpg | 36.83dB
25-05-22 14:11:40.163 : --52--> desert_111_11.jpg | 36.88dB
25-05-22 14:11:40.250 : --53--> forest_111_00.jpg | 33.05dB
25-05-22 14:11:40.334 : --54--> forest_111_01.jpg | 32.18dB
25-05-22 14:11:40.402 : --55--> forest_111_10.jpg | 31.83dB
25-05-22 14:11:40.486 : --56--> forest_111_11.jpg | 32.80dB
25-05-22 14:11:40.568 : --57--> freeway_111_00.jpg | 33.97dB
25-05-22 14:11:40.652 : --58--> freeway_111_01.jpg | 35.29dB
25-05-22 14:11:40.735 : --59--> freeway_111_10.jpg | 35.03dB
25-05-22 14:11:40.813 : --60--> freeway_111_11.jpg | 34.92dB
25-05-22 14:11:40.890 : --61--> golf_course_111_00.jpg | 32.85dB
25-05-22 14:11:40.962 : --62--> golf_course_111_01.jpg | 32.25dB
25-05-22 14:11:41.040 : --63--> golf_course_111_10.jpg | 33.65dB
25-05-22 14:11:41.119 : --64--> golf_course_111_11.jpg | 34.08dB
25-05-22 14:11:41.192 : --65--> ground_track_field_111_00.jpg | 33.62dB
25-05-22 14:11:41.276 : --66--> ground_track_field_111_01.jpg | 29.51dB
25-05-22 14:11:41.362 : --67--> ground_track_field_111_10.jpg | 30.96dB
25-05-22 14:11:41.438 : --68--> ground_track_field_111_11.jpg | 30.10dB
25-05-22 14:11:41.512 : --69--> harbor_111_00.jpg | 32.94dB
25-05-22 14:11:41.599 : --70--> harbor_111_01.jpg | 31.32dB
25-05-22 14:11:41.679 : --71--> harbor_111_10.jpg | 30.91dB
25-05-22 14:11:41.753 : --72--> harbor_111_11.jpg | 32.61dB
25-05-22 14:11:41.834 : --73--> industrial_area_111_00.jpg | 31.78dB
25-05-22 14:11:41.917 : --74--> industrial_area_111_01.jpg | 31.98dB
25-05-22 14:11:42.003 : --75--> industrial_area_111_10.jpg | 32.18dB
25-05-22 14:11:42.075 : --76--> industrial_area_111_11.jpg | 31.59dB
25-05-22 14:11:42.156 : --77--> intersection_111_00.jpg | 30.85dB
25-05-22 14:11:42.258 : --78--> intersection_111_01.jpg | 30.94dB
25-05-22 14:11:42.339 : --79--> intersection_111_10.jpg | 30.65dB
25-05-22 14:11:42.414 : --80--> intersection_111_11.jpg | 30.44dB
25-05-22 14:11:42.494 : --81--> island_111_00.jpg | 31.51dB
25-05-22 14:11:42.561 : --82--> island_111_01.jpg | 33.95dB
25-05-22 14:11:42.659 : --83--> island_111_10.jpg | 32.67dB
25-05-22 14:11:42.728 : --84--> island_111_11.jpg | 32.11dB
25-05-22 14:11:42.799 : --85--> lake_111_00.jpg | 32.56dB
25-05-22 14:11:42.876 : --86--> lake_111_01.jpg | 32.35dB
25-05-22 14:11:42.948 : --87--> lake_111_10.jpg | 31.70dB
25-05-22 14:11:43.029 : --88--> lake_111_11.jpg | 31.04dB
25-05-22 14:11:43.115 : --89--> meadow_111_00.jpg | 30.15dB
25-05-22 14:11:43.193 : --90--> meadow_111_01.jpg | 30.22dB
25-05-22 14:11:43.263 : --91--> meadow_111_10.jpg | 30.27dB
25-05-22 14:11:40.822 : --92--> meadow_111_11.jpg | 30.42dB
25-05-22 14:11:40.894 : --93--> medium_residential_111_00.jpg | 28.92dB
25-05-22 14:11:40.975 : --94--> medium_residential_111_01.jpg | 28.37dB
25-05-22 14:11:41.060 : --95--> medium_residential_111_10.jpg | 28.74dB
25-05-22 14:11:41.148 : --96--> medium_residential_111_11.jpg | 29.27dB
25-05-22 14:11:41.214 : --97--> mobile_home_park_111_00.jpg | 31.11dB
25-05-22 14:11:41.288 : --98--> mobile_home_park_111_01.jpg | 31.66dB
25-05-22 14:11:41.373 : --99--> mobile_home_park_111_10.jpg | 31.90dB
25-05-22 14:11:41.449 : -100--> mobile_home_park_111_11.jpg | 31.95dB
25-05-22 14:11:41.524 : -101--> mountain_111_00.jpg | 28.97dB
25-05-22 14:11:41.610 : -102--> mountain_111_01.jpg | 29.67dB
25-05-22 14:11:41.686 : -103--> mountain_111_10.jpg | 29.42dB
25-05-22 14:11:41.758 : -104--> mountain_111_11.jpg | 29.75dB
25-05-22 14:11:41.842 : -105--> overpass_111_00.jpg | 30.39dB
25-05-22 14:11:41.917 : -106--> overpass_111_01.jpg | 30.09dB
25-05-22 14:11:41.992 : -107--> overpass_111_10.jpg | 30.74dB
25-05-22 14:11:42.070 : -108--> overpass_111_11.jpg | 31.40dB
25-05-22 14:11:42.169 : -109--> palace_111_00.jpg | 30.17dB
25-05-22 14:11:42.238 : -110--> palace_111_01.jpg | 30.04dB
25-05-22 14:11:42.326 : -111--> palace_111_10.jpg | 31.02dB
25-05-22 14:11:42.401 : -112--> palace_111_11.jpg | 29.50dB
25-05-22 14:11:42.480 : -113--> parking_lot_111_00.jpg | 29.47dB
25-05-22 14:11:42.562 : -114--> parking_lot_111_01.jpg | 29.77dB
25-05-22 14:11:42.645 : -115--> parking_lot_111_10.jpg | 31.35dB
25-05-22 14:11:42.730 : -116--> parking_lot_111_11.jpg | 30.17dB
25-05-22 14:11:42.818 : -117--> railway_111_00.jpg | 30.32dB
25-05-22 14:11:42.905 : -118--> railway_111_01.jpg | 29.86dB
25-05-22 14:11:42.987 : -119--> railway_111_10.jpg | 32.68dB
25-05-22 14:11:43.079 : -120--> railway_111_11.jpg | 29.32dB
25-05-22 14:11:43.149 : -121--> railway_station_111_00.jpg | 31.06dB
25-05-22 14:11:43.251 : -122--> railway_station_111_01.jpg | 31.55dB
25-05-22 14:11:43.335 : -123--> railway_station_111_10.jpg | 31.18dB
25-05-22 14:11:43.407 : -124--> railway_station_111_11.jpg | 31.65dB
25-05-22 14:11:43.489 : -125--> rectangular_farmland_111_00.jpg | 33.59dB
25-05-22 14:11:43.565 : -126--> rectangular_farmland_111_01.jpg | 32.09dB
25-05-22 14:11:43.652 : -127--> rectangular_farmland_111_10.jpg | 33.96dB
25-05-22 14:11:43.727 : -128--> rectangular_farmland_111_11.jpg | 34.32dB
25-05-22 14:11:43.803 : -129--> river_111_00.jpg | 30.33dB
25-05-22 14:11:43.878 : -130--> river_111_01.jpg | 30.09dB
25-05-22 14:11:43.955 : -131--> river_111_10.jpg | 29.66dB
25-05-22 14:11:44.043 : -132--> river_111_11.jpg | 31.43dB
25-05-22 14:11:44.127 : -133--> roundabout_111_00.jpg | 30.67dB
25-05-22 14:11:44.199 : -134--> roundabout_111_01.jpg | 32.24dB
25-05-22 14:11:44.278 : -135--> roundabout_111_10.jpg | 30.47dB
25-05-22 14:11:44.361 : -136--> roundabout_111_11.jpg | 30.94dB
25-05-22 14:11:44.436 : -137--> runway_111_00.jpg | 36.65dB
25-05-22 14:11:44.518 : -138--> runway_111_01.jpg | 36.02dB
25-05-22 14:11:44.611 : -139--> runway_111_10.jpg | 36.66dB
25-05-22 14:11:44.684 : -140--> runway_111_11.jpg | 37.68dB
25-05-22 14:11:44.754 : -141--> sea_ice_111_00.jpg | 33.76dB
25-05-22 14:11:44.830 : -142--> sea_ice_111_01.jpg | 34.77dB
25-05-22 14:11:44.912 : -143--> sea_ice_111_10.jpg | 33.84dB
25-05-22 14:11:44.996 : -144--> sea_ice_111_11.jpg | 34.83dB
25-05-22 14:11:45.072 : -145--> ship_111_00.jpg | 38.78dB
25-05-22 14:11:45.145 : -146--> ship_111_01.jpg | 34.68dB
25-05-22 14:11:45.228 : -147--> ship_111_10.jpg | 42.80dB
25-05-22 14:11:45.304 : -148--> ship_111_11.jpg | 40.23dB
25-05-22 14:11:45.388 : -149--> snowberg_111_00.jpg | 34.33dB
25-05-22 14:11:45.459 : -150--> snowberg_111_01.jpg | 32.97dB
25-05-22 14:11:45.540 : -151--> snowberg_111_10.jpg | 32.12dB
25-05-22 14:11:45.612 : -152--> snowberg_111_11.jpg | 32.12dB
25-05-22 14:11:45.704 : -153--> sparse_residential_111_00.jpg | 30.57dB
25-05-22 14:11:45.801 : -154--> sparse_residential_111_01.jpg | 30.80dB
25-05-22 14:11:45.886 : -155--> sparse_residential_111_10.jpg | 29.90dB
25-05-22 14:11:45.962 : -156--> sparse_residential_111_11.jpg | 30.11dB
25-05-22 14:11:46.060 : -157--> stadium_111_00.jpg | 30.49dB
25-05-22 14:11:46.138 : -158--> stadium_111_01.jpg | 30.27dB
25-05-22 14:11:46.212 : -159--> stadium_111_10.jpg | 31.52dB
25-05-22 14:11:46.295 : -160--> stadium_111_11.jpg | 30.31dB
25-05-22 14:11:46.377 : -161--> storage_tank_111_00.jpg | 31.92dB
25-05-22 14:11:46.483 : -162--> storage_tank_111_01.jpg | 32.13dB
25-05-22 14:11:46.570 : -163--> storage_tank_111_10.jpg | 30.85dB
25-05-22 14:11:46.641 : -164--> storage_tank_111_11.jpg | 31.41dB
25-05-22 14:11:46.714 : -165--> tennis_court_111_00.jpg | 32.28dB
25-05-22 14:11:46.789 : -166--> tennis_court_111_01.jpg | 31.69dB
25-05-22 14:11:46.876 : -167--> tennis_court_111_10.jpg | 32.12dB
25-05-22 14:11:46.961 : -168--> tennis_court_111_11.jpg | 29.78dB
25-05-22 14:11:47.039 : -169--> terrace_111_00.jpg | 32.32dB
25-05-22 14:11:47.129 : -170--> terrace_111_01.jpg | 33.44dB
25-05-22 14:11:47.239 : -171--> terrace_111_10.jpg | 32.34dB
25-05-22 14:11:47.312 : -172--> terrace_111_11.jpg | 32.29dB
25-05-22 14:11:47.390 : -173--> thermal_power_station_111_00.jpg | 30.13dB
25-05-22 14:11:47.463 : -174--> thermal_power_station_111_01.jpg | 31.73dB
25-05-22 14:11:47.534 : -175--> thermal_power_station_111_10.jpg | 30.03dB
25-05-22 14:11:47.621 : -176--> thermal_power_station_111_11.jpg | 30.58dB
25-05-22 14:11:47.695 : -177--> wetland_111_00.jpg | 31.43dB
25-05-22 14:11:47.795 : -178--> wetland_111_01.jpg | 31.50dB
25-05-22 14:11:47.886 : -179--> wetland_111_10.jpg | 31.73dB
25-05-22 14:11:47.973 : -180--> wetland_111_11.jpg | 31.06dB
25-05-22 14:11:47.982 : <epoch:  1, iter:  60,000, Average PSNR : 32.30dB

25-05-22 14:44:38.775 : <epoch:  2, iter:  70,000, lr:2.500e-05> G_loss: 9.700e-05 
25-05-22 14:44:38.776 : Saving the model.
25-05-22 14:44:39.431 : ---1--> airplane_111_00.jpg | 30.72dB
25-05-22 14:44:39.494 : ---2--> airplane_111_01.jpg | 35.55dB
25-05-22 14:44:39.578 : ---3--> airplane_111_10.jpg | 33.11dB
25-05-22 14:44:39.653 : ---4--> airplane_111_11.jpg | 33.03dB
25-05-22 14:44:39.734 : ---5--> airport_111_00.jpg | 34.63dB
25-05-22 14:44:39.805 : ---6--> airport_111_01.jpg | 32.55dB
25-05-22 14:44:39.878 : ---7--> airport_111_10.jpg | 32.10dB
25-05-22 14:44:39.953 : ---8--> airport_111_11.jpg | 33.00dB
25-05-22 14:44:40.036 : ---9--> baseball_diamond_111_00.jpg | 32.83dB
25-05-22 14:44:40.102 : --10--> baseball_diamond_111_01.jpg | 34.45dB
25-05-22 14:44:40.174 : --11--> baseball_diamond_111_10.jpg | 32.73dB
25-05-22 14:44:40.273 : --12--> baseball_diamond_111_11.jpg | 35.57dB
25-05-22 14:44:40.346 : --13--> basketball_court_111_00.jpg | 30.67dB
25-05-22 14:44:40.421 : --14--> basketball_court_111_01.jpg | 30.25dB
25-05-22 14:44:40.509 : --15--> basketball_court_111_10.jpg | 33.64dB
25-05-22 14:44:40.593 : --16--> basketball_court_111_11.jpg | 31.72dB
25-05-22 14:44:40.669 : --17--> beach_111_00.jpg | 28.80dB
25-05-22 14:44:40.752 : --18--> beach_111_01.jpg | 31.95dB
25-05-22 14:44:40.833 : --19--> beach_111_10.jpg | 29.92dB
25-05-22 14:44:40.917 : --20--> beach_111_11.jpg | 34.56dB
25-05-22 14:44:40.996 : --21--> bridge_111_00.jpg | 40.97dB
25-05-22 14:44:41.079 : --22--> bridge_111_01.jpg | 34.50dB
25-05-22 14:44:41.169 : --23--> bridge_111_10.jpg | 33.44dB
25-05-22 14:44:41.254 : --24--> bridge_111_11.jpg | 37.00dB
25-05-22 14:44:41.336 : --25--> chaparral_111_00.jpg | 30.52dB
25-05-22 14:44:41.412 : --26--> chaparral_111_01.jpg | 30.74dB
25-05-22 14:44:41.500 : --27--> chaparral_111_10.jpg | 31.07dB
25-05-22 14:44:41.581 : --28--> chaparral_111_11.jpg | 28.88dB
25-05-22 14:44:41.657 : --29--> church_111_00.jpg | 31.84dB
25-05-22 14:44:41.736 : --30--> church_111_01.jpg | 30.87dB
25-05-22 14:44:41.809 : --31--> church_111_10.jpg | 34.66dB
25-05-22 14:44:41.904 : --32--> church_111_11.jpg | 30.71dB
25-05-22 14:44:41.984 : --33--> circular_farmland_111_00.jpg | 32.97dB
25-05-22 14:44:42.067 : --34--> circular_farmland_111_01.jpg | 34.02dB
25-05-22 14:44:42.142 : --35--> circular_farmland_111_10.jpg | 34.20dB
25-05-22 14:44:42.232 : --36--> circular_farmland_111_11.jpg | 34.24dB
25-05-22 14:44:42.309 : --37--> cloud_111_00.jpg | 41.08dB
25-05-22 14:44:42.395 : --38--> cloud_111_01.jpg | 36.82dB
25-05-22 14:44:42.480 : --39--> cloud_111_10.jpg | 36.41dB
25-05-22 14:44:42.552 : --40--> cloud_111_11.jpg | 36.97dB
25-05-22 14:44:42.628 : --41--> commercial_area_111_00.jpg | 33.37dB
25-05-22 14:44:42.712 : --42--> commercial_area_111_01.jpg | 32.51dB
25-05-22 14:44:42.798 : --43--> commercial_area_111_10.jpg | 33.21dB
25-05-22 14:44:40.392 : --44--> commercial_area_111_11.jpg | 33.12dB
25-05-22 14:44:40.468 : --45--> dense_residential_111_00.jpg | 30.40dB
25-05-22 14:44:40.578 : --46--> dense_residential_111_01.jpg | 29.44dB
25-05-22 14:44:40.661 : --47--> dense_residential_111_10.jpg | 29.91dB
25-05-22 14:44:40.748 : --48--> dense_residential_111_11.jpg | 29.74dB
25-05-22 14:44:40.834 : --49--> desert_111_00.jpg | 36.73dB
25-05-22 14:44:40.932 : --50--> desert_111_01.jpg | 36.54dB
25-05-22 14:44:41.003 : --51--> desert_111_10.jpg | 36.82dB
25-05-22 14:44:41.079 : --52--> desert_111_11.jpg | 36.87dB
25-05-22 14:44:41.159 : --53--> forest_111_00.jpg | 33.05dB
25-05-22 14:44:41.249 : --54--> forest_111_01.jpg | 32.16dB
25-05-22 14:44:41.338 : --55--> forest_111_10.jpg | 31.82dB
25-05-22 14:44:41.427 : --56--> forest_111_11.jpg | 32.78dB
25-05-22 14:44:41.521 : --57--> freeway_111_00.jpg | 33.96dB
25-05-22 14:44:41.611 : --58--> freeway_111_01.jpg | 35.28dB
25-05-22 14:44:41.716 : --59--> freeway_111_10.jpg | 35.01dB
25-05-22 14:44:41.790 : --60--> freeway_111_11.jpg | 34.92dB
25-05-22 14:44:41.862 : --61--> golf_course_111_00.jpg | 32.87dB
25-05-22 14:44:41.944 : --62--> golf_course_111_01.jpg | 32.25dB
25-05-22 14:44:42.018 : --63--> golf_course_111_10.jpg | 33.65dB
25-05-22 14:44:42.111 : --64--> golf_course_111_11.jpg | 34.11dB
25-05-22 14:44:42.184 : --65--> ground_track_field_111_00.jpg | 33.61dB
25-05-22 14:44:42.288 : --66--> ground_track_field_111_01.jpg | 29.50dB
25-05-22 14:44:42.364 : --67--> ground_track_field_111_10.jpg | 30.94dB
25-05-22 14:44:42.446 : --68--> ground_track_field_111_11.jpg | 30.10dB
25-05-22 14:44:42.539 : --69--> harbor_111_00.jpg | 32.95dB
25-05-22 14:44:42.630 : --70--> harbor_111_01.jpg | 31.35dB
25-05-22 14:44:42.725 : --71--> harbor_111_10.jpg | 30.91dB
25-05-22 14:44:42.804 : --72--> harbor_111_11.jpg | 32.57dB
25-05-22 14:44:42.875 : --73--> industrial_area_111_00.jpg | 31.77dB
25-05-22 14:44:42.969 : --74--> industrial_area_111_01.jpg | 31.87dB
25-05-22 14:44:43.049 : --75--> industrial_area_111_10.jpg | 32.18dB
25-05-22 14:44:43.126 : --76--> industrial_area_111_11.jpg | 31.58dB
25-05-22 14:44:43.208 : --77--> intersection_111_00.jpg | 30.83dB
25-05-22 14:44:43.316 : --78--> intersection_111_01.jpg | 30.96dB
25-05-22 14:44:43.393 : --79--> intersection_111_10.jpg | 30.66dB
25-05-22 14:44:43.475 : --80--> intersection_111_11.jpg | 30.43dB
25-05-22 14:44:43.558 : --81--> island_111_00.jpg | 31.57dB
25-05-22 14:44:43.632 : --82--> island_111_01.jpg | 33.93dB
25-05-22 14:44:43.728 : --83--> island_111_10.jpg | 32.69dB
25-05-22 14:44:43.803 : --84--> island_111_11.jpg | 32.11dB
25-05-22 14:44:43.899 : --85--> lake_111_00.jpg | 32.55dB
25-05-22 14:44:43.997 : --86--> lake_111_01.jpg | 32.40dB
25-05-22 14:44:44.072 : --87--> lake_111_10.jpg | 31.70dB
25-05-22 14:44:44.172 : --88--> lake_111_11.jpg | 31.05dB
25-05-22 14:44:44.244 : --89--> meadow_111_00.jpg | 30.14dB
25-05-22 14:44:44.327 : --90--> meadow_111_01.jpg | 30.22dB
25-05-22 14:44:44.398 : --91--> meadow_111_10.jpg | 30.26dB
25-05-22 14:44:44.495 : --92--> meadow_111_11.jpg | 30.41dB
25-05-22 14:44:44.569 : --93--> medium_residential_111_00.jpg | 28.92dB
25-05-22 14:44:44.644 : --94--> medium_residential_111_01.jpg | 28.38dB
25-05-22 14:44:44.713 : --95--> medium_residential_111_10.jpg | 28.74dB
25-05-22 14:44:44.801 : --96--> medium_residential_111_11.jpg | 29.27dB
25-05-22 14:44:44.885 : --97--> mobile_home_park_111_00.jpg | 31.14dB
25-05-22 14:44:44.971 : --98--> mobile_home_park_111_01.jpg | 31.67dB
25-05-22 14:44:45.066 : --99--> mobile_home_park_111_10.jpg | 31.90dB
25-05-22 14:44:45.138 : -100--> mobile_home_park_111_11.jpg | 31.94dB
25-05-22 14:44:45.220 : -101--> mountain_111_00.jpg | 28.96dB
25-05-22 14:44:45.312 : -102--> mountain_111_01.jpg | 29.67dB
25-05-22 14:44:45.384 : -103--> mountain_111_10.jpg | 29.42dB
25-05-22 14:44:45.480 : -104--> mountain_111_11.jpg | 29.75dB
25-05-22 14:44:45.563 : -105--> overpass_111_00.jpg | 30.39dB
25-05-22 14:44:45.632 : -106--> overpass_111_01.jpg | 30.14dB
25-05-22 14:44:45.706 : -107--> overpass_111_10.jpg | 30.81dB
25-05-22 14:44:45.784 : -108--> overpass_111_11.jpg | 31.43dB
25-05-22 14:44:45.866 : -109--> palace_111_00.jpg | 30.16dB
25-05-22 14:44:45.937 : -110--> palace_111_01.jpg | 30.04dB
25-05-22 14:44:46.022 : -111--> palace_111_10.jpg | 31.12dB
25-05-22 14:44:46.105 : -112--> palace_111_11.jpg | 29.51dB
25-05-22 14:44:46.179 : -113--> parking_lot_111_00.jpg | 29.47dB
25-05-22 14:44:46.257 : -114--> parking_lot_111_01.jpg | 29.80dB
25-05-22 14:44:46.337 : -115--> parking_lot_111_10.jpg | 31.34dB
25-05-22 14:44:46.413 : -116--> parking_lot_111_11.jpg | 30.16dB
25-05-22 14:44:46.484 : -117--> railway_111_00.jpg | 30.32dB
25-05-22 14:44:46.558 : -118--> railway_111_01.jpg | 29.91dB
25-05-22 14:44:46.626 : -119--> railway_111_10.jpg | 32.69dB
25-05-22 14:44:46.704 : -120--> railway_111_11.jpg | 29.31dB
25-05-22 14:44:46.794 : -121--> railway_station_111_00.jpg | 31.07dB
25-05-22 14:44:46.864 : -122--> railway_station_111_01.jpg | 31.55dB
25-05-22 14:44:46.949 : -123--> railway_station_111_10.jpg | 31.17dB
25-05-22 14:44:47.034 : -124--> railway_station_111_11.jpg | 31.72dB
25-05-22 14:44:47.110 : -125--> rectangular_farmland_111_00.jpg | 33.61dB
25-05-22 14:44:47.194 : -126--> rectangular_farmland_111_01.jpg | 32.08dB
25-05-22 14:44:47.273 : -127--> rectangular_farmland_111_10.jpg | 33.99dB
25-05-22 14:44:47.358 : -128--> rectangular_farmland_111_11.jpg | 34.31dB
25-05-22 14:44:47.426 : -129--> river_111_00.jpg | 30.33dB
25-05-22 14:44:47.503 : -130--> river_111_01.jpg | 30.07dB
25-05-22 14:44:47.577 : -131--> river_111_10.jpg | 29.67dB
25-05-22 14:44:47.648 : -132--> river_111_11.jpg | 31.43dB
25-05-22 14:44:47.714 : -133--> roundabout_111_00.jpg | 30.69dB
25-05-22 14:44:47.799 : -134--> roundabout_111_01.jpg | 32.24dB
25-05-22 14:44:47.874 : -135--> roundabout_111_10.jpg | 30.46dB
25-05-22 14:44:47.956 : -136--> roundabout_111_11.jpg | 30.97dB
25-05-22 14:44:48.045 : -137--> runway_111_00.jpg | 36.64dB
25-05-22 14:44:48.115 : -138--> runway_111_01.jpg | 35.98dB
25-05-22 14:44:48.189 : -139--> runway_111_10.jpg | 36.65dB
25-05-22 14:44:48.280 : -140--> runway_111_11.jpg | 37.68dB
25-05-22 14:44:48.355 : -141--> sea_ice_111_00.jpg | 33.77dB
25-05-22 14:44:48.436 : -142--> sea_ice_111_01.jpg | 34.76dB
25-05-22 14:44:48.513 : -143--> sea_ice_111_10.jpg | 33.83dB
25-05-22 14:44:48.621 : -144--> sea_ice_111_11.jpg | 34.84dB
25-05-22 14:44:48.700 : -145--> ship_111_00.jpg | 38.78dB
25-05-22 14:44:48.782 : -146--> ship_111_01.jpg | 34.68dB
25-05-22 14:44:48.869 : -147--> ship_111_10.jpg | 42.75dB
25-05-22 14:44:48.947 : -148--> ship_111_11.jpg | 40.20dB
25-05-22 14:44:49.022 : -149--> snowberg_111_00.jpg | 34.35dB
25-05-22 14:44:49.098 : -150--> snowberg_111_01.jpg | 32.95dB
25-05-22 14:44:49.176 : -151--> snowberg_111_10.jpg | 32.13dB
25-05-22 14:44:49.260 : -152--> snowberg_111_11.jpg | 32.13dB
25-05-22 14:44:49.334 : -153--> sparse_residential_111_00.jpg | 30.60dB
25-05-22 14:44:49.414 : -154--> sparse_residential_111_01.jpg | 30.78dB
25-05-22 14:44:49.492 : -155--> sparse_residential_111_10.jpg | 29.90dB
25-05-22 14:44:49.572 : -156--> sparse_residential_111_11.jpg | 30.10dB
25-05-22 14:44:49.664 : -157--> stadium_111_00.jpg | 30.48dB
25-05-22 14:44:49.741 : -158--> stadium_111_01.jpg | 30.26dB
25-05-22 14:44:49.813 : -159--> stadium_111_10.jpg | 31.52dB
25-05-22 14:44:49.889 : -160--> stadium_111_11.jpg | 30.31dB
25-05-22 14:44:49.971 : -161--> storage_tank_111_00.jpg | 31.91dB
25-05-22 14:44:50.058 : -162--> storage_tank_111_01.jpg | 32.15dB
25-05-22 14:44:50.139 : -163--> storage_tank_111_10.jpg | 30.89dB
25-05-22 14:44:50.227 : -164--> storage_tank_111_11.jpg | 31.42dB
25-05-22 14:44:50.305 : -165--> tennis_court_111_00.jpg | 32.28dB
25-05-22 14:44:50.401 : -166--> tennis_court_111_01.jpg | 31.68dB
25-05-22 14:44:50.491 : -167--> tennis_court_111_10.jpg | 32.12dB
25-05-22 14:44:50.586 : -168--> tennis_court_111_11.jpg | 29.79dB
25-05-22 14:44:50.680 : -169--> terrace_111_00.jpg | 32.28dB
25-05-22 14:44:50.772 : -170--> terrace_111_01.jpg | 33.45dB
25-05-22 14:44:50.847 : -171--> terrace_111_10.jpg | 32.33dB
25-05-22 14:44:50.919 : -172--> terrace_111_11.jpg | 32.37dB
25-05-22 14:44:50.993 : -173--> thermal_power_station_111_00.jpg | 30.20dB
25-05-22 14:44:51.075 : -174--> thermal_power_station_111_01.jpg | 31.75dB
25-05-22 14:44:51.156 : -175--> thermal_power_station_111_10.jpg | 30.04dB
25-05-22 14:44:51.224 : -176--> thermal_power_station_111_11.jpg | 30.62dB
25-05-22 14:44:51.300 : -177--> wetland_111_00.jpg | 31.44dB
25-05-22 14:44:51.387 : -178--> wetland_111_01.jpg | 31.51dB
25-05-22 14:44:51.454 : -179--> wetland_111_10.jpg | 31.73dB
25-05-22 14:44:51.528 : -180--> wetland_111_11.jpg | 31.07dB
25-05-22 14:44:51.541 : <epoch:  2, iter:  70,000, Average PSNR : 32.30dB

25-05-22 15:18:17.680 : <epoch:  2, iter:  80,000, lr:2.500e-05> G_loss: 6.093e-05 
25-05-22 15:18:17.681 : Saving the model.
25-05-22 15:18:18.465 : ---1--> airplane_111_00.jpg | 30.73dB
25-05-22 15:18:18.544 : ---2--> airplane_111_01.jpg | 35.57dB
25-05-22 15:18:18.616 : ---3--> airplane_111_10.jpg | 33.08dB
25-05-22 15:18:18.708 : ---4--> airplane_111_11.jpg | 33.13dB
25-05-22 15:18:18.807 : ---5--> airport_111_00.jpg | 34.68dB
25-05-22 15:18:18.895 : ---6--> airport_111_01.jpg | 32.58dB
25-05-22 15:18:18.973 : ---7--> airport_111_10.jpg | 32.13dB
25-05-22 15:18:19.055 : ---8--> airport_111_11.jpg | 33.04dB
25-05-22 15:18:19.131 : ---9--> baseball_diamond_111_00.jpg | 32.85dB
25-05-22 15:18:19.233 : --10--> baseball_diamond_111_01.jpg | 34.47dB
25-05-22 15:18:19.314 : --11--> baseball_diamond_111_10.jpg | 32.76dB
25-05-22 15:18:19.410 : --12--> baseball_diamond_111_11.jpg | 35.59dB
25-05-22 15:18:19.505 : --13--> basketball_court_111_00.jpg | 30.68dB
25-05-22 15:18:19.617 : --14--> basketball_court_111_01.jpg | 30.27dB
25-05-22 15:18:19.706 : --15--> basketball_court_111_10.jpg | 33.64dB
25-05-22 15:18:19.803 : --16--> basketball_court_111_11.jpg | 31.72dB
25-05-22 15:18:19.910 : --17--> beach_111_00.jpg | 28.82dB
25-05-22 15:18:20.016 : --18--> beach_111_01.jpg | 31.96dB
25-05-22 15:18:20.098 : --19--> beach_111_10.jpg | 29.92dB
25-05-22 15:18:20.198 : --20--> beach_111_11.jpg | 34.59dB
25-05-22 15:18:20.293 : --21--> bridge_111_00.jpg | 40.94dB
25-05-22 15:18:20.398 : --22--> bridge_111_01.jpg | 34.52dB
25-05-22 15:18:20.483 : --23--> bridge_111_10.jpg | 33.44dB
25-05-22 15:18:20.565 : --24--> bridge_111_11.jpg | 36.97dB
25-05-22 15:18:20.669 : --25--> chaparral_111_00.jpg | 30.54dB
25-05-22 15:18:20.754 : --26--> chaparral_111_01.jpg | 30.76dB
25-05-22 15:18:20.827 : --27--> chaparral_111_10.jpg | 31.09dB
25-05-22 15:18:20.909 : --28--> chaparral_111_11.jpg | 28.88dB
25-05-22 15:18:20.981 : --29--> church_111_00.jpg | 31.85dB
25-05-22 15:18:21.059 : --30--> church_111_01.jpg | 30.87dB
25-05-22 15:18:21.169 : --31--> church_111_10.jpg | 34.66dB
25-05-22 15:18:21.261 : --32--> church_111_11.jpg | 30.70dB
25-05-22 15:18:21.349 : --33--> circular_farmland_111_00.jpg | 33.00dB
25-05-22 15:18:21.434 : --34--> circular_farmland_111_01.jpg | 33.98dB
25-05-22 15:18:21.515 : --35--> circular_farmland_111_10.jpg | 34.20dB
25-05-22 15:18:21.604 : --36--> circular_farmland_111_11.jpg | 34.23dB
25-05-22 15:18:21.690 : --37--> cloud_111_00.jpg | 41.06dB
25-05-22 15:18:21.790 : --38--> cloud_111_01.jpg | 36.79dB
25-05-22 15:18:21.871 : --39--> cloud_111_10.jpg | 36.41dB
25-05-22 15:18:21.945 : --40--> cloud_111_11.jpg | 36.85dB
25-05-22 15:18:22.036 : --41--> commercial_area_111_00.jpg | 33.39dB
25-05-22 15:18:22.131 : --42--> commercial_area_111_01.jpg | 32.53dB
25-05-22 15:18:22.214 : --43--> commercial_area_111_10.jpg | 33.25dB
25-05-22 15:18:22.286 : --44--> commercial_area_111_11.jpg | 33.19dB
25-05-22 15:18:22.373 : --45--> dense_residential_111_00.jpg | 30.42dB
25-05-22 15:18:22.454 : --46--> dense_residential_111_01.jpg | 29.47dB
25-05-22 15:18:22.554 : --47--> dense_residential_111_10.jpg | 29.93dB
25-05-22 15:18:22.633 : --48--> dense_residential_111_11.jpg | 29.76dB
25-05-22 15:18:22.704 : --49--> desert_111_00.jpg | 36.78dB
25-05-22 15:18:22.820 : --50--> desert_111_01.jpg | 36.65dB
25-05-22 15:18:22.895 : --51--> desert_111_10.jpg | 36.90dB
25-05-22 15:18:22.994 : --52--> desert_111_11.jpg | 36.96dB
25-05-22 15:18:23.078 : --53--> forest_111_00.jpg | 33.04dB
25-05-22 15:18:23.173 : --54--> forest_111_01.jpg | 32.18dB
25-05-22 15:18:23.259 : --55--> forest_111_10.jpg | 31.83dB
25-05-22 15:18:23.341 : --56--> forest_111_11.jpg | 32.79dB
25-05-22 15:18:23.432 : --57--> freeway_111_00.jpg | 33.98dB
25-05-22 15:18:23.523 : --58--> freeway_111_01.jpg | 35.31dB
25-05-22 15:18:23.607 : --59--> freeway_111_10.jpg | 34.99dB
25-05-22 15:18:23.697 : --60--> freeway_111_11.jpg | 34.93dB
25-05-22 15:18:23.776 : --61--> golf_course_111_00.jpg | 32.87dB
25-05-22 15:18:23.862 : --62--> golf_course_111_01.jpg | 32.26dB
25-05-22 15:18:23.948 : --63--> golf_course_111_10.jpg | 33.64dB
25-05-22 15:18:24.033 : --64--> golf_course_111_11.jpg | 34.06dB
25-05-22 15:18:24.124 : --65--> ground_track_field_111_00.jpg | 33.61dB
25-05-22 15:18:24.210 : --66--> ground_track_field_111_01.jpg | 29.51dB
25-05-22 15:18:24.283 : --67--> ground_track_field_111_10.jpg | 30.96dB
25-05-22 15:18:24.371 : --68--> ground_track_field_111_11.jpg | 30.09dB
25-05-22 15:18:24.461 : --69--> harbor_111_00.jpg | 32.96dB
25-05-22 15:18:24.554 : --70--> harbor_111_01.jpg | 31.35dB
25-05-22 15:18:24.639 : --71--> harbor_111_10.jpg | 30.91dB
25-05-22 15:18:24.724 : --72--> harbor_111_11.jpg | 32.59dB
25-05-22 15:18:24.812 : --73--> industrial_area_111_00.jpg | 31.77dB
25-05-22 15:18:24.909 : --74--> industrial_area_111_01.jpg | 32.03dB
25-05-22 15:18:25.003 : --75--> industrial_area_111_10.jpg | 32.20dB
25-05-22 15:18:25.082 : --76--> industrial_area_111_11.jpg | 31.60dB
25-05-22 15:18:25.162 : --77--> intersection_111_00.jpg | 30.84dB
25-05-22 15:18:25.237 : --78--> intersection_111_01.jpg | 30.95dB
25-05-22 15:18:25.318 : --79--> intersection_111_10.jpg | 30.67dB
25-05-22 15:18:25.392 : --80--> intersection_111_11.jpg | 30.45dB
25-05-22 15:18:25.473 : --81--> island_111_00.jpg | 31.56dB
25-05-22 15:18:25.558 : --82--> island_111_01.jpg | 33.90dB
25-05-22 15:18:25.650 : --83--> island_111_10.jpg | 32.66dB
25-05-22 15:18:25.755 : --84--> island_111_11.jpg | 32.08dB
25-05-22 15:18:25.832 : --85--> lake_111_00.jpg | 32.55dB
25-05-22 15:18:25.934 : --86--> lake_111_01.jpg | 32.36dB
25-05-22 15:18:26.033 : --87--> lake_111_10.jpg | 31.70dB
25-05-22 15:18:26.111 : --88--> lake_111_11.jpg | 31.05dB
25-05-22 15:18:26.214 : --89--> meadow_111_00.jpg | 30.15dB
25-05-22 15:18:26.293 : --90--> meadow_111_01.jpg | 30.22dB
25-05-22 15:18:26.366 : --91--> meadow_111_10.jpg | 30.27dB
25-05-22 15:18:26.473 : --92--> meadow_111_11.jpg | 30.42dB
25-05-22 15:18:26.554 : --93--> medium_residential_111_00.jpg | 28.93dB
25-05-22 15:18:26.658 : --94--> medium_residential_111_01.jpg | 28.39dB
25-05-22 15:18:26.747 : --95--> medium_residential_111_10.jpg | 28.77dB
25-05-22 15:18:26.826 : --96--> medium_residential_111_11.jpg | 29.28dB
25-05-22 15:18:26.901 : --97--> mobile_home_park_111_00.jpg | 31.12dB
25-05-22 15:18:26.983 : --98--> mobile_home_park_111_01.jpg | 31.66dB
25-05-22 15:18:27.077 : --99--> mobile_home_park_111_10.jpg | 31.92dB
25-05-22 15:18:27.156 : -100--> mobile_home_park_111_11.jpg | 31.96dB
25-05-22 15:18:27.229 : -101--> mountain_111_00.jpg | 28.97dB
25-05-22 15:18:27.333 : -102--> mountain_111_01.jpg | 29.68dB
25-05-22 15:18:27.416 : -103--> mountain_111_10.jpg | 29.43dB
25-05-22 15:18:27.493 : -104--> mountain_111_11.jpg | 29.76dB
25-05-22 15:18:27.568 : -105--> overpass_111_00.jpg | 30.42dB
25-05-22 15:18:27.673 : -106--> overpass_111_01.jpg | 30.15dB
25-05-22 15:18:27.758 : -107--> overpass_111_10.jpg | 30.84dB
25-05-22 15:18:27.841 : -108--> overpass_111_11.jpg | 31.45dB
25-05-22 15:18:27.928 : -109--> palace_111_00.jpg | 30.15dB
25-05-22 15:18:28.004 : -110--> palace_111_01.jpg | 30.04dB
25-05-22 15:18:28.079 : -111--> palace_111_10.jpg | 31.11dB
25-05-22 15:18:28.177 : -112--> palace_111_11.jpg | 29.51dB
25-05-22 15:18:28.272 : -113--> parking_lot_111_00.jpg | 29.49dB
25-05-22 15:18:28.370 : -114--> parking_lot_111_01.jpg | 29.81dB
25-05-22 15:18:28.472 : -115--> parking_lot_111_10.jpg | 31.35dB
25-05-22 15:18:28.586 : -116--> parking_lot_111_11.jpg | 30.18dB
25-05-22 15:18:28.690 : -117--> railway_111_00.jpg | 30.33dB
25-05-22 15:18:28.769 : -118--> railway_111_01.jpg | 29.91dB
25-05-22 15:18:28.853 : -119--> railway_111_10.jpg | 32.67dB
25-05-22 15:18:28.952 : -120--> railway_111_11.jpg | 29.32dB
25-05-22 15:18:29.033 : -121--> railway_station_111_00.jpg | 31.06dB
25-05-22 15:18:29.114 : -122--> railway_station_111_01.jpg | 31.55dB
25-05-22 15:18:29.206 : -123--> railway_station_111_10.jpg | 31.18dB
25-05-22 15:18:29.288 : -124--> railway_station_111_11.jpg | 31.75dB
25-05-22 15:18:29.373 : -125--> rectangular_farmland_111_00.jpg | 33.63dB
25-05-22 15:18:29.458 : -126--> rectangular_farmland_111_01.jpg | 32.09dB
25-05-22 15:18:29.545 : -127--> rectangular_farmland_111_10.jpg | 33.99dB
25-05-22 15:18:29.634 : -128--> rectangular_farmland_111_11.jpg | 34.29dB
25-05-22 15:18:29.716 : -129--> river_111_00.jpg | 30.34dB
25-05-22 15:18:29.806 : -130--> river_111_01.jpg | 30.08dB
25-05-22 15:18:29.881 : -131--> river_111_10.jpg | 29.68dB
25-05-22 15:18:29.961 : -132--> river_111_11.jpg | 31.44dB
25-05-22 15:18:30.047 : -133--> roundabout_111_00.jpg | 30.69dB
25-05-22 15:18:30.145 : -134--> roundabout_111_01.jpg | 32.25dB
25-05-22 15:18:30.219 : -135--> roundabout_111_10.jpg | 30.49dB
25-05-22 15:18:30.296 : -136--> roundabout_111_11.jpg | 30.96dB
25-05-22 15:18:30.401 : -137--> runway_111_00.jpg | 36.69dB
25-05-22 15:18:30.485 : -138--> runway_111_01.jpg | 36.02dB
25-05-22 15:18:30.570 : -139--> runway_111_10.jpg | 36.66dB
25-05-22 15:18:30.657 : -140--> runway_111_11.jpg | 37.67dB
25-05-22 15:18:30.739 : -141--> sea_ice_111_00.jpg | 33.79dB
25-05-22 15:18:30.832 : -142--> sea_ice_111_01.jpg | 34.78dB
25-05-22 15:18:30.911 : -143--> sea_ice_111_10.jpg | 33.84dB
25-05-22 15:18:31.004 : -144--> sea_ice_111_11.jpg | 34.83dB
25-05-22 15:18:31.087 : -145--> ship_111_00.jpg | 38.83dB
25-05-22 15:18:31.173 : -146--> ship_111_01.jpg | 34.68dB
25-05-22 15:18:31.250 : -147--> ship_111_10.jpg | 42.75dB
25-05-22 15:18:31.328 : -148--> ship_111_11.jpg | 40.19dB
25-05-22 15:18:31.408 : -149--> snowberg_111_00.jpg | 34.29dB
25-05-22 15:18:31.498 : -150--> snowberg_111_01.jpg | 32.97dB
25-05-22 15:18:31.573 : -151--> snowberg_111_10.jpg | 32.18dB
25-05-22 15:18:31.674 : -152--> snowberg_111_11.jpg | 32.13dB
25-05-22 15:18:31.751 : -153--> sparse_residential_111_00.jpg | 30.62dB
25-05-22 15:18:29.310 : -154--> sparse_residential_111_01.jpg | 30.80dB
25-05-22 15:18:29.387 : -155--> sparse_residential_111_10.jpg | 29.92dB
25-05-22 15:18:29.466 : -156--> sparse_residential_111_11.jpg | 30.12dB
25-05-22 15:18:29.551 : -157--> stadium_111_00.jpg | 30.49dB
25-05-22 15:18:29.628 : -158--> stadium_111_01.jpg | 30.26dB
25-05-22 15:18:29.711 : -159--> stadium_111_10.jpg | 31.54dB
25-05-22 15:18:29.807 : -160--> stadium_111_11.jpg | 30.32dB
25-05-22 15:18:29.888 : -161--> storage_tank_111_00.jpg | 31.92dB
25-05-22 15:18:29.967 : -162--> storage_tank_111_01.jpg | 32.15dB
25-05-22 15:18:30.054 : -163--> storage_tank_111_10.jpg | 30.89dB
25-05-22 15:18:30.130 : -164--> storage_tank_111_11.jpg | 31.43dB
25-05-22 15:18:30.238 : -165--> tennis_court_111_00.jpg | 32.27dB
25-05-22 15:18:30.329 : -166--> tennis_court_111_01.jpg | 31.69dB
25-05-22 15:18:30.404 : -167--> tennis_court_111_10.jpg | 32.11dB
25-05-22 15:18:30.485 : -168--> tennis_court_111_11.jpg | 29.79dB
25-05-22 15:18:30.562 : -169--> terrace_111_00.jpg | 32.32dB
25-05-22 15:18:30.647 : -170--> terrace_111_01.jpg | 33.46dB
25-05-22 15:18:30.721 : -171--> terrace_111_10.jpg | 32.36dB
25-05-22 15:18:30.809 : -172--> terrace_111_11.jpg | 32.43dB
25-05-22 15:18:30.904 : -173--> thermal_power_station_111_00.jpg | 30.22dB
25-05-22 15:18:30.986 : -174--> thermal_power_station_111_01.jpg | 31.75dB
25-05-22 15:18:31.069 : -175--> thermal_power_station_111_10.jpg | 30.06dB
25-05-22 15:18:31.150 : -176--> thermal_power_station_111_11.jpg | 30.65dB
25-05-22 15:18:31.225 : -177--> wetland_111_00.jpg | 31.45dB
25-05-22 15:18:31.311 : -178--> wetland_111_01.jpg | 31.51dB
25-05-22 15:18:31.393 : -179--> wetland_111_10.jpg | 31.74dB
25-05-22 15:18:31.472 : -180--> wetland_111_11.jpg | 31.08dB
25-05-22 15:18:31.482 : <epoch:  2, iter:  80,000, Average PSNR : 32.31dB

25-05-22 15:52:04.005 : <epoch:  2, iter:  90,000, lr:2.500e-05> G_loss: 7.017e-05 
25-05-22 15:52:04.006 : Saving the model.
25-05-22 15:52:04.733 : ---1--> airplane_111_00.jpg | 30.73dB
25-05-22 15:52:04.802 : ---2--> airplane_111_01.jpg | 35.54dB
25-05-22 15:52:04.868 : ---3--> airplane_111_10.jpg | 33.10dB
25-05-22 15:52:04.943 : ---4--> airplane_111_11.jpg | 33.14dB
25-05-22 15:52:05.025 : ---5--> airport_111_00.jpg | 34.64dB
25-05-22 15:52:05.096 : ---6--> airport_111_01.jpg | 32.57dB
25-05-22 15:52:05.168 : ---7--> airport_111_10.jpg | 32.11dB
25-05-22 15:52:05.259 : ---8--> airport_111_11.jpg | 33.01dB
25-05-22 15:52:05.327 : ---9--> baseball_diamond_111_00.jpg | 32.82dB
25-05-22 15:52:05.418 : --10--> baseball_diamond_111_01.jpg | 34.46dB
25-05-22 15:52:05.506 : --11--> baseball_diamond_111_10.jpg | 32.73dB
25-05-22 15:52:05.573 : --12--> baseball_diamond_111_11.jpg | 35.58dB
25-05-22 15:52:05.665 : --13--> basketball_court_111_00.jpg | 30.68dB
25-05-22 15:52:05.764 : --14--> basketball_court_111_01.jpg | 30.26dB
25-05-22 15:52:05.843 : --15--> basketball_court_111_10.jpg | 33.65dB
25-05-22 15:52:05.918 : --16--> basketball_court_111_11.jpg | 31.72dB
25-05-22 15:52:05.992 : --17--> beach_111_00.jpg | 28.77dB
25-05-22 15:52:06.076 : --18--> beach_111_01.jpg | 31.96dB
25-05-22 15:52:06.150 : --19--> beach_111_10.jpg | 29.91dB
25-05-22 15:52:06.233 : --20--> beach_111_11.jpg | 34.59dB
25-05-22 15:52:06.308 : --21--> bridge_111_00.jpg | 40.94dB
25-05-22 15:52:06.392 : --22--> bridge_111_01.jpg | 34.52dB
25-05-22 15:52:06.475 : --23--> bridge_111_10.jpg | 33.45dB
25-05-22 15:52:06.547 : --24--> bridge_111_11.jpg | 37.00dB
25-05-22 15:52:06.645 : --25--> chaparral_111_00.jpg | 30.53dB
25-05-22 15:52:06.723 : --26--> chaparral_111_01.jpg | 30.73dB
25-05-22 15:52:06.797 : --27--> chaparral_111_10.jpg | 31.09dB
25-05-22 15:52:06.878 : --28--> chaparral_111_11.jpg | 28.88dB
25-05-22 15:52:06.958 : --29--> church_111_00.jpg | 31.86dB
25-05-22 15:52:07.046 : --30--> church_111_01.jpg | 30.88dB
25-05-22 15:52:07.150 : --31--> church_111_10.jpg | 34.69dB
25-05-22 15:52:07.228 : --32--> church_111_11.jpg | 30.71dB
25-05-22 15:52:07.315 : --33--> circular_farmland_111_00.jpg | 32.99dB
25-05-22 15:52:07.401 : --34--> circular_farmland_111_01.jpg | 33.98dB
25-05-22 15:52:07.472 : --35--> circular_farmland_111_10.jpg | 34.21dB
25-05-22 15:52:07.544 : --36--> circular_farmland_111_11.jpg | 34.21dB
25-05-22 15:52:07.623 : --37--> cloud_111_00.jpg | 40.97dB
25-05-22 15:52:07.698 : --38--> cloud_111_01.jpg | 36.84dB
25-05-22 15:52:07.771 : --39--> cloud_111_10.jpg | 36.42dB
25-05-22 15:52:07.856 : --40--> cloud_111_11.jpg | 36.92dB
25-05-22 15:52:07.936 : --41--> commercial_area_111_00.jpg | 33.39dB
25-05-22 15:52:08.020 : --42--> commercial_area_111_01.jpg | 32.51dB
25-05-22 15:52:08.141 : --43--> commercial_area_111_10.jpg | 33.22dB
25-05-22 15:52:08.251 : --44--> commercial_area_111_11.jpg | 33.19dB
25-05-22 15:52:08.330 : --45--> dense_residential_111_00.jpg | 30.43dB
25-05-22 15:52:08.406 : --46--> dense_residential_111_01.jpg | 29.47dB
25-05-22 15:52:08.479 : --47--> dense_residential_111_10.jpg | 29.93dB
25-05-22 15:52:08.569 : --48--> dense_residential_111_11.jpg | 29.75dB
25-05-22 15:52:08.649 : --49--> desert_111_00.jpg | 36.75dB
25-05-22 15:52:08.732 : --50--> desert_111_01.jpg | 36.60dB
25-05-22 15:52:08.810 : --51--> desert_111_10.jpg | 36.86dB
25-05-22 15:52:08.902 : --52--> desert_111_11.jpg | 36.93dB
25-05-22 15:52:08.978 : --53--> forest_111_00.jpg | 33.04dB
25-05-22 15:52:09.053 : --54--> forest_111_01.jpg | 32.18dB
25-05-22 15:52:09.126 : --55--> forest_111_10.jpg | 31.84dB
25-05-22 15:52:09.196 : --56--> forest_111_11.jpg | 32.79dB
25-05-22 15:52:09.273 : --57--> freeway_111_00.jpg | 33.97dB
25-05-22 15:52:09.345 : --58--> freeway_111_01.jpg | 35.30dB
25-05-22 15:52:09.419 : --59--> freeway_111_10.jpg | 35.01dB
25-05-22 15:52:09.492 : --60--> freeway_111_11.jpg | 34.92dB
25-05-22 15:52:09.573 : --61--> golf_course_111_00.jpg | 32.88dB
25-05-22 15:52:09.667 : --62--> golf_course_111_01.jpg | 32.27dB
25-05-22 15:52:09.752 : --63--> golf_course_111_10.jpg | 33.65dB
25-05-22 15:52:09.834 : --64--> golf_course_111_11.jpg | 34.05dB
25-05-22 15:52:09.919 : --65--> ground_track_field_111_00.jpg | 33.62dB
25-05-22 15:52:09.995 : --66--> ground_track_field_111_01.jpg | 29.53dB
25-05-22 15:52:10.108 : --67--> ground_track_field_111_10.jpg | 30.97dB
25-05-22 15:52:10.209 : --68--> ground_track_field_111_11.jpg | 30.10dB
25-05-22 15:52:10.292 : --69--> harbor_111_00.jpg | 32.94dB
25-05-22 15:52:10.382 : --70--> harbor_111_01.jpg | 31.34dB
25-05-22 15:52:10.483 : --71--> harbor_111_10.jpg | 30.91dB
25-05-22 15:52:10.580 : --72--> harbor_111_11.jpg | 32.61dB
25-05-22 15:52:10.653 : --73--> industrial_area_111_00.jpg | 31.79dB
25-05-22 15:52:10.729 : --74--> industrial_area_111_01.jpg | 31.88dB
25-05-22 15:52:10.805 : --75--> industrial_area_111_10.jpg | 32.20dB
25-05-22 15:52:10.885 : --76--> industrial_area_111_11.jpg | 31.60dB
25-05-22 15:52:10.964 : --77--> intersection_111_00.jpg | 30.85dB
25-05-22 15:52:11.069 : --78--> intersection_111_01.jpg | 30.80dB
25-05-22 15:52:11.145 : --79--> intersection_111_10.jpg | 30.60dB
25-05-22 15:52:11.220 : --80--> intersection_111_11.jpg | 30.46dB
25-05-22 15:52:11.321 : --81--> island_111_00.jpg | 31.36dB
25-05-22 15:52:11.396 : --82--> island_111_01.jpg | 33.91dB
25-05-22 15:52:11.474 : --83--> island_111_10.jpg | 32.68dB
25-05-22 15:52:11.562 : --84--> island_111_11.jpg | 32.10dB
25-05-22 15:52:11.659 : --85--> lake_111_00.jpg | 32.56dB
25-05-22 15:52:11.742 : --86--> lake_111_01.jpg | 32.37dB
25-05-22 15:52:11.814 : --87--> lake_111_10.jpg | 31.68dB
25-05-22 15:52:11.902 : --88--> lake_111_11.jpg | 31.02dB
25-05-22 15:52:11.975 : --89--> meadow_111_00.jpg | 30.15dB
25-05-22 15:52:12.054 : --90--> meadow_111_01.jpg | 30.12dB
25-05-22 15:52:12.128 : --91--> meadow_111_10.jpg | 30.27dB
25-05-22 15:52:12.212 : --92--> meadow_111_11.jpg | 30.41dB
25-05-22 15:52:12.288 : --93--> medium_residential_111_00.jpg | 28.93dB
25-05-22 15:52:12.384 : --94--> medium_residential_111_01.jpg | 28.38dB
25-05-22 15:52:12.461 : --95--> medium_residential_111_10.jpg | 28.78dB
25-05-22 15:52:12.533 : --96--> medium_residential_111_11.jpg | 29.28dB
25-05-22 15:52:12.613 : --97--> mobile_home_park_111_00.jpg | 31.13dB
25-05-22 15:52:12.707 : --98--> mobile_home_park_111_01.jpg | 31.65dB
25-05-22 15:52:12.802 : --99--> mobile_home_park_111_10.jpg | 31.91dB
25-05-22 15:52:12.883 : -100--> mobile_home_park_111_11.jpg | 31.94dB
25-05-22 15:52:12.977 : -101--> mountain_111_00.jpg | 28.97dB
25-05-22 15:52:13.053 : -102--> mountain_111_01.jpg | 29.67dB
25-05-22 15:52:13.138 : -103--> mountain_111_10.jpg | 29.39dB
25-05-22 15:52:13.241 : -104--> mountain_111_11.jpg | 29.74dB
25-05-22 15:52:13.337 : -105--> overpass_111_00.jpg | 30.42dB
25-05-22 15:52:13.412 : -106--> overpass_111_01.jpg | 30.10dB
25-05-22 15:52:13.491 : -107--> overpass_111_10.jpg | 30.85dB
25-05-22 15:52:13.571 : -108--> overpass_111_11.jpg | 31.45dB
25-05-22 15:52:13.644 : -109--> palace_111_00.jpg | 30.16dB
25-05-22 15:52:13.740 : -110--> palace_111_01.jpg | 30.03dB
25-05-22 15:52:13.820 : -111--> palace_111_10.jpg | 31.04dB
25-05-22 15:52:13.893 : -112--> palace_111_11.jpg | 29.52dB
25-05-22 15:52:13.978 : -113--> parking_lot_111_00.jpg | 29.50dB
25-05-22 15:52:14.057 : -114--> parking_lot_111_01.jpg | 29.81dB
25-05-22 15:52:14.137 : -115--> parking_lot_111_10.jpg | 31.36dB
25-05-22 15:52:14.213 : -116--> parking_lot_111_11.jpg | 30.19dB
25-05-22 15:52:14.304 : -117--> railway_111_00.jpg | 30.33dB
25-05-22 15:52:14.380 : -118--> railway_111_01.jpg | 29.89dB
25-05-22 15:52:14.454 : -119--> railway_111_10.jpg | 32.66dB
25-05-22 15:52:14.542 : -120--> railway_111_11.jpg | 29.34dB
25-05-22 15:52:14.610 : -121--> railway_station_111_00.jpg | 31.07dB
25-05-22 15:52:14.690 : -122--> railway_station_111_01.jpg | 31.53dB
25-05-22 15:52:14.770 : -123--> railway_station_111_10.jpg | 31.18dB
25-05-22 15:52:12.379 : -124--> railway_station_111_11.jpg | 31.69dB
25-05-22 15:52:12.459 : -125--> rectangular_farmland_111_00.jpg | 33.61dB
25-05-22 15:52:12.546 : -126--> rectangular_farmland_111_01.jpg | 32.07dB
25-05-22 15:52:12.620 : -127--> rectangular_farmland_111_10.jpg | 33.97dB
25-05-22 15:52:12.720 : -128--> rectangular_farmland_111_11.jpg | 34.28dB
25-05-22 15:52:12.793 : -129--> river_111_00.jpg | 30.34dB
25-05-22 15:52:12.875 : -130--> river_111_01.jpg | 30.08dB
25-05-22 15:52:12.957 : -131--> river_111_10.jpg | 29.68dB
25-05-22 15:52:13.039 : -132--> river_111_11.jpg | 31.43dB
25-05-22 15:52:13.113 : -133--> roundabout_111_00.jpg | 30.68dB
25-05-22 15:52:13.212 : -134--> roundabout_111_01.jpg | 32.25dB
25-05-22 15:52:13.282 : -135--> roundabout_111_10.jpg | 30.48dB
25-05-22 15:52:13.357 : -136--> roundabout_111_11.jpg | 30.95dB
25-05-22 15:52:13.477 : -137--> runway_111_00.jpg | 36.65dB
25-05-22 15:52:13.558 : -138--> runway_111_01.jpg | 36.03dB
25-05-22 15:52:13.641 : -139--> runway_111_10.jpg | 36.66dB
25-05-22 15:52:13.722 : -140--> runway_111_11.jpg | 37.66dB
25-05-22 15:52:13.836 : -141--> sea_ice_111_00.jpg | 33.78dB
25-05-22 15:52:13.909 : -142--> sea_ice_111_01.jpg | 34.76dB
25-05-22 15:52:13.984 : -143--> sea_ice_111_10.jpg | 33.84dB
25-05-22 15:52:14.066 : -144--> sea_ice_111_11.jpg | 34.84dB
25-05-22 15:52:14.161 : -145--> ship_111_00.jpg | 38.79dB
25-05-22 15:52:14.239 : -146--> ship_111_01.jpg | 34.68dB
25-05-22 15:52:14.323 : -147--> ship_111_10.jpg | 42.77dB
25-05-22 15:52:14.405 : -148--> ship_111_11.jpg | 40.22dB
25-05-22 15:52:14.478 : -149--> snowberg_111_00.jpg | 34.28dB
25-05-22 15:52:14.567 : -150--> snowberg_111_01.jpg | 32.78dB
25-05-22 15:52:14.647 : -151--> snowberg_111_10.jpg | 32.04dB
25-05-22 15:52:14.737 : -152--> snowberg_111_11.jpg | 32.12dB
25-05-22 15:52:14.809 : -153--> sparse_residential_111_00.jpg | 30.62dB
25-05-22 15:52:14.926 : -154--> sparse_residential_111_01.jpg | 30.80dB
25-05-22 15:52:15.004 : -155--> sparse_residential_111_10.jpg | 29.91dB
25-05-22 15:52:15.080 : -156--> sparse_residential_111_11.jpg | 30.12dB
25-05-22 15:52:15.168 : -157--> stadium_111_00.jpg | 30.49dB
25-05-22 15:52:15.241 : -158--> stadium_111_01.jpg | 30.27dB
25-05-22 15:52:15.368 : -159--> stadium_111_10.jpg | 31.53dB
25-05-22 15:52:15.444 : -160--> stadium_111_11.jpg | 30.33dB
25-05-22 15:52:15.521 : -161--> storage_tank_111_00.jpg | 31.92dB
25-05-22 15:52:15.605 : -162--> storage_tank_111_01.jpg | 32.13dB
25-05-22 15:52:15.673 : -163--> storage_tank_111_10.jpg | 30.84dB
25-05-22 15:52:15.752 : -164--> storage_tank_111_11.jpg | 31.42dB
25-05-22 15:52:15.833 : -165--> tennis_court_111_00.jpg | 32.31dB
25-05-22 15:52:15.945 : -166--> tennis_court_111_01.jpg | 31.70dB
25-05-22 15:52:16.030 : -167--> tennis_court_111_10.jpg | 32.13dB
25-05-22 15:52:16.105 : -168--> tennis_court_111_11.jpg | 29.77dB
25-05-22 15:52:16.183 : -169--> terrace_111_00.jpg | 32.29dB
25-05-22 15:52:16.264 : -170--> terrace_111_01.jpg | 33.47dB
25-05-22 15:52:16.339 : -171--> terrace_111_10.jpg | 32.35dB
25-05-22 15:52:16.421 : -172--> terrace_111_11.jpg | 32.34dB
25-05-22 15:52:16.505 : -173--> thermal_power_station_111_00.jpg | 30.08dB
25-05-22 15:52:16.580 : -174--> thermal_power_station_111_01.jpg | 31.73dB
25-05-22 15:52:16.654 : -175--> thermal_power_station_111_10.jpg | 30.04dB
25-05-22 15:52:16.733 : -176--> thermal_power_station_111_11.jpg | 30.62dB
25-05-22 15:52:16.817 : -177--> wetland_111_00.jpg | 31.45dB
25-05-22 15:52:16.906 : -178--> wetland_111_01.jpg | 31.52dB
25-05-22 15:52:16.991 : -179--> wetland_111_10.jpg | 31.74dB
25-05-22 15:52:17.069 : -180--> wetland_111_11.jpg | 31.08dB
25-05-22 15:52:17.081 : <epoch:  2, iter:  90,000, Average PSNR : 32.30dB

25-05-22 16:25:20.988 : <epoch:  3, iter: 100,000, lr:2.500e-05> G_loss: 1.394e-04 
25-05-22 16:25:20.989 : Saving the model.
25-05-22 16:25:21.692 : ---1--> airplane_111_00.jpg | 30.74dB
25-05-22 16:25:21.758 : ---2--> airplane_111_01.jpg | 35.60dB
25-05-22 16:25:21.823 : ---3--> airplane_111_10.jpg | 33.12dB
25-05-22 16:25:21.899 : ---4--> airplane_111_11.jpg | 33.04dB
25-05-22 16:25:21.981 : ---5--> airport_111_00.jpg | 34.66dB
25-05-22 16:25:22.047 : ---6--> airport_111_01.jpg | 32.58dB
25-05-22 16:25:22.133 : ---7--> airport_111_10.jpg | 32.12dB
25-05-22 16:25:22.219 : ---8--> airport_111_11.jpg | 33.03dB
25-05-22 16:25:22.306 : ---9--> baseball_diamond_111_00.jpg | 32.80dB
25-05-22 16:25:22.387 : --10--> baseball_diamond_111_01.jpg | 34.37dB
25-05-22 16:25:22.473 : --11--> baseball_diamond_111_10.jpg | 32.72dB
25-05-22 16:25:22.545 : --12--> baseball_diamond_111_11.jpg | 35.61dB
25-05-22 16:25:22.628 : --13--> basketball_court_111_00.jpg | 30.69dB
25-05-22 16:25:22.713 : --14--> basketball_court_111_01.jpg | 30.26dB
25-05-22 16:25:22.795 : --15--> basketball_court_111_10.jpg | 33.68dB
25-05-22 16:25:22.872 : --16--> basketball_court_111_11.jpg | 31.73dB
25-05-22 16:25:22.953 : --17--> beach_111_00.jpg | 28.85dB
25-05-22 16:25:23.040 : --18--> beach_111_01.jpg | 31.97dB
25-05-22 16:25:23.107 : --19--> beach_111_10.jpg | 29.94dB
25-05-22 16:25:23.185 : --20--> beach_111_11.jpg | 34.55dB
25-05-22 16:25:23.281 : --21--> bridge_111_00.jpg | 40.95dB
25-05-22 16:25:23.352 : --22--> bridge_111_01.jpg | 34.51dB
25-05-22 16:25:23.439 : --23--> bridge_111_10.jpg | 33.45dB
25-05-22 16:25:23.525 : --24--> bridge_111_11.jpg | 37.00dB
25-05-22 16:25:23.610 : --25--> chaparral_111_00.jpg | 30.53dB
25-05-22 16:25:23.678 : --26--> chaparral_111_01.jpg | 30.66dB
25-05-22 16:25:23.755 : --27--> chaparral_111_10.jpg | 31.08dB
25-05-22 16:25:23.837 : --28--> chaparral_111_11.jpg | 28.88dB
25-05-22 16:25:23.904 : --29--> church_111_00.jpg | 31.86dB
25-05-22 16:25:23.978 : --30--> church_111_01.jpg | 30.89dB
25-05-22 16:25:24.066 : --31--> church_111_10.jpg | 34.67dB
25-05-22 16:25:24.161 : --32--> church_111_11.jpg | 30.72dB
25-05-22 16:25:24.240 : --33--> circular_farmland_111_00.jpg | 32.98dB
25-05-22 16:25:24.321 : --34--> circular_farmland_111_01.jpg | 33.96dB
25-05-22 16:25:24.394 : --35--> circular_farmland_111_10.jpg | 34.19dB
25-05-22 16:25:24.473 : --36--> circular_farmland_111_11.jpg | 34.24dB
25-05-22 16:25:24.540 : --37--> cloud_111_00.jpg | 41.06dB
25-05-22 16:25:24.616 : --38--> cloud_111_01.jpg | 36.85dB
25-05-22 16:25:24.698 : --39--> cloud_111_10.jpg | 36.45dB
25-05-22 16:25:24.780 : --40--> cloud_111_11.jpg | 36.95dB
25-05-22 16:25:24.872 : --41--> commercial_area_111_00.jpg | 33.41dB
25-05-22 16:25:24.950 : --42--> commercial_area_111_01.jpg | 32.53dB
25-05-22 16:25:25.031 : --43--> commercial_area_111_10.jpg | 33.28dB
25-05-22 16:25:25.108 : --44--> commercial_area_111_11.jpg | 33.17dB
25-05-22 16:25:25.205 : --45--> dense_residential_111_00.jpg | 30.42dB
25-05-22 16:25:25.277 : --46--> dense_residential_111_01.jpg | 29.48dB
25-05-22 16:25:25.364 : --47--> dense_residential_111_10.jpg | 29.94dB
25-05-22 16:25:25.444 : --48--> dense_residential_111_11.jpg | 29.76dB
25-05-22 16:25:25.512 : --49--> desert_111_00.jpg | 36.79dB
25-05-22 16:25:25.589 : --50--> desert_111_01.jpg | 36.63dB
25-05-22 16:25:25.679 : --51--> desert_111_10.jpg | 36.89dB
25-05-22 16:25:25.763 : --52--> desert_111_11.jpg | 36.96dB
25-05-22 16:25:25.841 : --53--> forest_111_00.jpg | 33.04dB
25-05-22 16:25:25.920 : --54--> forest_111_01.jpg | 32.18dB
25-05-22 16:25:26.008 : --55--> forest_111_10.jpg | 31.84dB
25-05-22 16:25:26.088 : --56--> forest_111_11.jpg | 32.78dB
25-05-22 16:25:26.158 : --57--> freeway_111_00.jpg | 33.96dB
25-05-22 16:25:26.252 : --58--> freeway_111_01.jpg | 35.27dB
25-05-22 16:25:26.347 : --59--> freeway_111_10.jpg | 35.01dB
25-05-22 16:25:26.440 : --60--> freeway_111_11.jpg | 34.94dB
25-05-22 16:25:26.522 : --61--> golf_course_111_00.jpg | 32.87dB
25-05-22 16:25:26.603 : --62--> golf_course_111_01.jpg | 32.27dB
25-05-22 16:25:26.678 : --63--> golf_course_111_10.jpg | 33.66dB
25-05-22 16:25:26.750 : --64--> golf_course_111_11.jpg | 34.07dB
25-05-22 16:25:26.822 : --65--> ground_track_field_111_00.jpg | 33.63dB
25-05-22 16:25:26.895 : --66--> ground_track_field_111_01.jpg | 29.52dB
25-05-22 16:25:26.968 : --67--> ground_track_field_111_10.jpg | 30.97dB
25-05-22 16:25:27.045 : --68--> ground_track_field_111_11.jpg | 30.11dB
25-05-22 16:25:27.127 : --69--> harbor_111_00.jpg | 32.89dB
25-05-22 16:25:27.211 : --70--> harbor_111_01.jpg | 31.34dB
25-05-22 16:25:27.317 : --71--> harbor_111_10.jpg | 30.93dB
25-05-22 16:25:27.400 : --72--> harbor_111_11.jpg | 32.55dB
25-05-22 16:25:27.474 : --73--> industrial_area_111_00.jpg | 31.78dB
25-05-22 16:25:27.552 : --74--> industrial_area_111_01.jpg | 31.91dB
25-05-22 16:25:27.636 : --75--> industrial_area_111_10.jpg | 32.21dB
25-05-22 16:25:27.710 : --76--> industrial_area_111_11.jpg | 31.61dB
25-05-22 16:25:27.789 : --77--> intersection_111_00.jpg | 30.86dB
25-05-22 16:25:27.863 : --78--> intersection_111_01.jpg | 30.93dB
25-05-22 16:25:27.941 : --79--> intersection_111_10.jpg | 30.67dB
25-05-22 16:25:28.032 : --80--> intersection_111_11.jpg | 30.45dB
25-05-22 16:25:28.113 : --81--> island_111_00.jpg | 31.58dB
25-05-22 16:25:28.192 : --82--> island_111_01.jpg | 33.95dB
25-05-22 16:25:28.271 : --83--> island_111_10.jpg | 32.69dB
25-05-22 16:25:28.345 : --84--> island_111_11.jpg | 32.15dB
25-05-22 16:25:28.422 : --85--> lake_111_00.jpg | 32.57dB
25-05-22 16:25:28.496 : --86--> lake_111_01.jpg | 32.37dB
25-05-22 16:25:28.590 : --87--> lake_111_10.jpg | 31.71dB
25-05-22 16:25:28.660 : --88--> lake_111_11.jpg | 31.06dB
25-05-22 16:25:28.733 : --89--> meadow_111_00.jpg | 30.15dB
25-05-22 16:25:28.809 : --90--> meadow_111_01.jpg | 30.23dB
25-05-22 16:25:28.883 : --91--> meadow_111_10.jpg | 30.27dB
25-05-22 16:25:28.967 : --92--> meadow_111_11.jpg | 30.42dB
25-05-22 16:25:29.044 : --93--> medium_residential_111_00.jpg | 28.95dB
25-05-22 16:25:29.121 : --94--> medium_residential_111_01.jpg | 28.39dB
25-05-22 16:25:29.186 : --95--> medium_residential_111_10.jpg | 28.78dB
25-05-22 16:25:29.261 : --96--> medium_residential_111_11.jpg | 29.29dB
25-05-22 16:25:29.356 : --97--> mobile_home_park_111_00.jpg | 31.15dB
25-05-22 16:25:29.433 : --98--> mobile_home_park_111_01.jpg | 31.66dB
25-05-22 16:25:29.528 : --99--> mobile_home_park_111_10.jpg | 31.91dB
25-05-22 16:25:29.620 : -100--> mobile_home_park_111_11.jpg | 31.93dB
25-05-22 16:25:29.708 : -101--> mountain_111_00.jpg | 28.98dB
25-05-22 16:25:29.776 : -102--> mountain_111_01.jpg | 29.68dB
25-05-22 16:25:29.874 : -103--> mountain_111_10.jpg | 29.44dB
25-05-22 16:25:29.959 : -104--> mountain_111_11.jpg | 29.76dB
25-05-22 16:25:30.042 : -105--> overpass_111_00.jpg | 30.41dB
25-05-22 16:25:30.117 : -106--> overpass_111_01.jpg | 30.08dB
25-05-22 16:25:30.189 : -107--> overpass_111_10.jpg | 30.74dB
25-05-22 16:25:30.285 : -108--> overpass_111_11.jpg | 31.45dB
25-05-22 16:25:30.375 : -109--> palace_111_00.jpg | 30.14dB
25-05-22 16:25:30.445 : -110--> palace_111_01.jpg | 30.04dB
25-05-22 16:25:30.523 : -111--> palace_111_10.jpg | 31.13dB
25-05-22 16:25:30.625 : -112--> palace_111_11.jpg | 29.51dB
25-05-22 16:25:30.712 : -113--> parking_lot_111_00.jpg | 29.50dB
25-05-22 16:25:30.803 : -114--> parking_lot_111_01.jpg | 29.82dB
25-05-22 16:25:30.892 : -115--> parking_lot_111_10.jpg | 31.30dB
25-05-22 16:25:30.977 : -116--> parking_lot_111_11.jpg | 30.20dB
25-05-22 16:25:31.070 : -117--> railway_111_00.jpg | 30.33dB
25-05-22 16:25:31.142 : -118--> railway_111_01.jpg | 29.85dB
25-05-22 16:25:31.215 : -119--> railway_111_10.jpg | 32.64dB
25-05-22 16:25:31.286 : -120--> railway_111_11.jpg | 29.34dB
25-05-22 16:25:31.380 : -121--> railway_station_111_00.jpg | 31.07dB
25-05-22 16:25:31.463 : -122--> railway_station_111_01.jpg | 31.56dB
25-05-22 16:25:31.537 : -123--> railway_station_111_10.jpg | 31.19dB
25-05-22 16:25:31.612 : -124--> railway_station_111_11.jpg | 31.77dB
25-05-22 16:25:31.688 : -125--> rectangular_farmland_111_00.jpg | 33.61dB
25-05-22 16:25:31.784 : -126--> rectangular_farmland_111_01.jpg | 31.94dB
25-05-22 16:25:31.854 : -127--> rectangular_farmland_111_10.jpg | 33.99dB
25-05-22 16:25:31.925 : -128--> rectangular_farmland_111_11.jpg | 34.32dB
25-05-22 16:25:32.016 : -129--> river_111_00.jpg | 30.33dB
25-05-22 16:25:32.101 : -130--> river_111_01.jpg | 30.09dB
25-05-22 16:25:32.177 : -131--> river_111_10.jpg | 29.69dB
25-05-22 16:25:32.258 : -132--> river_111_11.jpg | 31.44dB
25-05-22 16:25:32.340 : -133--> roundabout_111_00.jpg | 30.69dB
25-05-22 16:25:32.432 : -134--> roundabout_111_01.jpg | 32.28dB
25-05-22 16:25:32.526 : -135--> roundabout_111_10.jpg | 30.51dB
25-05-22 16:25:32.611 : -136--> roundabout_111_11.jpg | 30.96dB
25-05-22 16:25:32.684 : -137--> runway_111_00.jpg | 36.66dB
25-05-22 16:25:32.758 : -138--> runway_111_01.jpg | 36.00dB
25-05-22 16:25:32.832 : -139--> runway_111_10.jpg | 36.65dB
25-05-22 16:25:32.916 : -140--> runway_111_11.jpg | 37.73dB
25-05-22 16:25:32.998 : -141--> sea_ice_111_00.jpg | 33.76dB
25-05-22 16:25:33.089 : -142--> sea_ice_111_01.jpg | 34.71dB
25-05-22 16:25:33.155 : -143--> sea_ice_111_10.jpg | 33.83dB
25-05-22 16:25:33.242 : -144--> sea_ice_111_11.jpg | 34.83dB
25-05-22 16:25:33.326 : -145--> ship_111_00.jpg | 38.82dB
25-05-22 16:25:33.412 : -146--> ship_111_01.jpg | 34.70dB
25-05-22 16:25:33.482 : -147--> ship_111_10.jpg | 42.79dB
25-05-22 16:25:33.552 : -148--> ship_111_11.jpg | 40.20dB
25-05-22 16:25:33.634 : -149--> snowberg_111_00.jpg | 34.30dB
25-05-22 16:25:33.728 : -150--> snowberg_111_01.jpg | 32.98dB
25-05-22 16:25:33.812 : -151--> snowberg_111_10.jpg | 32.21dB
25-05-22 16:25:33.903 : -152--> snowberg_111_11.jpg | 32.14dB
25-05-22 16:25:33.978 : -153--> sparse_residential_111_00.jpg | 30.61dB
25-05-22 16:25:34.056 : -154--> sparse_residential_111_01.jpg | 30.80dB
25-05-22 16:25:34.132 : -155--> sparse_residential_111_10.jpg | 29.92dB
25-05-22 16:25:34.226 : -156--> sparse_residential_111_11.jpg | 30.12dB
25-05-22 16:25:34.299 : -157--> stadium_111_00.jpg | 30.50dB
25-05-22 16:25:34.377 : -158--> stadium_111_01.jpg | 30.27dB
25-05-22 16:25:34.464 : -159--> stadium_111_10.jpg | 31.54dB
25-05-22 16:25:34.541 : -160--> stadium_111_11.jpg | 30.33dB
25-05-22 16:25:34.617 : -161--> storage_tank_111_00.jpg | 31.94dB
25-05-22 16:25:34.695 : -162--> storage_tank_111_01.jpg | 32.16dB
25-05-22 16:25:34.788 : -163--> storage_tank_111_10.jpg | 30.86dB
25-05-22 16:25:34.875 : -164--> storage_tank_111_11.jpg | 31.43dB
25-05-22 16:25:34.971 : -165--> tennis_court_111_00.jpg | 32.30dB
25-05-22 16:25:35.049 : -166--> tennis_court_111_01.jpg | 31.70dB
25-05-22 16:25:35.121 : -167--> tennis_court_111_10.jpg | 32.13dB
25-05-22 16:25:35.201 : -168--> tennis_court_111_11.jpg | 29.79dB
25-05-22 16:25:35.292 : -169--> terrace_111_00.jpg | 32.28dB
25-05-22 16:25:35.401 : -170--> terrace_111_01.jpg | 33.47dB
25-05-22 16:25:35.480 : -171--> terrace_111_10.jpg | 32.37dB
25-05-22 16:25:35.567 : -172--> terrace_111_11.jpg | 32.43dB
25-05-22 16:25:35.664 : -173--> thermal_power_station_111_00.jpg | 30.20dB
25-05-22 16:25:35.756 : -174--> thermal_power_station_111_01.jpg | 31.75dB
25-05-22 16:25:35.866 : -175--> thermal_power_station_111_10.jpg | 30.05dB
25-05-22 16:25:35.937 : -176--> thermal_power_station_111_11.jpg | 30.64dB
25-05-22 16:25:36.032 : -177--> wetland_111_00.jpg | 31.45dB
25-05-22 16:25:36.111 : -178--> wetland_111_01.jpg | 31.51dB
25-05-22 16:25:36.184 : -179--> wetland_111_10.jpg | 31.74dB
25-05-22 16:25:36.264 : -180--> wetland_111_11.jpg | 31.07dB
25-05-22 16:25:36.276 : <epoch:  3, iter: 100,000, Average PSNR : 32.31dB

25-05-22 16:58:19.783 : <epoch:  3, iter: 110,000, lr:2.500e-05> G_loss: 9.900e-05 
25-05-22 16:58:19.784 : Saving the model.
25-05-22 16:58:20.597 : ---1--> airplane_111_00.jpg | 30.75dB
25-05-22 16:58:20.673 : ---2--> airplane_111_01.jpg | 35.60dB
25-05-22 16:58:20.757 : ---3--> airplane_111_10.jpg | 33.11dB
25-05-22 16:58:20.848 : ---4--> airplane_111_11.jpg | 33.08dB
25-05-22 16:58:20.920 : ---5--> airport_111_00.jpg | 34.66dB
25-05-22 16:58:21.006 : ---6--> airport_111_01.jpg | 32.58dB
25-05-22 16:58:21.096 : ---7--> airport_111_10.jpg | 32.12dB
25-05-22 16:58:21.180 : ---8--> airport_111_11.jpg | 33.02dB
25-05-22 16:58:21.284 : ---9--> baseball_diamond_111_00.jpg | 32.79dB
25-05-22 16:58:21.377 : --10--> baseball_diamond_111_01.jpg | 34.35dB
25-05-22 16:58:21.470 : --11--> baseball_diamond_111_10.jpg | 32.74dB
25-05-22 16:58:21.588 : --12--> baseball_diamond_111_11.jpg | 35.61dB
25-05-22 16:58:21.666 : --13--> basketball_court_111_00.jpg | 30.69dB
25-05-22 16:58:21.744 : --14--> basketball_court_111_01.jpg | 30.26dB
25-05-22 16:58:21.839 : --15--> basketball_court_111_10.jpg | 33.67dB
25-05-22 16:58:21.928 : --16--> basketball_court_111_11.jpg | 31.73dB
25-05-22 16:58:22.008 : --17--> beach_111_00.jpg | 28.85dB
25-05-22 16:58:22.087 : --18--> beach_111_01.jpg | 31.97dB
25-05-22 16:58:22.177 : --19--> beach_111_10.jpg | 29.93dB
25-05-22 16:58:22.259 : --20--> beach_111_11.jpg | 34.55dB
25-05-22 16:58:22.334 : --21--> bridge_111_00.jpg | 40.96dB
25-05-22 16:58:22.433 : --22--> bridge_111_01.jpg | 34.51dB
25-05-22 16:58:22.508 : --23--> bridge_111_10.jpg | 33.44dB
25-05-22 16:58:22.602 : --24--> bridge_111_11.jpg | 36.99dB
25-05-22 16:58:22.694 : --25--> chaparral_111_00.jpg | 30.54dB
25-05-22 16:58:22.775 : --26--> chaparral_111_01.jpg | 30.77dB
25-05-22 16:58:22.853 : --27--> chaparral_111_10.jpg | 31.09dB
25-05-22 16:58:22.960 : --28--> chaparral_111_11.jpg | 28.90dB
25-05-22 16:58:23.048 : --29--> church_111_00.jpg | 31.87dB
25-05-22 16:58:23.136 : --30--> church_111_01.jpg | 30.87dB
25-05-22 16:58:23.228 : --31--> church_111_10.jpg | 34.52dB
25-05-22 16:58:23.308 : --32--> church_111_11.jpg | 30.70dB
25-05-22 16:58:23.384 : --33--> circular_farmland_111_00.jpg | 33.00dB
25-05-22 16:58:23.465 : --34--> circular_farmland_111_01.jpg | 33.97dB
25-05-22 16:58:23.558 : --35--> circular_farmland_111_10.jpg | 34.16dB
25-05-22 16:58:23.645 : --36--> circular_farmland_111_11.jpg | 34.26dB
25-05-22 16:58:23.726 : --37--> cloud_111_00.jpg | 41.00dB
25-05-22 16:58:23.813 : --38--> cloud_111_01.jpg | 36.83dB
25-05-22 16:58:23.905 : --39--> cloud_111_10.jpg | 36.42dB
25-05-22 16:58:23.993 : --40--> cloud_111_11.jpg | 36.95dB
25-05-22 16:58:24.072 : --41--> commercial_area_111_00.jpg | 33.37dB
25-05-22 16:58:24.164 : --42--> commercial_area_111_01.jpg | 32.45dB
25-05-22 16:58:24.241 : --43--> commercial_area_111_10.jpg | 33.26dB
25-05-22 16:58:24.319 : --44--> commercial_area_111_11.jpg | 33.11dB
25-05-22 16:58:24.403 : --45--> dense_residential_111_00.jpg | 30.43dB
25-05-22 16:58:24.491 : --46--> dense_residential_111_01.jpg | 29.47dB
25-05-22 16:58:24.575 : --47--> dense_residential_111_10.jpg | 29.94dB
25-05-22 16:58:24.657 : --48--> dense_residential_111_11.jpg | 29.76dB
25-05-22 16:58:24.737 : --49--> desert_111_00.jpg | 36.77dB
25-05-22 16:58:24.819 : --50--> desert_111_01.jpg | 36.63dB
25-05-22 16:58:24.902 : --51--> desert_111_10.jpg | 36.86dB
25-05-22 16:58:24.989 : --52--> desert_111_11.jpg | 36.91dB
25-05-22 16:58:25.070 : --53--> forest_111_00.jpg | 33.00dB
25-05-22 16:58:25.165 : --54--> forest_111_01.jpg | 32.16dB
25-05-22 16:58:25.246 : --55--> forest_111_10.jpg | 31.82dB
25-05-22 16:58:25.328 : --56--> forest_111_11.jpg | 32.77dB
25-05-22 16:58:25.433 : --57--> freeway_111_00.jpg | 33.94dB
25-05-22 16:58:25.517 : --58--> freeway_111_01.jpg | 35.29dB
25-05-22 16:58:25.601 : --59--> freeway_111_10.jpg | 35.01dB
25-05-22 16:58:25.693 : --60--> freeway_111_11.jpg | 34.91dB
25-05-22 16:58:25.800 : --61--> golf_course_111_00.jpg | 32.90dB
25-05-22 16:58:25.906 : --62--> golf_course_111_01.jpg | 32.27dB
25-05-22 16:58:25.995 : --63--> golf_course_111_10.jpg | 33.67dB
25-05-22 16:58:26.071 : --64--> golf_course_111_11.jpg | 34.14dB
25-05-22 16:58:26.162 : --65--> ground_track_field_111_00.jpg | 33.61dB
25-05-22 16:58:26.243 : --66--> ground_track_field_111_01.jpg | 29.52dB
25-05-22 16:58:26.333 : --67--> ground_track_field_111_10.jpg | 30.96dB
25-05-22 16:58:26.440 : --68--> ground_track_field_111_11.jpg | 30.11dB
25-05-22 16:58:26.546 : --69--> harbor_111_00.jpg | 32.91dB
25-05-22 16:58:26.647 : --70--> harbor_111_01.jpg | 31.36dB
25-05-22 16:58:26.729 : --71--> harbor_111_10.jpg | 30.94dB
25-05-22 16:58:26.827 : --72--> harbor_111_11.jpg | 32.50dB
25-05-22 16:58:26.945 : --73--> industrial_area_111_00.jpg | 31.79dB
25-05-22 16:58:27.038 : --74--> industrial_area_111_01.jpg | 32.05dB
25-05-22 16:58:27.131 : --75--> industrial_area_111_10.jpg | 32.20dB
25-05-22 16:58:27.212 : --76--> industrial_area_111_11.jpg | 31.61dB
25-05-22 16:58:27.290 : --77--> intersection_111_00.jpg | 30.86dB
25-05-22 16:58:27.399 : --78--> intersection_111_01.jpg | 30.98dB
25-05-22 16:58:27.492 : --79--> intersection_111_10.jpg | 30.66dB
25-05-22 16:58:27.570 : --80--> intersection_111_11.jpg | 30.46dB
25-05-22 16:58:27.661 : --81--> island_111_00.jpg | 31.58dB
25-05-22 16:58:27.756 : --82--> island_111_01.jpg | 33.88dB
25-05-22 16:58:27.857 : --83--> island_111_10.jpg | 32.70dB
25-05-22 16:58:27.934 : --84--> island_111_11.jpg | 32.13dB
25-05-22 16:58:28.016 : --85--> lake_111_00.jpg | 32.57dB
25-05-22 16:58:28.107 : --86--> lake_111_01.jpg | 32.38dB
25-05-22 16:58:28.195 : --87--> lake_111_10.jpg | 31.73dB
25-05-22 16:58:28.269 : --88--> lake_111_11.jpg | 31.08dB
25-05-22 16:58:28.354 : --89--> meadow_111_00.jpg | 30.15dB
25-05-22 16:58:28.438 : --90--> meadow_111_01.jpg | 30.23dB
25-05-22 16:58:28.517 : --91--> meadow_111_10.jpg | 30.27dB
25-05-22 16:58:28.599 : --92--> meadow_111_11.jpg | 30.42dB
25-05-22 16:58:28.676 : --93--> medium_residential_111_00.jpg | 28.95dB
25-05-22 16:58:28.775 : --94--> medium_residential_111_01.jpg | 28.40dB
25-05-22 16:58:28.850 : --95--> medium_residential_111_10.jpg | 28.78dB
25-05-22 16:58:28.931 : --96--> medium_residential_111_11.jpg | 29.30dB
25-05-22 16:58:29.013 : --97--> mobile_home_park_111_00.jpg | 31.13dB
25-05-22 16:58:29.101 : --98--> mobile_home_park_111_01.jpg | 31.67dB
25-05-22 16:58:29.192 : --99--> mobile_home_park_111_10.jpg | 31.90dB
25-05-22 16:58:29.279 : -100--> mobile_home_park_111_11.jpg | 31.96dB
25-05-22 16:58:29.383 : -101--> mountain_111_00.jpg | 28.98dB
25-05-22 16:58:29.465 : -102--> mountain_111_01.jpg | 29.67dB
25-05-22 16:58:29.537 : -103--> mountain_111_10.jpg | 29.44dB
25-05-22 16:58:29.624 : -104--> mountain_111_11.jpg | 29.75dB
25-05-22 16:58:29.698 : -105--> overpass_111_00.jpg | 30.43dB
25-05-22 16:58:29.781 : -106--> overpass_111_01.jpg | 30.10dB
25-05-22 16:58:29.862 : -107--> overpass_111_10.jpg | 30.85dB
25-05-22 16:58:29.951 : -108--> overpass_111_11.jpg | 31.46dB
25-05-22 16:58:30.028 : -109--> palace_111_00.jpg | 30.18dB
25-05-22 16:58:30.134 : -110--> palace_111_01.jpg | 30.04dB
25-05-22 16:58:30.219 : -111--> palace_111_10.jpg | 31.16dB
25-05-22 16:58:30.308 : -112--> palace_111_11.jpg | 29.52dB
25-05-22 16:58:30.393 : -113--> parking_lot_111_00.jpg | 29.49dB
25-05-22 16:58:30.484 : -114--> parking_lot_111_01.jpg | 29.82dB
25-05-22 16:58:30.574 : -115--> parking_lot_111_10.jpg | 31.37dB
25-05-22 16:58:30.653 : -116--> parking_lot_111_11.jpg | 30.18dB
25-05-22 16:58:30.762 : -117--> railway_111_00.jpg | 30.32dB
25-05-22 16:58:30.869 : -118--> railway_111_01.jpg | 29.89dB
25-05-22 16:58:30.952 : -119--> railway_111_10.jpg | 32.64dB
25-05-22 16:58:31.032 : -120--> railway_111_11.jpg | 29.34dB
25-05-22 16:58:31.116 : -121--> railway_station_111_00.jpg | 31.06dB
25-05-22 16:58:31.208 : -122--> railway_station_111_01.jpg | 31.56dB
25-05-22 16:58:31.297 : -123--> railway_station_111_10.jpg | 31.21dB
25-05-22 16:58:31.379 : -124--> railway_station_111_11.jpg | 31.77dB
25-05-22 16:58:31.496 : -125--> rectangular_farmland_111_00.jpg | 33.62dB
25-05-22 16:58:31.574 : -126--> rectangular_farmland_111_01.jpg | 31.96dB
25-05-22 16:58:31.673 : -127--> rectangular_farmland_111_10.jpg | 34.00dB
25-05-22 16:58:31.760 : -128--> rectangular_farmland_111_11.jpg | 34.29dB
25-05-22 16:58:31.836 : -129--> river_111_00.jpg | 30.33dB
25-05-22 16:58:31.926 : -130--> river_111_01.jpg | 30.08dB
25-05-22 16:58:32.010 : -131--> river_111_10.jpg | 29.69dB
25-05-22 16:58:32.097 : -132--> river_111_11.jpg | 31.45dB
25-05-22 16:58:32.173 : -133--> roundabout_111_00.jpg | 30.69dB
25-05-22 16:58:32.268 : -134--> roundabout_111_01.jpg | 32.27dB
25-05-22 16:58:32.350 : -135--> roundabout_111_10.jpg | 30.53dB
25-05-22 16:58:32.442 : -136--> roundabout_111_11.jpg | 30.98dB
25-05-22 16:58:32.536 : -137--> runway_111_00.jpg | 36.64dB
25-05-22 16:58:32.623 : -138--> runway_111_01.jpg | 35.98dB
25-05-22 16:58:32.705 : -139--> runway_111_10.jpg | 36.64dB
25-05-22 16:58:32.818 : -140--> runway_111_11.jpg | 37.72dB
25-05-22 16:58:32.912 : -141--> sea_ice_111_00.jpg | 33.78dB
25-05-22 16:58:33.004 : -142--> sea_ice_111_01.jpg | 34.73dB
25-05-22 16:58:33.077 : -143--> sea_ice_111_10.jpg | 33.85dB
25-05-22 16:58:33.153 : -144--> sea_ice_111_11.jpg | 34.85dB
25-05-22 16:58:33.230 : -145--> ship_111_00.jpg | 38.79dB
25-05-22 16:58:33.309 : -146--> ship_111_01.jpg | 34.70dB
25-05-22 16:58:33.392 : -147--> ship_111_10.jpg | 42.77dB
25-05-22 16:58:33.463 : -148--> ship_111_11.jpg | 40.17dB
25-05-22 16:58:33.538 : -149--> snowberg_111_00.jpg | 34.28dB
25-05-22 16:58:33.623 : -150--> snowberg_111_01.jpg | 33.00dB
25-05-22 16:58:33.699 : -151--> snowberg_111_10.jpg | 32.22dB
25-05-22 16:58:33.779 : -152--> snowberg_111_11.jpg | 32.16dB
25-05-22 16:58:33.856 : -153--> sparse_residential_111_00.jpg | 30.61dB
25-05-22 16:58:33.952 : -154--> sparse_residential_111_01.jpg | 30.81dB
25-05-22 16:58:34.038 : -155--> sparse_residential_111_10.jpg | 29.92dB
25-05-22 16:58:34.119 : -156--> sparse_residential_111_11.jpg | 30.12dB
25-05-22 16:58:34.198 : -157--> stadium_111_00.jpg | 30.51dB
25-05-22 16:58:34.277 : -158--> stadium_111_01.jpg | 30.27dB
25-05-22 16:58:34.354 : -159--> stadium_111_10.jpg | 31.53dB
25-05-22 16:58:34.436 : -160--> stadium_111_11.jpg | 30.33dB
25-05-22 16:58:32.063 : -161--> storage_tank_111_00.jpg | 31.83dB
25-05-22 16:58:32.135 : -162--> storage_tank_111_01.jpg | 32.17dB
25-05-22 16:58:32.209 : -163--> storage_tank_111_10.jpg | 30.88dB
25-05-22 16:58:32.299 : -164--> storage_tank_111_11.jpg | 31.44dB
25-05-22 16:58:32.385 : -165--> tennis_court_111_00.jpg | 32.29dB
25-05-22 16:58:32.458 : -166--> tennis_court_111_01.jpg | 31.70dB
25-05-22 16:58:32.537 : -167--> tennis_court_111_10.jpg | 32.14dB
25-05-22 16:58:32.623 : -168--> tennis_court_111_11.jpg | 29.81dB
25-05-22 16:58:32.714 : -169--> terrace_111_00.jpg | 32.26dB
25-05-22 16:58:32.808 : -170--> terrace_111_01.jpg | 33.39dB
25-05-22 16:58:32.895 : -171--> terrace_111_10.jpg | 32.35dB
25-05-22 16:58:32.979 : -172--> terrace_111_11.jpg | 32.43dB
25-05-22 16:58:33.070 : -173--> thermal_power_station_111_00.jpg | 30.24dB
25-05-22 16:58:33.160 : -174--> thermal_power_station_111_01.jpg | 31.75dB
25-05-22 16:58:33.261 : -175--> thermal_power_station_111_10.jpg | 30.06dB
25-05-22 16:58:33.341 : -176--> thermal_power_station_111_11.jpg | 30.65dB
25-05-22 16:58:33.419 : -177--> wetland_111_00.jpg | 31.45dB
25-05-22 16:58:33.498 : -178--> wetland_111_01.jpg | 31.52dB
25-05-22 16:58:33.578 : -179--> wetland_111_10.jpg | 31.75dB
25-05-22 16:58:33.656 : -180--> wetland_111_11.jpg | 31.08dB
25-05-22 16:58:33.666 : <epoch:  3, iter: 110,000, Average PSNR : 32.31dB

25-05-22 17:31:12.800 : <epoch:  3, iter: 120,000, lr:6.250e-06> G_loss: 9.721e-05 
25-05-22 17:31:12.800 : Saving the model.
25-05-22 17:31:13.609 : ---1--> airplane_111_00.jpg | 30.72dB
25-05-22 17:31:13.691 : ---2--> airplane_111_01.jpg | 35.59dB
25-05-22 17:31:13.759 : ---3--> airplane_111_10.jpg | 33.05dB
25-05-22 17:31:13.841 : ---4--> airplane_111_11.jpg | 33.08dB
25-05-22 17:31:13.911 : ---5--> airport_111_00.jpg | 34.66dB
25-05-22 17:31:13.990 : ---6--> airport_111_01.jpg | 32.58dB
25-05-22 17:31:14.061 : ---7--> airport_111_10.jpg | 32.12dB
25-05-22 17:31:14.139 : ---8--> airport_111_11.jpg | 33.01dB
25-05-22 17:31:14.208 : ---9--> baseball_diamond_111_00.jpg | 32.79dB
25-05-22 17:31:14.278 : --10--> baseball_diamond_111_01.jpg | 34.40dB
25-05-22 17:31:14.353 : --11--> baseball_diamond_111_10.jpg | 32.73dB
25-05-22 17:31:14.434 : --12--> baseball_diamond_111_11.jpg | 35.54dB
25-05-22 17:31:14.519 : --13--> basketball_court_111_00.jpg | 30.68dB
25-05-22 17:31:14.590 : --14--> basketball_court_111_01.jpg | 30.26dB
25-05-22 17:31:14.662 : --15--> basketball_court_111_10.jpg | 33.66dB
25-05-22 17:31:14.738 : --16--> basketball_court_111_11.jpg | 31.73dB
25-05-22 17:31:14.831 : --17--> beach_111_00.jpg | 28.83dB
25-05-22 17:31:14.899 : --18--> beach_111_01.jpg | 31.97dB
25-05-22 17:31:14.977 : --19--> beach_111_10.jpg | 29.93dB
25-05-22 17:31:15.050 : --20--> beach_111_11.jpg | 34.57dB
25-05-22 17:31:15.130 : --21--> bridge_111_00.jpg | 40.95dB
25-05-22 17:31:15.221 : --22--> bridge_111_01.jpg | 34.48dB
25-05-22 17:31:15.294 : --23--> bridge_111_10.jpg | 33.44dB
25-05-22 17:31:15.368 : --24--> bridge_111_11.jpg | 36.96dB
25-05-22 17:31:15.462 : --25--> chaparral_111_00.jpg | 30.53dB
25-05-22 17:31:15.537 : --26--> chaparral_111_01.jpg | 30.74dB
25-05-22 17:31:15.615 : --27--> chaparral_111_10.jpg | 31.07dB
25-05-22 17:31:15.693 : --28--> chaparral_111_11.jpg | 28.89dB
25-05-22 17:31:15.767 : --29--> church_111_00.jpg | 31.85dB
25-05-22 17:31:15.849 : --30--> church_111_01.jpg | 30.89dB
25-05-22 17:31:15.931 : --31--> church_111_10.jpg | 34.48dB
25-05-22 17:31:16.016 : --32--> church_111_11.jpg | 30.71dB
25-05-22 17:31:16.104 : --33--> circular_farmland_111_00.jpg | 32.92dB
25-05-22 17:31:16.181 : --34--> circular_farmland_111_01.jpg | 33.95dB
25-05-22 17:31:16.255 : --35--> circular_farmland_111_10.jpg | 34.20dB
25-05-22 17:31:16.328 : --36--> circular_farmland_111_11.jpg | 34.22dB
25-05-22 17:31:16.405 : --37--> cloud_111_00.jpg | 40.84dB
25-05-22 17:31:16.473 : --38--> cloud_111_01.jpg | 36.74dB
25-05-22 17:31:16.551 : --39--> cloud_111_10.jpg | 36.38dB
25-05-22 17:31:16.636 : --40--> cloud_111_11.jpg | 36.92dB
25-05-22 17:31:16.716 : --41--> commercial_area_111_00.jpg | 33.38dB
25-05-22 17:31:16.799 : --42--> commercial_area_111_01.jpg | 32.51dB
25-05-22 17:31:16.867 : --43--> commercial_area_111_10.jpg | 33.27dB
25-05-22 17:31:16.950 : --44--> commercial_area_111_11.jpg | 33.16dB
25-05-22 17:31:17.033 : --45--> dense_residential_111_00.jpg | 30.43dB
25-05-22 17:31:17.111 : --46--> dense_residential_111_01.jpg | 29.47dB
25-05-22 17:31:17.211 : --47--> dense_residential_111_10.jpg | 29.93dB
25-05-22 17:31:17.277 : --48--> dense_residential_111_11.jpg | 29.76dB
25-05-22 17:31:17.355 : --49--> desert_111_00.jpg | 36.71dB
25-05-22 17:31:17.427 : --50--> desert_111_01.jpg | 36.55dB
25-05-22 17:31:17.524 : --51--> desert_111_10.jpg | 36.82dB
25-05-22 17:31:17.607 : --52--> desert_111_11.jpg | 36.88dB
25-05-22 17:31:17.684 : --53--> forest_111_00.jpg | 33.05dB
25-05-22 17:31:17.777 : --54--> forest_111_01.jpg | 32.17dB
25-05-22 17:31:17.854 : --55--> forest_111_10.jpg | 31.83dB
25-05-22 17:31:17.933 : --56--> forest_111_11.jpg | 32.78dB
25-05-22 17:31:18.017 : --57--> freeway_111_00.jpg | 33.94dB
25-05-22 17:31:18.092 : --58--> freeway_111_01.jpg | 35.28dB
25-05-22 17:31:18.172 : --59--> freeway_111_10.jpg | 35.00dB
25-05-22 17:31:18.247 : --60--> freeway_111_11.jpg | 34.93dB
25-05-22 17:31:18.318 : --61--> golf_course_111_00.jpg | 32.88dB
25-05-22 17:31:18.399 : --62--> golf_course_111_01.jpg | 32.27dB
25-05-22 17:31:18.481 : --63--> golf_course_111_10.jpg | 33.65dB
25-05-22 17:31:18.559 : --64--> golf_course_111_11.jpg | 34.06dB
25-05-22 17:31:18.633 : --65--> ground_track_field_111_00.jpg | 33.63dB
25-05-22 17:31:18.711 : --66--> ground_track_field_111_01.jpg | 29.51dB
25-05-22 17:31:18.789 : --67--> ground_track_field_111_10.jpg | 30.96dB
25-05-22 17:31:18.866 : --68--> ground_track_field_111_11.jpg | 30.10dB
25-05-22 17:31:18.940 : --69--> harbor_111_00.jpg | 32.90dB
25-05-22 17:31:19.028 : --70--> harbor_111_01.jpg | 31.35dB
25-05-22 17:31:19.111 : --71--> harbor_111_10.jpg | 30.94dB
25-05-22 17:31:19.187 : --72--> harbor_111_11.jpg | 32.52dB
25-05-22 17:31:19.269 : --73--> industrial_area_111_00.jpg | 31.78dB
25-05-22 17:31:19.345 : --74--> industrial_area_111_01.jpg | 32.02dB
25-05-22 17:31:19.423 : --75--> industrial_area_111_10.jpg | 32.19dB
25-05-22 17:31:19.494 : --76--> industrial_area_111_11.jpg | 31.58dB
25-05-22 17:31:19.586 : --77--> intersection_111_00.jpg | 30.86dB
25-05-22 17:31:19.671 : --78--> intersection_111_01.jpg | 30.97dB
25-05-22 17:31:19.752 : --79--> intersection_111_10.jpg | 30.67dB
25-05-22 17:31:19.847 : --80--> intersection_111_11.jpg | 30.47dB
25-05-22 17:31:19.922 : --81--> island_111_00.jpg | 31.58dB
25-05-22 17:31:20.009 : --82--> island_111_01.jpg | 33.93dB
25-05-22 17:31:20.082 : --83--> island_111_10.jpg | 32.69dB
25-05-22 17:31:20.158 : --84--> island_111_11.jpg | 32.12dB
25-05-22 17:31:20.244 : --85--> lake_111_00.jpg | 32.55dB
25-05-22 17:31:20.318 : --86--> lake_111_01.jpg | 32.36dB
25-05-22 17:31:20.404 : --87--> lake_111_10.jpg | 31.72dB
25-05-22 17:31:20.473 : --88--> lake_111_11.jpg | 31.07dB
25-05-22 17:31:20.545 : --89--> meadow_111_00.jpg | 30.15dB
25-05-22 17:31:20.630 : --90--> meadow_111_01.jpg | 30.22dB
25-05-22 17:31:20.712 : --91--> meadow_111_10.jpg | 30.26dB
25-05-22 17:31:20.802 : --92--> meadow_111_11.jpg | 30.41dB
25-05-22 17:31:20.877 : --93--> medium_residential_111_00.jpg | 28.95dB
25-05-22 17:31:20.964 : --94--> medium_residential_111_01.jpg | 28.39dB
25-05-22 17:31:21.036 : --95--> medium_residential_111_10.jpg | 28.78dB
25-05-22 17:31:21.120 : --96--> medium_residential_111_11.jpg | 29.30dB
25-05-22 17:31:21.195 : --97--> mobile_home_park_111_00.jpg | 31.13dB
25-05-22 17:31:21.283 : --98--> mobile_home_park_111_01.jpg | 31.67dB
25-05-22 17:31:21.352 : --99--> mobile_home_park_111_10.jpg | 31.90dB
25-05-22 17:31:21.442 : -100--> mobile_home_park_111_11.jpg | 31.96dB
25-05-22 17:31:21.511 : -101--> mountain_111_00.jpg | 28.98dB
25-05-22 17:31:21.598 : -102--> mountain_111_01.jpg | 29.67dB
25-05-22 17:31:21.678 : -103--> mountain_111_10.jpg | 29.44dB
25-05-22 17:31:21.774 : -104--> mountain_111_11.jpg | 29.76dB
25-05-22 17:31:21.854 : -105--> overpass_111_00.jpg | 30.43dB
25-05-22 17:31:21.927 : -106--> overpass_111_01.jpg | 30.14dB
25-05-22 17:31:22.006 : -107--> overpass_111_10.jpg | 30.86dB
25-05-22 17:31:22.080 : -108--> overpass_111_11.jpg | 31.45dB
25-05-22 17:31:22.164 : -109--> palace_111_00.jpg | 30.16dB
25-05-22 17:31:22.239 : -110--> palace_111_01.jpg | 30.04dB
25-05-22 17:31:22.319 : -111--> palace_111_10.jpg | 31.15dB
25-05-22 17:31:22.389 : -112--> palace_111_11.jpg | 29.53dB
25-05-22 17:31:22.467 : -113--> parking_lot_111_00.jpg | 29.50dB
25-05-22 17:31:22.553 : -114--> parking_lot_111_01.jpg | 29.82dB
25-05-22 17:31:22.623 : -115--> parking_lot_111_10.jpg | 31.34dB
25-05-22 17:31:22.692 : -116--> parking_lot_111_11.jpg | 30.18dB
25-05-22 17:31:22.764 : -117--> railway_111_00.jpg | 30.33dB
25-05-22 17:31:22.847 : -118--> railway_111_01.jpg | 29.90dB
25-05-22 17:31:22.924 : -119--> railway_111_10.jpg | 32.65dB
25-05-22 17:31:22.997 : -120--> railway_111_11.jpg | 29.34dB
25-05-22 17:31:23.067 : -121--> railway_station_111_00.jpg | 31.06dB
25-05-22 17:31:23.145 : -122--> railway_station_111_01.jpg | 31.56dB
25-05-22 17:31:23.218 : -123--> railway_station_111_10.jpg | 31.19dB
25-05-22 17:31:23.286 : -124--> railway_station_111_11.jpg | 31.73dB
25-05-22 17:31:23.378 : -125--> rectangular_farmland_111_00.jpg | 33.60dB
25-05-22 17:31:23.456 : -126--> rectangular_farmland_111_01.jpg | 31.94dB
25-05-22 17:31:23.525 : -127--> rectangular_farmland_111_10.jpg | 33.97dB
25-05-22 17:31:23.596 : -128--> rectangular_farmland_111_11.jpg | 34.26dB
25-05-22 17:31:23.677 : -129--> river_111_00.jpg | 30.33dB
25-05-22 17:31:23.746 : -130--> river_111_01.jpg | 30.09dB
25-05-22 17:31:23.814 : -131--> river_111_10.jpg | 29.68dB
25-05-22 17:31:23.891 : -132--> river_111_11.jpg | 31.44dB
25-05-22 17:31:23.963 : -133--> roundabout_111_00.jpg | 30.69dB
25-05-22 17:31:24.033 : -134--> roundabout_111_01.jpg | 32.27dB
25-05-22 17:31:24.107 : -135--> roundabout_111_10.jpg | 30.52dB
25-05-22 17:31:24.184 : -136--> roundabout_111_11.jpg | 30.98dB
25-05-22 17:31:24.256 : -137--> runway_111_00.jpg | 36.67dB
25-05-22 17:31:24.328 : -138--> runway_111_01.jpg | 36.01dB
25-05-22 17:31:24.398 : -139--> runway_111_10.jpg | 36.68dB
25-05-22 17:31:24.475 : -140--> runway_111_11.jpg | 37.66dB
25-05-22 17:31:24.547 : -141--> sea_ice_111_00.jpg | 33.78dB
25-05-22 17:31:24.619 : -142--> sea_ice_111_01.jpg | 34.77dB
25-05-22 17:31:24.719 : -143--> sea_ice_111_10.jpg | 33.85dB
25-05-22 17:31:24.794 : -144--> sea_ice_111_11.jpg | 34.83dB
25-05-22 17:31:24.869 : -145--> ship_111_00.jpg | 38.80dB
25-05-22 17:31:24.960 : -146--> ship_111_01.jpg | 34.71dB
25-05-22 17:31:25.038 : -147--> ship_111_10.jpg | 42.79dB
25-05-22 17:31:25.119 : -148--> ship_111_11.jpg | 40.22dB
25-05-22 17:31:25.194 : -149--> snowberg_111_00.jpg | 34.35dB
25-05-22 17:31:25.261 : -150--> snowberg_111_01.jpg | 32.97dB
25-05-22 17:31:25.335 : -151--> snowberg_111_10.jpg | 32.21dB
25-05-22 17:31:25.417 : -152--> snowberg_111_11.jpg | 32.13dB
25-05-22 17:31:25.487 : -153--> sparse_residential_111_00.jpg | 30.60dB
25-05-22 17:31:25.560 : -154--> sparse_residential_111_01.jpg | 30.80dB
25-05-22 17:31:25.630 : -155--> sparse_residential_111_10.jpg | 29.92dB
25-05-22 17:31:25.707 : -156--> sparse_residential_111_11.jpg | 30.12dB
25-05-22 17:31:25.785 : -157--> stadium_111_00.jpg | 30.51dB
25-05-22 17:31:25.859 : -158--> stadium_111_01.jpg | 30.28dB
25-05-22 17:31:25.929 : -159--> stadium_111_10.jpg | 31.54dB
25-05-22 17:31:26.004 : -160--> stadium_111_11.jpg | 30.33dB
25-05-22 17:31:26.082 : -161--> storage_tank_111_00.jpg | 31.92dB
25-05-22 17:31:26.175 : -162--> storage_tank_111_01.jpg | 32.16dB
25-05-22 17:31:26.257 : -163--> storage_tank_111_10.jpg | 30.90dB
25-05-22 17:31:26.329 : -164--> storage_tank_111_11.jpg | 31.44dB
25-05-22 17:31:26.411 : -165--> tennis_court_111_00.jpg | 32.30dB
25-05-22 17:31:26.483 : -166--> tennis_court_111_01.jpg | 31.70dB
25-05-22 17:31:26.565 : -167--> tennis_court_111_10.jpg | 32.14dB
25-05-22 17:31:26.642 : -168--> tennis_court_111_11.jpg | 29.81dB
25-05-22 17:31:26.728 : -169--> terrace_111_00.jpg | 32.32dB
25-05-22 17:31:26.805 : -170--> terrace_111_01.jpg | 33.42dB
25-05-22 17:31:26.882 : -171--> terrace_111_10.jpg | 32.35dB
25-05-22 17:31:26.968 : -172--> terrace_111_11.jpg | 32.39dB
25-05-22 17:31:27.043 : -173--> thermal_power_station_111_00.jpg | 30.23dB
25-05-22 17:31:27.130 : -174--> thermal_power_station_111_01.jpg | 31.74dB
25-05-22 17:31:27.208 : -175--> thermal_power_station_111_10.jpg | 30.04dB
25-05-22 17:31:27.281 : -176--> thermal_power_station_111_11.jpg | 30.64dB
25-05-22 17:31:27.366 : -177--> wetland_111_00.jpg | 31.44dB
25-05-22 17:31:27.437 : -178--> wetland_111_01.jpg | 31.51dB
25-05-22 17:31:27.508 : -179--> wetland_111_10.jpg | 31.73dB
25-05-22 17:31:27.586 : -180--> wetland_111_11.jpg | 31.07dB
25-05-22 17:31:27.595 : <epoch:  3, iter: 120,000, Average PSNR : 32.31dB

25-05-22 18:04:17.918 : <epoch:  4, iter: 130,000, lr:1.250e-05> G_loss: 8.909e-05 
25-05-22 18:04:17.919 : Saving the model.
25-05-22 18:04:18.529 : ---1--> airplane_111_00.jpg | 30.76dB
25-05-22 18:04:18.614 : ---2--> airplane_111_01.jpg | 35.58dB
25-05-22 18:04:18.699 : ---3--> airplane_111_10.jpg | 33.08dB
25-05-22 18:04:18.771 : ---4--> airplane_111_11.jpg | 33.17dB
25-05-22 18:04:18.848 : ---5--> airport_111_00.jpg | 34.66dB
25-05-22 18:04:18.925 : ---6--> airport_111_01.jpg | 32.59dB
25-05-22 18:04:19.002 : ---7--> airport_111_10.jpg | 32.14dB
25-05-22 18:04:19.077 : ---8--> airport_111_11.jpg | 33.01dB
25-05-22 18:04:19.142 : ---9--> baseball_diamond_111_00.jpg | 32.81dB
25-05-22 18:04:19.215 : --10--> baseball_diamond_111_01.jpg | 34.45dB
25-05-22 18:04:19.287 : --11--> baseball_diamond_111_10.jpg | 32.75dB
25-05-22 18:04:19.359 : --12--> baseball_diamond_111_11.jpg | 35.59dB
25-05-22 18:04:19.434 : --13--> basketball_court_111_00.jpg | 30.70dB
25-05-22 18:04:19.520 : --14--> basketball_court_111_01.jpg | 30.27dB
25-05-22 18:04:19.589 : --15--> basketball_court_111_10.jpg | 33.67dB
25-05-22 18:04:19.658 : --16--> basketball_court_111_11.jpg | 31.74dB
25-05-22 18:04:19.734 : --17--> beach_111_00.jpg | 28.86dB
25-05-22 18:04:19.801 : --18--> beach_111_01.jpg | 31.98dB
25-05-22 18:04:19.876 : --19--> beach_111_10.jpg | 29.93dB
25-05-22 18:04:19.951 : --20--> beach_111_11.jpg | 34.58dB
25-05-22 18:04:20.023 : --21--> bridge_111_00.jpg | 40.99dB
25-05-22 18:04:20.103 : --22--> bridge_111_01.jpg | 34.52dB
25-05-22 18:04:20.181 : --23--> bridge_111_10.jpg | 33.45dB
25-05-22 18:04:20.262 : --24--> bridge_111_11.jpg | 37.03dB
25-05-22 18:04:20.334 : --25--> chaparral_111_00.jpg | 30.55dB
25-05-22 18:04:20.424 : --26--> chaparral_111_01.jpg | 30.77dB
25-05-22 18:04:20.546 : --27--> chaparral_111_10.jpg | 31.09dB
25-05-22 18:04:20.608 : --28--> chaparral_111_11.jpg | 28.89dB
25-05-22 18:04:20.683 : --29--> church_111_00.jpg | 31.88dB
25-05-22 18:04:20.769 : --30--> church_111_01.jpg | 30.90dB
25-05-22 18:04:20.835 : --31--> church_111_10.jpg | 34.61dB
25-05-22 18:04:20.932 : --32--> church_111_11.jpg | 30.72dB
25-05-22 18:04:21.010 : --33--> circular_farmland_111_00.jpg | 33.01dB
25-05-22 18:04:21.112 : --34--> circular_farmland_111_01.jpg | 33.97dB
25-05-22 18:04:21.192 : --35--> circular_farmland_111_10.jpg | 34.23dB
25-05-22 18:04:21.275 : --36--> circular_farmland_111_11.jpg | 34.27dB
25-05-22 18:04:21.347 : --37--> cloud_111_00.jpg | 41.10dB
25-05-22 18:04:21.409 : --38--> cloud_111_01.jpg | 36.85dB
25-05-22 18:04:21.477 : --39--> cloud_111_10.jpg | 36.44dB
25-05-22 18:04:21.552 : --40--> cloud_111_11.jpg | 36.98dB
25-05-22 18:04:21.643 : --41--> commercial_area_111_00.jpg | 33.39dB
25-05-22 18:04:21.716 : --42--> commercial_area_111_01.jpg | 32.50dB
25-05-22 18:04:21.795 : --43--> commercial_area_111_10.jpg | 33.26dB
25-05-22 18:04:21.878 : --44--> commercial_area_111_11.jpg | 33.16dB
25-05-22 18:04:21.972 : --45--> dense_residential_111_00.jpg | 30.44dB
25-05-22 18:04:22.043 : --46--> dense_residential_111_01.jpg | 29.49dB
25-05-22 18:04:22.116 : --47--> dense_residential_111_10.jpg | 29.95dB
25-05-22 18:04:22.199 : --48--> dense_residential_111_11.jpg | 29.77dB
25-05-22 18:04:22.276 : --49--> desert_111_00.jpg | 36.78dB
25-05-22 18:04:22.354 : --50--> desert_111_01.jpg | 36.63dB
25-05-22 18:04:22.438 : --51--> desert_111_10.jpg | 36.87dB
25-05-22 18:04:22.518 : --52--> desert_111_11.jpg | 36.96dB
25-05-22 18:04:22.600 : --53--> forest_111_00.jpg | 33.06dB
25-05-22 18:04:22.682 : --54--> forest_111_01.jpg | 32.18dB
25-05-22 18:04:22.750 : --55--> forest_111_10.jpg | 31.84dB
25-05-22 18:04:22.821 : --56--> forest_111_11.jpg | 32.80dB
25-05-22 18:04:22.893 : --57--> freeway_111_00.jpg | 33.97dB
25-05-22 18:04:22.967 : --58--> freeway_111_01.jpg | 35.30dB
25-05-22 18:04:23.045 : --59--> freeway_111_10.jpg | 35.04dB
25-05-22 18:04:23.126 : --60--> freeway_111_11.jpg | 34.93dB
25-05-22 18:04:23.191 : --61--> golf_course_111_00.jpg | 32.89dB
25-05-22 18:04:23.275 : --62--> golf_course_111_01.jpg | 32.28dB
25-05-22 18:04:23.349 : --63--> golf_course_111_10.jpg | 33.67dB
25-05-22 18:04:23.420 : --64--> golf_course_111_11.jpg | 34.13dB
25-05-22 18:04:23.487 : --65--> ground_track_field_111_00.jpg | 33.64dB
25-05-22 18:04:23.563 : --66--> ground_track_field_111_01.jpg | 29.53dB
25-05-22 18:04:23.629 : --67--> ground_track_field_111_10.jpg | 30.97dB
25-05-22 18:04:23.694 : --68--> ground_track_field_111_11.jpg | 30.11dB
25-05-22 18:04:23.764 : --69--> harbor_111_00.jpg | 32.96dB
25-05-22 18:04:23.833 : --70--> harbor_111_01.jpg | 31.36dB
25-05-22 18:04:23.903 : --71--> harbor_111_10.jpg | 30.94dB
25-05-22 18:04:23.971 : --72--> harbor_111_11.jpg | 32.55dB
25-05-22 18:04:24.067 : --73--> industrial_area_111_00.jpg | 31.81dB
25-05-22 18:04:24.138 : --74--> industrial_area_111_01.jpg | 32.05dB
25-05-22 18:04:24.214 : --75--> industrial_area_111_10.jpg | 32.21dB
25-05-22 18:04:24.285 : --76--> industrial_area_111_11.jpg | 31.61dB
25-05-22 18:04:24.347 : --77--> intersection_111_00.jpg | 30.88dB
25-05-22 18:04:24.425 : --78--> intersection_111_01.jpg | 30.98dB
25-05-22 18:04:24.493 : --79--> intersection_111_10.jpg | 30.69dB
25-05-22 18:04:24.561 : --80--> intersection_111_11.jpg | 30.47dB
25-05-22 18:04:24.632 : --81--> island_111_00.jpg | 31.60dB
25-05-22 18:04:24.701 : --82--> island_111_01.jpg | 33.96dB
25-05-22 18:04:24.777 : --83--> island_111_10.jpg | 32.70dB
25-05-22 18:04:24.843 : --84--> island_111_11.jpg | 32.15dB
25-05-22 18:04:24.924 : --85--> lake_111_00.jpg | 32.56dB
25-05-22 18:04:24.994 : --86--> lake_111_01.jpg | 32.39dB
25-05-22 18:04:25.080 : --87--> lake_111_10.jpg | 31.72dB
25-05-22 18:04:25.170 : --88--> lake_111_11.jpg | 31.09dB
25-05-22 18:04:25.246 : --89--> meadow_111_00.jpg | 30.16dB
25-05-22 18:04:25.308 : --90--> meadow_111_01.jpg | 30.24dB
25-05-22 18:04:25.380 : --91--> meadow_111_10.jpg | 30.28dB
25-05-22 18:04:25.453 : --92--> meadow_111_11.jpg | 30.42dB
25-05-22 18:04:25.536 : --93--> medium_residential_111_00.jpg | 28.96dB
25-05-22 18:04:25.612 : --94--> medium_residential_111_01.jpg | 28.40dB
25-05-22 18:04:25.707 : --95--> medium_residential_111_10.jpg | 28.78dB
25-05-22 18:04:25.775 : --96--> medium_residential_111_11.jpg | 29.30dB
25-05-22 18:04:25.853 : --97--> mobile_home_park_111_00.jpg | 31.15dB
25-05-22 18:04:25.927 : --98--> mobile_home_park_111_01.jpg | 31.66dB
25-05-22 18:04:25.997 : --99--> mobile_home_park_111_10.jpg | 31.93dB
25-05-22 18:04:26.066 : -100--> mobile_home_park_111_11.jpg | 31.99dB
25-05-22 18:04:26.154 : -101--> mountain_111_00.jpg | 28.98dB
25-05-22 18:04:26.237 : -102--> mountain_111_01.jpg | 29.69dB
25-05-22 18:04:26.329 : -103--> mountain_111_10.jpg | 29.45dB
25-05-22 18:04:26.405 : -104--> mountain_111_11.jpg | 29.77dB
25-05-22 18:04:26.476 : -105--> overpass_111_00.jpg | 30.45dB
25-05-22 18:04:26.544 : -106--> overpass_111_01.jpg | 30.18dB
25-05-22 18:04:26.621 : -107--> overpass_111_10.jpg | 30.86dB
25-05-22 18:04:26.694 : -108--> overpass_111_11.jpg | 31.46dB
25-05-22 18:04:26.763 : -109--> palace_111_00.jpg | 30.17dB
25-05-22 18:04:26.840 : -110--> palace_111_01.jpg | 30.05dB
25-05-22 18:04:26.912 : -111--> palace_111_10.jpg | 31.16dB
25-05-22 18:04:26.987 : -112--> palace_111_11.jpg | 29.53dB
25-05-22 18:04:27.060 : -113--> parking_lot_111_00.jpg | 29.50dB
25-05-22 18:04:27.126 : -114--> parking_lot_111_01.jpg | 29.83dB
25-05-22 18:04:27.195 : -115--> parking_lot_111_10.jpg | 31.38dB
25-05-22 18:04:27.266 : -116--> parking_lot_111_11.jpg | 30.20dB
25-05-22 18:04:27.350 : -117--> railway_111_00.jpg | 30.33dB
25-05-22 18:04:27.419 : -118--> railway_111_01.jpg | 29.92dB
25-05-22 18:04:27.495 : -119--> railway_111_10.jpg | 32.68dB
25-05-22 18:04:27.563 : -120--> railway_111_11.jpg | 29.35dB
25-05-22 18:04:27.630 : -121--> railway_station_111_00.jpg | 31.08dB
25-05-22 18:04:27.701 : -122--> railway_station_111_01.jpg | 31.56dB
25-05-22 18:04:27.773 : -123--> railway_station_111_10.jpg | 31.20dB
25-05-22 18:04:27.850 : -124--> railway_station_111_11.jpg | 31.76dB
25-05-22 18:04:27.922 : -125--> rectangular_farmland_111_00.jpg | 33.63dB
25-05-22 18:04:27.989 : -126--> rectangular_farmland_111_01.jpg | 31.94dB
25-05-22 18:04:28.058 : -127--> rectangular_farmland_111_10.jpg | 34.01dB
25-05-22 18:04:28.128 : -128--> rectangular_farmland_111_11.jpg | 34.32dB
25-05-22 18:04:28.195 : -129--> river_111_00.jpg | 30.34dB
25-05-22 18:04:28.284 : -130--> river_111_01.jpg | 30.10dB
25-05-22 18:04:28.351 : -131--> river_111_10.jpg | 29.70dB
25-05-22 18:04:28.417 : -132--> river_111_11.jpg | 31.45dB
25-05-22 18:04:28.485 : -133--> roundabout_111_00.jpg | 30.69dB
25-05-22 18:04:28.553 : -134--> roundabout_111_01.jpg | 32.28dB
25-05-22 18:04:28.632 : -135--> roundabout_111_10.jpg | 30.55dB
25-05-22 18:04:28.711 : -136--> roundabout_111_11.jpg | 30.99dB
25-05-22 18:04:28.774 : -137--> runway_111_00.jpg | 36.66dB
25-05-22 18:04:28.847 : -138--> runway_111_01.jpg | 36.03dB
25-05-22 18:04:28.927 : -139--> runway_111_10.jpg | 36.68dB
25-05-22 18:04:28.993 : -140--> runway_111_11.jpg | 37.71dB
25-05-22 18:04:29.071 : -141--> sea_ice_111_00.jpg | 33.80dB
25-05-22 18:04:29.144 : -142--> sea_ice_111_01.jpg | 34.80dB
25-05-22 18:04:29.215 : -143--> sea_ice_111_10.jpg | 33.89dB
25-05-22 18:04:29.289 : -144--> sea_ice_111_11.jpg | 34.88dB
25-05-22 18:04:29.362 : -145--> ship_111_00.jpg | 38.84dB
25-05-22 18:04:29.434 : -146--> ship_111_01.jpg | 34.71dB
25-05-22 18:04:29.504 : -147--> ship_111_10.jpg | 42.83dB
25-05-22 18:04:29.579 : -148--> ship_111_11.jpg | 40.22dB
25-05-22 18:04:29.649 : -149--> snowberg_111_00.jpg | 34.34dB
25-05-22 18:04:29.725 : -150--> snowberg_111_01.jpg | 33.00dB
25-05-22 18:04:29.794 : -151--> snowberg_111_10.jpg | 32.24dB
25-05-22 18:04:29.858 : -152--> snowberg_111_11.jpg | 32.17dB
25-05-22 18:04:29.937 : -153--> sparse_residential_111_00.jpg | 30.63dB
25-05-22 18:04:30.013 : -154--> sparse_residential_111_01.jpg | 30.81dB
25-05-22 18:04:30.078 : -155--> sparse_residential_111_10.jpg | 29.93dB
25-05-22 18:04:30.152 : -156--> sparse_residential_111_11.jpg | 30.12dB
25-05-22 18:04:30.220 : -157--> stadium_111_00.jpg | 30.51dB
25-05-22 18:04:30.286 : -158--> stadium_111_01.jpg | 30.29dB
25-05-22 18:04:30.355 : -159--> stadium_111_10.jpg | 31.55dB
25-05-22 18:04:30.425 : -160--> stadium_111_11.jpg | 30.34dB
25-05-22 18:04:30.500 : -161--> storage_tank_111_00.jpg | 31.93dB
25-05-22 18:04:30.579 : -162--> storage_tank_111_01.jpg | 32.18dB
25-05-22 18:04:30.641 : -163--> storage_tank_111_10.jpg | 30.92dB
25-05-22 18:04:30.714 : -164--> storage_tank_111_11.jpg | 31.44dB
25-05-22 18:04:30.790 : -165--> tennis_court_111_00.jpg | 32.32dB
25-05-22 18:04:30.858 : -166--> tennis_court_111_01.jpg | 31.71dB
25-05-22 18:04:30.941 : -167--> tennis_court_111_10.jpg | 32.16dB
25-05-22 18:04:31.007 : -168--> tennis_court_111_11.jpg | 29.81dB
25-05-22 18:04:31.073 : -169--> terrace_111_00.jpg | 32.26dB
25-05-22 18:04:31.136 : -170--> terrace_111_01.jpg | 33.46dB
25-05-22 18:04:31.201 : -171--> terrace_111_10.jpg | 32.35dB
25-05-22 18:04:31.285 : -172--> terrace_111_11.jpg | 32.42dB
25-05-22 18:04:31.374 : -173--> thermal_power_station_111_00.jpg | 30.23dB
25-05-22 18:04:31.437 : -174--> thermal_power_station_111_01.jpg | 31.74dB
25-05-22 18:04:31.506 : -175--> thermal_power_station_111_10.jpg | 30.05dB
25-05-22 18:04:31.575 : -176--> thermal_power_station_111_11.jpg | 30.66dB
25-05-22 18:04:31.646 : -177--> wetland_111_00.jpg | 31.45dB
25-05-22 18:04:31.725 : -178--> wetland_111_01.jpg | 31.51dB
25-05-22 18:04:31.788 : -179--> wetland_111_10.jpg | 31.75dB
25-05-22 18:04:31.866 : -180--> wetland_111_11.jpg | 31.08dB
25-05-22 18:04:31.876 : <epoch:  4, iter: 130,000, Average PSNR : 32.33dB

25-05-22 18:36:32.288 : <epoch:  4, iter: 140,000, lr:1.250e-05> G_loss: 5.371e-05 
25-05-22 18:36:32.289 : Saving the model.
25-05-22 18:36:32.911 : ---1--> airplane_111_00.jpg | 30.75dB
25-05-22 18:36:32.980 : ---2--> airplane_111_01.jpg | 35.59dB
25-05-22 18:36:33.053 : ---3--> airplane_111_10.jpg | 33.11dB
25-05-22 18:36:33.118 : ---4--> airplane_111_11.jpg | 33.16dB
25-05-22 18:36:33.205 : ---5--> airport_111_00.jpg | 34.67dB
25-05-22 18:36:33.277 : ---6--> airport_111_01.jpg | 32.58dB
25-05-22 18:36:33.339 : ---7--> airport_111_10.jpg | 32.14dB
25-05-22 18:36:33.415 : ---8--> airport_111_11.jpg | 33.02dB
25-05-22 18:36:33.487 : ---9--> baseball_diamond_111_00.jpg | 32.83dB
25-05-22 18:36:33.566 : --10--> baseball_diamond_111_01.jpg | 34.47dB
25-05-22 18:36:33.641 : --11--> baseball_diamond_111_10.jpg | 32.75dB
25-05-22 18:36:33.720 : --12--> baseball_diamond_111_11.jpg | 35.56dB
25-05-22 18:36:33.784 : --13--> basketball_court_111_00.jpg | 30.69dB
25-05-22 18:36:33.864 : --14--> basketball_court_111_01.jpg | 30.28dB
25-05-22 18:36:33.929 : --15--> basketball_court_111_10.jpg | 33.68dB
25-05-22 18:36:34.002 : --16--> basketball_court_111_11.jpg | 31.74dB
25-05-22 18:36:34.086 : --17--> beach_111_00.jpg | 28.86dB
25-05-22 18:36:34.161 : --18--> beach_111_01.jpg | 31.97dB
25-05-22 18:36:34.233 : --19--> beach_111_10.jpg | 29.93dB
25-05-22 18:36:34.319 : --20--> beach_111_11.jpg | 34.57dB
25-05-22 18:36:34.388 : --21--> bridge_111_00.jpg | 41.01dB
25-05-22 18:36:34.467 : --22--> bridge_111_01.jpg | 34.52dB
25-05-22 18:36:34.551 : --23--> bridge_111_10.jpg | 33.47dB
25-05-22 18:36:34.642 : --24--> bridge_111_11.jpg | 37.03dB
25-05-22 18:36:34.730 : --25--> chaparral_111_00.jpg | 30.55dB
25-05-22 18:36:34.794 : --26--> chaparral_111_01.jpg | 30.77dB
25-05-22 18:36:34.863 : --27--> chaparral_111_10.jpg | 31.10dB
25-05-22 18:36:34.932 : --28--> chaparral_111_11.jpg | 28.90dB
25-05-22 18:36:35.019 : --29--> church_111_00.jpg | 31.88dB
25-05-22 18:36:35.109 : --30--> church_111_01.jpg | 30.89dB
25-05-22 18:36:35.202 : --31--> church_111_10.jpg | 34.49dB
25-05-22 18:36:35.279 : --32--> church_111_11.jpg | 30.73dB
25-05-22 18:36:35.354 : --33--> circular_farmland_111_00.jpg | 33.01dB
25-05-22 18:36:35.421 : --34--> circular_farmland_111_01.jpg | 34.02dB
25-05-22 18:36:35.496 : --35--> circular_farmland_111_10.jpg | 34.22dB
25-05-22 18:36:35.567 : --36--> circular_farmland_111_11.jpg | 34.26dB
25-05-22 18:36:35.644 : --37--> cloud_111_00.jpg | 41.13dB
25-05-22 18:36:35.718 : --38--> cloud_111_01.jpg | 36.87dB
25-05-22 18:36:35.790 : --39--> cloud_111_10.jpg | 36.47dB
25-05-22 18:36:35.857 : --40--> cloud_111_11.jpg | 36.96dB
25-05-22 18:36:35.927 : --41--> commercial_area_111_00.jpg | 33.41dB
25-05-22 18:36:36.001 : --42--> commercial_area_111_01.jpg | 32.55dB
25-05-22 18:36:36.074 : --43--> commercial_area_111_10.jpg | 33.24dB
25-05-22 18:36:36.138 : --44--> commercial_area_111_11.jpg | 33.19dB
25-05-22 18:36:36.245 : --45--> dense_residential_111_00.jpg | 30.43dB
25-05-22 18:36:36.311 : --46--> dense_residential_111_01.jpg | 29.49dB
25-05-22 18:36:36.389 : --47--> dense_residential_111_10.jpg | 29.94dB
25-05-22 18:36:36.454 : --48--> dense_residential_111_11.jpg | 29.77dB
25-05-22 18:36:36.521 : --49--> desert_111_00.jpg | 36.79dB
25-05-22 18:36:36.592 : --50--> desert_111_01.jpg | 36.62dB
25-05-22 18:36:36.658 : --51--> desert_111_10.jpg | 36.87dB
25-05-22 18:36:36.725 : --52--> desert_111_11.jpg | 36.93dB
25-05-22 18:36:36.810 : --53--> forest_111_00.jpg | 33.06dB
25-05-22 18:36:36.882 : --54--> forest_111_01.jpg | 32.19dB
25-05-22 18:36:36.951 : --55--> forest_111_10.jpg | 31.84dB
25-05-22 18:36:37.032 : --56--> forest_111_11.jpg | 32.79dB
25-05-22 18:36:37.108 : --57--> freeway_111_00.jpg | 33.96dB
25-05-22 18:36:37.175 : --58--> freeway_111_01.jpg | 35.35dB
25-05-22 18:36:37.246 : --59--> freeway_111_10.jpg | 35.07dB
25-05-22 18:36:37.334 : --60--> freeway_111_11.jpg | 34.95dB
25-05-22 18:36:37.412 : --61--> golf_course_111_00.jpg | 32.89dB
25-05-22 18:36:37.491 : --62--> golf_course_111_01.jpg | 32.27dB
25-05-22 18:36:37.556 : --63--> golf_course_111_10.jpg | 33.67dB
25-05-22 18:36:37.633 : --64--> golf_course_111_11.jpg | 34.13dB
25-05-22 18:36:37.717 : --65--> ground_track_field_111_00.jpg | 33.63dB
25-05-22 18:36:37.808 : --66--> ground_track_field_111_01.jpg | 29.52dB
25-05-22 18:36:37.887 : --67--> ground_track_field_111_10.jpg | 30.96dB
25-05-22 18:36:37.955 : --68--> ground_track_field_111_11.jpg | 30.11dB
25-05-22 18:36:38.038 : --69--> harbor_111_00.jpg | 32.96dB
25-05-22 18:36:38.113 : --70--> harbor_111_01.jpg | 31.37dB
25-05-22 18:36:38.178 : --71--> harbor_111_10.jpg | 30.94dB
25-05-22 18:36:38.244 : --72--> harbor_111_11.jpg | 32.60dB
25-05-22 18:36:38.324 : --73--> industrial_area_111_00.jpg | 31.80dB
25-05-22 18:36:38.396 : --74--> industrial_area_111_01.jpg | 32.05dB
25-05-22 18:36:38.467 : --75--> industrial_area_111_10.jpg | 32.21dB
25-05-22 18:36:38.545 : --76--> industrial_area_111_11.jpg | 31.62dB
25-05-22 18:36:38.616 : --77--> intersection_111_00.jpg | 30.86dB
25-05-22 18:36:38.681 : --78--> intersection_111_01.jpg | 30.97dB
25-05-22 18:36:38.755 : --79--> intersection_111_10.jpg | 30.68dB
25-05-22 18:36:38.833 : --80--> intersection_111_11.jpg | 30.48dB
25-05-22 18:36:38.902 : --81--> island_111_00.jpg | 31.59dB
25-05-22 18:36:38.969 : --82--> island_111_01.jpg | 33.96dB
25-05-22 18:36:39.040 : --83--> island_111_10.jpg | 32.73dB
25-05-22 18:36:39.111 : --84--> island_111_11.jpg | 32.17dB
25-05-22 18:36:39.181 : --85--> lake_111_00.jpg | 32.57dB
25-05-22 18:36:39.249 : --86--> lake_111_01.jpg | 32.40dB
25-05-22 18:36:39.323 : --87--> lake_111_10.jpg | 31.72dB
25-05-22 18:36:39.393 : --88--> lake_111_11.jpg | 31.09dB
25-05-22 18:36:39.464 : --89--> meadow_111_00.jpg | 30.16dB
25-05-22 18:36:39.532 : --90--> meadow_111_01.jpg | 30.24dB
25-05-22 18:36:39.600 : --91--> meadow_111_10.jpg | 30.27dB
25-05-22 18:36:39.676 : --92--> meadow_111_11.jpg | 30.42dB
25-05-22 18:36:39.755 : --93--> medium_residential_111_00.jpg | 28.96dB
25-05-22 18:36:39.834 : --94--> medium_residential_111_01.jpg | 28.41dB
25-05-22 18:36:39.912 : --95--> medium_residential_111_10.jpg | 28.78dB
25-05-22 18:36:39.980 : --96--> medium_residential_111_11.jpg | 29.31dB
25-05-22 18:36:40.053 : --97--> mobile_home_park_111_00.jpg | 31.15dB
25-05-22 18:36:40.117 : --98--> mobile_home_park_111_01.jpg | 31.68dB
25-05-22 18:36:40.200 : --99--> mobile_home_park_111_10.jpg | 31.93dB
25-05-22 18:36:40.269 : -100--> mobile_home_park_111_11.jpg | 31.97dB
25-05-22 18:36:40.344 : -101--> mountain_111_00.jpg | 28.98dB
25-05-22 18:36:40.421 : -102--> mountain_111_01.jpg | 29.68dB
25-05-22 18:36:40.487 : -103--> mountain_111_10.jpg | 29.44dB
25-05-22 18:36:40.566 : -104--> mountain_111_11.jpg | 29.77dB
25-05-22 18:36:40.646 : -105--> overpass_111_00.jpg | 30.46dB
25-05-22 18:36:40.708 : -106--> overpass_111_01.jpg | 30.13dB
25-05-22 18:36:40.772 : -107--> overpass_111_10.jpg | 30.83dB
25-05-22 18:36:40.837 : -108--> overpass_111_11.jpg | 31.45dB
25-05-22 18:36:40.911 : -109--> palace_111_00.jpg | 30.16dB
25-05-22 18:36:40.981 : -110--> palace_111_01.jpg | 30.05dB
25-05-22 18:36:41.063 : -111--> palace_111_10.jpg | 31.15dB
25-05-22 18:36:41.138 : -112--> palace_111_11.jpg | 29.53dB
25-05-22 18:36:41.204 : -113--> parking_lot_111_00.jpg | 29.51dB
25-05-22 18:36:41.290 : -114--> parking_lot_111_01.jpg | 29.85dB
25-05-22 18:36:41.368 : -115--> parking_lot_111_10.jpg | 31.38dB
25-05-22 18:36:41.433 : -116--> parking_lot_111_11.jpg | 30.19dB
25-05-22 18:36:41.511 : -117--> railway_111_00.jpg | 30.33dB
25-05-22 18:36:41.588 : -118--> railway_111_01.jpg | 29.92dB
25-05-22 18:36:41.658 : -119--> railway_111_10.jpg | 32.69dB
25-05-22 18:36:41.729 : -120--> railway_111_11.jpg | 29.34dB
25-05-22 18:36:41.804 : -121--> railway_station_111_00.jpg | 31.08dB
25-05-22 18:36:41.871 : -122--> railway_station_111_01.jpg | 31.54dB
25-05-22 18:36:41.944 : -123--> railway_station_111_10.jpg | 31.20dB
25-05-22 18:36:42.024 : -124--> railway_station_111_11.jpg | 31.75dB
25-05-22 18:36:42.117 : -125--> rectangular_farmland_111_00.jpg | 33.63dB
25-05-22 18:36:42.200 : -126--> rectangular_farmland_111_01.jpg | 32.07dB
25-05-22 18:36:42.271 : -127--> rectangular_farmland_111_10.jpg | 33.97dB
25-05-22 18:36:42.344 : -128--> rectangular_farmland_111_11.jpg | 34.33dB
25-05-22 18:36:42.415 : -129--> river_111_00.jpg | 30.35dB
25-05-22 18:36:42.481 : -130--> river_111_01.jpg | 30.09dB
25-05-22 18:36:42.554 : -131--> river_111_10.jpg | 29.69dB
25-05-22 18:36:42.627 : -132--> river_111_11.jpg | 31.45dB
25-05-22 18:36:42.694 : -133--> roundabout_111_00.jpg | 30.70dB
25-05-22 18:36:42.763 : -134--> roundabout_111_01.jpg | 32.26dB
25-05-22 18:36:42.848 : -135--> roundabout_111_10.jpg | 30.53dB
25-05-22 18:36:42.925 : -136--> roundabout_111_11.jpg | 31.00dB
25-05-22 18:36:42.992 : -137--> runway_111_00.jpg | 36.71dB
25-05-22 18:36:43.069 : -138--> runway_111_01.jpg | 36.05dB
25-05-22 18:36:43.141 : -139--> runway_111_10.jpg | 36.67dB
25-05-22 18:36:43.226 : -140--> runway_111_11.jpg | 37.70dB
25-05-22 18:36:43.309 : -141--> sea_ice_111_00.jpg | 33.79dB
25-05-22 18:36:43.376 : -142--> sea_ice_111_01.jpg | 34.82dB
25-05-22 18:36:43.445 : -143--> sea_ice_111_10.jpg | 33.87dB
25-05-22 18:36:43.509 : -144--> sea_ice_111_11.jpg | 34.86dB
25-05-22 18:36:43.580 : -145--> ship_111_00.jpg | 38.83dB
25-05-22 18:36:43.649 : -146--> ship_111_01.jpg | 34.72dB
25-05-22 18:36:43.733 : -147--> ship_111_10.jpg | 42.85dB
25-05-22 18:36:43.808 : -148--> ship_111_11.jpg | 40.23dB
25-05-22 18:36:43.871 : -149--> snowberg_111_00.jpg | 34.30dB
25-05-22 18:36:43.951 : -150--> snowberg_111_01.jpg | 33.00dB
25-05-22 18:36:44.032 : -151--> snowberg_111_10.jpg | 32.23dB
25-05-22 18:36:44.103 : -152--> snowberg_111_11.jpg | 32.17dB
25-05-22 18:36:44.173 : -153--> sparse_residential_111_00.jpg | 30.62dB
25-05-22 18:36:44.243 : -154--> sparse_residential_111_01.jpg | 30.81dB
25-05-22 18:36:44.324 : -155--> sparse_residential_111_10.jpg | 29.92dB
25-05-22 18:36:44.393 : -156--> sparse_residential_111_11.jpg | 30.13dB
25-05-22 18:36:44.456 : -157--> stadium_111_00.jpg | 30.51dB
25-05-22 18:36:44.528 : -158--> stadium_111_01.jpg | 30.29dB
25-05-22 18:36:44.597 : -159--> stadium_111_10.jpg | 31.55dB
25-05-22 18:36:44.679 : -160--> stadium_111_11.jpg | 30.33dB
25-05-22 18:36:44.772 : -161--> storage_tank_111_00.jpg | 31.94dB
25-05-22 18:36:44.840 : -162--> storage_tank_111_01.jpg | 32.17dB
25-05-22 18:36:44.909 : -163--> storage_tank_111_10.jpg | 30.87dB
25-05-22 18:36:44.977 : -164--> storage_tank_111_11.jpg | 31.44dB
25-05-22 18:36:45.048 : -165--> tennis_court_111_00.jpg | 32.33dB
25-05-22 18:36:45.114 : -166--> tennis_court_111_01.jpg | 31.71dB
25-05-22 18:36:45.198 : -167--> tennis_court_111_10.jpg | 32.15dB
25-05-22 18:36:45.268 : -168--> tennis_court_111_11.jpg | 29.80dB
25-05-22 18:36:45.335 : -169--> terrace_111_00.jpg | 32.27dB
25-05-22 18:36:45.413 : -170--> terrace_111_01.jpg | 33.47dB
25-05-22 18:36:45.489 : -171--> terrace_111_10.jpg | 32.37dB
25-05-22 18:36:45.568 : -172--> terrace_111_11.jpg | 32.44dB
25-05-22 18:36:45.637 : -173--> thermal_power_station_111_00.jpg | 30.17dB
25-05-22 18:36:45.706 : -174--> thermal_power_station_111_01.jpg | 31.75dB
25-05-22 18:36:45.778 : -175--> thermal_power_station_111_10.jpg | 30.06dB
25-05-22 18:36:45.849 : -176--> thermal_power_station_111_11.jpg | 30.65dB
25-05-22 18:36:45.920 : -177--> wetland_111_00.jpg | 31.45dB
25-05-22 18:36:45.987 : -178--> wetland_111_01.jpg | 31.51dB
25-05-22 18:36:46.049 : -179--> wetland_111_10.jpg | 31.74dB
25-05-22 18:36:46.119 : -180--> wetland_111_11.jpg | 31.09dB
25-05-22 18:36:46.128 : <epoch:  4, iter: 140,000, Average PSNR : 32.33dB

25-05-22 19:08:50.550 : <epoch:  4, iter: 150,000, lr:1.250e-05> G_loss: 4.208e-05 
25-05-22 19:08:50.552 : Saving the model.
25-05-22 19:08:51.243 : ---1--> airplane_111_00.jpg | 30.74dB
25-05-22 19:08:51.319 : ---2--> airplane_111_01.jpg | 35.60dB
25-05-22 19:08:51.385 : ---3--> airplane_111_10.jpg | 33.11dB
25-05-22 19:08:51.456 : ---4--> airplane_111_11.jpg | 33.16dB
25-05-22 19:08:51.520 : ---5--> airport_111_00.jpg | 34.68dB
25-05-22 19:08:51.591 : ---6--> airport_111_01.jpg | 32.59dB
25-05-22 19:08:51.669 : ---7--> airport_111_10.jpg | 32.14dB
25-05-22 19:08:51.762 : ---8--> airport_111_11.jpg | 33.02dB
25-05-22 19:08:51.827 : ---9--> baseball_diamond_111_00.jpg | 32.83dB
25-05-22 19:08:51.889 : --10--> baseball_diamond_111_01.jpg | 34.46dB
25-05-22 19:08:51.993 : --11--> baseball_diamond_111_10.jpg | 32.75dB
25-05-22 19:08:52.082 : --12--> baseball_diamond_111_11.jpg | 35.60dB
25-05-22 19:08:52.155 : --13--> basketball_court_111_00.jpg | 30.70dB
25-05-22 19:08:52.232 : --14--> basketball_court_111_01.jpg | 30.27dB
25-05-22 19:08:52.310 : --15--> basketball_court_111_10.jpg | 33.68dB
25-05-22 19:08:52.380 : --16--> basketball_court_111_11.jpg | 31.73dB
25-05-22 19:08:52.452 : --17--> beach_111_00.jpg | 28.86dB
25-05-22 19:08:52.522 : --18--> beach_111_01.jpg | 31.97dB
25-05-22 19:08:52.598 : --19--> beach_111_10.jpg | 29.94dB
25-05-22 19:08:52.676 : --20--> beach_111_11.jpg | 34.59dB
25-05-22 19:08:52.753 : --21--> bridge_111_00.jpg | 40.95dB
25-05-22 19:08:52.832 : --22--> bridge_111_01.jpg | 34.53dB
25-05-22 19:08:52.906 : --23--> bridge_111_10.jpg | 33.46dB
25-05-22 19:08:52.983 : --24--> bridge_111_11.jpg | 37.00dB
25-05-22 19:08:53.060 : --25--> chaparral_111_00.jpg | 30.54dB
25-05-22 19:08:53.146 : --26--> chaparral_111_01.jpg | 30.77dB
25-05-22 19:08:53.217 : --27--> chaparral_111_10.jpg | 31.10dB
25-05-22 19:08:53.293 : --28--> chaparral_111_11.jpg | 28.89dB
25-05-22 19:08:53.361 : --29--> church_111_00.jpg | 31.88dB
25-05-22 19:08:53.444 : --30--> church_111_01.jpg | 30.90dB
25-05-22 19:08:53.517 : --31--> church_111_10.jpg | 34.54dB
25-05-22 19:08:53.604 : --32--> church_111_11.jpg | 30.72dB
25-05-22 19:08:53.688 : --33--> circular_farmland_111_00.jpg | 33.01dB
25-05-22 19:08:53.776 : --34--> circular_farmland_111_01.jpg | 33.98dB
25-05-22 19:08:53.855 : --35--> circular_farmland_111_10.jpg | 34.22dB
25-05-22 19:08:53.923 : --36--> circular_farmland_111_11.jpg | 34.24dB
25-05-22 19:08:53.993 : --37--> cloud_111_00.jpg | 41.03dB
25-05-22 19:08:54.059 : --38--> cloud_111_01.jpg | 36.84dB
25-05-22 19:08:54.139 : --39--> cloud_111_10.jpg | 36.44dB
25-05-22 19:08:54.222 : --40--> cloud_111_11.jpg | 36.97dB
25-05-22 19:08:54.291 : --41--> commercial_area_111_00.jpg | 33.39dB
25-05-22 19:08:54.360 : --42--> commercial_area_111_01.jpg | 32.54dB
25-05-22 19:08:54.427 : --43--> commercial_area_111_10.jpg | 33.26dB
25-05-22 19:08:54.519 : --44--> commercial_area_111_11.jpg | 33.19dB
25-05-22 19:08:54.593 : --45--> dense_residential_111_00.jpg | 30.45dB
25-05-22 19:08:54.668 : --46--> dense_residential_111_01.jpg | 29.50dB
25-05-22 19:08:54.747 : --47--> dense_residential_111_10.jpg | 29.95dB
25-05-22 19:08:54.816 : --48--> dense_residential_111_11.jpg | 29.79dB
25-05-22 19:08:54.887 : --49--> desert_111_00.jpg | 36.77dB
25-05-22 19:08:54.964 : --50--> desert_111_01.jpg | 36.62dB
25-05-22 19:08:55.037 : --51--> desert_111_10.jpg | 36.86dB
25-05-22 19:08:55.103 : --52--> desert_111_11.jpg | 36.92dB
25-05-22 19:08:55.176 : --53--> forest_111_00.jpg | 33.06dB
25-05-22 19:08:55.256 : --54--> forest_111_01.jpg | 32.18dB
25-05-22 19:08:55.326 : --55--> forest_111_10.jpg | 31.84dB
25-05-22 19:08:55.400 : --56--> forest_111_11.jpg | 32.81dB
25-05-22 19:08:55.465 : --57--> freeway_111_00.jpg | 33.98dB
25-05-22 19:08:55.543 : --58--> freeway_111_01.jpg | 35.31dB
25-05-22 19:08:55.631 : --59--> freeway_111_10.jpg | 35.05dB
25-05-22 19:08:55.718 : --60--> freeway_111_11.jpg | 34.93dB
25-05-22 19:08:55.782 : --61--> golf_course_111_00.jpg | 32.90dB
25-05-22 19:08:55.863 : --62--> golf_course_111_01.jpg | 32.28dB
25-05-22 19:08:55.937 : --63--> golf_course_111_10.jpg | 33.68dB
25-05-22 19:08:56.010 : --64--> golf_course_111_11.jpg | 34.15dB
25-05-22 19:08:56.076 : --65--> ground_track_field_111_00.jpg | 33.63dB
25-05-22 19:08:56.147 : --66--> ground_track_field_111_01.jpg | 29.53dB
25-05-22 19:08:56.235 : --67--> ground_track_field_111_10.jpg | 30.97dB
25-05-22 19:08:56.328 : --68--> ground_track_field_111_11.jpg | 30.12dB
25-05-22 19:08:56.390 : --69--> harbor_111_00.jpg | 32.97dB
25-05-22 19:08:56.464 : --70--> harbor_111_01.jpg | 31.37dB
25-05-22 19:08:56.542 : --71--> harbor_111_10.jpg | 30.95dB
25-05-22 19:08:56.625 : --72--> harbor_111_11.jpg | 32.58dB
25-05-22 19:08:56.707 : --73--> industrial_area_111_00.jpg | 31.81dB
25-05-22 19:08:56.788 : --74--> industrial_area_111_01.jpg | 32.05dB
25-05-22 19:08:56.863 : --75--> industrial_area_111_10.jpg | 32.20dB
25-05-22 19:08:56.945 : --76--> industrial_area_111_11.jpg | 31.63dB
25-05-22 19:08:57.024 : --77--> intersection_111_00.jpg | 30.88dB
25-05-22 19:08:57.100 : --78--> intersection_111_01.jpg | 30.97dB
25-05-22 19:08:57.166 : --79--> intersection_111_10.jpg | 30.69dB
25-05-22 19:08:57.246 : --80--> intersection_111_11.jpg | 30.48dB
25-05-22 19:08:57.313 : --81--> island_111_00.jpg | 31.58dB
25-05-22 19:08:57.383 : --82--> island_111_01.jpg | 33.95dB
25-05-22 19:08:57.458 : --83--> island_111_10.jpg | 32.72dB
25-05-22 19:08:57.527 : --84--> island_111_11.jpg | 32.14dB
25-05-22 19:08:57.595 : --85--> lake_111_00.jpg | 32.57dB
25-05-22 19:08:57.687 : --86--> lake_111_01.jpg | 32.40dB
25-05-22 19:08:57.757 : --87--> lake_111_10.jpg | 31.73dB
25-05-22 19:08:57.839 : --88--> lake_111_11.jpg | 31.09dB
25-05-22 19:08:57.919 : --89--> meadow_111_00.jpg | 30.16dB
25-05-22 19:08:57.982 : --90--> meadow_111_01.jpg | 30.24dB
25-05-22 19:08:58.056 : --91--> meadow_111_10.jpg | 30.27dB
25-05-22 19:08:58.146 : --92--> meadow_111_11.jpg | 30.43dB
25-05-22 19:08:58.215 : --93--> medium_residential_111_00.jpg | 28.96dB
25-05-22 19:08:58.298 : --94--> medium_residential_111_01.jpg | 28.40dB
25-05-22 19:08:58.366 : --95--> medium_residential_111_10.jpg | 28.79dB
25-05-22 19:08:58.443 : --96--> medium_residential_111_11.jpg | 29.30dB
25-05-22 19:08:58.511 : --97--> mobile_home_park_111_00.jpg | 31.14dB
25-05-22 19:08:58.582 : --98--> mobile_home_park_111_01.jpg | 31.68dB
25-05-22 19:08:58.658 : --99--> mobile_home_park_111_10.jpg | 31.94dB
25-05-22 19:08:58.723 : -100--> mobile_home_park_111_11.jpg | 31.97dB
25-05-22 19:08:58.795 : -101--> mountain_111_00.jpg | 28.98dB
25-05-22 19:08:58.868 : -102--> mountain_111_01.jpg | 29.68dB
25-05-22 19:08:58.935 : -103--> mountain_111_10.jpg | 29.44dB
25-05-22 19:08:59.020 : -104--> mountain_111_11.jpg | 29.77dB
25-05-22 19:08:59.113 : -105--> overpass_111_00.jpg | 30.46dB
25-05-22 19:08:59.187 : -106--> overpass_111_01.jpg | 30.13dB
25-05-22 19:08:59.267 : -107--> overpass_111_10.jpg | 30.86dB
25-05-22 19:08:59.344 : -108--> overpass_111_11.jpg | 31.45dB
25-05-22 19:08:59.414 : -109--> palace_111_00.jpg | 30.18dB
25-05-22 19:08:59.488 : -110--> palace_111_01.jpg | 30.05dB
25-05-22 19:08:59.568 : -111--> palace_111_10.jpg | 31.14dB
25-05-22 19:08:59.636 : -112--> palace_111_11.jpg | 29.53dB
25-05-22 19:08:59.729 : -113--> parking_lot_111_00.jpg | 29.52dB
25-05-22 19:08:59.800 : -114--> parking_lot_111_01.jpg | 29.83dB
25-05-22 19:08:59.872 : -115--> parking_lot_111_10.jpg | 31.38dB
25-05-22 19:08:59.951 : -116--> parking_lot_111_11.jpg | 30.21dB
25-05-22 19:09:00.024 : -117--> railway_111_00.jpg | 30.34dB
25-05-22 19:09:00.094 : -118--> railway_111_01.jpg | 29.93dB
25-05-22 19:09:00.169 : -119--> railway_111_10.jpg | 32.69dB
25-05-22 19:09:00.234 : -120--> railway_111_11.jpg | 29.37dB
25-05-22 19:09:00.306 : -121--> railway_station_111_00.jpg | 31.09dB
25-05-22 19:09:00.376 : -122--> railway_station_111_01.jpg | 31.56dB
25-05-22 19:09:00.445 : -123--> railway_station_111_10.jpg | 31.21dB
25-05-22 19:09:00.527 : -124--> railway_station_111_11.jpg | 31.77dB
25-05-22 19:09:00.601 : -125--> rectangular_farmland_111_00.jpg | 33.62dB
25-05-22 19:09:00.670 : -126--> rectangular_farmland_111_01.jpg | 32.11dB
25-05-22 19:09:00.750 : -127--> rectangular_farmland_111_10.jpg | 33.96dB
25-05-22 19:09:00.818 : -128--> rectangular_farmland_111_11.jpg | 34.25dB
25-05-22 19:09:00.886 : -129--> river_111_00.jpg | 30.34dB
25-05-22 19:09:00.969 : -130--> river_111_01.jpg | 30.09dB
25-05-22 19:09:01.039 : -131--> river_111_10.jpg | 29.70dB
25-05-22 19:09:01.137 : -132--> river_111_11.jpg | 31.45dB
25-05-22 19:09:01.207 : -133--> roundabout_111_00.jpg | 30.69dB
25-05-22 19:09:01.289 : -134--> roundabout_111_01.jpg | 32.27dB
25-05-22 19:09:01.370 : -135--> roundabout_111_10.jpg | 30.53dB
25-05-22 19:09:01.450 : -136--> roundabout_111_11.jpg | 30.93dB
25-05-22 19:09:01.515 : -137--> runway_111_00.jpg | 36.67dB
25-05-22 19:09:01.586 : -138--> runway_111_01.jpg | 36.03dB
25-05-22 19:09:01.654 : -139--> runway_111_10.jpg | 36.65dB
25-05-22 19:09:01.724 : -140--> runway_111_11.jpg | 37.68dB
25-05-22 19:09:01.797 : -141--> sea_ice_111_00.jpg | 33.81dB
25-05-22 19:09:01.873 : -142--> sea_ice_111_01.jpg | 34.78dB
25-05-22 19:09:01.949 : -143--> sea_ice_111_10.jpg | 33.88dB
25-05-22 19:09:02.014 : -144--> sea_ice_111_11.jpg | 34.88dB
25-05-22 19:09:02.088 : -145--> ship_111_00.jpg | 38.82dB
25-05-22 19:09:02.165 : -146--> ship_111_01.jpg | 34.69dB
25-05-22 19:09:02.241 : -147--> ship_111_10.jpg | 42.78dB
25-05-22 19:09:02.326 : -148--> ship_111_11.jpg | 40.20dB
25-05-22 19:09:02.410 : -149--> snowberg_111_00.jpg | 34.34dB
25-05-22 19:09:02.491 : -150--> snowberg_111_01.jpg | 32.99dB
25-05-22 19:09:02.573 : -151--> snowberg_111_10.jpg | 32.24dB
25-05-22 19:09:02.650 : -152--> snowberg_111_11.jpg | 32.15dB
25-05-22 19:09:02.721 : -153--> sparse_residential_111_00.jpg | 30.63dB
25-05-22 19:09:02.788 : -154--> sparse_residential_111_01.jpg | 30.82dB
25-05-22 19:09:02.867 : -155--> sparse_residential_111_10.jpg | 29.92dB
25-05-22 19:09:02.942 : -156--> sparse_residential_111_11.jpg | 30.12dB
25-05-22 19:09:03.022 : -157--> stadium_111_00.jpg | 30.50dB
25-05-22 19:09:03.091 : -158--> stadium_111_01.jpg | 30.28dB
25-05-22 19:09:03.182 : -159--> stadium_111_10.jpg | 31.54dB
25-05-22 19:09:03.273 : -160--> stadium_111_11.jpg | 30.34dB
25-05-22 19:09:03.344 : -161--> storage_tank_111_00.jpg | 31.94dB
25-05-22 19:09:03.447 : -162--> storage_tank_111_01.jpg | 32.16dB
25-05-22 19:09:03.521 : -163--> storage_tank_111_10.jpg | 30.89dB
25-05-22 19:09:03.586 : -164--> storage_tank_111_11.jpg | 31.43dB
25-05-22 19:09:03.682 : -165--> tennis_court_111_00.jpg | 32.32dB
25-05-22 19:09:03.755 : -166--> tennis_court_111_01.jpg | 31.71dB
25-05-22 19:09:03.821 : -167--> tennis_court_111_10.jpg | 32.16dB
25-05-22 19:09:03.891 : -168--> tennis_court_111_11.jpg | 29.82dB
25-05-22 19:09:03.963 : -169--> terrace_111_00.jpg | 32.28dB
25-05-22 19:09:04.039 : -170--> terrace_111_01.jpg | 33.46dB
25-05-22 19:09:04.115 : -171--> terrace_111_10.jpg | 32.36dB
25-05-22 19:09:04.196 : -172--> terrace_111_11.jpg | 32.43dB
25-05-22 19:09:04.275 : -173--> thermal_power_station_111_00.jpg | 30.23dB
25-05-22 19:09:04.348 : -174--> thermal_power_station_111_01.jpg | 31.76dB
25-05-22 19:09:04.417 : -175--> thermal_power_station_111_10.jpg | 30.06dB
25-05-22 19:09:04.509 : -176--> thermal_power_station_111_11.jpg | 30.65dB
25-05-22 19:09:04.574 : -177--> wetland_111_00.jpg | 31.45dB
25-05-22 19:09:04.663 : -178--> wetland_111_01.jpg | 31.52dB
25-05-22 19:09:04.727 : -179--> wetland_111_10.jpg | 31.75dB
25-05-22 19:09:04.788 : -180--> wetland_111_11.jpg | 31.09dB
25-05-22 19:09:04.798 : <epoch:  4, iter: 150,000, Average PSNR : 32.33dB

25-05-22 19:41:01.231 : <epoch:  5, iter: 160,000, lr:1.250e-05> G_loss: 1.106e-04 
25-05-22 19:41:01.231 : Saving the model.
25-05-22 19:41:01.851 : ---1--> airplane_111_00.jpg | 30.74dB
25-05-22 19:41:01.918 : ---2--> airplane_111_01.jpg | 35.55dB
25-05-22 19:41:01.981 : ---3--> airplane_111_10.jpg | 33.07dB
25-05-22 19:41:02.068 : ---4--> airplane_111_11.jpg | 33.20dB
25-05-22 19:41:02.146 : ---5--> airport_111_00.jpg | 34.69dB
25-05-22 19:41:02.211 : ---6--> airport_111_01.jpg | 32.59dB
25-05-22 19:41:02.286 : ---7--> airport_111_10.jpg | 32.14dB
25-05-22 19:41:02.349 : ---8--> airport_111_11.jpg | 33.03dB
25-05-22 19:41:02.422 : ---9--> baseball_diamond_111_00.jpg | 32.85dB
25-05-22 19:41:02.491 : --10--> baseball_diamond_111_01.jpg | 34.47dB
25-05-22 19:41:02.555 : --11--> baseball_diamond_111_10.jpg | 32.75dB
25-05-22 19:41:02.630 : --12--> baseball_diamond_111_11.jpg | 35.58dB
25-05-22 19:41:02.708 : --13--> basketball_court_111_00.jpg | 30.69dB
25-05-22 19:41:02.774 : --14--> basketball_court_111_01.jpg | 30.27dB
25-05-22 19:41:02.848 : --15--> basketball_court_111_10.jpg | 33.65dB
25-05-22 19:41:02.926 : --16--> basketball_court_111_11.jpg | 31.74dB
25-05-22 19:41:02.995 : --17--> beach_111_00.jpg | 28.86dB
25-05-22 19:41:03.065 : --18--> beach_111_01.jpg | 31.98dB
25-05-22 19:41:03.133 : --19--> beach_111_10.jpg | 29.94dB
25-05-22 19:41:03.202 : --20--> beach_111_11.jpg | 34.60dB
25-05-22 19:41:03.273 : --21--> bridge_111_00.jpg | 40.99dB
25-05-22 19:41:03.350 : --22--> bridge_111_01.jpg | 34.54dB
25-05-22 19:41:03.437 : --23--> bridge_111_10.jpg | 33.45dB
25-05-22 19:41:03.503 : --24--> bridge_111_11.jpg | 37.01dB
25-05-22 19:41:03.566 : --25--> chaparral_111_00.jpg | 30.54dB
25-05-22 19:41:03.628 : --26--> chaparral_111_01.jpg | 30.77dB
25-05-22 19:41:03.697 : --27--> chaparral_111_10.jpg | 31.09dB
25-05-22 19:41:03.771 : --28--> chaparral_111_11.jpg | 28.90dB
25-05-22 19:41:03.840 : --29--> church_111_00.jpg | 31.87dB
25-05-22 19:41:03.913 : --30--> church_111_01.jpg | 30.88dB
25-05-22 19:41:03.997 : --31--> church_111_10.jpg | 34.60dB
25-05-22 19:41:04.064 : --32--> church_111_11.jpg | 30.73dB
25-05-22 19:41:04.133 : --33--> circular_farmland_111_00.jpg | 33.02dB
25-05-22 19:41:04.215 : --34--> circular_farmland_111_01.jpg | 34.02dB
25-05-22 19:41:04.298 : --35--> circular_farmland_111_10.jpg | 34.21dB
25-05-22 19:41:04.370 : --36--> circular_farmland_111_11.jpg | 34.25dB
25-05-22 19:41:04.440 : --37--> cloud_111_00.jpg | 41.10dB
25-05-22 19:41:04.511 : --38--> cloud_111_01.jpg | 36.85dB
25-05-22 19:41:04.581 : --39--> cloud_111_10.jpg | 36.44dB
25-05-22 19:41:04.647 : --40--> cloud_111_11.jpg | 36.99dB
25-05-22 19:41:04.713 : --41--> commercial_area_111_00.jpg | 33.39dB
25-05-22 19:41:04.788 : --42--> commercial_area_111_01.jpg | 32.55dB
25-05-22 19:41:04.881 : --43--> commercial_area_111_10.jpg | 33.26dB
25-05-22 19:41:04.951 : --44--> commercial_area_111_11.jpg | 33.20dB
25-05-22 19:41:05.021 : --45--> dense_residential_111_00.jpg | 30.43dB
25-05-22 19:41:05.087 : --46--> dense_residential_111_01.jpg | 29.48dB
25-05-22 19:41:05.153 : --47--> dense_residential_111_10.jpg | 29.95dB
25-05-22 19:41:05.219 : --48--> dense_residential_111_11.jpg | 29.77dB
25-05-22 19:41:05.284 : --49--> desert_111_00.jpg | 36.78dB
25-05-22 19:41:05.348 : --50--> desert_111_01.jpg | 36.60dB
25-05-22 19:41:05.428 : --51--> desert_111_10.jpg | 36.85dB
25-05-22 19:41:05.494 : --52--> desert_111_11.jpg | 36.90dB
25-05-22 19:41:05.559 : --53--> forest_111_00.jpg | 33.06dB
25-05-22 19:41:05.653 : --54--> forest_111_01.jpg | 32.17dB
25-05-22 19:41:05.720 : --55--> forest_111_10.jpg | 31.83dB
25-05-22 19:41:05.790 : --56--> forest_111_11.jpg | 32.81dB
25-05-22 19:41:05.862 : --57--> freeway_111_00.jpg | 33.96dB
25-05-22 19:41:05.934 : --58--> freeway_111_01.jpg | 35.33dB
25-05-22 19:41:06.003 : --59--> freeway_111_10.jpg | 35.07dB
25-05-22 19:41:06.070 : --60--> freeway_111_11.jpg | 34.94dB
25-05-22 19:41:06.139 : --61--> golf_course_111_00.jpg | 32.90dB
25-05-22 19:41:06.215 : --62--> golf_course_111_01.jpg | 32.28dB
25-05-22 19:41:06.302 : --63--> golf_course_111_10.jpg | 33.67dB
25-05-22 19:41:06.373 : --64--> golf_course_111_11.jpg | 34.15dB
25-05-22 19:41:06.440 : --65--> ground_track_field_111_00.jpg | 33.63dB
25-05-22 19:41:06.505 : --66--> ground_track_field_111_01.jpg | 29.52dB
25-05-22 19:41:06.576 : --67--> ground_track_field_111_10.jpg | 30.97dB
25-05-22 19:41:06.641 : --68--> ground_track_field_111_11.jpg | 30.12dB
25-05-22 19:41:06.716 : --69--> harbor_111_00.jpg | 32.97dB
25-05-22 19:41:06.779 : --70--> harbor_111_01.jpg | 31.37dB
25-05-22 19:41:06.850 : --71--> harbor_111_10.jpg | 30.95dB
25-05-22 19:41:06.921 : --72--> harbor_111_11.jpg | 32.62dB
25-05-22 19:41:06.989 : --73--> industrial_area_111_00.jpg | 31.82dB
25-05-22 19:41:07.054 : --74--> industrial_area_111_01.jpg | 32.06dB
25-05-22 19:41:07.122 : --75--> industrial_area_111_10.jpg | 32.20dB
25-05-22 19:41:07.194 : --76--> industrial_area_111_11.jpg | 31.61dB
25-05-22 19:41:07.260 : --77--> intersection_111_00.jpg | 30.88dB
25-05-22 19:41:07.331 : --78--> intersection_111_01.jpg | 30.97dB
25-05-22 19:41:07.407 : --79--> intersection_111_10.jpg | 30.68dB
25-05-22 19:41:07.471 : --80--> intersection_111_11.jpg | 30.48dB
25-05-22 19:41:07.540 : --81--> island_111_00.jpg | 31.58dB
25-05-22 19:41:07.613 : --82--> island_111_01.jpg | 33.95dB
25-05-22 19:41:07.684 : --83--> island_111_10.jpg | 32.71dB
25-05-22 19:41:07.762 : --84--> island_111_11.jpg | 32.14dB
25-05-22 19:41:07.824 : --85--> lake_111_00.jpg | 32.57dB
25-05-22 19:41:07.899 : --86--> lake_111_01.jpg | 32.41dB
25-05-22 19:41:07.967 : --87--> lake_111_10.jpg | 31.72dB
25-05-22 19:41:08.036 : --88--> lake_111_11.jpg | 31.10dB
25-05-22 19:41:08.102 : --89--> meadow_111_00.jpg | 30.16dB
25-05-22 19:41:08.180 : --90--> meadow_111_01.jpg | 30.24dB
25-05-22 19:41:08.244 : --91--> meadow_111_10.jpg | 30.27dB
25-05-22 19:41:08.310 : --92--> meadow_111_11.jpg | 30.43dB
25-05-22 19:41:08.377 : --93--> medium_residential_111_00.jpg | 28.96dB
25-05-22 19:41:08.447 : --94--> medium_residential_111_01.jpg | 28.41dB
25-05-22 19:41:08.516 : --95--> medium_residential_111_10.jpg | 28.78dB
25-05-22 19:41:08.581 : --96--> medium_residential_111_11.jpg | 29.31dB
25-05-22 19:41:08.655 : --97--> mobile_home_park_111_00.jpg | 31.14dB
25-05-22 19:41:08.728 : --98--> mobile_home_park_111_01.jpg | 31.69dB
25-05-22 19:41:08.804 : --99--> mobile_home_park_111_10.jpg | 31.93dB
25-05-22 19:41:08.868 : -100--> mobile_home_park_111_11.jpg | 31.98dB
25-05-22 19:41:08.939 : -101--> mountain_111_00.jpg | 28.98dB
25-05-22 19:41:09.013 : -102--> mountain_111_01.jpg | 29.68dB
25-05-22 19:41:09.080 : -103--> mountain_111_10.jpg | 29.44dB
25-05-22 19:41:09.147 : -104--> mountain_111_11.jpg | 29.76dB
25-05-22 19:41:09.218 : -105--> overpass_111_00.jpg | 30.45dB
25-05-22 19:41:09.286 : -106--> overpass_111_01.jpg | 30.18dB
25-05-22 19:41:09.348 : -107--> overpass_111_10.jpg | 30.87dB
25-05-22 19:41:09.427 : -108--> overpass_111_11.jpg | 31.46dB
25-05-22 19:41:09.500 : -109--> palace_111_00.jpg | 30.15dB
25-05-22 19:41:09.575 : -110--> palace_111_01.jpg | 30.05dB
25-05-22 19:41:09.641 : -111--> palace_111_10.jpg | 31.16dB
25-05-22 19:41:09.710 : -112--> palace_111_11.jpg | 29.53dB
25-05-22 19:41:09.780 : -113--> parking_lot_111_00.jpg | 29.51dB
25-05-22 19:41:09.866 : -114--> parking_lot_111_01.jpg | 29.84dB
25-05-22 19:41:09.933 : -115--> parking_lot_111_10.jpg | 31.39dB
25-05-22 19:41:10.010 : -116--> parking_lot_111_11.jpg | 30.21dB
25-05-22 19:41:10.078 : -117--> railway_111_00.jpg | 30.34dB
25-05-22 19:41:10.146 : -118--> railway_111_01.jpg | 29.94dB
25-05-22 19:41:10.217 : -119--> railway_111_10.jpg | 32.70dB
25-05-22 19:41:10.302 : -120--> railway_111_11.jpg | 29.35dB
25-05-22 19:41:10.366 : -121--> railway_station_111_00.jpg | 31.09dB
25-05-22 19:41:10.436 : -122--> railway_station_111_01.jpg | 31.55dB
25-05-22 19:41:10.510 : -123--> railway_station_111_10.jpg | 31.20dB
25-05-22 19:41:10.581 : -124--> railway_station_111_11.jpg | 31.76dB
25-05-22 19:41:10.650 : -125--> rectangular_farmland_111_00.jpg | 33.62dB
25-05-22 19:41:10.719 : -126--> rectangular_farmland_111_01.jpg | 32.12dB
25-05-22 19:41:10.792 : -127--> rectangular_farmland_111_10.jpg | 33.98dB
25-05-22 19:41:10.869 : -128--> rectangular_farmland_111_11.jpg | 34.32dB
25-05-22 19:41:10.936 : -129--> river_111_00.jpg | 30.33dB
25-05-22 19:41:10.998 : -130--> river_111_01.jpg | 30.10dB
25-05-22 19:41:11.068 : -131--> river_111_10.jpg | 29.69dB
25-05-22 19:41:11.135 : -132--> river_111_11.jpg | 31.45dB
25-05-22 19:41:11.198 : -133--> roundabout_111_00.jpg | 30.69dB
25-05-22 19:41:11.264 : -134--> roundabout_111_01.jpg | 32.26dB
25-05-22 19:41:11.331 : -135--> roundabout_111_10.jpg | 30.52dB
25-05-22 19:41:11.402 : -136--> roundabout_111_11.jpg | 30.97dB
25-05-22 19:41:11.485 : -137--> runway_111_00.jpg | 36.75dB
25-05-22 19:41:11.548 : -138--> runway_111_01.jpg | 36.03dB
25-05-22 19:41:11.616 : -139--> runway_111_10.jpg | 36.67dB
25-05-22 19:41:11.681 : -140--> runway_111_11.jpg | 37.71dB
25-05-22 19:41:11.767 : -141--> sea_ice_111_00.jpg | 33.80dB
25-05-22 19:41:11.838 : -142--> sea_ice_111_01.jpg | 34.81dB
25-05-22 19:41:11.923 : -143--> sea_ice_111_10.jpg | 33.87dB
25-05-22 19:41:11.991 : -144--> sea_ice_111_11.jpg | 34.88dB
25-05-22 19:41:12.067 : -145--> ship_111_00.jpg | 38.84dB
25-05-22 19:41:12.130 : -146--> ship_111_01.jpg | 34.71dB
25-05-22 19:41:12.201 : -147--> ship_111_10.jpg | 42.83dB
25-05-22 19:41:12.271 : -148--> ship_111_11.jpg | 40.24dB
25-05-22 19:41:12.344 : -149--> snowberg_111_00.jpg | 34.32dB
25-05-22 19:41:12.413 : -150--> snowberg_111_01.jpg | 32.99dB
25-05-22 19:41:12.487 : -151--> snowberg_111_10.jpg | 32.24dB
25-05-22 19:41:12.558 : -152--> snowberg_111_11.jpg | 32.16dB
25-05-22 19:41:12.630 : -153--> sparse_residential_111_00.jpg | 30.62dB
25-05-22 19:41:12.706 : -154--> sparse_residential_111_01.jpg | 30.81dB
25-05-22 19:41:12.769 : -155--> sparse_residential_111_10.jpg | 29.93dB
25-05-22 19:41:12.850 : -156--> sparse_residential_111_11.jpg | 30.12dB
25-05-22 19:41:12.921 : -157--> stadium_111_00.jpg | 30.50dB
25-05-22 19:41:12.999 : -158--> stadium_111_01.jpg | 30.28dB
25-05-22 19:41:13.064 : -159--> stadium_111_10.jpg | 31.54dB
25-05-22 19:41:13.137 : -160--> stadium_111_11.jpg | 30.34dB
25-05-22 19:41:13.214 : -161--> storage_tank_111_00.jpg | 31.94dB
25-05-22 19:41:13.289 : -162--> storage_tank_111_01.jpg | 32.18dB
25-05-22 19:41:13.358 : -163--> storage_tank_111_10.jpg | 30.91dB
25-05-22 19:41:13.439 : -164--> storage_tank_111_11.jpg | 31.43dB
25-05-22 19:41:13.505 : -165--> tennis_court_111_00.jpg | 32.31dB
25-05-22 19:41:13.572 : -166--> tennis_court_111_01.jpg | 31.71dB
25-05-22 19:41:13.637 : -167--> tennis_court_111_10.jpg | 32.16dB
25-05-22 19:41:13.716 : -168--> tennis_court_111_11.jpg | 29.81dB
25-05-22 19:41:13.799 : -169--> terrace_111_00.jpg | 32.38dB
25-05-22 19:41:13.866 : -170--> terrace_111_01.jpg | 33.47dB
25-05-22 19:41:13.934 : -171--> terrace_111_10.jpg | 32.36dB
25-05-22 19:41:14.001 : -172--> terrace_111_11.jpg | 32.44dB
25-05-22 19:41:14.076 : -173--> thermal_power_station_111_00.jpg | 30.24dB
25-05-22 19:41:14.138 : -174--> thermal_power_station_111_01.jpg | 31.75dB
25-05-22 19:41:14.203 : -175--> thermal_power_station_111_10.jpg | 30.05dB
25-05-22 19:41:14.269 : -176--> thermal_power_station_111_11.jpg | 30.65dB
25-05-22 19:41:14.344 : -177--> wetland_111_00.jpg | 31.45dB
25-05-22 19:41:14.405 : -178--> wetland_111_01.jpg | 31.51dB
25-05-22 19:41:14.476 : -179--> wetland_111_10.jpg | 31.74dB
25-05-22 19:41:14.537 : -180--> wetland_111_11.jpg | 31.08dB
25-05-22 19:41:14.547 : <epoch:  5, iter: 160,000, Average PSNR : 32.33dB

25-05-22 20:12:53.089 : <epoch:  5, iter: 170,000, lr:1.250e-05> G_loss: 3.396e-05 
25-05-22 20:12:53.090 : Saving the model.
25-05-22 20:12:53.827 : ---1--> airplane_111_00.jpg | 30.74dB
25-05-22 20:12:53.888 : ---2--> airplane_111_01.jpg | 35.60dB
25-05-22 20:12:53.970 : ---3--> airplane_111_10.jpg | 33.12dB
25-05-22 20:12:54.039 : ---4--> airplane_111_11.jpg | 33.15dB
25-05-22 20:12:54.099 : ---5--> airport_111_00.jpg | 34.66dB
25-05-22 20:12:54.169 : ---6--> airport_111_01.jpg | 32.57dB
25-05-22 20:12:54.251 : ---7--> airport_111_10.jpg | 32.11dB
25-05-22 20:12:54.315 : ---8--> airport_111_11.jpg | 33.02dB
25-05-22 20:12:54.381 : ---9--> baseball_diamond_111_00.jpg | 32.82dB
25-05-22 20:12:54.445 : --10--> baseball_diamond_111_01.jpg | 34.46dB
25-05-22 20:12:54.510 : --11--> baseball_diamond_111_10.jpg | 32.73dB
25-05-22 20:12:54.577 : --12--> baseball_diamond_111_11.jpg | 35.52dB
25-05-22 20:12:54.648 : --13--> basketball_court_111_00.jpg | 30.69dB
25-05-22 20:12:54.716 : --14--> basketball_court_111_01.jpg | 30.27dB
25-05-22 20:12:54.785 : --15--> basketball_court_111_10.jpg | 33.69dB
25-05-22 20:12:54.845 : --16--> basketball_court_111_11.jpg | 31.73dB
25-05-22 20:12:54.913 : --17--> beach_111_00.jpg | 28.87dB
25-05-22 20:12:54.980 : --18--> beach_111_01.jpg | 31.99dB
25-05-22 20:12:55.067 : --19--> beach_111_10.jpg | 29.94dB
25-05-22 20:12:55.145 : --20--> beach_111_11.jpg | 34.59dB
25-05-22 20:12:55.218 : --21--> bridge_111_00.jpg | 40.96dB
25-05-22 20:12:55.293 : --22--> bridge_111_01.jpg | 34.50dB
25-05-22 20:12:55.364 : --23--> bridge_111_10.jpg | 33.44dB
25-05-22 20:12:55.436 : --24--> bridge_111_11.jpg | 37.01dB
25-05-22 20:12:55.509 : --25--> chaparral_111_00.jpg | 30.54dB
25-05-22 20:12:55.580 : --26--> chaparral_111_01.jpg | 30.76dB
25-05-22 20:12:55.665 : --27--> chaparral_111_10.jpg | 31.03dB
25-05-22 20:12:55.732 : --28--> chaparral_111_11.jpg | 28.89dB
25-05-22 20:12:55.812 : --29--> church_111_00.jpg | 31.89dB
25-05-22 20:12:55.887 : --30--> church_111_01.jpg | 30.87dB
25-05-22 20:12:55.969 : --31--> church_111_10.jpg | 34.51dB
25-05-22 20:12:56.032 : --32--> church_111_11.jpg | 30.73dB
25-05-22 20:12:56.102 : --33--> circular_farmland_111_00.jpg | 33.01dB
25-05-22 20:12:56.173 : --34--> circular_farmland_111_01.jpg | 34.03dB
25-05-22 20:12:56.246 : --35--> circular_farmland_111_10.jpg | 34.22dB
25-05-22 20:12:56.329 : --36--> circular_farmland_111_11.jpg | 34.23dB
25-05-22 20:12:56.394 : --37--> cloud_111_00.jpg | 40.78dB
25-05-22 20:12:56.474 : --38--> cloud_111_01.jpg | 36.74dB
25-05-22 20:12:56.560 : --39--> cloud_111_10.jpg | 36.37dB
25-05-22 20:12:56.640 : --40--> cloud_111_11.jpg | 36.91dB
25-05-22 20:12:56.733 : --41--> commercial_area_111_00.jpg | 33.36dB
25-05-22 20:12:56.821 : --42--> commercial_area_111_01.jpg | 32.49dB
25-05-22 20:12:56.890 : --43--> commercial_area_111_10.jpg | 33.21dB
25-05-22 20:12:56.964 : --44--> commercial_area_111_11.jpg | 33.10dB
25-05-22 20:12:57.032 : --45--> dense_residential_111_00.jpg | 30.46dB
25-05-22 20:12:57.111 : --46--> dense_residential_111_01.jpg | 29.48dB
25-05-22 20:12:57.187 : --47--> dense_residential_111_10.jpg | 29.95dB
25-05-22 20:12:57.259 : --48--> dense_residential_111_11.jpg | 29.77dB
25-05-22 20:12:57.325 : --49--> desert_111_00.jpg | 36.72dB
25-05-22 20:12:57.397 : --50--> desert_111_01.jpg | 36.57dB
25-05-22 20:12:57.473 : --51--> desert_111_10.jpg | 36.82dB
25-05-22 20:12:57.543 : --52--> desert_111_11.jpg | 36.87dB
25-05-22 20:12:57.608 : --53--> forest_111_00.jpg | 33.06dB
25-05-22 20:12:57.687 : --54--> forest_111_01.jpg | 32.18dB
25-05-22 20:12:57.761 : --55--> forest_111_10.jpg | 31.84dB
25-05-22 20:12:57.851 : --56--> forest_111_11.jpg | 32.80dB
25-05-22 20:12:57.921 : --57--> freeway_111_00.jpg | 33.96dB
25-05-22 20:12:57.992 : --58--> freeway_111_01.jpg | 35.31dB
25-05-22 20:12:58.058 : --59--> freeway_111_10.jpg | 35.04dB
25-05-22 20:12:58.123 : --60--> freeway_111_11.jpg | 34.93dB
25-05-22 20:12:58.199 : --61--> golf_course_111_00.jpg | 32.88dB
25-05-22 20:12:58.279 : --62--> golf_course_111_01.jpg | 32.27dB
25-05-22 20:12:58.353 : --63--> golf_course_111_10.jpg | 33.67dB
25-05-22 20:12:58.425 : --64--> golf_course_111_11.jpg | 34.17dB
25-05-22 20:12:58.507 : --65--> ground_track_field_111_00.jpg | 33.63dB
25-05-22 20:12:58.579 : --66--> ground_track_field_111_01.jpg | 29.53dB
25-05-22 20:12:58.648 : --67--> ground_track_field_111_10.jpg | 30.96dB
25-05-22 20:12:58.723 : --68--> ground_track_field_111_11.jpg | 30.11dB
25-05-22 20:12:58.795 : --69--> harbor_111_00.jpg | 32.96dB
25-05-22 20:12:58.862 : --70--> harbor_111_01.jpg | 31.36dB
25-05-22 20:12:58.933 : --71--> harbor_111_10.jpg | 30.95dB
25-05-22 20:12:59.005 : --72--> harbor_111_11.jpg | 32.59dB
25-05-22 20:12:59.084 : --73--> industrial_area_111_00.jpg | 31.80dB
25-05-22 20:12:59.169 : --74--> industrial_area_111_01.jpg | 31.98dB
25-05-22 20:12:59.284 : --75--> industrial_area_111_10.jpg | 32.20dB
25-05-22 20:12:59.358 : --76--> industrial_area_111_11.jpg | 31.59dB
25-05-22 20:12:59.419 : --77--> intersection_111_00.jpg | 30.86dB
25-05-22 20:12:59.501 : --78--> intersection_111_01.jpg | 30.96dB
25-05-22 20:12:59.567 : --79--> intersection_111_10.jpg | 30.68dB
25-05-22 20:12:59.635 : --80--> intersection_111_11.jpg | 30.47dB
25-05-22 20:12:59.711 : --81--> island_111_00.jpg | 31.57dB
25-05-22 20:12:59.778 : --82--> island_111_01.jpg | 33.88dB
25-05-22 20:12:59.839 : --83--> island_111_10.jpg | 32.70dB
25-05-22 20:12:59.919 : --84--> island_111_11.jpg | 32.12dB
25-05-22 20:12:59.993 : --85--> lake_111_00.jpg | 32.56dB
25-05-22 20:13:00.071 : --86--> lake_111_01.jpg | 32.39dB
25-05-22 20:13:00.143 : --87--> lake_111_10.jpg | 31.72dB
25-05-22 20:13:00.218 : --88--> lake_111_11.jpg | 31.09dB
25-05-22 20:13:00.291 : --89--> meadow_111_00.jpg | 30.15dB
25-05-22 20:13:00.371 : --90--> meadow_111_01.jpg | 30.24dB
25-05-22 20:13:00.441 : --91--> meadow_111_10.jpg | 30.27dB
25-05-22 20:13:00.505 : --92--> meadow_111_11.jpg | 30.42dB
25-05-22 20:13:00.572 : --93--> medium_residential_111_00.jpg | 28.95dB
25-05-22 20:13:00.648 : --94--> medium_residential_111_01.jpg | 28.41dB
25-05-22 20:13:00.724 : --95--> medium_residential_111_10.jpg | 28.78dB
25-05-22 20:13:00.788 : --96--> medium_residential_111_11.jpg | 29.30dB
25-05-22 20:13:00.872 : --97--> mobile_home_park_111_00.jpg | 31.12dB
25-05-22 20:13:00.947 : --98--> mobile_home_park_111_01.jpg | 31.64dB
25-05-22 20:13:01.029 : --99--> mobile_home_park_111_10.jpg | 31.91dB
25-05-22 20:13:01.107 : -100--> mobile_home_park_111_11.jpg | 31.95dB
25-05-22 20:13:01.176 : -101--> mountain_111_00.jpg | 28.96dB
25-05-22 20:13:01.249 : -102--> mountain_111_01.jpg | 29.67dB
25-05-22 20:13:01.315 : -103--> mountain_111_10.jpg | 29.44dB
25-05-22 20:13:01.402 : -104--> mountain_111_11.jpg | 29.76dB
25-05-22 20:13:01.470 : -105--> overpass_111_00.jpg | 30.46dB
25-05-22 20:13:01.553 : -106--> overpass_111_01.jpg | 30.15dB
25-05-22 20:13:01.617 : -107--> overpass_111_10.jpg | 30.87dB
25-05-22 20:13:01.680 : -108--> overpass_111_11.jpg | 31.44dB
25-05-22 20:13:01.755 : -109--> palace_111_00.jpg | 30.17dB
25-05-22 20:13:01.822 : -110--> palace_111_01.jpg | 30.04dB
25-05-22 20:13:01.918 : -111--> palace_111_10.jpg | 31.14dB
25-05-22 20:13:01.996 : -112--> palace_111_11.jpg | 29.52dB
25-05-22 20:13:02.065 : -113--> parking_lot_111_00.jpg | 29.51dB
25-05-22 20:13:02.138 : -114--> parking_lot_111_01.jpg | 29.82dB
25-05-22 20:13:02.220 : -115--> parking_lot_111_10.jpg | 31.38dB
25-05-22 20:13:02.287 : -116--> parking_lot_111_11.jpg | 30.20dB
25-05-22 20:13:02.359 : -117--> railway_111_00.jpg | 30.31dB
25-05-22 20:13:02.437 : -118--> railway_111_01.jpg | 29.93dB
25-05-22 20:13:02.505 : -119--> railway_111_10.jpg | 32.69dB
25-05-22 20:13:02.590 : -120--> railway_111_11.jpg | 29.35dB
25-05-22 20:13:02.666 : -121--> railway_station_111_00.jpg | 31.08dB
25-05-22 20:13:02.730 : -122--> railway_station_111_01.jpg | 31.54dB
25-05-22 20:13:02.797 : -123--> railway_station_111_10.jpg | 31.19dB
25-05-22 20:13:02.861 : -124--> railway_station_111_11.jpg | 31.75dB
25-05-22 20:13:02.925 : -125--> rectangular_farmland_111_00.jpg | 33.57dB
25-05-22 20:13:02.995 : -126--> rectangular_farmland_111_01.jpg | 32.06dB
25-05-22 20:13:03.064 : -127--> rectangular_farmland_111_10.jpg | 33.93dB
25-05-22 20:13:03.137 : -128--> rectangular_farmland_111_11.jpg | 34.26dB
25-05-22 20:13:03.214 : -129--> river_111_00.jpg | 30.33dB
25-05-22 20:13:03.286 : -130--> river_111_01.jpg | 30.08dB
25-05-22 20:13:03.365 : -131--> river_111_10.jpg | 29.70dB
25-05-22 20:13:03.434 : -132--> river_111_11.jpg | 31.43dB
25-05-22 20:13:03.506 : -133--> roundabout_111_00.jpg | 30.71dB
25-05-22 20:13:03.589 : -134--> roundabout_111_01.jpg | 32.27dB
25-05-22 20:13:03.663 : -135--> roundabout_111_10.jpg | 30.53dB
25-05-22 20:13:03.734 : -136--> roundabout_111_11.jpg | 31.00dB
25-05-22 20:13:03.827 : -137--> runway_111_00.jpg | 36.65dB
25-05-22 20:13:03.891 : -138--> runway_111_01.jpg | 36.01dB
25-05-22 20:13:03.966 : -139--> runway_111_10.jpg | 36.65dB
25-05-22 20:13:04.028 : -140--> runway_111_11.jpg | 37.69dB
25-05-22 20:13:04.100 : -141--> sea_ice_111_00.jpg | 33.78dB
25-05-22 20:13:04.179 : -142--> sea_ice_111_01.jpg | 34.75dB
25-05-22 20:13:04.253 : -143--> sea_ice_111_10.jpg | 33.86dB
25-05-22 20:13:04.321 : -144--> sea_ice_111_11.jpg | 34.87dB
25-05-22 20:13:04.389 : -145--> ship_111_00.jpg | 38.81dB
25-05-22 20:13:04.463 : -146--> ship_111_01.jpg | 34.68dB
25-05-22 20:13:04.545 : -147--> ship_111_10.jpg | 42.80dB
25-05-22 20:13:04.613 : -148--> ship_111_11.jpg | 40.18dB
25-05-22 20:13:04.688 : -149--> snowberg_111_00.jpg | 34.23dB
25-05-22 20:13:04.759 : -150--> snowberg_111_01.jpg | 32.95dB
25-05-22 20:13:04.825 : -151--> snowberg_111_10.jpg | 32.21dB
25-05-22 20:13:04.902 : -152--> snowberg_111_11.jpg | 32.12dB
25-05-22 20:13:04.973 : -153--> sparse_residential_111_00.jpg | 30.62dB
25-05-22 20:13:05.040 : -154--> sparse_residential_111_01.jpg | 30.80dB
25-05-22 20:13:05.116 : -155--> sparse_residential_111_10.jpg | 29.92dB
25-05-22 20:13:05.184 : -156--> sparse_residential_111_11.jpg | 30.12dB
25-05-22 20:13:05.266 : -157--> stadium_111_00.jpg | 30.51dB
25-05-22 20:13:05.331 : -158--> stadium_111_01.jpg | 30.27dB
25-05-22 20:13:05.400 : -159--> stadium_111_10.jpg | 31.52dB
25-05-22 20:13:05.488 : -160--> stadium_111_11.jpg | 30.33dB
25-05-22 20:13:05.555 : -161--> storage_tank_111_00.jpg | 31.93dB
25-05-22 20:13:05.624 : -162--> storage_tank_111_01.jpg | 32.16dB
25-05-22 20:13:05.700 : -163--> storage_tank_111_10.jpg | 30.90dB
25-05-22 20:13:05.777 : -164--> storage_tank_111_11.jpg | 31.41dB
25-05-22 20:13:05.847 : -165--> tennis_court_111_00.jpg | 32.31dB
25-05-22 20:13:05.921 : -166--> tennis_court_111_01.jpg | 31.72dB
25-05-22 20:13:05.984 : -167--> tennis_court_111_10.jpg | 32.16dB
25-05-22 20:13:06.057 : -168--> tennis_court_111_11.jpg | 29.80dB
25-05-22 20:13:06.125 : -169--> terrace_111_00.jpg | 32.24dB
25-05-22 20:13:06.190 : -170--> terrace_111_01.jpg | 33.41dB
25-05-22 20:13:06.262 : -171--> terrace_111_10.jpg | 32.32dB
25-05-22 20:13:06.345 : -172--> terrace_111_11.jpg | 32.40dB
25-05-22 20:13:06.416 : -173--> thermal_power_station_111_00.jpg | 30.21dB
25-05-22 20:13:06.487 : -174--> thermal_power_station_111_01.jpg | 31.71dB
25-05-22 20:13:06.554 : -175--> thermal_power_station_111_10.jpg | 30.04dB
25-05-22 20:13:06.635 : -176--> thermal_power_station_111_11.jpg | 30.64dB
25-05-22 20:13:06.709 : -177--> wetland_111_00.jpg | 31.45dB
25-05-22 20:13:06.785 : -178--> wetland_111_01.jpg | 31.51dB
25-05-22 20:13:06.846 : -179--> wetland_111_10.jpg | 31.74dB
25-05-22 20:13:06.932 : -180--> wetland_111_11.jpg | 31.08dB
25-05-22 20:13:06.941 : <epoch:  5, iter: 170,000, Average PSNR : 32.31dB

